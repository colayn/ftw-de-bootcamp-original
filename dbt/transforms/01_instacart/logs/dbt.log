[0m13:33:11.496838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e1a81040f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e1a7dcf6610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e1a7dcf65e0>]}


============================== 13:33:11.549650 | a4c7733f-64d5-425d-b801-a80e231a97c7 ==============================
[0m13:33:11.549650 [info ] [MainThread]: Running with dbt=1.8.9
[0m13:33:11.550839 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'printer_width': '80', 'target_path': 'None', 'empty': 'False', 'partial_parse': 'True', 'log_cache_events': 'False', 'invocation_command': 'dbt build --profiles-dir .', 'no_print': 'None', 'static_parser': 'True', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'log_path': '/workdir/transforms/01_mpg/logs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_colors': 'True', 'cache_selected_only': 'False', 'version_check': 'True', 'log_format': 'default', 'introspect': 'True', 'write_json': 'True', 'profiles_dir': '.', 'debug': 'False', 'fail_fast': 'False', 'quiet': 'False'}
[0m13:33:11.555524 [error] [MainThread]: Encountered an error:
Runtime Error
  Could not find profile named 'clickhouse_ftw'
[0m13:33:11.558261 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 0.21043192, "process_in_blocks": "69272", "process_kernel_time": 0.616665, "process_mem_max_rss": "90116", "process_out_blocks": "6600", "process_user_time": 3.24493}
[0m13:33:11.559311 [debug] [MainThread]: Command `dbt build` failed at 13:33:11.559050 after 0.21 seconds
[0m13:33:11.559985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e1a81040f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e1a7e1386d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e1a7dda6b50>]}
[0m13:33:11.560602 [debug] [MainThread]: Flushing usage events
[0m13:38:53.969457 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd827a73430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd824854610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd824854760>]}


============================== 13:38:54.030621 | 108503a8-91fc-4f48-bfaa-d65aa9d29597 ==============================
[0m13:38:54.030621 [info ] [MainThread]: Running with dbt=1.8.9
[0m13:38:54.031812 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'target_path': 'None', 'log_path': '/workdir/transforms/01_mpg/logs', 'profiles_dir': '.', 'no_print': 'None', 'log_cache_events': 'False', 'log_format': 'default', 'version_check': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'empty': 'False', 'invocation_command': 'dbt build --profiles-dir .', 'partial_parse': 'True', 'debug': 'False', 'quiet': 'False', 'write_json': 'True', 'printer_width': '80', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'static_parser': 'True'}
[0m13:38:54.036700 [error] [MainThread]: Encountered an error:
Runtime Error
  The profile 'clickhouse_ftw' does not have a target named 'local'. The valid target names for this profile are:
   - default
[0m13:38:54.038555 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 0.2641497, "process_in_blocks": "0", "process_kernel_time": 0.419579, "process_mem_max_rss": "90508", "process_out_blocks": "6592", "process_user_time": 3.079913}
[0m13:38:54.039637 [debug] [MainThread]: Command `dbt build` failed at 13:38:54.039394 after 0.27 seconds
[0m13:38:54.040302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd827a73430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd82492c9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd82492cc40>]}
[0m13:38:54.040923 [debug] [MainThread]: Flushing usage events
[0m13:39:47.944821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x747853433310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x747850094ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x747850094970>]}


============================== 13:39:47.953921 | b2275fa3-9c95-41b4-abd3-54a53878eea5 ==============================
[0m13:39:47.953921 [info ] [MainThread]: Running with dbt=1.8.9
[0m13:39:47.955046 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'version_check': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'False', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'partial_parse': 'True', 'log_path': '/workdir/transforms/01_mpg/logs', 'debug': 'False', 'write_json': 'True', 'invocation_command': 'dbt build --profiles-dir .', 'use_colors': 'True', 'target_path': 'None', 'profiles_dir': '.', 'printer_width': '80', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_format': 'default', 'log_cache_events': 'False', 'fail_fast': 'False', 'introspect': 'True'}
[0m13:39:47.959729 [error] [MainThread]: Encountered an error:
Runtime Error
  The profile 'clickhouse_ftw' does not have a target named 'local'. The valid target names for this profile are:
   - default
[0m13:39:47.961173 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 0.20792367, "process_in_blocks": "0", "process_kernel_time": 0.469234, "process_mem_max_rss": "90452", "process_out_blocks": "6592", "process_user_time": 3.105227}
[0m13:39:47.962177 [debug] [MainThread]: Command `dbt build` failed at 13:39:47.961961 after 0.21 seconds
[0m13:39:47.962828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x747853433310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7478500f7100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7478500f73a0>]}
[0m13:39:47.963404 [debug] [MainThread]: Flushing usage events
[0m13:40:52.203528 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70a4a14e2310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70a49e1564f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70a49e156640>]}


============================== 13:40:52.212859 | 0be9a68d-fe76-4c4c-af1b-c30303b9ad1a ==============================
[0m13:40:52.212859 [info ] [MainThread]: Running with dbt=1.8.9
[0m13:40:52.214033 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt build --profiles-dir .', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'debug': 'False', 'use_colors': 'True', 'fail_fast': 'False', 'warn_error': 'None', 'version_check': 'True', 'indirect_selection': 'eager', 'log_path': '/workdir/transforms/01_mpg/logs', 'log_cache_events': 'False', 'static_parser': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'printer_width': '80', 'no_print': 'None', 'write_json': 'True', 'profiles_dir': '.', 'quiet': 'False', 'empty': 'False', 'use_experimental_parser': 'False', 'target_path': 'None'}
[0m13:40:52.218674 [error] [MainThread]: Encountered an error:
Runtime Error
  The profile 'clickhouse_ftw' does not have a target named 'local'. The valid target names for this profile are:
   - default
[0m13:40:52.220206 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 0.20925443, "process_in_blocks": "0", "process_kernel_time": 0.455506, "process_mem_max_rss": "90652", "process_out_blocks": "6600", "process_user_time": 3.069458}
[0m13:40:52.221236 [debug] [MainThread]: Command `dbt build` failed at 13:40:52.221028 after 0.21 seconds
[0m13:40:52.221937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70a4a14e2310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70a4a34d14c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70a49e20a6a0>]}
[0m13:40:52.222522 [debug] [MainThread]: Flushing usage events
[0m13:49:05.081504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x782879785f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78287642aa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78287642a940>]}


============================== 13:49:05.090773 | 7075433c-ca52-4abc-a332-6ad5e3f145b5 ==============================
[0m13:49:05.090773 [info ] [MainThread]: Running with dbt=1.8.9
[0m13:49:05.091934 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'log_path': '/workdir/transforms/01_mpg/logs', 'debug': 'False', 'profiles_dir': '.', 'printer_width': '80', 'invocation_command': 'dbt build --profiles-dir .', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'empty': 'False', 'no_print': 'None', 'warn_error': 'None', 'log_cache_events': 'False', 'static_parser': 'True', 'write_json': 'True', 'log_format': 'default', 'indirect_selection': 'eager', 'partial_parse': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'quiet': 'False', 'fail_fast': 'False', 'use_colors': 'True'}
[0m13:49:05.096596 [error] [MainThread]: Encountered an error:
Runtime Error
  The profile 'clickhouse_ftw' does not have a target named 'local'. The valid target names for this profile are:
   - default
[0m13:49:05.098164 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 0.20678261, "process_in_blocks": "0", "process_kernel_time": 0.436945, "process_mem_max_rss": "90400", "process_out_blocks": "6592", "process_user_time": 3.07358}
[0m13:49:05.099085 [debug] [MainThread]: Command `dbt build` failed at 13:49:05.098869 after 0.21 seconds
[0m13:49:05.099742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x782879785f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7828776e2af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78287688c3d0>]}
[0m13:49:05.100333 [debug] [MainThread]: Flushing usage events
[0m13:56:21.648058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7935b6bbe310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7935b381eb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7935b381e9d0>]}


============================== 13:56:21.657287 | 25ad8516-ac49-40ca-9986-ef3bdd6f6048 ==============================
[0m13:56:21.657287 [info ] [MainThread]: Running with dbt=1.8.9
[0m13:56:21.658414 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'fail_fast': 'False', 'empty': 'False', 'no_print': 'None', 'profiles_dir': '.', 'partial_parse': 'True', 'log_cache_events': 'False', 'static_parser': 'True', 'indirect_selection': 'eager', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_colors': 'True', 'invocation_command': 'dbt build --profiles-dir .', 'printer_width': '80', 'quiet': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'use_experimental_parser': 'False', 'introspect': 'True', 'target_path': 'None', 'debug': 'False', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'log_format': 'default'}
[0m13:56:21.663653 [error] [MainThread]: Encountered an error:
Runtime Error
  The profile 'clickhouse_ftw' does not have a target named 'local'. The valid target names for this profile are:
   - default
[0m13:56:21.665195 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 0.20876543, "process_in_blocks": "0", "process_kernel_time": 0.412855, "process_mem_max_rss": "90576", "process_out_blocks": "6600", "process_user_time": 3.105914}
[0m13:56:21.665988 [debug] [MainThread]: Command `dbt build` failed at 13:56:21.665779 after 0.21 seconds
[0m13:56:21.666623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7935b6bbe310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7935b8f79070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7935b6e43a00>]}
[0m13:56:21.667228 [debug] [MainThread]: Flushing usage events
[0m13:59:17.978509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5fdc249310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5fd8ea9490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5fd8ea95e0>]}


============================== 13:59:17.987710 | 7e66556e-9b99-4d45-a9d1-6acb4c970857 ==============================
[0m13:59:17.987710 [info ] [MainThread]: Running with dbt=1.8.9
[0m13:59:17.988967 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'fail_fast': 'False', 'quiet': 'False', 'debug': 'False', 'static_parser': 'True', 'target_path': 'None', 'printer_width': '80', 'log_path': '/workdir/transforms/01_mpg/logs', 'profiles_dir': '.', 'indirect_selection': 'eager', 'use_colors': 'True', 'invocation_command': 'dbt build --profiles-dir .', 'introspect': 'True', 'no_print': 'None', 'log_format': 'default', 'write_json': 'True', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'empty': 'False', 'warn_error': 'None'}
[0m13:59:17.994559 [error] [MainThread]: Encountered an error:
Runtime Error
  The profile 'clickhouse_ftw' does not have a target named 'local'. The valid target names for this profile are:
   - default
[0m13:59:17.996180 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 0.21011144, "process_in_blocks": "0", "process_kernel_time": 0.436567, "process_mem_max_rss": "90140", "process_out_blocks": "6592", "process_user_time": 3.019341}
[0m13:59:17.996984 [debug] [MainThread]: Command `dbt build` failed at 13:59:17.996773 after 0.21 seconds
[0m13:59:17.997624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5fdc249310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5fd92eb730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5fd8f5d880>]}
[0m13:59:17.998233 [debug] [MainThread]: Flushing usage events
[0m14:13:18.746364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7afd87f02310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7afd84b76460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7afd84b765b0>]}


============================== 14:13:18.805966 | bdd51c1e-c348-4ca7-9eef-32ef1719bf9e ==============================
[0m14:13:18.805966 [info ] [MainThread]: Running with dbt=1.8.9
[0m14:13:18.807076 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt build --profiles-dir .', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True', 'no_print': 'None', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'static_parser': 'True', 'profiles_dir': '.', 'target_path': 'None', 'log_path': '/workdir/transforms/01_mpg/logs', 'write_json': 'True', 'debug': 'False', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'warn_error': 'None', 'introspect': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'empty': 'False', 'quiet': 'False', 'printer_width': '80', 'fail_fast': 'False'}
[0m14:13:19.351234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bdd51c1e-c348-4ca7-9eef-32ef1719bf9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7afd84a55520>]}
[0m14:13:19.538233 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bdd51c1e-c348-4ca7-9eef-32ef1719bf9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7afd8813a7c0>]}
[0m14:13:19.539947 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m14:13:20.009465 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m14:13:20.010911 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:13:20.011586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'bdd51c1e-c348-4ca7-9eef-32ef1719bf9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7afd848541c0>]}
[0m14:13:24.546097 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.ex_01_mpg.cylinders_by_origin' (models/cylinders_by_origin.sql) depends on a source named 'default.auto_mpg___mpg_raw' which was not found
[0m14:13:24.598087 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 5.9948387, "process_in_blocks": "2680", "process_kernel_time": 0.470665, "process_mem_max_rss": "99680", "process_out_blocks": "6616", "process_user_time": 5.79588}
[0m14:13:24.598996 [debug] [MainThread]: Command `dbt build` failed at 14:13:24.598774 after 6.00 seconds
[0m14:13:24.599687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7afd87f02310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7afd83fa9760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7afd83fa92e0>]}
[0m14:13:24.600269 [debug] [MainThread]: Flushing usage events
[0m14:13:51.722950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72893fee7310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72893cb51b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72893cb51a30>]}


============================== 14:13:51.733282 | 3e678fd1-fad3-480c-ba55-9bb148e92a32 ==============================
[0m14:13:51.733282 [info ] [MainThread]: Running with dbt=1.8.9
[0m14:13:51.734510 [debug] [MainThread]: running dbt with arguments {'log_cache_events': 'False', 'indirect_selection': 'eager', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'quiet': 'False', 'empty': 'False', 'use_colors': 'True', 'warn_error': 'None', 'log_path': '/workdir/transforms/01_mpg/logs', 'write_json': 'True', 'no_print': 'None', 'static_parser': 'True', 'version_check': 'True', 'profiles_dir': '.', 'invocation_command': 'dbt build --profiles-dir .', 'fail_fast': 'False', 'target_path': 'None', 'debug': 'False', 'cache_selected_only': 'False', 'introspect': 'True', 'use_experimental_parser': 'False', 'log_format': 'default'}
[0m14:13:52.342249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3e678fd1-fad3-480c-ba55-9bb148e92a32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72893e62deb0>]}
[0m14:13:52.534156 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3e678fd1-fad3-480c-ba55-9bb148e92a32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72893ca1ee50>]}
[0m14:13:52.535416 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m14:13:52.945833 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m14:13:52.947163 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:13:52.947868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3e678fd1-fad3-480c-ba55-9bb148e92a32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72893c808b50>]}
[0m14:13:56.903662 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.ex_01_mpg.cylinders_by_origin' (models/cylinders_by_origin.sql) depends on a source named 'raw.auto_mpg___mpg_raw' which was not found
[0m14:13:56.905347 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 5.3724074, "process_in_blocks": "0", "process_kernel_time": 0.448038, "process_mem_max_rss": "100140", "process_out_blocks": "6616", "process_user_time": 5.530069}
[0m14:13:56.906177 [debug] [MainThread]: Command `dbt build` failed at 14:13:56.905963 after 5.37 seconds
[0m14:13:56.906851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72893fee7310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72893c1d1b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72893bf25d90>]}
[0m14:13:56.907451 [debug] [MainThread]: Flushing usage events
[0m14:17:04.530070 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c4990ed3310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c498db2faf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c498db2f9a0>]}


============================== 14:17:04.539161 | a145353a-4abd-4695-bc95-0535de2e2efa ==============================
[0m14:17:04.539161 [info ] [MainThread]: Running with dbt=1.8.9
[0m14:17:04.540200 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'printer_width': '80', 'warn_error': 'None', 'debug': 'False', 'quiet': 'False', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'profiles_dir': '.', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'log_format': 'default', 'fail_fast': 'False', 'no_print': 'None', 'static_parser': 'True', 'log_path': '/workdir/transforms/01_mpg/logs', 'log_cache_events': 'False', 'empty': 'False', 'use_colors': 'True', 'target_path': 'None', 'indirect_selection': 'eager', 'partial_parse': 'True', 'version_check': 'True', 'invocation_command': 'dbt build --profiles-dir . --target local'}
[0m14:17:05.115387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a145353a-4abd-4695-bc95-0535de2e2efa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c4990478fd0>]}
[0m14:17:05.257311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a145353a-4abd-4695-bc95-0535de2e2efa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c498dafb070>]}
[0m14:17:05.258592 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m14:17:05.727025 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m14:17:05.728376 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:17:05.729112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a145353a-4abd-4695-bc95-0535de2e2efa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c498d7ca4f0>]}
[0m14:17:10.357670 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a145353a-4abd-4695-bc95-0535de2e2efa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c498d5c1ac0>]}
[0m14:17:10.781029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a145353a-4abd-4695-bc95-0535de2e2efa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c498d9ae8b0>]}
[0m14:17:10.782023 [info ] [MainThread]: Found 1 model, 1 source, 468 macros
[0m14:17:10.784903 [info ] [MainThread]: 
[0m14:17:10.785888 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m14:17:10.787625 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m14:17:10.831452 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:17:11.302961 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m14:17:11.307691 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:17:11.346951 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m14:17:11.361259 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m14:17:11.369081 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m14:17:11.371959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a145353a-4abd-4695-bc95-0535de2e2efa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c498d4cc550>]}
[0m14:17:11.412454 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m14:17:11.413788 [info ] [MainThread]: 
[0m14:17:11.441382 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m14:17:11.442501 [info ] [Thread-1  ]: 1 of 1 START sql view model `clean`.`cylinders_by_origin` ...................... [RUN]
[0m14:17:11.443628 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m14:17:11.444409 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m14:17:11.459529 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m14:17:11.460683 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m14:17:11.624460 [debug] [Thread-1  ]: Creating new relation cylinders_by_origin
[0m14:17:11.645223 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m14:17:11.747522 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m14:17:11.748879 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `clean`.`cylinders_by_origin` 
  
    
    
  as (
    SELECT 
  origin,
  avg(cylinders) AS avg_cyl,
  count() AS n
FROM `raw`.`auto_mpg___mpg_raw`  # Now matches
GROUP BY origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m14:17:11.753515 [debug] [Thread-1  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `clean`.`cylinders_by_origin` 
  
    
    
  as (
    SELECT 
  origin,
  avg(cylinders) AS avg_cyl,
  count() AS n
FROM `raw`.`auto_mpg___mpg_raw`  # Now matches
GROUP BY origin
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m14:17:11.761512 [debug] [Thread-1  ]: Database Error in model cylinders_by_origin (models/cylinders_by_origin.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 60
   Code: 60. DB::Exception: Table raw.auto_mpg___mpg_raw does not exist. (UNKNOWN_TABLE) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_mpg/models/cylinders_by_origin.sql
[0m14:17:11.764109 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a145353a-4abd-4695-bc95-0535de2e2efa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c498da72850>]}
[0m14:17:11.765298 [error] [Thread-1  ]: 1 of 1 ERROR creating sql view model `clean`.`cylinders_by_origin` ............. [[31mERROR[0m in 0.32s]
[0m14:17:11.766694 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m14:17:11.768786 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:17:11.769298 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m14:17:11.769849 [debug] [MainThread]: On list__clean: Close
[0m14:17:11.770317 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m14:17:11.770837 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m14:17:11.771701 [info ] [MainThread]: 
[0m14:17:11.772461 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.99 seconds (0.99s).
[0m14:17:11.773924 [debug] [MainThread]: Command end result
[0m14:17:11.860872 [info ] [MainThread]: 
[0m14:17:11.861874 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:17:11.862577 [info ] [MainThread]: 
[0m14:17:11.863523 [error] [MainThread]:   Database Error in model cylinders_by_origin (models/cylinders_by_origin.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 60
   Code: 60. DB::Exception: Table raw.auto_mpg___mpg_raw does not exist. (UNKNOWN_TABLE) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_mpg/models/cylinders_by_origin.sql
[0m14:17:11.864283 [info ] [MainThread]: 
[0m14:17:11.865069 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:17:11.866591 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 7.526383, "process_in_blocks": "7680", "process_kernel_time": 0.576779, "process_mem_max_rss": "113784", "process_out_blocks": "10424", "process_user_time": 6.521665}
[0m14:17:11.867580 [debug] [MainThread]: Command `dbt build` failed at 14:17:11.867342 after 7.53 seconds
[0m14:17:11.868373 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c4990ed3310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c498edf00d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c498c880ac0>]}
[0m14:17:11.869152 [debug] [MainThread]: Flushing usage events
[0m14:35:24.751058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x743736033310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x743732c96b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x743732c96a00>]}


============================== 14:35:24.760408 | fb11bea8-4915-475b-ada1-0c5125850489 ==============================
[0m14:35:24.760408 [info ] [MainThread]: Running with dbt=1.8.9
[0m14:35:24.761513 [debug] [MainThread]: running dbt with arguments {'log_cache_events': 'False', 'empty': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'target_path': 'None', 'cache_selected_only': 'False', 'log_format': 'default', 'indirect_selection': 'eager', 'printer_width': '80', 'introspect': 'True', 'warn_error': 'None', 'use_colors': 'True', 'fail_fast': 'False', 'no_print': 'None', 'static_parser': 'True', 'debug': 'False', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'write_json': 'True', 'invocation_command': 'dbt build --profiles-dir . --target local', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_experimental_parser': 'False', 'profiles_dir': '.'}
[0m14:35:25.335508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fb11bea8-4915-475b-ada1-0c5125850489', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x743732c5afd0>]}
[0m14:35:25.530060 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fb11bea8-4915-475b-ada1-0c5125850489', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x743732bb81c0>]}
[0m14:35:25.531308 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m14:35:25.941727 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m14:35:26.351245 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:35:26.352304 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/cylinders_by_origin.sql
[0m14:35:26.944525 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.ex_01_mpg.cylinders_by_origin' (models/cylinders_by_origin.sql) depends on a source named 'raw.autompg___cars' which was not found
[0m14:35:26.946197 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 2.3902361, "process_in_blocks": "0", "process_kernel_time": 0.506564, "process_mem_max_rss": "99832", "process_out_blocks": "6608", "process_user_time": 3.965448}
[0m14:35:26.946998 [debug] [MainThread]: Command `dbt build` failed at 14:35:26.946791 after 2.39 seconds
[0m14:35:26.947655 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x743736033310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x743732b22910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74373544edc0>]}
[0m14:35:26.948314 [debug] [MainThread]: Flushing usage events
[0m14:44:08.744982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ee6bb1f6310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ee6b7e5caf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ee6b7e5c9a0>]}


============================== 14:44:08.754616 | c6641145-d2d1-407d-9444-1cd0f718e4e2 ==============================
[0m14:44:08.754616 [info ] [MainThread]: Running with dbt=1.8.9
[0m14:44:08.755823 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'cache_selected_only': 'False', 'no_print': 'None', 'partial_parse': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'indirect_selection': 'eager', 'use_colors': 'True', 'empty': 'False', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'log_format': 'default', 'debug': 'False', 'invocation_command': 'dbt build --profiles-dir . --target local', 'printer_width': '80', 'profiles_dir': '.', 'quiet': 'False', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'introspect': 'True', 'write_json': 'True', 'log_cache_events': 'False'}
[0m14:44:09.363290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c6641145-d2d1-407d-9444-1cd0f718e4e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ee6b7d60460>]}
[0m14:44:09.562904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c6641145-d2d1-407d-9444-1cd0f718e4e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ee6b7d5c040>]}
[0m14:44:09.564150 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m14:44:10.033686 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m14:44:10.459930 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m14:44:10.461043 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/sources.yml
[0m14:44:10.461668 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/cylinders_by_origin.sql
[0m14:44:11.630429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c6641145-d2d1-407d-9444-1cd0f718e4e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ee6b6f4a130>]}
[0m14:44:12.031931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c6641145-d2d1-407d-9444-1cd0f718e4e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ee6b6f623d0>]}
[0m14:44:12.032876 [info ] [MainThread]: Found 1 model, 1 source, 468 macros
[0m14:44:12.035609 [info ] [MainThread]: 
[0m14:44:12.036769 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m14:44:12.038352 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m14:44:12.058925 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:44:12.498192 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m14:44:12.502415 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:44:12.648298 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m14:44:12.659558 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m14:44:12.667188 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m14:44:12.669721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c6641145-d2d1-407d-9444-1cd0f718e4e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ee6b6e9d0d0>]}
[0m14:44:12.671260 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m14:44:12.672375 [info ] [MainThread]: 
[0m14:44:12.743042 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m14:44:12.744135 [info ] [Thread-1  ]: 1 of 1 START sql view model `clean`.`cylinders_by_origin` ...................... [RUN]
[0m14:44:12.745016 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__clean, now model.ex_01_mpg.cylinders_by_origin)
[0m14:44:12.745729 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m14:44:12.761411 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m14:44:12.762518 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m14:44:12.868246 [debug] [Thread-1  ]: Creating new relation cylinders_by_origin
[0m14:44:12.940627 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m14:44:12.942267 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `clean`.`cylinders_by_origin` 
  
    
    
  as (
    SELECT 
  origin,
  avg(cylinders) AS avg_cyl,
  count() AS n
FROM `raw`.`autompg___cars`  # Now matches
GROUP BY origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m14:44:12.957016 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m14:44:13.032879 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c6641145-d2d1-407d-9444-1cd0f718e4e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ee6b7d470a0>]}
[0m14:44:13.034141 [info ] [Thread-1  ]: 1 of 1 OK created sql view model `clean`.`cylinders_by_origin` ................. [[32mOK[0m in 0.29s]
[0m14:44:13.035516 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m14:44:13.038800 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:44:13.040088 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m14:44:13.041324 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m14:44:13.042757 [info ] [MainThread]: 
[0m14:44:13.044226 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 1.01 seconds (1.01s).
[0m14:44:13.046214 [debug] [MainThread]: Command end result
[0m14:44:13.251231 [info ] [MainThread]: 
[0m14:44:13.252850 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:44:13.254123 [info ] [MainThread]: 
[0m14:44:13.255598 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:44:13.258381 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 4.712172, "process_in_blocks": "0", "process_kernel_time": 0.610888, "process_mem_max_rss": "113972", "process_out_blocks": "10400", "process_user_time": 5.093396}
[0m14:44:13.260231 [debug] [MainThread]: Command `dbt build` succeeded at 14:44:13.259742 after 4.71 seconds
[0m14:44:13.261514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ee6bb1f6310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ee6b9124ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ee6b7cf5910>]}
[0m14:44:13.262721 [debug] [MainThread]: Flushing usage events
[0m15:36:32.059955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52f5cfc310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52f296e520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52f296e670>]}


============================== 15:36:32.069567 | 4f5fbeec-8118-47ee-b8a8-fca4f5bad5f6 ==============================
[0m15:36:32.069567 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:36:32.070731 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'empty': 'False', 'invocation_command': 'dbt build --profiles-dir . --target local', 'static_parser': 'True', 'version_check': 'True', 'introspect': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_format': 'default', 'indirect_selection': 'eager', 'debug': 'False', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'profiles_dir': '.', 'use_colors': 'True', 'log_path': '/workdir/transforms/01_mpg/logs', 'printer_width': '80', 'quiet': 'False', 'fail_fast': 'False'}
[0m15:36:32.592414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4f5fbeec-8118-47ee-b8a8-fca4f5bad5f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52f52ac2b0>]}
[0m15:36:32.786598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4f5fbeec-8118-47ee-b8a8-fca4f5bad5f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52f447b5b0>]}
[0m15:36:32.787833 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m15:36:33.199061 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m15:36:33.576464 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m15:36:33.577406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4f5fbeec-8118-47ee-b8a8-fca4f5bad5f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52f44bb400>]}
[0m15:36:38.106699 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4f5fbeec-8118-47ee-b8a8-fca4f5bad5f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52f2946d60>]}
[0m15:36:38.502316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4f5fbeec-8118-47ee-b8a8-fca4f5bad5f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52f221fc10>]}
[0m15:36:38.503119 [info ] [MainThread]: Found 1 model, 1 source, 468 macros
[0m15:36:38.505470 [info ] [MainThread]: 
[0m15:36:38.506418 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:36:38.507898 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:36:38.569773 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:36:38.964924 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:36:38.968276 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:36:38.992527 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m15:36:39.003969 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m15:36:39.008991 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:36:39.011389 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4f5fbeec-8118-47ee-b8a8-fca4f5bad5f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52f1afb910>]}
[0m15:36:39.012278 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m15:36:39.060142 [info ] [MainThread]: 
[0m15:36:39.073042 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m15:36:39.074254 [info ] [Thread-1  ]: 1 of 1 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m15:36:39.075153 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__mart, now model.ex_01_mpg.cylinders_by_origin)
[0m15:36:39.075910 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m15:36:39.092653 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m15:36:39.093813 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m15:36:39.207094 [debug] [Thread-1  ]: Creating new relation cylinders_by_origin
[0m15:36:39.284530 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m15:36:39.286316 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin` 
  
    
    
  as (
    SELECT 
  origin,
  avg(cylinders) AS avg_cyl,
  count() AS n
FROM `raw`.`autompg___cars`  # Now matches
GROUP BY origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:36:39.298778 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:36:39.378951 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4f5fbeec-8118-47ee-b8a8-fca4f5bad5f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52f109de80>]}
[0m15:36:39.380156 [info ] [Thread-1  ]: 1 of 1 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 0.30s]
[0m15:36:39.381506 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m15:36:39.383505 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:36:39.384625 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m15:36:39.385771 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m15:36:39.387115 [info ] [MainThread]: 
[0m15:36:39.388583 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.88 seconds (0.88s).
[0m15:36:39.391355 [debug] [MainThread]: Command end result
[0m15:36:39.604911 [info ] [MainThread]: 
[0m15:36:39.606220 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:36:39.607164 [info ] [MainThread]: 
[0m15:36:39.608189 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m15:36:39.660447 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 7.792892, "process_in_blocks": "0", "process_kernel_time": 0.573635, "process_mem_max_rss": "114500", "process_out_blocks": "10408", "process_user_time": 6.610563}
[0m15:36:39.662144 [debug] [MainThread]: Command `dbt build` succeeded at 15:36:39.661729 after 7.79 seconds
[0m15:36:39.663457 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52f5cfc310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52f52ac2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52f1571370>]}
[0m15:36:39.664867 [debug] [MainThread]: Flushing usage events
[0m16:08:04.484447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x6ffe11620310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x6ffe0e285af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x6ffe0e2859a0>]}


============================== 16:08:04.493925 | abafa960-f2a3-4181-90bb-b47a4eb0c15d ==============================
[0m16:08:04.493925 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:08:04.495104 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'profiles_dir': '.', 'static_parser': 'True', 'warn_error': 'None', 'fail_fast': 'False', 'introspect': 'True', 'use_experimental_parser': 'False', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True', 'debug': 'False', 'printer_width': '80', 'quiet': 'False', 'empty': 'False', 'no_print': 'None', 'log_path': '/workdir/transforms/01_mpg/logs', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'target_path': 'None', 'use_colors': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'invocation_command': 'dbt build --profiles-dir . --target local', 'log_cache_events': 'False'}
[0m16:08:05.071459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'abafa960-f2a3-4181-90bb-b47a4eb0c15d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x6ffe13df58b0>]}
[0m16:08:05.267178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'abafa960-f2a3-4181-90bb-b47a4eb0c15d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x6ffe0e2e8040>]}
[0m16:08:05.268515 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m16:08:05.687968 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m16:08:06.111476 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 2 files added, 0 files changed.
[0m16:08:06.112378 [debug] [MainThread]: Partial parsing: added file: ex_01_mpg://models/mart/cylinders_by_origin.sql
[0m16:08:06.112987 [debug] [MainThread]: Partial parsing: added file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m16:08:06.113497 [debug] [MainThread]: Partial parsing: deleted file: ex_01_mpg://models/cylinders_by_origin.sql
[0m16:08:06.989566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'abafa960-f2a3-4181-90bb-b47a4eb0c15d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x6ffe0d5d9f40>]}
[0m16:08:07.402870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'abafa960-f2a3-4181-90bb-b47a4eb0c15d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x6ffe0d5d9d90>]}
[0m16:08:07.403773 [info ] [MainThread]: Found 2 models, 1 source, 468 macros
[0m16:08:07.406430 [info ] [MainThread]: 
[0m16:08:07.407566 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:08:07.419012 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:08:07.484570 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:08:07.932372 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:08:07.936459 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:08:07.958026 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m16:08:07.977250 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m16:08:07.985240 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:08:07.988116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'abafa960-f2a3-4181-90bb-b47a4eb0c15d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x6ffe0d146f70>]}
[0m16:08:07.990098 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m16:08:07.991411 [info ] [MainThread]: 
[0m16:08:08.209256 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m16:08:08.210381 [info ] [Thread-1  ]: 1 of 2 START sql table model `mart`.`mpg_standardized` ......................... [RUN]
[0m16:08:08.211431 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.mpg_standardized'
[0m16:08:08.212164 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m16:08:08.282988 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m16:08:08.284509 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m16:08:08.384178 [debug] [Thread-1  ]: Creating new relation mpg_standardized
[0m16:08:08.507560 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m16:08:08.618003 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `mart`.`mpg_standardized`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

select
  cast(mpg as float64)        as mpg,
  cast(cylinders as int32)    as cylinders,
  cast(displacement as float64) as displacement,
  cast(horsepower as float64) as horsepower,
  cast(weight as float64)     as weight,
  cast(acceleration as float64) as acceleration,
  cast(model_year as int32)   as model_year,
  origin,
  make
from `raw`.`autompg___cars`
          )
        
        ...
[0m16:08:08.623749 [debug] [Thread-1  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `mart`.`mpg_standardized`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

select
  cast(mpg as float64)        as mpg,
  cast(cylinders as int32)    as cylinders,
  cast(displacement as float64) as displacement,
  cast(horsepower as float64) as horsepower,
  cast(weight as float64)     as weight,
  cast(acceleration as float64) as acceleration,
  cast(model_year as int32)   as model_year,
  origin,
  make
from `raw`.`autompg___cars`
          )
        
        
[0m16:08:08.627477 [debug] [Thread-1  ]: Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 47
   Code: 47. DB::Exception: Missing columns: 'make' while processing query: 'SELECT CAST(mpg, 'float64') AS mpg, CAST(cylinders, 'int32') AS cylinders, CAST(displacement, 'float64') AS displacement, CAST(horsepower, 'float64') AS horsepower, CAST(weight, 'float64') AS weight, CAST(acceleration, 'float64') AS acceleration, CAST(model_year, 'int32') AS model_year, origin, make FROM raw.autompg___cars', required columns: 'origin' 'make' 'horsepower' 'mpg' 'weight' 'model_year' 'cylinders' 'displacement' 'acceleration', maybe you meant: 'origin', 'name', 'horsepower', 'mpg', 'weight', 'model_year', 'cylinders', 'displacement' or 'acceleration'. (UNKNOWN_IDENTIFIER) (version 23.12.6.19 (official build))
[0m16:08:08.630107 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'abafa960-f2a3-4181-90bb-b47a4eb0c15d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x6ffe0e243f40>]}
[0m16:08:08.631204 [error] [Thread-1  ]: 1 of 2 ERROR creating sql table model `mart`.`mpg_standardized` ................ [[31mERROR[0m in 0.42s]
[0m16:08:08.632594 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m16:08:08.634713 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m16:08:08.636076 [info ] [Thread-3  ]: 2 of 2 SKIP relation mart.cylinders_by_origin .................................. [[33mSKIP[0m]
[0m16:08:08.637519 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m16:08:08.640018 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:08:08.640863 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m16:08:08.641714 [debug] [MainThread]: On list__mart: Close
[0m16:08:08.642497 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m16:08:08.643344 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m16:08:08.644475 [info ] [MainThread]: 
[0m16:08:08.645418 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.24 seconds (1.24s).
[0m16:08:08.647707 [debug] [MainThread]: Command end result
[0m16:08:08.796641 [info ] [MainThread]: 
[0m16:08:08.798120 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:08:08.798973 [info ] [MainThread]: 
[0m16:08:08.800447 [error] [MainThread]:   Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 47
   Code: 47. DB::Exception: Missing columns: 'make' while processing query: 'SELECT CAST(mpg, 'float64') AS mpg, CAST(cylinders, 'int32') AS cylinders, CAST(displacement, 'float64') AS displacement, CAST(horsepower, 'float64') AS horsepower, CAST(weight, 'float64') AS weight, CAST(acceleration, 'float64') AS acceleration, CAST(model_year, 'int32') AS model_year, origin, make FROM raw.autompg___cars', required columns: 'origin' 'make' 'horsepower' 'mpg' 'weight' 'model_year' 'cylinders' 'displacement' 'acceleration', maybe you meant: 'origin', 'name', 'horsepower', 'mpg', 'weight', 'model_year', 'cylinders', 'displacement' or 'acceleration'. (UNKNOWN_IDENTIFIER) (version 23.12.6.19 (official build))
[0m16:08:08.801485 [info ] [MainThread]: 
[0m16:08:08.802576 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
[0m16:08:08.804571 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 4.5137253, "process_in_blocks": "0", "process_kernel_time": 0.63087, "process_mem_max_rss": "113916", "process_out_blocks": "10424", "process_user_time": 5.047947}
[0m16:08:08.805670 [debug] [MainThread]: Command `dbt build` failed at 16:08:08.805382 after 4.52 seconds
[0m16:08:08.806513 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x6ffe11620310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x6ffe0df1c310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x6ffe0df819d0>]}
[0m16:08:08.807346 [debug] [MainThread]: Flushing usage events
[0m16:16:48.691518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73081bbaf310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73081880ca90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73081880c940>]}


============================== 16:16:48.701317 | 571e97d5-3879-48af-b358-4c3fb6aba509 ==============================
[0m16:16:48.701317 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:16:48.702459 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'debug': 'False', 'warn_error': 'None', 'quiet': 'False', 'target_path': 'None', 'profiles_dir': '.', 'write_json': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt build --profiles-dir . --target local', 'version_check': 'True', 'static_parser': 'True', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'no_print': 'None', 'log_path': '/workdir/transforms/01_mpg/logs', 'cache_selected_only': 'False', 'empty': 'False', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'printer_width': '80'}
[0m16:16:49.231422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '571e97d5-3879-48af-b358-4c3fb6aba509', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7308187d9be0>]}
[0m16:16:49.427174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '571e97d5-3879-48af-b358-4c3fb6aba509', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x730818c5c040>]}
[0m16:16:49.428561 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m16:16:49.895302 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m16:16:50.312570 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m16:16:50.313564 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m16:16:50.314236 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/mart/cylinders_by_origin.sql
[0m16:16:51.134943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '571e97d5-3879-48af-b358-4c3fb6aba509', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x730817b18fd0>]}
[0m16:16:51.536154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '571e97d5-3879-48af-b358-4c3fb6aba509', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x730817a93730>]}
[0m16:16:51.537000 [info ] [MainThread]: Found 2 models, 1 source, 468 macros
[0m16:16:51.539674 [info ] [MainThread]: 
[0m16:16:51.540702 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:16:51.592419 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:16:51.552486 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:16:51.622638 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:16:51.624098 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:16:52.230507 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:16:52.238659 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:16:52.243050 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:16:52.248045 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:16:52.521642 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__mart_clean)
[0m16:16:52.522640 [debug] [ThreadPool]: Creating schema "schema: "mart_clean"
"
[0m16:16:52.523504 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__mart_mart)
[0m16:16:52.535809 [debug] [ThreadPool]: Creating schema "schema: "mart_mart"
"
[0m16:16:52.603189 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__mart_clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_clean"} */
create database if not exists `mart_clean`
        
  
        
  ...
[0m16:16:52.611881 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__mart_mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_mart"} */
create database if not exists `mart_mart`
        
  
        
  ...
[0m16:16:52.618822 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_clean"} */
create database if not exists `mart_clean`
        
  
        
  
[0m16:16:52.621062 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_mart"} */
create database if not exists `mart_mart`
        
  
        
  
[0m16:16:52.622711 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m16:16:52.624263 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m16:16:52.627805 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:16:52.629046 [debug] [MainThread]: Connection 'create__mart_clean' was left open.
[0m16:16:52.630306 [debug] [MainThread]: On create__mart_clean: Close
[0m16:16:52.631471 [debug] [MainThread]: Connection 'create__mart_mart' was left open.
[0m16:16:52.632698 [debug] [MainThread]: On create__mart_mart: Close
[0m16:16:52.633901 [info ] [MainThread]: 
[0m16:16:52.635328 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 1.09 seconds (1.09s).
[0m16:16:52.637061 [error] [MainThread]: Encountered an error:
Database Error
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 497
   Code: 497. DB::Exception: ftw_user: Not enough privileges. To execute this query, it's necessary to have the grant CREATE DATABASE ON mart_clean.*. (ACCESS_DENIED) (version 23.12.6.19 (official build))
[0m16:16:52.639698 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 4.140759, "process_in_blocks": "0", "process_kernel_time": 0.579005, "process_mem_max_rss": "112148", "process_out_blocks": "9368", "process_user_time": 4.852618}
[0m16:16:52.641247 [debug] [MainThread]: Command `dbt build` failed at 16:16:52.640828 after 4.14 seconds
[0m16:16:52.691283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73081bbaf310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73081783b9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x730816ea4670>]}
[0m16:16:52.692918 [debug] [MainThread]: Flushing usage events
[0m16:35:01.945765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x735946a4f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7359436b1af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7359436b19a0>]}


============================== 16:35:01.961762 | ddd886db-afcc-4b35-97c4-39a49767c406 ==============================
[0m16:35:01.961762 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:35:01.963664 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'log_path': '/workdir/transforms/01_mpg/logs', 'quiet': 'False', 'version_check': 'True', 'debug': 'False', 'log_format': 'default', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'no_print': 'None', 'profiles_dir': '.', 'invocation_command': 'dbt build --profiles-dir . --target local', 'printer_width': '80', 'static_parser': 'True', 'write_json': 'True', 'empty': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_cache_events': 'False'}
[0m16:35:02.586442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ddd886db-afcc-4b35-97c4-39a49767c406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x735945ff6fd0>]}
[0m16:35:02.783296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ddd886db-afcc-4b35-97c4-39a49767c406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73594367f070>]}
[0m16:35:02.784612 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m16:35:03.257226 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m16:35:03.672960 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m16:35:03.673836 [debug] [MainThread]: Partial parsing: added file: ex_01_mpg://models/macro/create_schema.sql
[0m16:35:04.548748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ddd886db-afcc-4b35-97c4-39a49767c406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x735942b7cf40>]}
[0m16:35:04.905718 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ddd886db-afcc-4b35-97c4-39a49767c406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x735942f341c0>]}
[0m16:35:04.906608 [info ] [MainThread]: Found 3 models, 1 source, 468 macros
[0m16:35:04.943570 [info ] [MainThread]: 
[0m16:35:04.944827 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:35:04.956356 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:35:04.968030 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:35:04.975657 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:35:05.055065 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:35:05.057743 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:35:05.068860 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:35:05.815314 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:35:05.825972 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:35:05.849141 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:35:05.852642 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:35:05.860433 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:35:06.071838 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.21 seconds
[0m16:35:06.145846 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__mart_clean)
[0m16:35:06.146914 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__mart_mart)
[0m16:35:06.148339 [debug] [ThreadPool]: Creating schema "schema: "mart_clean"
"
[0m16:35:06.149751 [debug] [ThreadPool]: Creating schema "schema: "mart_mart"
"
[0m16:35:06.163562 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__mart_clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_clean"} */
create database if not exists `mart_clean`
        
  
        
  ...
[0m16:35:06.172440 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__mart_mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_mart"} */
create database if not exists `mart_mart`
        
  
        
  ...
[0m16:35:06.177819 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_clean"} */
create database if not exists `mart_clean`
        
  
        
  
[0m16:35:06.178581 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m16:35:06.180911 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_mart"} */
create database if not exists `mart_mart`
        
  
        
  
[0m16:35:06.182625 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m16:35:06.184768 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:35:06.185892 [debug] [MainThread]: Connection 'list_' was left open.
[0m16:35:06.186993 [debug] [MainThread]: On list_: Close
[0m16:35:06.188068 [debug] [MainThread]: Connection 'create__mart_mart' was left open.
[0m16:35:06.189149 [debug] [MainThread]: On create__mart_mart: Close
[0m16:35:06.242557 [debug] [MainThread]: Connection 'create__mart_clean' was left open.
[0m16:35:06.243767 [debug] [MainThread]: On create__mart_clean: Close
[0m16:35:06.245243 [info ] [MainThread]: 
[0m16:35:06.246818 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 1.30 seconds (1.30s).
[0m16:35:06.248625 [error] [MainThread]: Encountered an error:
Database Error
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 497
   Code: 497. DB::Exception: ftw_user: Not enough privileges. To execute this query, it's necessary to have the grant CREATE DATABASE ON mart_clean.*. (ACCESS_DENIED) (version 23.12.6.19 (official build))
[0m16:35:06.251410 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 4.5685906, "process_in_blocks": "0", "process_kernel_time": 0.601303, "process_mem_max_rss": "111768", "process_out_blocks": "9368", "process_user_time": 5.029532}
[0m16:35:06.253148 [debug] [MainThread]: Command `dbt build` failed at 16:35:06.252730 after 4.57 seconds
[0m16:35:06.254579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x735946a4f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x735942afba60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7359428a6430>]}
[0m16:35:06.255901 [debug] [MainThread]: Flushing usage events
[0m16:35:58.384326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7aec7d30b310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7aec79f6aaf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7aec79f6a9a0>]}


============================== 16:35:58.393705 | 24c79631-913d-43bf-9543-afff78a2a29f ==============================
[0m16:35:58.393705 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:35:58.394868 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'log_format': 'default', 'fail_fast': 'False', 'version_check': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'partial_parse': 'True', 'empty': 'False', 'target_path': 'None', 'log_cache_events': 'False', 'quiet': 'False', 'invocation_command': 'dbt build --profiles-dir . --target local', 'log_path': '/workdir/transforms/01_mpg/logs', 'write_json': 'True', 'profiles_dir': '.', 'indirect_selection': 'eager', 'introspect': 'True', 'use_colors': 'True', 'printer_width': '80'}
[0m16:35:58.978214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '24c79631-913d-43bf-9543-afff78a2a29f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7aec7c8b43a0>]}
[0m16:35:59.176604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '24c79631-913d-43bf-9543-afff78a2a29f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7aec7b2a5eb0>]}
[0m16:35:59.177928 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m16:35:59.597796 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m16:36:00.016016 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:36:00.016963 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/macro/create_schema.sql
[0m16:36:00.890764 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '24c79631-913d-43bf-9543-afff78a2a29f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7aec794ae9a0>]}
[0m16:36:01.281186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '24c79631-913d-43bf-9543-afff78a2a29f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7aec79695310>]}
[0m16:36:01.282034 [info ] [MainThread]: Found 3 models, 1 source, 468 macros
[0m16:36:01.285035 [info ] [MainThread]: 
[0m16:36:01.286128 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:36:01.298404 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:36:01.310198 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:36:01.311756 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:36:01.376929 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:36:01.379579 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:36:01.385067 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:36:01.957007 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:36:01.961607 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:36:01.967442 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:36:01.974610 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:36:02.104315 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:36:02.109060 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:36:02.177681 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__mart_clean)
[0m16:36:02.178667 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__mart_mart)
[0m16:36:02.180160 [debug] [ThreadPool]: Creating schema "schema: "mart_clean"
"
[0m16:36:02.181638 [debug] [ThreadPool]: Creating schema "schema: "mart_mart"
"
[0m16:36:02.206049 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__mart_clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_clean"} */
create database if not exists `mart_clean`
        
  
        
  ...
[0m16:36:02.210413 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__mart_mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_mart"} */
create database if not exists `mart_mart`
        
  
        
  ...
[0m16:36:02.216224 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_clean"} */
create database if not exists `mart_clean`
        
  
        
  
[0m16:36:02.218198 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_mart"} */
create database if not exists `mart_mart`
        
  
        
  
[0m16:36:02.219515 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m16:36:02.220852 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m16:36:02.224157 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:36:02.225287 [debug] [MainThread]: Connection 'create__mart_clean' was left open.
[0m16:36:02.277440 [debug] [MainThread]: On create__mart_clean: Close
[0m16:36:02.278613 [debug] [MainThread]: Connection 'list_' was left open.
[0m16:36:02.279749 [debug] [MainThread]: On list_: Close
[0m16:36:02.280833 [debug] [MainThread]: Connection 'create__mart_mart' was left open.
[0m16:36:02.281946 [debug] [MainThread]: On create__mart_mart: Close
[0m16:36:02.283206 [info ] [MainThread]: 
[0m16:36:02.284647 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 1.00 seconds (1.00s).
[0m16:36:02.286408 [error] [MainThread]: Encountered an error:
Database Error
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 497
   Code: 497. DB::Exception: ftw_user: Not enough privileges. To execute this query, it's necessary to have the grant CREATE DATABASE ON mart_clean.*. (ACCESS_DENIED) (version 23.12.6.19 (official build))
[0m16:36:02.289385 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 4.094927, "process_in_blocks": "0", "process_kernel_time": 0.580362, "process_mem_max_rss": "112192", "process_out_blocks": "9368", "process_user_time": 4.754816}
[0m16:36:02.291212 [debug] [MainThread]: Command `dbt build` failed at 16:36:02.290700 after 4.10 seconds
[0m16:36:02.292675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7aec7d30b310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7aec78f42100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7aec78f34ca0>]}
[0m16:36:02.293986 [debug] [MainThread]: Flushing usage events
[0m16:36:15.451603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x724cf556a310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x724cf21caa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x724cf21ca940>]}


============================== 16:36:15.462146 | 6b361c23-5c78-4f04-8984-48a92998c78c ==============================
[0m16:36:15.462146 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:36:15.463290 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'invocation_command': 'dbt build --profiles-dir . --target local', 'log_format': 'default', 'static_parser': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'introspect': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'target_path': 'None', 'empty': 'False', 'log_cache_events': 'False', 'write_json': 'True', 'use_colors': 'True', 'printer_width': '80', 'no_print': 'None', 'profiles_dir': '.', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'quiet': 'False'}
[0m16:36:16.035585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6b361c23-5c78-4f04-8984-48a92998c78c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x724cf3ee3fa0>]}
[0m16:36:16.230742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6b361c23-5c78-4f04-8984-48a92998c78c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x724cf2cf2bb0>]}
[0m16:36:16.232116 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m16:36:16.648023 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m16:36:17.065777 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
[0m16:36:17.066670 [debug] [MainThread]: Partial parsing: added file: ex_01_mpg://models/macro/generate_schema_name.sql
[0m16:36:17.067191 [debug] [MainThread]: Partial parsing: deleted file: ex_01_mpg://models/macro/create_schema.sql
[0m16:36:17.935130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6b361c23-5c78-4f04-8984-48a92998c78c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x724cf1707130>]}
[0m16:36:18.327090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6b361c23-5c78-4f04-8984-48a92998c78c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x724cf1a650a0>]}
[0m16:36:18.327927 [info ] [MainThread]: Found 3 models, 1 source, 468 macros
[0m16:36:18.330718 [info ] [MainThread]: 
[0m16:36:18.331740 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:36:18.343323 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:36:18.344974 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:36:18.356897 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:36:18.427667 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:36:18.432142 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:36:18.442042 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:36:19.240623 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:36:19.243401 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:36:19.251966 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:36:19.256985 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:36:19.320130 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:36:19.540605 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:36:19.627665 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__mart_clean)
[0m16:36:19.629624 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__mart_mart)
[0m16:36:19.631593 [debug] [ThreadPool]: Creating schema "schema: "mart_clean"
"
[0m16:36:19.633425 [debug] [ThreadPool]: Creating schema "schema: "mart_mart"
"
[0m16:36:19.732183 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__mart_clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_clean"} */
create database if not exists `mart_clean`
        
  
        
  ...
[0m16:36:19.736393 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__mart_mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_mart"} */
create database if not exists `mart_mart`
        
  
        
  ...
[0m16:36:19.742067 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_clean"} */
create database if not exists `mart_clean`
        
  
        
  
[0m16:36:19.743447 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m16:36:19.745886 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_mart"} */
create database if not exists `mart_mart`
        
  
        
  
[0m16:36:19.747148 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m16:36:19.748773 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:36:19.749580 [debug] [MainThread]: Connection 'list_' was left open.
[0m16:36:19.750369 [debug] [MainThread]: On list_: Close
[0m16:36:19.751123 [debug] [MainThread]: Connection 'create__mart_clean' was left open.
[0m16:36:19.751896 [debug] [MainThread]: On create__mart_clean: Close
[0m16:36:19.752628 [debug] [MainThread]: Connection 'create__mart_mart' was left open.
[0m16:36:19.753366 [debug] [MainThread]: On create__mart_mart: Close
[0m16:36:19.754305 [info ] [MainThread]: 
[0m16:36:19.755328 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 1.42 seconds (1.42s).
[0m16:36:19.756500 [error] [MainThread]: Encountered an error:
Database Error
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 497
   Code: 497. DB::Exception: ftw_user: Not enough privileges. To execute this query, it's necessary to have the grant CREATE DATABASE ON mart_clean.*. (ACCESS_DENIED) (version 23.12.6.19 (official build))
[0m16:36:19.758428 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 4.5035124, "process_in_blocks": "0", "process_kernel_time": 0.655504, "process_mem_max_rss": "112104", "process_out_blocks": "9376", "process_user_time": 4.905839}
[0m16:36:19.759464 [debug] [MainThread]: Command `dbt build` failed at 16:36:19.759197 after 4.50 seconds
[0m16:36:19.760332 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x724cf556a310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x724cf13bcaf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x724cf11a6580>]}
[0m16:36:19.761273 [debug] [MainThread]: Flushing usage events
[0m16:37:07.485842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710e344b0310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710e31124520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710e31124670>]}


============================== 16:37:07.495143 | 30e9c8b5-56be-4a16-a2bb-f88bee4e7c9a ==============================
[0m16:37:07.495143 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:37:07.496276 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_experimental_parser': 'False', 'printer_width': '80', 'invocation_command': 'dbt build --profiles-dir . --target local', 'version_check': 'True', 'fail_fast': 'False', 'partial_parse': 'True', 'target_path': 'None', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'static_parser': 'True', 'introspect': 'True', 'debug': 'False', 'empty': 'False', 'profiles_dir': '.', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'log_format': 'default', 'log_path': '/workdir/transforms/01_mpg/logs', 'use_colors': 'True', 'cache_selected_only': 'False', 'write_json': 'True', 'warn_error': 'None'}
[0m16:37:08.075752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '30e9c8b5-56be-4a16-a2bb-f88bee4e7c9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710e33a4eca0>]}
[0m16:37:08.268128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '30e9c8b5-56be-4a16-a2bb-f88bee4e7c9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710e30fb4370>]}
[0m16:37:08.269403 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m16:37:08.682090 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m16:37:09.101366 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m16:37:09.102313 [debug] [MainThread]: Partial parsing: added file: ex_01_mpg://models/macro/create_schema.sql
[0m16:37:09.997192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '30e9c8b5-56be-4a16-a2bb-f88bee4e7c9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710e305d4fd0>]}
[0m16:37:10.396344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '30e9c8b5-56be-4a16-a2bb-f88bee4e7c9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710e30749dc0>]}
[0m16:37:10.397170 [info ] [MainThread]: Found 4 models, 1 source, 468 macros
[0m16:37:10.399971 [info ] [MainThread]: 
[0m16:37:10.400991 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:37:10.413008 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:37:10.456986 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:37:10.463658 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:37:10.489888 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:37:10.557847 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:37:10.559905 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:37:11.433890 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:37:11.457231 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:37:11.444709 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:37:11.466079 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:37:11.468763 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:37:11.479311 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:37:11.766999 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__mart_clean)
[0m16:37:11.767977 [debug] [ThreadPool]: Creating schema "schema: "mart_clean"
"
[0m16:37:11.768893 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__mart_mart)
[0m16:37:11.783359 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__mart_clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_clean"} */
create database if not exists `mart_clean`
        
  
        
  ...
[0m16:37:11.784841 [debug] [ThreadPool]: Creating schema "schema: "mart_mart"
"
[0m16:37:11.793940 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__mart_mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_mart"} */
create database if not exists `mart_mart`
        
  
        
  ...
[0m16:37:11.795739 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_clean"} */
create database if not exists `mart_clean`
        
  
        
  
[0m16:37:11.798221 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m16:37:11.800269 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_mart"} */
create database if not exists `mart_mart`
        
  
        
  
[0m16:37:11.802076 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m16:37:11.804526 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:37:11.857528 [debug] [MainThread]: Connection 'list_' was left open.
[0m16:37:11.858742 [debug] [MainThread]: On list_: Close
[0m16:37:11.859847 [debug] [MainThread]: Connection 'create__mart_clean' was left open.
[0m16:37:11.861008 [debug] [MainThread]: On create__mart_clean: Close
[0m16:37:11.862149 [debug] [MainThread]: Connection 'create__mart_mart' was left open.
[0m16:37:11.863338 [debug] [MainThread]: On create__mart_mart: Close
[0m16:37:11.864828 [info ] [MainThread]: 
[0m16:37:11.866401 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 1.46 seconds (1.46s).
[0m16:37:11.867971 [error] [MainThread]: Encountered an error:
Database Error
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 497
   Code: 497. DB::Exception: ftw_user: Not enough privileges. To execute this query, it's necessary to have the grant CREATE DATABASE ON mart_clean.*. (ACCESS_DENIED) (version 23.12.6.19 (official build))
[0m16:37:11.870867 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 4.5758843, "process_in_blocks": "0", "process_kernel_time": 0.645108, "process_mem_max_rss": "112176", "process_out_blocks": "9400", "process_user_time": 5.070689}
[0m16:37:11.872616 [debug] [MainThread]: Command `dbt build` failed at 16:37:11.872182 after 4.58 seconds
[0m16:37:11.873920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710e344b0310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710e30664730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710e30749c40>]}
[0m16:37:11.875189 [debug] [MainThread]: Flushing usage events
[0m16:40:23.263018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b68a210d310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b689ed732e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b689ed73430>]}


============================== 16:40:23.272983 | 46ca07e5-6fac-4bc1-8917-7258e67c4a7a ==============================
[0m16:40:23.272983 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:40:23.274178 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'introspect': 'True', 'target_path': 'None', 'quiet': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'log_format': 'default', 'debug': 'False', 'partial_parse': 'True', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'printer_width': '80', 'no_print': 'None', 'use_colors': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'static_parser': 'True', 'warn_error': 'None', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'empty': 'None', 'profiles_dir': '/workdir/transforms/01_mpg'}
[0m16:40:23.607755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '46ca07e5-6fac-4bc1-8917-7258e67c4a7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b689ee2b970>]}
[0m16:40:23.673421 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.6076764, "process_in_blocks": "8", "process_kernel_time": 0.459289, "process_mem_max_rss": "91576", "process_out_blocks": "6592", "process_user_time": 3.221907}
[0m16:40:23.674221 [debug] [MainThread]: Command `dbt clean` succeeded at 16:40:23.674011 after 0.61 seconds
[0m16:40:23.674858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b68a210d310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b689ebab430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b689ed73910>]}
[0m16:40:23.675529 [debug] [MainThread]: Flushing usage events
[0m16:40:32.896634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7651a3dd9310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7651a0a3eaf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7651a0a3e9a0>]}


============================== 16:40:32.956981 | e0a4c0c3-80cf-4c9b-a972-ad8ea7fe303a ==============================
[0m16:40:32.956981 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:40:32.958181 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt build --profiles-dir . --target local', 'log_cache_events': 'False', 'empty': 'False', 'fail_fast': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'introspect': 'True', 'target_path': 'None', 'partial_parse': 'True', 'write_json': 'True', 'profiles_dir': '.', 'version_check': 'True', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'quiet': 'False', 'use_experimental_parser': 'False', 'static_parser': 'True', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'printer_width': '80'}
[0m16:40:33.485416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e0a4c0c3-80cf-4c9b-a972-ad8ea7fe303a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7651a0959c70>]}
[0m16:40:33.677944 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e0a4c0c3-80cf-4c9b-a972-ad8ea7fe303a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7651a1c76700>]}
[0m16:40:33.679219 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m16:40:34.102684 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m16:40:34.104062 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m16:40:34.104745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e0a4c0c3-80cf-4c9b-a972-ad8ea7fe303a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7651a06f03d0>]}
[0m16:40:38.762295 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.mart
- models.clean
[0m16:40:38.784816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e0a4c0c3-80cf-4c9b-a972-ad8ea7fe303a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7651a0746be0>]}
[0m16:40:39.194455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e0a4c0c3-80cf-4c9b-a972-ad8ea7fe303a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7651a095cdf0>]}
[0m16:40:39.195326 [info ] [MainThread]: Found 2 models, 1 source, 468 macros
[0m16:40:39.198128 [info ] [MainThread]: 
[0m16:40:39.199254 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:40:39.211052 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:40:39.212053 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:40:39.281849 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:40:39.289783 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:40:39.763227 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:40:39.769650 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:40:39.772615 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:40:39.776201 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:40:39.875844 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__mart_mart)
[0m16:40:39.877131 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__mart_clean)
[0m16:40:39.878895 [debug] [ThreadPool]: Creating schema "schema: "mart_mart"
"
[0m16:40:39.880332 [debug] [ThreadPool]: Creating schema "schema: "mart_clean"
"
[0m16:40:39.962551 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__mart_mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_mart"} */
create database if not exists `mart_mart`
        
  
        
  ...
[0m16:40:39.968205 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__mart_clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_clean"} */
create database if not exists `mart_clean`
        
  
        
  ...
[0m16:40:39.973894 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_mart"} */
create database if not exists `mart_mart`
        
  
        
  
[0m16:40:39.976183 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_clean"} */
create database if not exists `mart_clean`
        
  
        
  
[0m16:40:39.977658 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m16:40:39.979110 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m16:40:39.982527 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:40:39.983682 [debug] [MainThread]: Connection 'create__mart_clean' was left open.
[0m16:40:39.984932 [debug] [MainThread]: On create__mart_clean: Close
[0m16:40:39.986093 [debug] [MainThread]: Connection 'create__mart_mart' was left open.
[0m16:40:39.987249 [debug] [MainThread]: On create__mart_mart: Close
[0m16:40:39.988423 [info ] [MainThread]: 
[0m16:40:39.989931 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.79 seconds (0.79s).
[0m16:40:39.991736 [error] [MainThread]: Encountered an error:
Database Error
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 497
   Code: 497. DB::Exception: ftw_user: Not enough privileges. To execute this query, it's necessary to have the grant CREATE DATABASE ON mart_mart.*. (ACCESS_DENIED) (version 23.12.6.19 (official build))
[0m16:40:39.994487 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 7.2886744, "process_in_blocks": "0", "process_kernel_time": 0.6108, "process_mem_max_rss": "112572", "process_out_blocks": "9384", "process_user_time": 6.33521}
[0m16:40:39.996144 [debug] [MainThread]: Command `dbt build` failed at 16:40:39.995726 after 7.29 seconds
[0m16:40:39.997651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7651a3dd9310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7651a04a3e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7651a0237df0>]}
[0m16:40:39.998976 [debug] [MainThread]: Flushing usage events
[0m16:43:43.030332 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x731769f68310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x731766bc8af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x731766bc89a0>]}


============================== 16:43:43.039556 | e6d73261-3a04-411e-bd49-89f62361e7f3 ==============================
[0m16:43:43.039556 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:43:43.040639 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'fail_fast': 'False', 'introspect': 'True', 'warn_error': 'None', 'debug': 'False', 'no_print': 'None', 'invocation_command': 'dbt build --profiles-dir . --target local', 'use_experimental_parser': 'False', 'static_parser': 'True', 'printer_width': '80', 'empty': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'indirect_selection': 'eager', 'use_colors': 'True', 'quiet': 'False', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False', 'profiles_dir': '.', 'partial_parse': 'True'}
[0m16:43:43.564652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e6d73261-3a04-411e-bd49-89f62361e7f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x731766bc8f70>]}
[0m16:43:43.755568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e6d73261-3a04-411e-bd49-89f62361e7f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73176a1974c0>]}
[0m16:43:43.756876 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m16:43:44.225299 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m16:43:44.637697 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:43:44.638344 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:43:44.652558 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.mart
- models.clean
[0m16:43:44.763345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e6d73261-3a04-411e-bd49-89f62361e7f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73176640a130>]}
[0m16:43:45.180844 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e6d73261-3a04-411e-bd49-89f62361e7f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7317663b79a0>]}
[0m16:43:45.220765 [info ] [MainThread]: Found 2 models, 1 source, 468 macros
[0m16:43:45.223633 [info ] [MainThread]: 
[0m16:43:45.224749 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:43:45.236714 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:43:45.258309 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:43:45.321812 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:43:45.271054 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:43:46.034320 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:43:46.039836 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:43:46.044031 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:43:46.046379 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:43:46.144622 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__mart_mart)
[0m16:43:46.146341 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__mart_clean)
[0m16:43:46.148020 [debug] [ThreadPool]: Creating schema "schema: "mart_mart"
"
[0m16:43:46.149695 [debug] [ThreadPool]: Creating schema "schema: "mart_clean"
"
[0m16:43:46.236719 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__mart_clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_clean"} */
create database if not exists `mart_clean`
        
  
        
  ...
[0m16:43:46.234847 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__mart_mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_mart"} */
create database if not exists `mart_mart`
        
  
        
  ...
[0m16:43:46.245347 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_clean"} */
create database if not exists `mart_clean`
        
  
        
  
[0m16:43:46.247624 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m16:43:46.251486 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_mart"} */
create database if not exists `mart_mart`
        
  
        
  
[0m16:43:46.253069 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m16:43:46.255304 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:43:46.256673 [debug] [MainThread]: Connection 'create__mart_clean' was left open.
[0m16:43:46.258489 [debug] [MainThread]: On create__mart_clean: Close
[0m16:43:46.259619 [debug] [MainThread]: Connection 'create__mart_mart' was left open.
[0m16:43:46.260746 [debug] [MainThread]: On create__mart_mart: Close
[0m16:43:46.261876 [info ] [MainThread]: 
[0m16:43:46.263272 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 1.04 seconds (1.04s).
[0m16:43:46.264947 [error] [MainThread]: Encountered an error:
Database Error
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 497
   Code: 497. DB::Exception: ftw_user: Not enough privileges. To execute this query, it's necessary to have the grant CREATE DATABASE ON mart_clean.*. (ACCESS_DENIED) (version 23.12.6.19 (official build))
[0m16:43:46.267694 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 3.4278169, "process_in_blocks": "0", "process_kernel_time": 0.589237, "process_mem_max_rss": "109356", "process_out_blocks": "8408", "process_user_time": 4.512244}
[0m16:43:46.269321 [debug] [MainThread]: Command `dbt build` failed at 16:43:46.268879 after 3.43 seconds
[0m16:43:46.321926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x731769f68310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x731766353730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7317662b9370>]}
[0m16:43:46.323242 [debug] [MainThread]: Flushing usage events
[0m16:44:04.848944 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x766c48fdcf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x766c45c85a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x766c45c85940>]}


============================== 16:44:04.909017 | ffa1644e-8161-42a5-8b32-a2a019953414 ==============================
[0m16:44:04.909017 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:44:04.910135 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'debug': 'False', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'no_print': 'None', 'static_parser': 'True', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'write_json': 'True', 'log_path': '/workdir/transforms/01_mpg/logs', 'cache_selected_only': 'False', 'version_check': 'True', 'partial_parse': 'True', 'profiles_dir': '.', 'printer_width': '80', 'target_path': 'None', 'invocation_command': 'dbt build --profiles-dir . --target local', 'indirect_selection': 'eager', 'empty': 'False', 'use_colors': 'True', 'log_cache_events': 'False'}
[0m16:44:05.438148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ffa1644e-8161-42a5-8b32-a2a019953414', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x766c45b70670>]}
[0m16:44:05.633323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ffa1644e-8161-42a5-8b32-a2a019953414', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x766c465a0610>]}
[0m16:44:05.634638 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m16:44:06.102182 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m16:44:06.433214 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m16:44:06.434112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ffa1644e-8161-42a5-8b32-a2a019953414', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x766c46fb7910>]}
[0m16:44:11.124078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ffa1644e-8161-42a5-8b32-a2a019953414', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x766c44f51130>]}
[0m16:44:11.509352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ffa1644e-8161-42a5-8b32-a2a019953414', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x766c44e66880>]}
[0m16:44:11.510178 [info ] [MainThread]: Found 2 models, 1 source, 468 macros
[0m16:44:11.512701 [info ] [MainThread]: 
[0m16:44:11.513729 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:44:11.525085 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:44:11.531768 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:44:11.635161 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:44:11.640690 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:44:12.363676 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:44:12.367308 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:44:12.372953 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:44:12.375114 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:44:12.442168 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__mart_clean)
[0m16:44:12.443720 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__mart_mart)
[0m16:44:12.445445 [debug] [ThreadPool]: Creating schema "schema: "mart_clean"
"
[0m16:44:12.447204 [debug] [ThreadPool]: Creating schema "schema: "mart_mart"
"
[0m16:44:12.529128 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__mart_clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_clean"} */
create database if not exists `mart_clean`
        
  
        
  ...
[0m16:44:12.533145 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__mart_mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_mart"} */
create database if not exists `mart_mart`
        
  
        
  ...
[0m16:44:12.539119 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_clean"} */
create database if not exists `mart_clean`
        
  
        
  
[0m16:44:12.541316 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_mart"} */
create database if not exists `mart_mart`
        
  
        
  
[0m16:44:12.542750 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m16:44:12.544161 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m16:44:12.547483 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:44:12.548633 [debug] [MainThread]: Connection 'create__mart_mart' was left open.
[0m16:44:12.549707 [debug] [MainThread]: On create__mart_mart: Close
[0m16:44:12.602453 [debug] [MainThread]: Connection 'create__mart_clean' was left open.
[0m16:44:12.603690 [debug] [MainThread]: On create__mart_clean: Close
[0m16:44:12.604792 [info ] [MainThread]: 
[0m16:44:12.606122 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 1.09 seconds (1.09s).
[0m16:44:12.607766 [error] [MainThread]: Encountered an error:
Database Error
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 497
   Code: 497. DB::Exception: ftw_user: Not enough privileges. To execute this query, it's necessary to have the grant CREATE DATABASE ON mart_clean.*. (ACCESS_DENIED) (version 23.12.6.19 (official build))
[0m16:44:12.610357 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 7.9030128, "process_in_blocks": "0", "process_kernel_time": 0.621796, "process_mem_max_rss": "112948", "process_out_blocks": "9368", "process_user_time": 6.773526}
[0m16:44:12.611915 [debug] [MainThread]: Command `dbt build` failed at 16:44:12.611486 after 7.90 seconds
[0m16:44:12.613224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x766c48fdcf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x766c445ee910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x766c4418dca0>]}
[0m16:44:12.614437 [debug] [MainThread]: Flushing usage events
[0m16:44:59.251333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73de2779f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73de243f1b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73de243f19d0>]}


============================== 16:44:59.260760 | 73bbf2fa-6e29-4f5b-8779-e864e2868738 ==============================
[0m16:44:59.260760 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:44:59.261820 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'log_format': 'default', 'quiet': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'no_print': 'None', 'introspect': 'True', 'indirect_selection': 'eager', 'empty': 'False', 'static_parser': 'True', 'partial_parse': 'True', 'printer_width': '80', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'profiles_dir': '.', 'debug': 'False', 'warn_error': 'None', 'target_path': 'None', 'invocation_command': 'dbt build --profiles-dir . --target local', 'version_check': 'True', 'use_colors': 'True', 'cache_selected_only': 'False'}
[0m16:44:59.837864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '73bbf2fa-6e29-4f5b-8779-e864e2868738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73de26d373a0>]}
[0m16:44:59.981670 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '73bbf2fa-6e29-4f5b-8779-e864e2868738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73de24500e80>]}
[0m16:45:00.033310 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m16:45:00.452348 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m16:45:00.864921 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:45:00.865617 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:45:01.037417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '73bbf2fa-6e29-4f5b-8779-e864e2868738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73de23c34130>]}
[0m16:45:01.441328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '73bbf2fa-6e29-4f5b-8779-e864e2868738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73de23c8a370>]}
[0m16:45:01.442185 [info ] [MainThread]: Found 2 models, 1 source, 468 macros
[0m16:45:01.444730 [info ] [MainThread]: 
[0m16:45:01.445752 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:45:01.457438 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:45:01.459086 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:45:01.551466 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:45:01.565985 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:45:02.122035 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:45:02.127198 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:45:02.133780 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:45:02.138635 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:45:02.160374 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__mart_clean)
[0m16:45:02.161215 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__mart_mart)
[0m16:45:02.162286 [debug] [ThreadPool]: Creating schema "schema: "mart_clean"
"
[0m16:45:02.163481 [debug] [ThreadPool]: Creating schema "schema: "mart_mart"
"
[0m16:45:02.178176 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__mart_clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_clean"} */
create database if not exists `mart_clean`
        
  
        
  ...
[0m16:45:02.234228 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__mart_mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_mart"} */
create database if not exists `mart_mart`
        
  
        
  ...
[0m16:45:02.240021 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_clean"} */
create database if not exists `mart_clean`
        
  
        
  
[0m16:45:02.242399 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_mart"} */
create database if not exists `mart_mart`
        
  
        
  
[0m16:45:02.243933 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m16:45:02.245525 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m16:45:02.248716 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:45:02.249638 [debug] [MainThread]: Connection 'create__mart_mart' was left open.
[0m16:45:02.250505 [debug] [MainThread]: On create__mart_mart: Close
[0m16:45:02.251575 [debug] [MainThread]: Connection 'create__mart_clean' was left open.
[0m16:45:02.252524 [debug] [MainThread]: On create__mart_clean: Close
[0m16:45:02.253786 [info ] [MainThread]: 
[0m16:45:02.255306 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.81 seconds (0.81s).
[0m16:45:02.256964 [error] [MainThread]: Encountered an error:
Database Error
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 497
   Code: 497. DB::Exception: ftw_user: Not enough privileges. To execute this query, it's necessary to have the grant CREATE DATABASE ON mart_clean.*. (ACCESS_DENIED) (version 23.12.6.19 (official build))
[0m16:45:02.258976 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 3.2007086, "process_in_blocks": "0", "process_kernel_time": 0.570517, "process_mem_max_rss": "109436", "process_out_blocks": "8408", "process_user_time": 4.340722}
[0m16:45:02.259962 [debug] [MainThread]: Command `dbt build` failed at 16:45:02.259720 after 3.20 seconds
[0m16:45:02.260796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73de2779f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73de23928d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73de22f1f730>]}
[0m16:45:02.261565 [debug] [MainThread]: Flushing usage events
[0m16:46:42.099570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79ccafeaa310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79ccacb0e220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79ccacb0e370>]}


============================== 16:46:42.109090 | bab29ebb-e692-4e22-aabc-5b19385db847 ==============================
[0m16:46:42.109090 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:46:42.110241 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'debug': 'False', 'empty': 'None', 'log_path': '/workdir/transforms/01_mpg/logs', 'static_parser': 'True', 'no_print': 'None', 'write_json': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'log_format': 'default', 'use_experimental_parser': 'False', 'version_check': 'True', 'profiles_dir': '/workdir/transforms/01_mpg', 'use_colors': 'True', 'printer_width': '80', 'warn_error': 'None', 'introspect': 'True', 'indirect_selection': 'eager'}
[0m16:46:42.434160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bab29ebb-e692-4e22-aabc-5b19385db847', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79ccacb68e80>]}
[0m16:46:42.498805 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.59386694, "process_in_blocks": "0", "process_kernel_time": 0.442788, "process_mem_max_rss": "91672", "process_out_blocks": "6592", "process_user_time": 3.255739}
[0m16:46:42.499628 [debug] [MainThread]: Command `dbt clean` succeeded at 16:46:42.499410 after 0.59 seconds
[0m16:46:42.500282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79ccafeaa310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79ccac948eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79ccacf6a520>]}
[0m16:46:42.500889 [debug] [MainThread]: Flushing usage events
[0m16:46:56.902340 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790dcc352310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790dc8fbaac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790dc8fba970>]}


============================== 16:46:56.913001 | 1f7f4730-4e80-40e8-b796-315b3455facc ==============================
[0m16:46:56.913001 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:46:56.914083 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'cache_selected_only': 'False', 'log_format': 'default', 'invocation_command': 'dbt build --profiles-dir . --target local', 'warn_error': 'None', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'write_json': 'True', 'target_path': 'None', 'partial_parse': 'True', 'fail_fast': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'empty': 'False', 'introspect': 'True', 'no_print': 'None', 'printer_width': '80', 'use_colors': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'profiles_dir': '.', 'quiet': 'False', 'version_check': 'True', 'log_cache_events': 'False'}
[0m16:46:57.448598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1f7f4730-4e80-40e8-b796-315b3455facc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790dc8ed2970>]}
[0m16:46:57.645237 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1f7f4730-4e80-40e8-b796-315b3455facc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790dc8eb4f10>]}
[0m16:46:57.646556 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m16:46:58.115331 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m16:46:58.116853 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m16:46:58.117616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '1f7f4730-4e80-40e8-b796-315b3455facc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790dc8c73cd0>]}
[0m16:47:03.004182 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1f7f4730-4e80-40e8-b796-315b3455facc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790dc88405e0>]}
[0m16:47:03.356647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1f7f4730-4e80-40e8-b796-315b3455facc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790dca1ec880>]}
[0m16:47:03.357451 [info ] [MainThread]: Found 2 models, 1 source, 468 macros
[0m16:47:03.360061 [info ] [MainThread]: 
[0m16:47:03.361162 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:47:03.410342 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:47:03.412332 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:47:03.442513 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:47:03.512190 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:47:04.284056 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:47:04.309281 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:47:04.312335 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:47:04.330269 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:47:04.416500 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__mart_mart)
[0m16:47:04.418135 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__mart_clean)
[0m16:47:04.419810 [debug] [ThreadPool]: Creating schema "schema: "mart_mart"
"
[0m16:47:04.421479 [debug] [ThreadPool]: Creating schema "schema: "mart_clean"
"
[0m16:47:04.510768 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__mart_mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_mart"} */
create database if not exists `mart_mart`
        
  
        
  ...
[0m16:47:04.513263 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__mart_clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_clean"} */
create database if not exists `mart_clean`
        
  
        
  ...
[0m16:47:04.517096 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_mart"} */
create database if not exists `mart_mart`
        
  
        
  
[0m16:47:04.518398 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "create__mart_clean"} */
create database if not exists `mart_clean`
        
  
        
  
[0m16:47:04.519203 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m16:47:04.520055 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m16:47:04.521853 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:47:04.522767 [debug] [MainThread]: Connection 'create__mart_mart' was left open.
[0m16:47:04.523722 [debug] [MainThread]: On create__mart_mart: Close
[0m16:47:04.524508 [debug] [MainThread]: Connection 'create__mart_clean' was left open.
[0m16:47:04.525379 [debug] [MainThread]: On create__mart_clean: Close
[0m16:47:04.526254 [info ] [MainThread]: 
[0m16:47:04.527345 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 1.17 seconds (1.17s).
[0m16:47:04.528598 [error] [MainThread]: Encountered an error:
Database Error
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 497
   Code: 497. DB::Exception: ftw_user: Not enough privileges. To execute this query, it's necessary to have the grant CREATE DATABASE ON mart_mart.*. (ACCESS_DENIED) (version 23.12.6.19 (official build))
[0m16:47:04.530682 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 7.8179274, "process_in_blocks": "0", "process_kernel_time": 0.613648, "process_mem_max_rss": "112404", "process_out_blocks": "9376", "process_user_time": 6.605687}
[0m16:47:04.531933 [debug] [MainThread]: Command `dbt build` failed at 16:47:04.531627 after 7.82 seconds
[0m16:47:04.532938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790dcc352310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790dc8702fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790dc75b0700>]}
[0m16:47:04.534035 [debug] [MainThread]: Flushing usage events
[0m16:53:09.540925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x772185f48310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x772182ba6ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x772182ba6970>]}


============================== 16:53:09.550674 | e9b5ea38-360c-44ef-a888-47a45eff89a4 ==============================
[0m16:53:09.550674 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:53:09.551777 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'invocation_command': 'dbt build --profiles-dir . --target local', 'partial_parse': 'True', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/workdir/transforms/01_mpg/logs', 'empty': 'False', 'log_cache_events': 'False', 'printer_width': '80', 'cache_selected_only': 'False', 'introspect': 'True', 'log_format': 'default', 'version_check': 'True', 'quiet': 'False', 'static_parser': 'True', 'debug': 'False', 'indirect_selection': 'eager', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'no_print': 'None', 'profiles_dir': '.', 'use_colors': 'True', 'write_json': 'True'}
[0m16:53:10.129254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e9b5ea38-360c-44ef-a888-47a45eff89a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x772182aa9580>]}
[0m16:53:10.325367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e9b5ea38-360c-44ef-a888-47a45eff89a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x772182c085b0>]}
[0m16:53:10.326667 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m16:53:10.747090 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m16:53:11.133099 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m16:53:11.133961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e9b5ea38-360c-44ef-a888-47a45eff89a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x772183ede070>]}
[0m16:53:15.717845 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e9b5ea38-360c-44ef-a888-47a45eff89a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x772181e70130>]}
[0m16:53:16.070575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e9b5ea38-360c-44ef-a888-47a45eff89a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x772181d968b0>]}
[0m16:53:16.071434 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m16:53:16.074185 [info ] [MainThread]: 
[0m16:53:16.075241 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:53:16.125964 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:53:16.132637 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:53:16.151986 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:53:16.152665 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:53:16.614899 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:53:16.619280 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:53:16.623699 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:53:16.629006 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:53:16.648367 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m16:53:16.660440 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m16:53:16.661693 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m16:53:16.716217 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m16:53:16.725197 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:53:16.729161 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:53:16.732836 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e9b5ea38-360c-44ef-a888-47a45eff89a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x772181d29cd0>]}
[0m16:53:16.734716 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m16:53:16.736133 [info ] [MainThread]: 
[0m16:53:16.762244 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m16:53:16.763378 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m16:53:16.764418 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.mpg_standardized'
[0m16:53:16.765138 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m16:53:16.834506 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m16:53:16.836151 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m16:53:16.935692 [debug] [Thread-1  ]: Creating new relation mpg_standardized
[0m16:53:17.054936 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m16:53:17.163702 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

select
  toFloat64OrNull(mpg)            as mpg,
  toInt64OrNull(cylinders)        as cylinders,
  toFloat64OrNull(displacement)   as displacement,
  toFloat64OrNull(horsepower)     as horsepower,
  toInt64OrNull(weight)           as weight,
  toFloat64OrNull(acceleration)   as acceleration,
  toInt64OrNull(model_year)       as model_year,
  toString(origin)                as origin,
  toString(name)                  as make   -- raw column is `name`
from `raw`.`autompg___cars`
          )
        
        ...
[0m16:53:17.180701 [debug] [Thread-1  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

select
  toFloat64OrNull(mpg)            as mpg,
  toInt64OrNull(cylinders)        as cylinders,
  toFloat64OrNull(displacement)   as displacement,
  toFloat64OrNull(horsepower)     as horsepower,
  toInt64OrNull(weight)           as weight,
  toFloat64OrNull(acceleration)   as acceleration,
  toInt64OrNull(model_year)       as model_year,
  toString(origin)                as origin,
  toString(name)                  as make   -- raw column is `name`
from `raw`.`autompg___cars`
          )
        
        
[0m16:53:17.186953 [debug] [Thread-1  ]: Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 43
   Code: 43. DB::Exception: Illegal type Float64 of first argument of function toFloat64OrNull. Conversion functions with postfix 'OrZero' or 'OrNull' should take String argument: While processing toFloat64OrNull(mpg) AS mpg, toInt64OrNull(cylinders) AS cylinders, toFloat64OrNull(displacement) AS displacement, toFloat64OrNull(horsepower) AS horsepower, toInt64OrNull(weight) AS weight, toFloat64OrNull(acceleration) AS acceleration, toInt64OrNull(model_year) AS model_year, toString(origin) AS origin, toString(name) AS make. (ILLEGAL_TYPE_OF_ARGUMENT) (version 23.12.6.19 (official build))
[0m16:53:17.191584 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e9b5ea38-360c-44ef-a888-47a45eff89a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x772181066ca0>]}
[0m16:53:17.193336 [error] [Thread-1  ]: 1 of 2 ERROR creating sql table model `clean`.`mpg_standardized` ............... [[31mERROR[0m in 0.42s]
[0m16:53:17.195272 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m16:53:17.197975 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m16:53:17.199846 [info ] [Thread-3  ]: 2 of 2 SKIP relation mart.cylinders_by_origin .................................. [[33mSKIP[0m]
[0m16:53:17.201867 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m16:53:17.205368 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:53:17.206560 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m16:53:17.207723 [debug] [MainThread]: On list__clean: Close
[0m16:53:17.208793 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m16:53:17.209872 [debug] [MainThread]: On list__mart: Close
[0m16:53:17.210933 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m16:53:17.212075 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m16:53:17.213751 [info ] [MainThread]: 
[0m16:53:17.215083 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.14 seconds (1.14s).
[0m16:53:17.218121 [debug] [MainThread]: Command end result
[0m16:53:17.420247 [info ] [MainThread]: 
[0m16:53:17.421971 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:53:17.423403 [info ] [MainThread]: 
[0m16:53:17.425486 [error] [MainThread]:   Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 43
   Code: 43. DB::Exception: Illegal type Float64 of first argument of function toFloat64OrNull. Conversion functions with postfix 'OrZero' or 'OrNull' should take String argument: While processing toFloat64OrNull(mpg) AS mpg, toInt64OrNull(cylinders) AS cylinders, toFloat64OrNull(displacement) AS displacement, toFloat64OrNull(horsepower) AS horsepower, toInt64OrNull(weight) AS weight, toFloat64OrNull(acceleration) AS acceleration, toInt64OrNull(model_year) AS model_year, toString(origin) AS origin, toString(name) AS make. (ILLEGAL_TYPE_OF_ARGUMENT) (version 23.12.6.19 (official build))
[0m16:53:17.427000 [info ] [MainThread]: 
[0m16:53:17.428378 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
[0m16:53:17.431334 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 8.089641, "process_in_blocks": "0", "process_kernel_time": 0.597088, "process_mem_max_rss": "115328", "process_out_blocks": "10456", "process_user_time": 6.776556}
[0m16:53:17.432939 [debug] [MainThread]: Command `dbt build` failed at 16:53:17.432513 after 8.09 seconds
[0m16:53:17.434257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x772185f48310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77218231f160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x772182aa9580>]}
[0m16:53:17.435514 [debug] [MainThread]: Flushing usage events
[0m16:54:56.657055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b2981b40310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b297e7a7b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b297e7a79d0>]}


============================== 16:54:56.666034 | 6604c90a-9372-499a-9302-1b36ee427efc ==============================
[0m16:54:56.666034 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:54:56.667100 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'log_format': 'default', 'use_colors': 'True', 'quiet': 'False', 'target_path': 'None', 'debug': 'False', 'empty': 'False', 'indirect_selection': 'eager', 'partial_parse': 'True', 'profiles_dir': '.', 'version_check': 'True', 'warn_error': 'None', 'introspect': 'True', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'static_parser': 'True', 'fail_fast': 'False', 'write_json': 'True', 'no_print': 'None', 'invocation_command': 'dbt build --profiles-dir . --target local', 'log_path': '/workdir/transforms/01_mpg/logs', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m16:54:57.244820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6604c90a-9372-499a-9302-1b36ee427efc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b29810e3ca0>]}
[0m16:54:57.437277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6604c90a-9372-499a-9302-1b36ee427efc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b297e7e10a0>]}
[0m16:54:57.438524 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m16:54:57.848080 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m16:54:58.259842 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:54:58.260823 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m16:54:59.071733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6604c90a-9372-499a-9302-1b36ee427efc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b297db6b130>]}
[0m16:54:59.471917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6604c90a-9372-499a-9302-1b36ee427efc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b297da5a430>]}
[0m16:54:59.472757 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m16:54:59.475367 [info ] [MainThread]: 
[0m16:54:59.476363 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:54:59.488449 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:54:59.536166 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:54:59.570587 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:54:59.575068 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:55:00.206241 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:55:00.210446 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:55:00.212868 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:55:00.230585 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:55:00.434800 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m16:55:00.436326 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m16:55:00.457551 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m16:55:00.464831 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m16:55:00.476304 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:55:00.480483 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:55:00.484412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6604c90a-9372-499a-9302-1b36ee427efc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b297d51d880>]}
[0m16:55:00.486338 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m16:55:00.531803 [info ] [MainThread]: 
[0m16:55:00.558353 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m16:55:00.560177 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m16:55:00.561138 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__mart, now model.ex_01_mpg.mpg_standardized)
[0m16:55:00.561839 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m16:55:00.578873 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m16:55:00.580026 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m16:55:00.678593 [debug] [Thread-1  ]: Creating new relation mpg_standardized
[0m16:55:00.855097 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

select
  CAST(nullIf(CAST(mpg          AS String), '?') AS Float64) as mpg,
  CAST(nullIf(CAST(cylinders    AS String), '?') AS Int64)   as cylinders,
  CAST(nullIf(CAST(displacement AS String), '?') AS Float64) as displacement,
  CAST(nullIf(CAST(horsepower   AS String), '?') AS Float64) as horsepower,
  CAST(nullIf(CAST(weight       AS String), '?') AS Int64)   as weight,
  CAST(nullIf(CAST(acceleration AS String), '?') AS Float64) as acceleration,
  CAST(nullIf(CAST(model_year   AS String), '?') AS Int64)   as model_year,
  CAST(origin AS String) as origin,
  CAST(name   AS String) as make
from `raw`.`autompg___cars`
          )
        
        ...
[0m16:55:00.874905 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:55:00.891003 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized'
    
      and database = 'clean'
    
    order by position
  ...
[0m16:55:00.895910 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:55:00.934309 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m16:55:00.935747 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

select
  CAST(nullIf(CAST(mpg          AS String), '?') AS Float64) as mpg,
  CAST(nullIf(CAST(cylinders    AS String), '?') AS Int64)   as cylinders,
  CAST(nullIf(CAST(displacement AS String), '?') AS Float64) as displacement,
  CAST(nullIf(CAST(horsepower   AS String), '?') AS Float64) as horsepower,
  CAST(nullIf(CAST(weight       AS String), '?') AS Int64)   as weight,
  CAST(nullIf(CAST(acceleration AS String), '?') AS Float64) as acceleration,
  CAST(nullIf(CAST(model_year   AS String), '?') AS Int64)   as model_year,
  CAST(origin AS String) as origin,
  CAST(name   AS String) as make
from `raw`.`autompg___cars`
  ...
[0m16:55:00.951387 [debug] [Thread-1  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

select
  CAST(nullIf(CAST(mpg          AS String), '?') AS Float64) as mpg,
  CAST(nullIf(CAST(cylinders    AS String), '?') AS Int64)   as cylinders,
  CAST(nullIf(CAST(displacement AS String), '?') AS Float64) as displacement,
  CAST(nullIf(CAST(horsepower   AS String), '?') AS Float64) as horsepower,
  CAST(nullIf(CAST(weight       AS String), '?') AS Int64)   as weight,
  CAST(nullIf(CAST(acceleration AS String), '?') AS Float64) as acceleration,
  CAST(nullIf(CAST(model_year   AS String), '?') AS Int64)   as model_year,
  CAST(origin AS String) as origin,
  CAST(name   AS String) as make
from `raw`.`autompg___cars`
  
[0m16:55:00.954788 [debug] [Thread-1  ]: Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 349
   Code: 349. DB::Exception: Cannot convert NULL value to non-Nullable type: while executing 'FUNCTION CAST(horsepower :: 3, 'String' : 9) -> CAST(horsepower, 'String') String : 2'. (CANNOT_INSERT_NULL_IN_ORDINARY_COLUMN) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_mpg/models/clean/mpg_standardized.sql
[0m16:55:00.957337 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6604c90a-9372-499a-9302-1b36ee427efc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b297f9e3490>]}
[0m16:55:00.958508 [error] [Thread-1  ]: 1 of 2 ERROR creating sql table model `clean`.`mpg_standardized` ............... [[31mERROR[0m in 0.39s]
[0m16:55:00.959873 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m16:55:00.961401 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m16:55:00.962284 [info ] [Thread-3  ]: 2 of 2 SKIP relation mart.cylinders_by_origin .................................. [[33mSKIP[0m]
[0m16:55:00.963346 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m16:55:00.965196 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:55:00.965911 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m16:55:00.966457 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m16:55:00.966963 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m16:55:00.967451 [debug] [MainThread]: On list__clean: Close
[0m16:55:00.968159 [info ] [MainThread]: 
[0m16:55:00.968877 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.49 seconds (1.49s).
[0m16:55:00.970285 [debug] [MainThread]: Command end result
[0m16:55:01.061337 [info ] [MainThread]: 
[0m16:55:01.062320 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:55:01.062967 [info ] [MainThread]: 
[0m16:55:01.063895 [error] [MainThread]:   Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 349
   Code: 349. DB::Exception: Cannot convert NULL value to non-Nullable type: while executing 'FUNCTION CAST(horsepower :: 3, 'String' : 9) -> CAST(horsepower, 'String') String : 2'. (CANNOT_INSERT_NULL_IN_ORDINARY_COLUMN) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_mpg/models/clean/mpg_standardized.sql
[0m16:55:01.064585 [info ] [MainThread]: 
[0m16:55:01.065229 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
[0m16:55:01.066592 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 4.600109, "process_in_blocks": "0", "process_kernel_time": 0.580871, "process_mem_max_rss": "114416", "process_out_blocks": "10464", "process_user_time": 5.042442}
[0m16:55:01.067406 [debug] [MainThread]: Command `dbt build` failed at 16:55:01.067210 after 4.60 seconds
[0m16:55:01.068124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b2981b40310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b297da5aa60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b297dee1f70>]}
[0m16:55:01.068852 [debug] [MainThread]: Flushing usage events
[0m16:57:36.797025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76551d1ff310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765519e62a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765519e62940>]}


============================== 16:57:36.806578 | 608108d3-2acc-43bc-afdd-e5ef3386dbb8 ==============================
[0m16:57:36.806578 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:57:36.807724 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'profiles_dir': '.', 'indirect_selection': 'eager', 'partial_parse': 'True', 'use_colors': 'True', 'static_parser': 'True', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'debug': 'False', 'invocation_command': 'dbt build --profiles-dir . --target local', 'printer_width': '80', 'log_format': 'default', 'cache_selected_only': 'False', 'warn_error': 'None', 'use_experimental_parser': 'False', 'target_path': 'None', 'log_path': '/workdir/transforms/01_mpg/logs', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'write_json': 'True', 'empty': 'False', 'quiet': 'False', 'fail_fast': 'False', 'log_cache_events': 'False'}
[0m16:57:37.389971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '608108d3-2acc-43bc-afdd-e5ef3386dbb8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765519d64a30>]}
[0m16:57:37.587252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '608108d3-2acc-43bc-afdd-e5ef3386dbb8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76551a2b3250>]}
[0m16:57:37.588573 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m16:57:38.003424 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m16:57:38.418781 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:57:38.419821 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m16:57:39.289472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '608108d3-2acc-43bc-afdd-e5ef3386dbb8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765519232130>]}
[0m16:57:39.691486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '608108d3-2acc-43bc-afdd-e5ef3386dbb8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7655190efe20>]}
[0m16:57:39.692372 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m16:57:39.695054 [info ] [MainThread]: 
[0m16:57:39.696106 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:57:39.708224 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:57:39.714907 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:57:39.729927 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:57:39.733603 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:57:40.267861 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:57:40.286275 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:57:40.291747 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:57:40.298364 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:57:40.517639 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m16:57:40.519452 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m16:57:40.597065 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m16:57:40.601020 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m16:57:40.612183 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:57:40.614202 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:57:40.622372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '608108d3-2acc-43bc-afdd-e5ef3386dbb8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7655190afb50>]}
[0m16:57:40.624298 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m16:57:40.625716 [info ] [MainThread]: 
[0m16:57:40.700124 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m16:57:40.701340 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m16:57:40.702258 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__mart, now model.ex_01_mpg.mpg_standardized)
[0m16:57:40.703054 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m16:57:40.719431 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m16:57:40.720527 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m16:57:40.992841 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
          )
        
        ...
[0m16:57:41.013552 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:57:41.029376 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m16:57:41.035628 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:57:41.041732 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m16:57:41.042913 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
  ...
[0m16:57:41.050746 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:57:41.059115 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */
EXCHANGE TABLES `clean`.`mpg_standardized__dbt_backup` AND `clean`.`mpg_standardized` 
  
  ...
[0m16:57:41.085324 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:57:41.130224 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m16:57:41.134248 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:57:41.190003 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '608108d3-2acc-43bc-afdd-e5ef3386dbb8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765518cc7790>]}
[0m16:57:41.191267 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized` ................... [[32mOK[0m in 0.49s]
[0m16:57:41.192694 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m16:57:41.194806 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m16:57:41.196244 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m16:57:41.197889 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m16:57:41.198991 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m16:57:41.207090 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m16:57:41.208468 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m16:57:41.301457 [debug] [Thread-3  ]: Creating new relation cylinders_by_origin
[0m16:57:41.322908 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m16:57:41.430198 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m16:57:41.431831 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:57:41.443061 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:57:41.449477 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '608108d3-2acc-43bc-afdd-e5ef3386dbb8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765518cc7df0>]}
[0m16:57:41.452227 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 0.25s]
[0m16:57:41.454901 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m16:57:41.458618 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:57:41.459428 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m16:57:41.460268 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m16:57:41.461119 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m16:57:41.462136 [debug] [MainThread]: On list__clean: Close
[0m16:57:41.463684 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m16:57:41.464432 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m16:57:41.465754 [info ] [MainThread]: 
[0m16:57:41.466494 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.77 seconds (1.77s).
[0m16:57:41.468456 [debug] [MainThread]: Command end result
[0m16:57:41.620338 [info ] [MainThread]: 
[0m16:57:41.621907 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:57:41.623023 [info ] [MainThread]: 
[0m16:57:41.624279 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m16:57:41.626700 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 5.0217857, "process_in_blocks": "0", "process_kernel_time": 0.598008, "process_mem_max_rss": "114268", "process_out_blocks": "10480", "process_user_time": 5.281254}
[0m16:57:41.628002 [debug] [MainThread]: Command `dbt build` succeeded at 16:57:41.627678 after 5.02 seconds
[0m16:57:41.629083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76551d1ff310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765519e173a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765519e17700>]}
[0m16:57:41.630090 [debug] [MainThread]: Flushing usage events
[0m10:29:24.564673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74315181b310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74314e478a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74314e478940>]}


============================== 10:29:24.617579 | 137ce063-02c1-488c-8a25-e2b3b0384657 ==============================
[0m10:29:24.617579 [info ] [MainThread]: Running with dbt=1.8.9
[0m10:29:24.619237 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt build --profiles-dir . --target local', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'partial_parse': 'True', 'log_format': 'default', 'use_experimental_parser': 'False', 'version_check': 'True', 'indirect_selection': 'eager', 'printer_width': '80', 'no_print': 'None', 'log_path': '/workdir/transforms/01_mpg/logs', 'log_cache_events': 'False', 'profiles_dir': '.', 'fail_fast': 'False', 'quiet': 'False', 'use_colors': 'True', 'cache_selected_only': 'False', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'debug': 'False', 'empty': 'False'}
[0m10:29:25.263834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '137ce063-02c1-488c-8a25-e2b3b0384657', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x743150dc4fd0>]}
[0m10:29:25.535000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '137ce063-02c1-488c-8a25-e2b3b0384657', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74314ef5d430>]}
[0m10:29:25.536543 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m10:29:26.053557 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m10:29:26.503430 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:29:26.504081 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:29:26.638141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '137ce063-02c1-488c-8a25-e2b3b0384657', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74314dcfbe20>]}
[0m10:29:27.236372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '137ce063-02c1-488c-8a25-e2b3b0384657', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74314dc07c10>]}
[0m10:29:27.237525 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m10:29:27.241126 [info ] [MainThread]: 
[0m10:29:27.242487 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m10:29:27.258632 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m10:29:27.259967 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m10:29:27.331584 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:29:27.335457 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:29:27.895496 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m10:29:27.904636 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m10:29:27.906994 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:29:27.925123 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:29:28.026156 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m10:29:28.028917 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m10:29:28.050596 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m10:29:28.057142 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m10:29:28.068607 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:29:28.070403 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:29:28.145806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '137ce063-02c1-488c-8a25-e2b3b0384657', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74314db94670>]}
[0m10:29:28.147767 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m10:29:28.149274 [info ] [MainThread]: 
[0m10:29:28.229178 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m10:29:28.230775 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m10:29:28.232197 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.mpg_standardized'
[0m10:29:28.233234 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m10:29:28.253982 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m10:29:28.255206 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m10:29:28.527454 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m10:29:28.604195 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
          )
        
        ...
[0m10:29:28.628530 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m10:29:28.652375 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m10:29:28.657950 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:29:28.664817 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m10:29:28.666200 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
  ...
[0m10:29:28.672603 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:29:28.681769 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */
EXCHANGE TABLES `clean`.`mpg_standardized__dbt_backup` AND `clean`.`mpg_standardized` 
  
  ...
[0m10:29:28.685017 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:29:28.957349 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m10:29:28.960829 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:29:28.967306 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '137ce063-02c1-488c-8a25-e2b3b0384657', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x743150dbc820>]}
[0m10:29:28.968682 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized` ................... [[32mOK[0m in 0.73s]
[0m10:29:28.970114 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m10:29:28.971764 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m10:29:28.972903 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m10:29:28.974171 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m10:29:28.975077 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m10:29:29.030778 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m10:29:29.032044 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m10:29:29.135906 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m10:29:29.197873 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m10:29:29.199401 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin__dbt_tmp` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m10:29:29.215186 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m10:29:29.228341 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m10:29:29.231358 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:29:29.233483 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin` to `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m10:29:29.236302 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:29:29.243066 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin` 
  
  ...
[0m10:29:29.245897 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:29:29.247842 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin__dbt_tmp` to `mart`.`cylinders_by_origin` 
  
  ...
[0m10:29:29.250578 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:29:29.257266 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  ...
[0m10:29:29.260202 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m10:29:29.262714 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '137ce063-02c1-488c-8a25-e2b3b0384657', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74314ced2640>]}
[0m10:29:29.263838 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 0.29s]
[0m10:29:29.265176 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m10:29:29.267122 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:29:29.267681 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m10:29:29.268200 [debug] [MainThread]: On list__mart: Close
[0m10:29:29.268706 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m10:29:29.269191 [debug] [MainThread]: On list__clean: Close
[0m10:29:29.269679 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m10:29:29.270248 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m10:29:29.270740 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m10:29:29.271221 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m10:29:29.272098 [info ] [MainThread]: 
[0m10:29:29.272786 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 2.03 seconds (2.03s).
[0m10:29:29.274554 [debug] [MainThread]: Command end result
[0m10:29:29.429607 [info ] [MainThread]: 
[0m10:29:29.430586 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:29:29.431269 [info ] [MainThread]: 
[0m10:29:29.431933 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m10:29:29.433327 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 5.0828104, "process_in_blocks": "1320", "process_kernel_time": 0.638786, "process_mem_max_rss": "111484", "process_out_blocks": "9504", "process_user_time": 5.238449}
[0m10:29:29.434152 [debug] [MainThread]: Command `dbt build` succeeded at 10:29:29.433938 after 5.08 seconds
[0m10:29:29.434858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74315181b310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74314f740f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x743150dc4fd0>]}
[0m10:29:29.435469 [debug] [MainThread]: Flushing usage events
[0m15:01:30.514366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7206f9f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7203c00af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7203c009a0>]}


============================== 15:01:30.528193 | b64af2e6-6073-423f-8244-cf943957cb90 ==============================
[0m15:01:30.528193 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:01:30.542430 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'profiles_dir': '.', 'introspect': 'True', 'static_parser': 'True', 'version_check': 'True', 'fail_fast': 'False', 'invocation_command': 'dbt build --profiles-dir . --target local', 'log_format': 'default', 'partial_parse': 'True', 'warn_error': 'None', 'log_cache_events': 'False', 'use_colors': 'True', 'printer_width': '80', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'target_path': 'None'}
[0m15:01:30.929773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b64af2e6-6073-423f-8244-cf943957cb90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7206549fd0>]}
[0m15:01:31.053484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b64af2e6-6073-423f-8244-cf943957cb90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7203bcabe0>]}
[0m15:01:31.055664 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m15:01:31.287176 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m15:01:31.694999 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:01:31.696125 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m15:01:32.295846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b64af2e6-6073-423f-8244-cf943957cb90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72021ab130>]}
[0m15:01:32.633552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b64af2e6-6073-423f-8244-cf943957cb90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f720206eaf0>]}
[0m15:01:32.635037 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m15:01:32.639409 [info ] [MainThread]: 
[0m15:01:32.641223 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:01:32.660219 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:01:32.661350 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:01:32.697984 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:01:32.702405 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:01:33.155068 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:01:33.158208 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:01:33.162209 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:01:33.166021 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:01:33.304078 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m15:01:33.305354 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m15:01:33.322650 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m15:01:33.328209 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m15:01:33.338105 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:01:33.339870 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:01:33.364451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b64af2e6-6073-423f-8244-cf943957cb90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7201bb1bb0>]}
[0m15:01:33.366209 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m15:01:33.367473 [info ] [MainThread]: 
[0m15:01:33.382924 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m15:01:33.384063 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m15:01:33.384987 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__mart, now model.ex_01_mpg.mpg_standardized)
[0m15:01:33.385703 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m15:01:33.401921 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m15:01:33.416144 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m15:01:33.568333 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  nullif(mpg, '?')::Float64           as mpg,
  nullif(cylinders, '?')::Int64       as cylinders,
  nullif(displacement, '?')::Float64  as displacement,
  nullif(horsepower, '?')::Float64    as horsepower,
  nullif(weight, '?')::Int64          as weight,
  nullif(acceleration, '?')::Float64  as acceleration,
  nullif(model_year, '?')::Int64      as model_year,
  nullif(origin, '?')::String         as origin,
  nullif(name, '?')::String           as make
from `raw`.`autompg___cars`
          )
        
        ...
[0m15:01:33.613285 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m15:01:33.643462 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m15:01:33.656208 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:01:33.666040 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m15:01:33.667656 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  nullif(mpg, '?')::Float64           as mpg,
  nullif(cylinders, '?')::Int64       as cylinders,
  nullif(displacement, '?')::Float64  as displacement,
  nullif(horsepower, '?')::Float64    as horsepower,
  nullif(weight, '?')::Int64          as weight,
  nullif(acceleration, '?')::Float64  as acceleration,
  nullif(model_year, '?')::Int64      as model_year,
  nullif(origin, '?')::String         as origin,
  nullif(name, '?')::String           as make
from `raw`.`autompg___cars`
  ...
[0m15:01:33.742226 [debug] [Thread-1  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  nullif(mpg, '?')::Float64           as mpg,
  nullif(cylinders, '?')::Int64       as cylinders,
  nullif(displacement, '?')::Float64  as displacement,
  nullif(horsepower, '?')::Float64    as horsepower,
  nullif(weight, '?')::Int64          as weight,
  nullif(acceleration, '?')::Float64  as acceleration,
  nullif(model_year, '?')::Int64      as model_year,
  nullif(origin, '?')::String         as origin,
  nullif(name, '?')::String           as make
from `raw`.`autompg___cars`
  
[0m15:01:33.755835 [debug] [Thread-1  ]: Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 53
   Code: 53. DB::Exception: Cannot convert string ? to type Float64. (TYPE_MISMATCH) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_mpg/models/clean/mpg_standardized.sql
[0m15:01:33.759165 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b64af2e6-6073-423f-8244-cf943957cb90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7203911580>]}
[0m15:01:33.760625 [error] [Thread-1  ]: 1 of 2 ERROR creating sql table model `clean`.`mpg_standardized` ............... [[31mERROR[0m in 0.37s]
[0m15:01:33.762850 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m15:01:33.765145 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m15:01:33.766368 [info ] [Thread-3  ]: 2 of 2 SKIP relation mart.cylinders_by_origin .................................. [[33mSKIP[0m]
[0m15:01:33.768219 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m15:01:33.771244 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:01:33.772287 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m15:01:33.773262 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m15:01:33.774190 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m15:01:33.775164 [debug] [MainThread]: On list__clean: Close
[0m15:01:33.776609 [info ] [MainThread]: 
[0m15:01:33.777956 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.14 seconds (1.14s).
[0m15:01:33.781011 [debug] [MainThread]: Command end result
[0m15:01:33.868528 [info ] [MainThread]: 
[0m15:01:33.869929 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:01:33.871020 [info ] [MainThread]: 
[0m15:01:33.872406 [error] [MainThread]:   Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 53
   Code: 53. DB::Exception: Cannot convert string ? to type Float64. (TYPE_MISMATCH) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_mpg/models/clean/mpg_standardized.sql
[0m15:01:33.873474 [info ] [MainThread]: 
[0m15:01:33.874501 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
[0m15:01:33.877516 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 3.5232182, "process_in_blocks": "73712", "process_kernel_time": 0.928247, "process_mem_max_rss": "113716", "process_out_blocks": "10472", "process_user_time": 6.787495}
[0m15:01:33.878825 [debug] [MainThread]: Command `dbt build` failed at 15:01:33.878525 after 3.52 seconds
[0m15:01:33.879862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7206f9f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7203cf53d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7201fe4d30>]}
[0m15:01:33.880857 [debug] [MainThread]: Flushing usage events
[0m15:04:39.189319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bb41e47b310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bb41b0efa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bb41b0ef940>]}


============================== 15:04:39.199820 | 22a4ac5c-0807-4463-a29e-9eb825d0ad9f ==============================
[0m15:04:39.199820 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:04:39.200938 [debug] [MainThread]: running dbt with arguments {'empty': 'False', 'debug': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'introspect': 'True', 'indirect_selection': 'eager', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'printer_width': '80', 'version_check': 'True', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'target_path': 'None', 'log_format': 'default', 'profiles_dir': '.', 'log_path': '/workdir/transforms/01_mpg/logs', 'static_parser': 'True', 'use_colors': 'True', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'no_print': 'None', 'invocation_command': 'dbt build --profiles-dir . --target local'}
[0m15:04:39.614140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '22a4ac5c-0807-4463-a29e-9eb825d0ad9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bb41da20fd0>]}
[0m15:04:39.767070 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '22a4ac5c-0807-4463-a29e-9eb825d0ad9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bb41c3f6730>]}
[0m15:04:39.769190 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m15:04:40.074617 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m15:04:40.412866 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m15:04:40.413951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '22a4ac5c-0807-4463-a29e-9eb825d0ad9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bb41c40f760>]}
[0m15:04:44.332900 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '22a4ac5c-0807-4463-a29e-9eb825d0ad9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bb41958a130>]}
[0m15:04:44.672896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '22a4ac5c-0807-4463-a29e-9eb825d0ad9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bb419624730>]}
[0m15:04:44.674161 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m15:04:44.678040 [info ] [MainThread]: 
[0m15:04:44.679849 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:04:44.693948 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:04:44.695054 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:04:44.726033 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:04:44.741968 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:04:48.214340 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:04:48.355690 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:04:48.459108 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m15:04:48.597162 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m15:04:48.600587 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m15:04:48.601574 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m15:04:48.617216 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m15:04:48.625407 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m15:04:48.865205 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m15:04:48.873793 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m15:04:48.876438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '22a4ac5c-0807-4463-a29e-9eb825d0ad9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bb4193b5f70>]}
[0m15:04:48.877921 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m15:04:48.878915 [info ] [MainThread]: 
[0m15:04:48.898553 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m15:04:48.899766 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m15:04:48.900914 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.mpg_standardized'
[0m15:04:48.901692 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m15:04:48.925761 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m15:04:48.927768 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m15:04:48.985653 [debug] [Thread-1  ]: Creating new relation mpg_standardized
[0m15:04:49.055054 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m15:04:51.772777 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64OrNull(mpg)          as mpg,
  toInt64OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt64OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt64OrNull(model_year)     as model_year,
  nullIf(origin, '?')           as origin,
  nullIf(name, '?')             as make
from `raw`.`autompg___cars`
          )
        
        ...
[0m15:04:52.030510 [debug] [Thread-1  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64OrNull(mpg)          as mpg,
  toInt64OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt64OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt64OrNull(model_year)     as model_year,
  nullIf(origin, '?')           as origin,
  nullIf(name, '?')             as make
from `raw`.`autompg___cars`
          )
        
        
[0m15:04:52.038868 [debug] [Thread-1  ]: Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 60
   Code: 60. DB::Exception: Table raw.autompg___cars does not exist. (UNKNOWN_TABLE) (version 23.12.6.19 (official build))
[0m15:04:52.044225 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '22a4ac5c-0807-4463-a29e-9eb825d0ad9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bb418738100>]}
[0m15:04:52.046729 [error] [Thread-1  ]: 1 of 2 ERROR creating sql table model `clean`.`mpg_standardized` ............... [[31mERROR[0m in 3.14s]
[0m15:04:52.049778 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m15:04:52.054480 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m15:04:52.056312 [info ] [Thread-3  ]: 2 of 2 SKIP relation mart.cylinders_by_origin .................................. [[33mSKIP[0m]
[0m15:04:52.057856 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m15:04:52.062115 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:04:52.063497 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m15:04:52.064851 [debug] [MainThread]: On list__clean: Close
[0m15:04:52.065751 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m15:04:52.066925 [debug] [MainThread]: On list__mart: Close
[0m15:04:52.068024 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m15:04:52.069203 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m15:04:52.070609 [info ] [MainThread]: 
[0m15:04:52.071915 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 7.39 seconds (7.39s).
[0m15:04:52.074352 [debug] [MainThread]: Command end result
[0m15:04:52.141814 [info ] [MainThread]: 
[0m15:04:52.142903 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:04:52.143844 [info ] [MainThread]: 
[0m15:04:52.144848 [error] [MainThread]:   Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 60
   Code: 60. DB::Exception: Table raw.autompg___cars does not exist. (UNKNOWN_TABLE) (version 23.12.6.19 (official build))
[0m15:04:52.145703 [info ] [MainThread]: 
[0m15:04:52.146905 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
[0m15:04:52.149220 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 13.082366, "process_in_blocks": "19264", "process_kernel_time": 0.978927, "process_mem_max_rss": "115072", "process_out_blocks": "10464", "process_user_time": 10.204092}
[0m15:04:52.150384 [debug] [MainThread]: Command `dbt build` failed at 15:04:52.150069 after 13.08 seconds
[0m15:04:52.151280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bb41e47b310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bb41af56340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bb41da20fd0>]}
[0m15:04:52.153569 [debug] [MainThread]: Flushing usage events
[0m15:07:30.170737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x747459a6b310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7474566d3be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7474566d3a90>]}


============================== 15:07:30.182776 | e4a47e31-46ae-4d76-9945-661ca3b2446e ==============================
[0m15:07:30.182776 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:07:30.184018 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '.', 'partial_parse': 'True', 'write_json': 'True', 'warn_error': 'None', 'printer_width': '80', 'log_format': 'default', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'empty': 'False', 'introspect': 'True', 'quiet': 'False', 'debug': 'False', 'cache_selected_only': 'False', 'use_colors': 'True', 'target_path': 'None', 'version_check': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_cache_events': 'False', 'invocation_command': 'dbt build --profiles-dir . --target local', 'static_parser': 'True'}
[0m15:07:30.578284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e4a47e31-46ae-4d76-9945-661ca3b2446e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x747456617490>]}
[0m15:07:30.696197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e4a47e31-46ae-4d76-9945-661ca3b2446e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7474566b0dc0>]}
[0m15:07:30.697710 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m15:07:30.916014 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m15:07:31.155265 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m15:07:31.156580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e4a47e31-46ae-4d76-9945-661ca3b2446e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7474561559d0>]}
[0m15:07:34.500431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e4a47e31-46ae-4d76-9945-661ca3b2446e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x747454b80130>]}
[0m15:07:34.772687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e4a47e31-46ae-4d76-9945-661ca3b2446e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x747454a9e1f0>]}
[0m15:07:34.773687 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m15:07:34.777122 [info ] [MainThread]: 
[0m15:07:34.778619 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:07:34.796066 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:07:34.797154 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:07:34.827770 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:07:34.822806 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:07:35.159932 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:07:35.164780 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:07:35.166273 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:07:35.171295 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:07:35.203973 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m15:07:35.205050 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m15:07:35.221910 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m15:07:35.227426 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m15:07:35.235356 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:07:35.237421 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:07:35.256388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e4a47e31-46ae-4d76-9945-661ca3b2446e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74745464ca00>]}
[0m15:07:35.257707 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m15:07:35.258763 [info ] [MainThread]: 
[0m15:07:35.275355 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m15:07:35.276642 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m15:07:35.277845 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.mpg_standardized'
[0m15:07:35.278713 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m15:07:35.299704 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m15:07:35.301041 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m15:07:35.380315 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m15:07:35.445873 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m15:07:35.450108 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:07:35.518761 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64OrNull(mpg)          as mpg,
  toInt64OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt64OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt64OrNull(model_year)     as model_year,
  nullIf(origin, '?')           as origin,
  nullIf(name, '?')             as make
from `raw`.`autompg___cars`
          )
        
        ...
[0m15:07:35.548146 [debug] [Thread-1  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64OrNull(mpg)          as mpg,
  toInt64OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt64OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt64OrNull(model_year)     as model_year,
  nullIf(origin, '?')           as origin,
  nullIf(name, '?')             as make
from `raw`.`autompg___cars`
          )
        
        
[0m15:07:35.553415 [debug] [Thread-1  ]: Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 43
   Code: 43. DB::Exception: Illegal type Float64 of first argument of function toFloat64OrNull. Conversion functions with postfix 'OrZero' or 'OrNull' should take String argument: While processing toFloat64OrNull(mpg) AS mpg, toInt64OrNull(cylinders) AS cylinders, toFloat64OrNull(displacement) AS displacement, toFloat64OrNull(horsepower) AS horsepower, toInt64OrNull(weight) AS weight, toFloat64OrNull(acceleration) AS acceleration, toInt64OrNull(model_year) AS model_year, nullIf(origin, '?') AS origin, nullIf(name, '?') AS make. (ILLEGAL_TYPE_OF_ARGUMENT) (version 23.12.6.19 (official build))
[0m15:07:35.556777 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4a47e31-46ae-4d76-9945-661ca3b2446e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x747454747c70>]}
[0m15:07:35.558750 [error] [Thread-1  ]: 1 of 2 ERROR creating sql table model `clean`.`mpg_standardized` ............... [[31mERROR[0m in 0.28s]
[0m15:07:35.560321 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m15:07:35.562389 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m15:07:35.563950 [info ] [Thread-3  ]: 2 of 2 SKIP relation mart.cylinders_by_origin .................................. [[33mSKIP[0m]
[0m15:07:35.565562 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m15:07:35.567997 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:07:35.568715 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m15:07:35.569300 [debug] [MainThread]: On list__clean: Close
[0m15:07:35.569947 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m15:07:35.570644 [debug] [MainThread]: On list__mart: Close
[0m15:07:35.571499 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m15:07:35.572012 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m15:07:35.572883 [info ] [MainThread]: 
[0m15:07:35.573661 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.79 seconds (0.79s).
[0m15:07:35.575642 [debug] [MainThread]: Command end result
[0m15:07:35.664739 [info ] [MainThread]: 
[0m15:07:35.666156 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:07:35.667823 [info ] [MainThread]: 
[0m15:07:35.669285 [error] [MainThread]:   Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 43
   Code: 43. DB::Exception: Illegal type Float64 of first argument of function toFloat64OrNull. Conversion functions with postfix 'OrZero' or 'OrNull' should take String argument: While processing toFloat64OrNull(mpg) AS mpg, toInt64OrNull(cylinders) AS cylinders, toFloat64OrNull(displacement) AS displacement, toFloat64OrNull(horsepower) AS horsepower, toInt64OrNull(weight) AS weight, toFloat64OrNull(acceleration) AS acceleration, toInt64OrNull(model_year) AS model_year, nullIf(origin, '?') AS origin, nullIf(name, '?') AS make. (ILLEGAL_TYPE_OF_ARGUMENT) (version 23.12.6.19 (official build))
[0m15:07:35.670468 [info ] [MainThread]: 
[0m15:07:35.671572 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
[0m15:07:35.673916 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 5.631135, "process_in_blocks": "19128", "process_kernel_time": 0.824312, "process_mem_max_rss": "115384", "process_out_blocks": "10456", "process_user_time": 9.298249}
[0m15:07:35.675339 [debug] [MainThread]: Command `dbt build` failed at 15:07:35.674973 after 5.63 seconds
[0m15:07:35.676482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x747459a6b310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x747457a08430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x747454b1e4c0>]}
[0m15:07:35.677634 [debug] [MainThread]: Flushing usage events
[0m15:09:42.946328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a1e57454310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a1e540a4a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a1e540a4940>]}


============================== 15:09:42.957984 | 13f005ef-bd73-487c-a4e2-121a3ccb6f6a ==============================
[0m15:09:42.957984 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:09:42.959334 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'cache_selected_only': 'False', 'debug': 'False', 'target_path': 'None', 'warn_error': 'None', 'static_parser': 'True', 'log_path': '/workdir/transforms/01_mpg/logs', 'indirect_selection': 'eager', 'empty': 'False', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'printer_width': '80', 'partial_parse': 'True', 'profiles_dir': '.', 'log_format': 'default', 'version_check': 'True', 'no_print': 'None', 'invocation_command': 'dbt build --profiles-dir . --target local', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_cache_events': 'False', 'use_colors': 'True', 'fail_fast': 'False', 'use_experimental_parser': 'False'}
[0m15:09:43.368710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '13f005ef-bd73-487c-a4e2-121a3ccb6f6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a1e53f10a30>]}
[0m15:09:43.532278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '13f005ef-bd73-487c-a4e2-121a3ccb6f6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a1e54098640>]}
[0m15:09:43.534392 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m15:09:43.788163 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m15:09:44.093503 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:09:44.094623 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m15:09:44.728298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '13f005ef-bd73-487c-a4e2-121a3ccb6f6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a1e52654130>]}
[0m15:09:45.057767 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '13f005ef-bd73-487c-a4e2-121a3ccb6f6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a1e52516d30>]}
[0m15:09:45.058840 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m15:09:45.062543 [info ] [MainThread]: 
[0m15:09:45.064184 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:09:45.079371 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:09:45.080721 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:09:45.119834 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:09:45.127697 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:09:45.462035 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:09:45.466912 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:09:45.468398 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:09:45.472545 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:09:45.583915 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m15:09:45.585047 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m15:09:45.600676 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m15:09:45.607796 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m15:09:45.616179 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:09:45.617745 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:09:45.639516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '13f005ef-bd73-487c-a4e2-121a3ccb6f6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a1e52078a30>]}
[0m15:09:45.641279 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m15:09:45.642469 [info ] [MainThread]: 
[0m15:09:45.665059 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m15:09:45.666809 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m15:09:45.667887 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__mart, now model.ex_01_mpg.mpg_standardized)
[0m15:09:45.668912 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m15:09:45.690167 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m15:09:45.691557 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m15:09:45.818447 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  cast(nullIf(mpg, '?') as Float64)          as mpg,
  cast(nullIf(cylinders, '?') as Int64)      as cylinders,
  cast(nullIf(displacement, '?') as Float64) as displacement,
  cast(nullIf(horsepower, '?') as Float64)   as horsepower,
  cast(nullIf(weight, '?') as Int64)         as weight,
  cast(nullIf(acceleration, '?') as Float64) as acceleration,
  cast(nullIf(model_year, '?') as Int64)     as model_year,
  nullIf(origin, '?')                        as origin,
  nullIf(name, '?')                          as make
from `raw`.`autompg___cars`
          )
        
        ...
[0m15:09:45.837416 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m15:09:45.858591 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m15:09:45.865042 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:09:45.876553 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m15:09:45.878826 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  cast(nullIf(mpg, '?') as Float64)          as mpg,
  cast(nullIf(cylinders, '?') as Int64)      as cylinders,
  cast(nullIf(displacement, '?') as Float64) as displacement,
  cast(nullIf(horsepower, '?') as Float64)   as horsepower,
  cast(nullIf(weight, '?') as Int64)         as weight,
  cast(nullIf(acceleration, '?') as Float64) as acceleration,
  cast(nullIf(model_year, '?') as Int64)     as model_year,
  nullIf(origin, '?')                        as origin,
  nullIf(name, '?')                          as make
from `raw`.`autompg___cars`
  ...
[0m15:09:45.885800 [debug] [Thread-1  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  cast(nullIf(mpg, '?') as Float64)          as mpg,
  cast(nullIf(cylinders, '?') as Int64)      as cylinders,
  cast(nullIf(displacement, '?') as Float64) as displacement,
  cast(nullIf(horsepower, '?') as Float64)   as horsepower,
  cast(nullIf(weight, '?') as Int64)         as weight,
  cast(nullIf(acceleration, '?') as Float64) as acceleration,
  cast(nullIf(model_year, '?') as Int64)     as model_year,
  nullIf(origin, '?')                        as origin,
  nullIf(name, '?')                          as make
from `raw`.`autompg___cars`
  
[0m15:09:45.891014 [debug] [Thread-1  ]: Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 53
   Code: 53. DB::Exception: Cannot convert string ? to type Float64. (TYPE_MISMATCH) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_mpg/models/clean/mpg_standardized.sql
[0m15:09:45.894808 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13f005ef-bd73-487c-a4e2-121a3ccb6f6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a1e575ea640>]}
[0m15:09:45.896787 [error] [Thread-1  ]: 1 of 2 ERROR creating sql table model `clean`.`mpg_standardized` ............... [[31mERROR[0m in 0.22s]
[0m15:09:45.898903 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m15:09:45.900779 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m15:09:45.902605 [info ] [Thread-3  ]: 2 of 2 SKIP relation mart.cylinders_by_origin .................................. [[33mSKIP[0m]
[0m15:09:45.904337 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m15:09:45.906924 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:09:45.907696 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m15:09:45.908292 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m15:09:45.908827 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m15:09:45.909718 [debug] [MainThread]: On list__clean: Close
[0m15:09:45.910681 [info ] [MainThread]: 
[0m15:09:45.911621 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.85 seconds (0.85s).
[0m15:09:45.913665 [debug] [MainThread]: Command end result
[0m15:09:45.982222 [info ] [MainThread]: 
[0m15:09:45.983196 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:09:45.983865 [info ] [MainThread]: 
[0m15:09:45.984802 [error] [MainThread]:   Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 53
   Code: 53. DB::Exception: Cannot convert string ? to type Float64. (TYPE_MISMATCH) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_mpg/models/clean/mpg_standardized.sql
[0m15:09:45.985478 [info ] [MainThread]: 
[0m15:09:45.986156 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
[0m15:09:45.987815 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 3.1680892, "process_in_blocks": "0", "process_kernel_time": 0.801163, "process_mem_max_rss": "114184", "process_out_blocks": "10472", "process_user_time": 6.977718}
[0m15:09:45.988844 [debug] [MainThread]: Command `dbt build` failed at 15:09:45.988542 after 3.17 seconds
[0m15:09:45.990014 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a1e57454310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a1e53930280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a1e54bd80a0>]}
[0m15:09:45.991050 [debug] [MainThread]: Flushing usage events
[0m15:21:56.776801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74cf6c0d2310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74cf68d3ea90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74cf68d3e940>]}


============================== 15:21:56.787440 | 1af09b9b-b935-41cb-a250-580ad68d2115 ==============================
[0m15:21:56.787440 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:21:56.788708 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'invocation_command': 'dbt build --profiles-dir . --target local', 'log_format': 'default', 'profiles_dir': '.', 'introspect': 'True', 'printer_width': '80', 'quiet': 'False', 'static_parser': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'cache_selected_only': 'False', 'debug': 'False', 'no_print': 'None', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'log_path': '/workdir/transforms/01_mpg/logs', 'fail_fast': 'False', 'log_cache_events': 'False', 'warn_error': 'None', 'use_colors': 'True', 'write_json': 'True', 'target_path': 'None', 'empty': 'False'}
[0m15:21:57.255997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1af09b9b-b935-41cb-a250-580ad68d2115', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74cf68d020d0>]}
[0m15:21:57.438294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1af09b9b-b935-41cb-a250-580ad68d2115', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74cf6c2fcd90>]}
[0m15:21:57.440504 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m15:21:57.667301 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m15:21:57.951154 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:21:57.952866 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m15:21:58.589431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1af09b9b-b935-41cb-a250-580ad68d2115', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74cf672e1130>]}
[0m15:21:58.871979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1af09b9b-b935-41cb-a250-580ad68d2115', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74cf672f98e0>]}
[0m15:21:58.873250 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m15:21:58.876758 [info ] [MainThread]: 
[0m15:21:58.878671 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:21:58.894358 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:21:58.895920 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:21:58.929002 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:21:58.927717 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:21:59.252841 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:21:59.257446 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:21:59.274700 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:21:59.280423 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:21:59.381568 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m15:21:59.382815 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m15:21:59.398737 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m15:21:59.404772 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m15:21:59.412942 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:21:59.414754 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:21:59.437852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1af09b9b-b935-41cb-a250-580ad68d2115', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74cf6694c760>]}
[0m15:21:59.439509 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m15:21:59.440647 [info ] [MainThread]: 
[0m15:21:59.462546 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m15:21:59.464603 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m15:21:59.466324 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__clean, now model.ex_01_mpg.mpg_standardized)
[0m15:21:59.467909 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m15:21:59.493296 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m15:21:59.494851 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m15:21:59.573816 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m15:21:59.578366 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:21:59.644256 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

-- models/clean/autompg_casted.sql
select
  toFloat64OrNull(nullIf(toString(mpg),          '?')) as mpg,
  toInt64OrNull  (nullIf(toString(cylinders),    '?')) as cylinders,
  toFloat64OrNull(nullIf(toString(displacement), '?')) as displacement,
  toFloat64OrNull(nullIf(toString(horsepower),   '?')) as horsepower,
  toInt64OrNull  (nullIf(toString(weight),       '?')) as weight,
  toFloat64OrNull(nullIf(toString(acceleration), '?')) as acceleration,
  toInt64OrNull  (nullIf(toString(model_year),   '?')) as model_year,
  nullIf(toString(origin), '?')                        as origin,
  nullIf(toString(name),   '?')                        as make
from `raw`.`autompg___cars`
          )
        
        ...
[0m15:21:59.667968 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m15:21:59.689121 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m15:21:59.694541 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:21:59.702196 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m15:21:59.703744 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

-- models/clean/autompg_casted.sql
select
  toFloat64OrNull(nullIf(toString(mpg),          '?')) as mpg,
  toInt64OrNull  (nullIf(toString(cylinders),    '?')) as cylinders,
  toFloat64OrNull(nullIf(toString(displacement), '?')) as displacement,
  toFloat64OrNull(nullIf(toString(horsepower),   '?')) as horsepower,
  toInt64OrNull  (nullIf(toString(weight),       '?')) as weight,
  toFloat64OrNull(nullIf(toString(acceleration), '?')) as acceleration,
  toInt64OrNull  (nullIf(toString(model_year),   '?')) as model_year,
  nullIf(toString(origin), '?')                        as origin,
  nullIf(toString(name),   '?')                        as make
from `raw`.`autompg___cars`
  ...
[0m15:21:59.712463 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:21:59.721909 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */
EXCHANGE TABLES `clean`.`mpg_standardized__dbt_backup` AND `clean`.`mpg_standardized` 
  
  ...
[0m15:21:59.725847 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:21:59.775492 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m15:21:59.779211 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:21:59.786072 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1af09b9b-b935-41cb-a250-580ad68d2115', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74cf664fdaf0>]}
[0m15:21:59.787473 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized` ................... [[32mOK[0m in 0.32s]
[0m15:21:59.788964 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m15:21:59.790559 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m15:21:59.791751 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m15:21:59.793082 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m15:21:59.794034 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m15:21:59.801849 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m15:21:59.803385 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m15:21:59.860067 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m15:21:59.924735 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m15:21:59.926720 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin__dbt_tmp` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:21:59.947530 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m15:21:59.965427 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m15:21:59.968912 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:21:59.971615 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin` to `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m15:21:59.974939 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:21:59.982042 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin` 
  
  ...
[0m15:21:59.985467 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:21:59.988651 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin__dbt_tmp` to `mart`.`cylinders_by_origin` 
  
  ...
[0m15:21:59.992997 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:22:00.002759 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  ...
[0m15:22:00.007126 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:22:00.010735 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1af09b9b-b935-41cb-a250-580ad68d2115', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74cf66d70df0>]}
[0m15:22:00.012790 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 0.22s]
[0m15:22:00.014454 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m15:22:00.016890 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:22:00.017932 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m15:22:00.018584 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m15:22:00.019214 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m15:22:00.019938 [debug] [MainThread]: On list__mart: Close
[0m15:22:00.020706 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m15:22:00.021620 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m15:22:00.022919 [info ] [MainThread]: 
[0m15:22:00.023679 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.14 seconds (1.14s).
[0m15:22:00.025620 [debug] [MainThread]: Command end result
[0m15:22:00.092571 [info ] [MainThread]: 
[0m15:22:00.093689 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:22:00.094668 [info ] [MainThread]: 
[0m15:22:00.095746 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m15:22:00.097837 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 3.4367929, "process_in_blocks": "0", "process_kernel_time": 0.806907, "process_mem_max_rss": "114068", "process_out_blocks": "10488", "process_user_time": 7.081189}
[0m15:22:00.099255 [debug] [MainThread]: Command `dbt build` succeeded at 15:22:00.098868 after 3.44 seconds
[0m15:22:00.099978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74cf6c0d2310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74cf68b284f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74cf68b28c40>]}
[0m15:22:00.100689 [debug] [MainThread]: Flushing usage events
[0m15:24:47.695807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae4e473c310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae4e13a3a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae4e13a3910>]}


============================== 15:24:47.711963 | 35d170f0-6ce1-4892-9142-e2106f8b263b ==============================
[0m15:24:47.711963 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:24:47.713816 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'use_colors': 'True', 'invocation_command': 'dbt build --profiles-dir . --target local', 'write_json': 'True', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'log_path': '/workdir/transforms/01_mpg/logs', 'printer_width': '80', 'no_print': 'None', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'indirect_selection': 'eager', 'fail_fast': 'False', 'partial_parse': 'True', 'log_format': 'default', 'warn_error': 'None', 'profiles_dir': '.', 'use_experimental_parser': 'False', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False', 'empty': 'False', 'version_check': 'True'}
[0m15:24:48.104056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '35d170f0-6ce1-4892-9142-e2106f8b263b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae4e12eb3d0>]}
[0m15:24:48.229932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '35d170f0-6ce1-4892-9142-e2106f8b263b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae4e13f3790>]}
[0m15:24:48.231741 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m15:24:48.437312 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m15:24:48.718813 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:24:48.720339 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m15:24:49.301668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '35d170f0-6ce1-4892-9142-e2106f8b263b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae4df94a130>]}
[0m15:24:49.649292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '35d170f0-6ce1-4892-9142-e2106f8b263b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae4df80d970>]}
[0m15:24:49.650444 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m15:24:49.653755 [info ] [MainThread]: 
[0m15:24:49.655574 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:24:49.671712 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:24:49.673281 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:24:49.703528 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:24:49.717213 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:24:50.044566 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:24:50.050820 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:24:50.053565 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:24:50.059527 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:24:50.167803 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m15:24:50.168845 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m15:24:50.187391 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m15:24:50.192404 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m15:24:50.200351 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:24:50.202077 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:24:50.222043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '35d170f0-6ce1-4892-9142-e2106f8b263b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae4df350dc0>]}
[0m15:24:50.223440 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m15:24:50.224278 [info ] [MainThread]: 
[0m15:24:50.240586 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m15:24:50.242527 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m15:24:50.243671 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__mart, now model.ex_01_mpg.mpg_standardized)
[0m15:24:50.244457 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m15:24:50.265575 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m15:24:50.266911 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m15:24:50.392211 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

-- models/clean/autompg_casted.sql
SELECT
  CAST(NULLIF(mpg, '?')          AS FLOAT) AS mpg,
  CAST(NULLIF(cylinders, '?')    AS INT)   AS cylinders,
  CAST(NULLIF(displacement, '?') AS FLOAT) AS displacement,
  CAST(NULLIF(horsepower, '?')   AS FLOAT) AS horsepower,
  CAST(NULLIF(weight, '?')       AS INT)   AS weight,
  CAST(NULLIF(acceleration, '?') AS FLOAT) AS acceleration,
  CAST(NULLIF(model_year, '?')   AS INT)   AS model_year,
  NULLIF(origin, '?')                       AS origin,
  NULLIF(name,   '?')                       AS make

from `raw`.`autompg___cars`
          )
        
        ...
[0m15:24:50.414854 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m15:24:50.437723 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m15:24:50.443566 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:24:50.453111 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m15:24:50.454863 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

-- models/clean/autompg_casted.sql
SELECT
  CAST(NULLIF(mpg, '?')          AS FLOAT) AS mpg,
  CAST(NULLIF(cylinders, '?')    AS INT)   AS cylinders,
  CAST(NULLIF(displacement, '?') AS FLOAT) AS displacement,
  CAST(NULLIF(horsepower, '?')   AS FLOAT) AS horsepower,
  CAST(NULLIF(weight, '?')       AS INT)   AS weight,
  CAST(NULLIF(acceleration, '?') AS FLOAT) AS acceleration,
  CAST(NULLIF(model_year, '?')   AS INT)   AS model_year,
  NULLIF(origin, '?')                       AS origin,
  NULLIF(name,   '?')                       AS make

from `raw`.`autompg___cars`
  ...
[0m15:24:50.460330 [debug] [Thread-1  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

-- models/clean/autompg_casted.sql
SELECT
  CAST(NULLIF(mpg, '?')          AS FLOAT) AS mpg,
  CAST(NULLIF(cylinders, '?')    AS INT)   AS cylinders,
  CAST(NULLIF(displacement, '?') AS FLOAT) AS displacement,
  CAST(NULLIF(horsepower, '?')   AS FLOAT) AS horsepower,
  CAST(NULLIF(weight, '?')       AS INT)   AS weight,
  CAST(NULLIF(acceleration, '?') AS FLOAT) AS acceleration,
  CAST(NULLIF(model_year, '?')   AS INT)   AS model_year,
  NULLIF(origin, '?')                       AS origin,
  NULLIF(name,   '?')                       AS make

from `raw`.`autompg___cars`
  
[0m15:24:50.463896 [debug] [Thread-1  ]: Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 53
   Code: 53. DB::Exception: Cannot convert string ? to type Float64. (TYPE_MISMATCH) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_mpg/models/clean/mpg_standardized.sql
[0m15:24:50.467603 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35d170f0-6ce1-4892-9142-e2106f8b263b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae4e13eadc0>]}
[0m15:24:50.469535 [error] [Thread-1  ]: 1 of 2 ERROR creating sql table model `clean`.`mpg_standardized` ............... [[31mERROR[0m in 0.22s]
[0m15:24:50.471793 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m15:24:50.474488 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m15:24:50.475645 [info ] [Thread-3  ]: 2 of 2 SKIP relation mart.cylinders_by_origin .................................. [[33mSKIP[0m]
[0m15:24:50.477022 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m15:24:50.479749 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:24:50.480792 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m15:24:50.481802 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m15:24:50.482800 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m15:24:50.483763 [debug] [MainThread]: On list__clean: Close
[0m15:24:50.485054 [info ] [MainThread]: 
[0m15:24:50.486193 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.83 seconds (0.83s).
[0m15:24:50.488575 [debug] [MainThread]: Command end result
[0m15:24:50.562053 [info ] [MainThread]: 
[0m15:24:50.563016 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:24:50.563813 [info ] [MainThread]: 
[0m15:24:50.565154 [error] [MainThread]:   Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 53
   Code: 53. DB::Exception: Cannot convert string ? to type Float64. (TYPE_MISMATCH) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_mpg/models/clean/mpg_standardized.sql
[0m15:24:50.566299 [info ] [MainThread]: 
[0m15:24:50.567380 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
[0m15:24:50.569639 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 2.9983177, "process_in_blocks": "0", "process_kernel_time": 0.774628, "process_mem_max_rss": "113544", "process_out_blocks": "10472", "process_user_time": 6.666801}
[0m15:24:50.571047 [debug] [MainThread]: Command `dbt build` failed at 15:24:50.570711 after 3.00 seconds
[0m15:24:50.572149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae4e473c310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae4e25e73a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae4e12eb3d0>]}
[0m15:24:50.573249 [debug] [MainThread]: Flushing usage events
[0m15:28:09.566048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78d7a4bf6310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78d7a1842b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78d7a18429d0>]}


============================== 15:28:09.579381 | 0090992f-c992-4353-b128-ab9a6a71792b ==============================
[0m15:28:09.579381 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:28:09.581293 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'empty': 'False', 'profiles_dir': '.', 'invocation_command': 'dbt build --profiles-dir . --target local', 'printer_width': '80', 'static_parser': 'True', 'log_format': 'default', 'quiet': 'False', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'warn_error': 'None', 'write_json': 'True', 'no_print': 'None', 'use_colors': 'True', 'cache_selected_only': 'False', 'debug': 'False', 'introspect': 'True', 'log_path': '/workdir/transforms/01_mpg/logs', 'send_anonymous_usage_stats': 'True'}
[0m15:28:09.960549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0090992f-c992-4353-b128-ab9a6a71792b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78d7a175d910>]}
[0m15:28:10.089364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0090992f-c992-4353-b128-ab9a6a71792b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78d7a177e7f0>]}
[0m15:28:10.091391 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m15:28:10.326808 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m15:28:10.609649 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:28:10.611160 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m15:28:11.175734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0090992f-c992-4353-b128-ab9a6a71792b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78d79fdf0130>]}
[0m15:28:11.440178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0090992f-c992-4353-b128-ab9a6a71792b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78d79fcac430>]}
[0m15:28:11.441402 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m15:28:11.445275 [info ] [MainThread]: 
[0m15:28:11.446682 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:28:11.464637 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:28:11.466264 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:28:11.502938 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:28:11.514557 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:28:11.855578 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:28:11.862030 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:28:11.865393 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:28:11.871164 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:28:11.989384 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m15:28:12.005818 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m15:28:12.008408 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m15:28:12.015091 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m15:28:12.019866 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:28:12.037811 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m15:28:12.048021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0090992f-c992-4353-b128-ab9a6a71792b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78d79f80eb50>]}
[0m15:28:12.049613 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m15:28:12.050813 [info ] [MainThread]: 
[0m15:28:12.067100 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m15:28:12.068670 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m15:28:12.070606 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__mart, now model.ex_01_mpg.mpg_standardized)
[0m15:28:12.071871 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m15:28:12.094966 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m15:28:12.096551 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m15:28:12.181071 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m15:28:12.184877 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:28:12.261714 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

-- models/clean/autompg_casted.sql
-- turn "?" -> NULL first, then cast; works reliably in ClickHouse/dbt-clickhouse
select
  case when toString(mpg)          = '?' then null else toFloat64OrNull(toString(mpg))          end as mpg,
  case when toString(cylinders)    = '?' then null else toInt64OrNull  (toString(cylinders))    end as cylinders,
  case when toString(displacement) = '?' then null else toFloat64OrNull(toString(displacement)) end as displacement,
  case when toString(horsepower)   = '?' then null else toFloat64OrNull(toString(horsepower))   end as horsepower,
  case when toString(weight)       = '?' then null else toInt64OrNull  (toString(weight))       end as weight,
  case when toString(acceleration) = '?' then null else toFloat64OrNull(toString(acceleration)) end as acceleration,
  case when toString(model_year)   = '?' then null else toInt64OrNull  (toString(model_year))   end as model_year,
  case when toString(origin)       = '?' then null else toString(origin)                         end as origin,
  case when toString(name)         = '?' then null else toString(name)                           end as make
from `raw`.`autompg___cars`
          )
        
        ...
[0m15:28:12.394659 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.13 seconds
[0m15:28:12.424441 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m15:28:12.430866 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:28:12.439392 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m15:28:12.441616 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

-- models/clean/autompg_casted.sql
-- turn "?" -> NULL first, then cast; works reliably in ClickHouse/dbt-clickhouse
select
  case when toString(mpg)          = '?' then null else toFloat64OrNull(toString(mpg))          end as mpg,
  case when toString(cylinders)    = '?' then null else toInt64OrNull  (toString(cylinders))    end as cylinders,
  case when toString(displacement) = '?' then null else toFloat64OrNull(toString(displacement)) end as displacement,
  case when toString(horsepower)   = '?' then null else toFloat64OrNull(toString(horsepower))   end as horsepower,
  case when toString(weight)       = '?' then null else toInt64OrNull  (toString(weight))       end as weight,
  case when toString(acceleration) = '?' then null else toFloat64OrNull(toString(acceleration)) end as acceleration,
  case when toString(model_year)   = '?' then null else toInt64OrNull  (toString(model_year))   end as model_year,
  case when toString(origin)       = '?' then null else toString(origin)                         end as origin,
  case when toString(name)         = '?' then null else toString(name)                           end as make
from `raw`.`autompg___cars`
  ...
[0m15:28:12.450565 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:28:12.463203 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */
EXCHANGE TABLES `clean`.`mpg_standardized__dbt_backup` AND `clean`.`mpg_standardized` 
  
  ...
[0m15:28:12.467042 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:28:12.532433 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m15:28:12.536795 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:28:12.546956 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0090992f-c992-4353-b128-ab9a6a71792b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78d79f052460>]}
[0m15:28:12.548967 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized` ................... [[32mOK[0m in 0.47s]
[0m15:28:12.551427 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m15:28:12.553432 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m15:28:12.554921 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m15:28:12.556564 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m15:28:12.557557 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m15:28:12.568782 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m15:28:12.570665 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m15:28:12.632985 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m15:28:12.919154 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m15:28:12.920627 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin__dbt_tmp` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:28:12.933325 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:28:12.951588 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m15:28:12.955867 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:28:12.959197 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin` to `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m15:28:12.962956 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:28:12.971818 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin` 
  
  ...
[0m15:28:12.975143 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:28:12.977851 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin__dbt_tmp` to `mart`.`cylinders_by_origin` 
  
  ...
[0m15:28:12.981122 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:28:12.991450 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  ...
[0m15:28:12.994714 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:28:12.997667 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0090992f-c992-4353-b128-ab9a6a71792b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78d7a188a1c0>]}
[0m15:28:12.999357 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 0.44s]
[0m15:28:13.001336 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m15:28:13.003453 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:28:13.004048 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m15:28:13.004625 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m15:28:13.005227 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m15:28:13.006154 [debug] [MainThread]: On list__clean: Close
[0m15:28:13.006932 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m15:28:13.007805 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m15:28:13.009165 [info ] [MainThread]: 
[0m15:28:13.010241 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.56 seconds (1.56s).
[0m15:28:13.013157 [debug] [MainThread]: Command end result
[0m15:28:13.086303 [info ] [MainThread]: 
[0m15:28:13.087304 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:28:13.088010 [info ] [MainThread]: 
[0m15:28:13.088743 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m15:28:13.090225 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 3.6482394, "process_in_blocks": "0", "process_kernel_time": 0.803086, "process_mem_max_rss": "114188", "process_out_blocks": "10496", "process_user_time": 7.104076}
[0m15:28:13.091091 [debug] [MainThread]: Command `dbt build` succeeded at 15:28:13.090859 after 3.65 seconds
[0m15:28:13.091924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78d7a4bf6310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78d7a2b10400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78d79e957fd0>]}
[0m15:28:13.093000 [debug] [MainThread]: Flushing usage events
[0m15:39:19.766985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d50f162de20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d50ee280490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d50ee2805e0>]}


============================== 15:39:19.779480 | a0b8b09a-edf3-46d2-959c-821a66707f62 ==============================
[0m15:39:19.779480 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:39:19.780729 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_colors': 'True', 'cache_selected_only': 'False', 'quiet': 'False', 'version_check': 'True', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'printer_width': '80', 'no_print': 'None', 'static_parser': 'True', 'log_cache_events': 'False', 'invocation_command': 'dbt build --profiles-dir . --target local', 'warn_error': 'None', 'profiles_dir': '.', 'partial_parse': 'True', 'debug': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'write_json': 'True', 'introspect': 'True', 'fail_fast': 'False', 'empty': 'False', 'log_format': 'default'}
[0m15:39:20.150436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a0b8b09a-edf3-46d2-959c-821a66707f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d50f0ab5910>]}
[0m15:39:20.299639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a0b8b09a-edf3-46d2-959c-821a66707f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d50ee0da7c0>]}
[0m15:39:20.301461 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m15:39:20.550403 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m15:39:20.869038 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:39:20.870362 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m15:39:21.444033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a0b8b09a-edf3-46d2-959c-821a66707f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d50ec82b130>]}
[0m15:39:21.695206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a0b8b09a-edf3-46d2-959c-821a66707f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d50ec6e5370>]}
[0m15:39:21.696154 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m15:39:21.699205 [info ] [MainThread]: 
[0m15:39:21.700706 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:39:21.715286 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:39:21.716357 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:39:21.744015 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:39:21.757145 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:39:22.080371 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:39:22.087362 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:39:22.188817 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:39:22.197955 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:39:22.205740 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m15:39:22.207140 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m15:39:22.223006 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m15:39:22.227776 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m15:39:22.236353 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:39:22.237844 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:39:22.260776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a0b8b09a-edf3-46d2-959c-821a66707f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d50ec231af0>]}
[0m15:39:22.262060 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m15:39:22.262942 [info ] [MainThread]: 
[0m15:39:22.283595 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m15:39:22.285493 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m15:39:22.288473 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__clean, now model.ex_01_mpg.mpg_standardized)
[0m15:39:22.290331 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m15:39:22.307390 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m15:39:22.308950 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m15:39:22.432283 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  coalesce(
        horsepower,
        avg(horsepower) over (partition by cylinders)
    ) as horsepower_imputed,
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
          )
        
        ...
[0m15:39:22.453576 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m15:39:22.477440 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m15:39:22.483699 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:39:22.492351 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m15:39:22.494066 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "horsepower_imputed", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  coalesce(
        horsepower,
        avg(horsepower) over (partition by cylinders)
    ) as horsepower_imputed,
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
  ...
[0m15:39:22.520207 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m15:39:22.530497 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */
EXCHANGE TABLES `clean`.`mpg_standardized__dbt_backup` AND `clean`.`mpg_standardized` 
  
  ...
[0m15:39:22.534417 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:39:22.598524 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m15:39:22.602273 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:39:22.611176 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0b8b09a-edf3-46d2-959c-821a66707f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d50ec2ca910>]}
[0m15:39:22.612963 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized` ................... [[32mOK[0m in 0.32s]
[0m15:39:22.614640 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m15:39:22.616889 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m15:39:22.618007 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m15:39:22.619612 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m15:39:22.620853 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m15:39:22.628502 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m15:39:22.630084 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m15:39:22.697499 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m15:39:22.765434 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m15:39:22.767427 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin__dbt_tmp` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:39:22.777625 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:39:22.803502 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m15:39:22.812729 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:39:22.816811 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin` to `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m15:39:22.824853 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:39:22.840539 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin` 
  
  ...
[0m15:39:22.846819 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:39:22.853101 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin__dbt_tmp` to `mart`.`cylinders_by_origin` 
  
  ...
[0m15:39:22.863047 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:39:22.876080 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  ...
[0m15:39:22.883629 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:39:22.888707 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0b8b09a-edf3-46d2-959c-821a66707f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d50ec2ca730>]}
[0m15:39:22.891044 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 0.27s]
[0m15:39:22.893762 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m15:39:22.901694 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:39:22.902993 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m15:39:22.904199 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m15:39:22.905363 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m15:39:22.906535 [debug] [MainThread]: On list__mart: Close
[0m15:39:22.907805 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m15:39:22.908989 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m15:39:22.910839 [info ] [MainThread]: 
[0m15:39:22.913697 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.21 seconds (1.21s).
[0m15:39:22.919545 [debug] [MainThread]: Command end result
[0m15:39:23.023195 [info ] [MainThread]: 
[0m15:39:23.024668 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:39:23.025836 [info ] [MainThread]: 
[0m15:39:23.027014 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m15:39:23.029796 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 3.3875275, "process_in_blocks": "0", "process_kernel_time": 0.820933, "process_mem_max_rss": "114092", "process_out_blocks": "10488", "process_user_time": 6.914438}
[0m15:39:23.031563 [debug] [MainThread]: Command `dbt build` succeeded at 15:39:23.031111 after 3.39 seconds
[0m15:39:23.032980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d50f162de20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d50eda51e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d50edf90bb0>]}
[0m15:39:23.034345 [debug] [MainThread]: Flushing usage events
[0m15:42:15.448030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c1d2184e310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c1d1e4a8af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c1d1e4a89a0>]}


============================== 15:42:15.459502 | aae55851-ed49-40fd-9f04-e05739afa03b ==============================
[0m15:42:15.459502 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:42:15.460717 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'log_cache_events': 'False', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt build --profiles-dir . --target local', 'log_format': 'default', 'profiles_dir': '.', 'partial_parse': 'True', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'quiet': 'False', 'use_experimental_parser': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'introspect': 'True', 'printer_width': '80', 'use_colors': 'True', 'debug': 'False', 'empty': 'False', 'indirect_selection': 'eager', 'version_check': 'True', 'target_path': 'None', 'write_json': 'True', 'fail_fast': 'False'}
[0m15:42:15.841567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'aae55851-ed49-40fd-9f04-e05739afa03b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c1d20de9fd0>]}
[0m15:42:15.964813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'aae55851-ed49-40fd-9f04-e05739afa03b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c1d1e395a90>]}
[0m15:42:15.966735 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m15:42:16.190469 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m15:42:16.470080 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:42:16.471155 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m15:42:17.031690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aae55851-ed49-40fd-9f04-e05739afa03b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c1d1ca57130>]}
[0m15:42:17.312427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aae55851-ed49-40fd-9f04-e05739afa03b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c1d1c917ac0>]}
[0m15:42:17.313469 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m15:42:17.316969 [info ] [MainThread]: 
[0m15:42:17.318568 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:42:17.335027 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:42:17.341457 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:42:17.371590 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:42:17.378211 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:42:17.707717 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:42:17.712362 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:42:17.713628 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:17.717976 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:17.840585 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m15:42:17.841673 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m15:42:17.857112 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m15:42:17.863677 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m15:42:17.873033 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:42:17.875477 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:42:17.896030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aae55851-ed49-40fd-9f04-e05739afa03b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c1d1c8d6910>]}
[0m15:42:17.897393 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m15:42:17.898667 [info ] [MainThread]: 
[0m15:42:17.914658 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m15:42:17.916455 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m15:42:17.917694 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__mart, now model.ex_01_mpg.mpg_standardized)
[0m15:42:17.918634 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m15:42:17.940158 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m15:42:17.941521 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m15:42:18.075194 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  /*
  coalesce(
        horsepower,
        avg(horsepower) over (partition by cylinders)
    ) as horsepower_imputed,
  */
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
          )
        
        ...
[0m15:42:18.092847 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m15:42:18.116687 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m15:42:18.122700 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:18.131228 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m15:42:18.133018 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  /*
  coalesce(
        horsepower,
        avg(horsepower) over (partition by cylinders)
    ) as horsepower_imputed,
  */
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
  ...
[0m15:42:18.140266 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:42:18.152454 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */
EXCHANGE TABLES `clean`.`mpg_standardized__dbt_backup` AND `clean`.`mpg_standardized` 
  
  ...
[0m15:42:18.156899 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:18.240249 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m15:42:18.245339 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:18.255720 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aae55851-ed49-40fd-9f04-e05739afa03b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c1d1c545a60>]}
[0m15:42:18.257584 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized` ................... [[32mOK[0m in 0.34s]
[0m15:42:18.259868 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m15:42:18.262072 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m15:42:18.263359 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m15:42:18.265323 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m15:42:18.266901 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m15:42:18.277326 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m15:42:18.278967 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m15:42:18.349167 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m15:42:18.636879 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m15:42:18.638679 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin__dbt_tmp` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:42:18.687181 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m15:42:18.709753 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m15:42:18.713541 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:18.717042 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin` to `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m15:42:18.721338 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:18.730303 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin` 
  
  ...
[0m15:42:18.733358 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:18.735535 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin__dbt_tmp` to `mart`.`cylinders_by_origin` 
  
  ...
[0m15:42:18.739123 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:18.747528 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  ...
[0m15:42:18.751207 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:18.754096 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aae55851-ed49-40fd-9f04-e05739afa03b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c1d1e14bfa0>]}
[0m15:42:18.755473 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 0.49s]
[0m15:42:18.757728 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m15:42:18.759990 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:42:18.760845 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m15:42:18.761705 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m15:42:18.762608 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m15:42:18.763159 [debug] [MainThread]: On list__clean: Close
[0m15:42:18.763724 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m15:42:18.764415 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m15:42:18.765548 [info ] [MainThread]: 
[0m15:42:18.766464 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.45 seconds (1.45s).
[0m15:42:18.768863 [debug] [MainThread]: Command end result
[0m15:42:18.840934 [info ] [MainThread]: 
[0m15:42:18.842281 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:42:18.843005 [info ] [MainThread]: 
[0m15:42:18.843946 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m15:42:18.845567 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 3.5258176, "process_in_blocks": "0", "process_kernel_time": 0.797307, "process_mem_max_rss": "114260", "process_out_blocks": "10488", "process_user_time": 7.242711}
[0m15:42:18.846452 [debug] [MainThread]: Command `dbt build` succeeded at 15:42:18.846214 after 3.53 seconds
[0m15:42:18.847230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c1d2184e310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c1d1dbc6280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c1d1c581bb0>]}
[0m15:42:18.847865 [debug] [MainThread]: Flushing usage events
[0m16:50:36.802716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c2ec332310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c2e8fa9a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c2e8fa9940>]}


============================== 16:50:36.843344 | 08f0177e-05b4-4442-b519-453a2f76b76a ==============================
[0m16:50:36.843344 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:50:36.844633 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'use_colors': 'True', 'printer_width': '80', 'fail_fast': 'False', 'partial_parse': 'True', 'static_parser': 'True', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'target_path': 'None', 'debug': 'False', 'version_check': 'True', 'introspect': 'True', 'quiet': 'False', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'write_json': 'True', 'empty': 'False', 'cache_selected_only': 'False', 'profiles_dir': '.', 'warn_error': 'None', 'invocation_command': 'dbt build --profiles-dir . --target local'}
[0m16:50:37.153323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '08f0177e-05b4-4442-b519-453a2f76b76a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c2e8f65850>]}
[0m16:50:37.266730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '08f0177e-05b4-4442-b519-453a2f76b76a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c2e8e7fca0>]}
[0m16:50:37.268206 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m16:50:37.452454 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m16:50:37.762672 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:50:37.763376 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:50:37.850210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '08f0177e-05b4-4442-b519-453a2f76b76a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c2e881be50>]}
[0m16:50:38.272667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '08f0177e-05b4-4442-b519-453a2f76b76a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c2e8866370>]}
[0m16:50:38.274421 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m16:50:38.279835 [info ] [MainThread]: 
[0m16:50:38.281983 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:50:38.306057 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:50:38.308183 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:50:38.376382 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:50:38.380132 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:50:38.647676 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:50:38.652543 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:50:38.660081 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:50:38.664687 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:50:38.684537 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m16:50:38.685565 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m16:50:38.697403 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m16:50:38.701765 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m16:50:38.711287 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:50:38.712971 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:50:38.730902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '08f0177e-05b4-4442-b519-453a2f76b76a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c2e871dc70>]}
[0m16:50:38.731995 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m16:50:38.732679 [info ] [MainThread]: 
[0m16:50:38.746854 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m16:50:38.748037 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m16:50:38.749207 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.mpg_standardized'
[0m16:50:38.750111 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m16:50:38.771147 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m16:50:38.772456 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m16:50:38.883153 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m16:50:38.948810 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  /*
  coalesce(
        horsepower,
        avg(horsepower) over (partition by cylinders)
    ) as horsepower_imputed,
  */
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
          )
        
        ...
[0m16:50:38.967159 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:50:38.983859 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m16:50:38.989349 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:50:38.996016 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m16:50:38.997569 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  /*
  coalesce(
        horsepower,
        avg(horsepower) over (partition by cylinders)
    ) as horsepower_imputed,
  */
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
  ...
[0m16:50:39.005046 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:50:39.014679 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */
EXCHANGE TABLES `clean`.`mpg_standardized__dbt_backup` AND `clean`.`mpg_standardized` 
  
  ...
[0m16:50:39.018072 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:50:39.140493 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m16:50:39.143889 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:50:39.150685 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '08f0177e-05b4-4442-b519-453a2f76b76a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c2eb8dd520>]}
[0m16:50:39.152134 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized` ................... [[32mOK[0m in 0.40s]
[0m16:50:39.153624 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m16:50:39.155318 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m16:50:39.156347 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m16:50:39.157465 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m16:50:39.158295 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m16:50:39.164429 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m16:50:39.165672 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m16:50:39.216734 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m16:50:39.277494 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m16:50:39.279292 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin__dbt_tmp` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:50:39.288573 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:50:39.303053 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m16:50:39.305994 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:50:39.307955 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin` to `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m16:50:39.310779 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:50:39.317506 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin` 
  
  ...
[0m16:50:39.320415 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:50:39.322454 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin__dbt_tmp` to `mart`.`cylinders_by_origin` 
  
  ...
[0m16:50:39.325195 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:50:39.331788 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  ...
[0m16:50:39.334819 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:50:39.337426 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '08f0177e-05b4-4442-b519-453a2f76b76a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c2e84ec1c0>]}
[0m16:50:39.338581 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 0.18s]
[0m16:50:39.339893 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m16:50:39.341845 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:50:39.342429 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m16:50:39.342980 [debug] [MainThread]: On list__mart: Close
[0m16:50:39.343526 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m16:50:39.344027 [debug] [MainThread]: On list__clean: Close
[0m16:50:39.344553 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m16:50:39.345082 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m16:50:39.345615 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m16:50:39.346115 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m16:50:39.347035 [info ] [MainThread]: 
[0m16:50:39.347791 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.07 seconds (1.07s).
[0m16:50:39.349511 [debug] [MainThread]: Command end result
[0m16:50:39.403090 [info ] [MainThread]: 
[0m16:50:39.404067 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:50:39.404680 [info ] [MainThread]: 
[0m16:50:39.405300 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m16:50:39.406614 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 2.716494, "process_in_blocks": "1176", "process_kernel_time": 0.663395, "process_mem_max_rss": "111588", "process_out_blocks": "9512", "process_user_time": 5.410069}
[0m16:50:39.407397 [debug] [MainThread]: Command `dbt build` succeeded at 16:50:39.407194 after 2.72 seconds
[0m16:50:39.408339 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c2ec332310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c2e864a100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74c2ea1b9070>]}
[0m16:50:39.409425 [debug] [MainThread]: Flushing usage events
[0m09:19:29.977543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7784f87b6310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7784f5403b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7784f5403a30>]}


============================== 09:19:29.987438 | 5541719b-e27a-486a-a8de-27661def451e ==============================
[0m09:19:29.987438 [info ] [MainThread]: Running with dbt=1.8.9
[0m09:19:29.988587 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'indirect_selection': 'eager', 'warn_error': 'None', 'version_check': 'True', 'quiet': 'False', 'empty': 'False', 'target_path': 'None', 'debug': 'False', 'invocation_command': 'dbt build --profiles-dir . --target local', 'printer_width': '80', 'log_format': 'default', 'profiles_dir': '.', 'use_colors': 'True', 'log_path': '/workdir/transforms/01_mpg/logs', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'static_parser': 'True', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m09:19:30.291757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5541719b-e27a-486a-a8de-27661def451e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7784f52cc3a0>]}
[0m09:19:30.411882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5541719b-e27a-486a-a8de-27661def451e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7784f5369610>]}
[0m09:19:30.413394 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m09:19:30.594048 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m09:19:30.887163 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:19:30.887885 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:19:30.963706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5541719b-e27a-486a-a8de-27661def451e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7784f4c8cdf0>]}
[0m09:19:31.364668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5541719b-e27a-486a-a8de-27661def451e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7784f4b94b80>]}
[0m09:19:31.366394 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m09:19:31.371183 [info ] [MainThread]: 
[0m09:19:31.373192 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m09:19:31.411092 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m09:19:31.418807 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m09:19:31.494040 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:19:31.489622 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:19:31.805583 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m09:19:31.810843 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m09:19:31.812737 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:19:31.817964 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:19:31.842380 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m09:19:31.843663 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m09:19:31.856052 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m09:19:31.861076 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m09:19:31.870616 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m09:19:31.872689 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m09:19:31.895924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5541719b-e27a-486a-a8de-27661def451e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7784f5369dc0>]}
[0m09:19:31.897528 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m09:19:31.898494 [info ] [MainThread]: 
[0m09:19:31.918629 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m09:19:31.919857 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m09:19:31.921089 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.mpg_standardized'
[0m09:19:31.921945 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m09:19:31.939595 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m09:19:31.940906 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m09:19:32.047454 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m09:19:32.105379 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  /*
  coalesce(
        horsepower,
        avg(horsepower) over (partition by cylinders)
    ) as horsepower_imputed,
  */
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
          )
        
        ...
[0m09:19:32.120977 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m09:19:32.138191 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m09:19:32.143018 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:19:32.150989 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m09:19:32.152497 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  /*
  coalesce(
        horsepower,
        avg(horsepower) over (partition by cylinders)
    ) as horsepower_imputed,
  */
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
  ...
[0m09:19:32.160897 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m09:19:32.169753 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */
EXCHANGE TABLES `clean`.`mpg_standardized__dbt_backup` AND `clean`.`mpg_standardized` 
  
  ...
[0m09:19:32.173007 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:19:32.289313 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m09:19:32.292676 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:19:32.299220 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5541719b-e27a-486a-a8de-27661def451e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7784f47e4ee0>]}
[0m09:19:32.300654 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized` ................... [[32mOK[0m in 0.38s]
[0m09:19:32.302228 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m09:19:32.303931 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m09:19:32.305028 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m09:19:32.306185 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m09:19:32.307111 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m09:19:32.313712 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m09:19:32.315085 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m09:19:32.366076 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m09:19:32.424834 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m09:19:32.426854 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin__dbt_tmp` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m09:19:32.436908 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m09:19:32.459638 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m09:19:32.463800 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:19:32.468884 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin` to `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m09:19:32.472989 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:19:32.479368 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin` 
  
  ...
[0m09:19:32.482369 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:19:32.484453 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin__dbt_tmp` to `mart`.`cylinders_by_origin` 
  
  ...
[0m09:19:32.487361 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:19:32.494056 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  ...
[0m09:19:32.497059 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:19:32.499678 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5541719b-e27a-486a-a8de-27661def451e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7784f47e4ee0>]}
[0m09:19:32.500899 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 0.19s]
[0m09:19:32.502203 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m09:19:32.504460 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:19:32.505327 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m09:19:32.506185 [debug] [MainThread]: On list__clean: Close
[0m09:19:32.507001 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m09:19:32.507838 [debug] [MainThread]: On list__mart: Close
[0m09:19:32.508680 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m09:19:32.509535 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m09:19:32.510327 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m09:19:32.511125 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m09:19:32.512589 [info ] [MainThread]: 
[0m09:19:32.513626 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.14 seconds (1.14s).
[0m09:19:32.516445 [debug] [MainThread]: Command end result
[0m09:19:32.583350 [info ] [MainThread]: 
[0m09:19:32.584334 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:19:32.584951 [info ] [MainThread]: 
[0m09:19:32.585671 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m09:19:32.587005 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 2.7343135, "process_in_blocks": "72", "process_kernel_time": 0.636494, "process_mem_max_rss": "111432", "process_out_blocks": "9512", "process_user_time": 5.346753}
[0m09:19:32.587777 [debug] [MainThread]: Command `dbt build` succeeded at 09:19:32.587581 after 2.74 seconds
[0m09:19:32.588423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7784f87b6310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7784f5f22760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7784f5369610>]}
[0m09:19:32.589039 [debug] [MainThread]: Flushing usage events
[0m09:19:49.189806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76712a5f0310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767127251b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7671272519d0>]}


============================== 09:19:49.199960 | 9585bed5-a783-4a2b-abdc-56317c924289 ==============================
[0m09:19:49.199960 [info ] [MainThread]: Running with dbt=1.8.9
[0m09:19:49.201208 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_format': 'default', 'invocation_command': 'dbt build --profiles-dir .', 'use_colors': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'cache_selected_only': 'False', 'profiles_dir': '.', 'target_path': 'None', 'no_print': 'None', 'fail_fast': 'False', 'printer_width': '80', 'partial_parse': 'True', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'write_json': 'True', 'static_parser': 'True', 'log_cache_events': 'False', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'log_path': '/workdir/transforms/01_mpg/logs', 'empty': 'False'}
[0m09:19:49.493886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9585bed5-a783-4a2b-abdc-56317c924289', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76712a7dc1f0>]}
[0m09:19:49.591996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9585bed5-a783-4a2b-abdc-56317c924289', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76712730c070>]}
[0m09:19:49.593481 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m09:19:49.759876 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m09:19:49.960104 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m09:19:49.961045 [debug] [MainThread]: previous checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, current checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979
[0m09:19:49.961792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '9585bed5-a783-4a2b-abdc-56317c924289', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7671285890a0>]}
[0m09:19:52.634520 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9585bed5-a783-4a2b-abdc-56317c924289', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767125700130>]}
[0m09:19:52.847419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9585bed5-a783-4a2b-abdc-56317c924289', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7671255e13a0>]}
[0m09:19:52.848335 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m09:19:52.851070 [info ] [MainThread]: 
[0m09:19:52.852082 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m09:19:52.866008 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m09:19:52.867314 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m09:19:52.887794 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:19:52.891683 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:19:53.148580 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m09:19:53.154125 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:19:53.155373 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m09:19:53.159309 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:19:53.182332 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m09:19:53.183374 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m09:19:53.195649 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m09:19:53.199826 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m09:19:53.205917 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m09:19:53.207250 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m09:19:53.222070 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9585bed5-a783-4a2b-abdc-56317c924289', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7671272096a0>]}
[0m09:19:53.223098 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m09:19:53.223764 [info ] [MainThread]: 
[0m09:19:53.236600 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m09:19:53.237819 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m09:19:53.238947 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.mpg_standardized'
[0m09:19:53.239703 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m09:19:53.256610 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m09:19:53.257874 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m09:19:53.359140 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m09:19:53.419440 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  /*
  coalesce(
        horsepower,
        avg(horsepower) over (partition by cylinders)
    ) as horsepower_imputed,
  */
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
          )
        
        ...
[0m09:19:53.438338 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m09:19:53.460511 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m09:19:53.468837 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m09:19:53.476606 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m09:19:53.478108 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  /*
  coalesce(
        horsepower,
        avg(horsepower) over (partition by cylinders)
    ) as horsepower_imputed,
  */
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
  ...
[0m09:19:53.487120 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m09:19:53.497600 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */
EXCHANGE TABLES `clean`.`mpg_standardized__dbt_backup` AND `clean`.`mpg_standardized` 
  
  ...
[0m09:19:53.502283 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:19:53.559415 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m09:19:53.563027 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:19:53.569882 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9585bed5-a783-4a2b-abdc-56317c924289', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7671249d8220>]}
[0m09:19:53.571378 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized` ................... [[32mOK[0m in 0.33s]
[0m09:19:53.572854 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m09:19:53.574617 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m09:19:53.575708 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m09:19:53.577013 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m09:19:53.577985 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m09:19:53.584963 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m09:19:53.586408 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m09:19:53.639715 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m09:19:53.709773 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m09:19:53.711766 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin__dbt_tmp` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m09:19:53.721964 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m09:19:53.746003 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m09:19:53.749061 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:19:53.751112 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin` to `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m09:19:53.753890 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:19:53.760167 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin` 
  
  ...
[0m09:19:53.763012 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:19:53.764991 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin__dbt_tmp` to `mart`.`cylinders_by_origin` 
  
  ...
[0m09:19:53.767827 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:19:53.774829 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  ...
[0m09:19:53.777877 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:19:53.780455 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9585bed5-a783-4a2b-abdc-56317c924289', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767125529f10>]}
[0m09:19:53.781607 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 0.20s]
[0m09:19:53.782931 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m09:19:53.785199 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:19:53.786178 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m09:19:53.787072 [debug] [MainThread]: On list__clean: Close
[0m09:19:53.787973 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m09:19:53.788848 [debug] [MainThread]: On list__mart: Close
[0m09:19:53.789686 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m09:19:53.790536 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m09:19:53.791357 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m09:19:53.792188 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m09:19:53.793693 [info ] [MainThread]: 
[0m09:19:53.794754 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.94 seconds (0.94s).
[0m09:19:53.797626 [debug] [MainThread]: Command end result
[0m09:19:53.947519 [info ] [MainThread]: 
[0m09:19:53.948529 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:19:53.949129 [info ] [MainThread]: 
[0m09:19:53.949792 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m09:19:53.951100 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 4.886012, "process_in_blocks": "472", "process_kernel_time": 0.681454, "process_mem_max_rss": "115164", "process_out_blocks": "10488", "process_user_time": 7.572941}
[0m09:19:53.951858 [debug] [MainThread]: Command `dbt build` succeeded at 09:19:53.951664 after 4.89 seconds
[0m09:19:53.952495 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76712a5f0310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x767126cc02e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76712526b7f0>]}
[0m09:19:53.953089 [debug] [MainThread]: Flushing usage events
[0m09:20:07.673229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a8b95ea5310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a8b92af0af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a8b92af09a0>]}


============================== 09:20:07.683119 | 3a58f05a-4b9e-491c-966b-6f51980380e1 ==============================
[0m09:20:07.683119 [info ] [MainThread]: Running with dbt=1.8.9
[0m09:20:07.684346 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'fail_fast': 'False', 'log_cache_events': 'False', 'target_path': 'None', 'empty': 'False', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'log_format': 'default', 'quiet': 'False', 'debug': 'False', 'use_colors': 'True', 'partial_parse': 'True', 'introspect': 'True', 'warn_error': 'None', 'printer_width': '80', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'profiles_dir': '.', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'write_json': 'True', 'version_check': 'True', 'no_print': 'None'}
[0m09:20:08.017646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3a58f05a-4b9e-491c-966b-6f51980380e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a8b92ab6a60>]}
[0m09:20:08.112416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3a58f05a-4b9e-491c-966b-6f51980380e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a8b929ed160>]}
[0m09:20:08.113797 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m09:20:08.279358 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m09:20:08.464198 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m09:20:08.465089 [debug] [MainThread]: previous checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, current checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1
[0m09:20:08.465825 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m09:20:08.466500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3a58f05a-4b9e-491c-966b-6f51980380e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a8b93e269d0>]}
[0m09:20:11.014034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3a58f05a-4b9e-491c-966b-6f51980380e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a8b90f9a130>]}
[0m09:20:11.254168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3a58f05a-4b9e-491c-966b-6f51980380e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a8b90e755b0>]}
[0m09:20:11.255062 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m09:20:11.257790 [info ] [MainThread]: 
[0m09:20:11.258785 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m09:20:11.271808 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m09:20:11.283499 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m09:20:11.293652 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:20:11.297658 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:20:14.825958 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m09:20:14.827479 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m09:20:15.078338 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m09:20:15.080613 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m09:20:15.120181 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m09:20:15.121400 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m09:20:15.133453 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m09:20:15.137619 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m09:20:15.391058 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m09:20:15.395930 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.26 seconds
[0m09:20:15.398456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3a58f05a-4b9e-491c-966b-6f51980380e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a8b92a546d0>]}
[0m09:20:15.399414 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m09:20:15.400036 [info ] [MainThread]: 
[0m09:20:15.413638 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m09:20:15.414825 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m09:20:15.415950 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.mpg_standardized'
[0m09:20:15.416761 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m09:20:15.434022 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m09:20:15.435367 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m09:20:15.474633 [debug] [Thread-1  ]: Creating new relation mpg_standardized
[0m09:20:15.528100 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m09:20:18.551553 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  /*
  coalesce(
        horsepower,
        avg(horsepower) over (partition by cylinders)
    ) as horsepower_imputed,
  */
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
          )
        
        ...
[0m09:20:18.817148 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.26 seconds
[0m09:20:18.834920 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized'
    
      and database = 'clean'
    
    order by position
  ...
[0m09:20:19.093954 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.26 seconds
[0m09:20:19.100622 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m09:20:19.102101 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  /*
  coalesce(
        horsepower,
        avg(horsepower) over (partition by cylinders)
    ) as horsepower_imputed,
  */
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
  ...
[0m09:20:19.360024 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.26 seconds
[0m09:20:19.443089 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a58f05a-4b9e-491c-966b-6f51980380e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a8b9542f820>]}
[0m09:20:19.445871 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized` ................... [[32mOK[0m in 4.02s]
[0m09:20:19.449099 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m09:20:19.452189 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m09:20:19.458585 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m09:20:19.461055 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m09:20:19.463045 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m09:20:19.479743 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m09:20:19.482739 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m09:20:19.534659 [debug] [Thread-3  ]: Creating new relation cylinders_by_origin
[0m09:20:19.558959 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m09:20:22.349583 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m09:20:22.351721 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m09:20:22.606093 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m09:20:22.609679 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a58f05a-4b9e-491c-966b-6f51980380e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a8b8fb17a60>]}
[0m09:20:22.611251 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 3.15s]
[0m09:20:22.612684 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m09:20:22.614720 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:20:22.615356 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m09:20:22.615917 [debug] [MainThread]: On list__mart: Close
[0m09:20:22.616468 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m09:20:22.617000 [debug] [MainThread]: On list__clean: Close
[0m09:20:22.617643 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m09:20:22.618184 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m09:20:22.618794 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m09:20:22.619405 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m09:20:22.620358 [info ] [MainThread]: 
[0m09:20:22.621095 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 11.36 seconds (11.36s).
[0m09:20:22.622905 [debug] [MainThread]: Command end result
[0m09:20:22.685072 [info ] [MainThread]: 
[0m09:20:22.686150 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:20:22.686840 [info ] [MainThread]: 
[0m09:20:22.687534 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m09:20:22.688935 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 15.112848, "process_in_blocks": "1032", "process_kernel_time": 0.656253, "process_mem_max_rss": "115432", "process_out_blocks": "10488", "process_user_time": 7.619336}
[0m09:20:22.689737 [debug] [MainThread]: Command `dbt build` succeeded at 09:20:22.689529 after 15.11 seconds
[0m09:20:22.690394 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a8b95ea5310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a8b90d938b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a8b90d93dc0>]}
[0m09:20:22.691039 [debug] [MainThread]: Flushing usage events
[0m09:23:13.208571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae42a1ca310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae426e1eaf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae426e1e9a0>]}


============================== 09:23:13.218943 | 93dec56c-d999-4581-9202-2050bced655a ==============================
[0m09:23:13.218943 [info ] [MainThread]: Running with dbt=1.8.9
[0m09:23:13.220058 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'partial_parse': 'True', 'profiles_dir': '.', 'introspect': 'True', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'cache_selected_only': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'log_format': 'default', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'debug': 'False', 'empty': 'False', 'target_path': 'None', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'write_json': 'True', 'quiet': 'False', 'version_check': 'True', 'printer_width': '80', 'static_parser': 'True', 'indirect_selection': 'eager', 'no_print': 'None', 'fail_fast': 'False'}
[0m09:23:13.512348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '93dec56c-d999-4581-9202-2050bced655a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae42c985880>]}
[0m09:23:13.637774 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '93dec56c-d999-4581-9202-2050bced655a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae426c8eaf0>]}
[0m09:23:13.639447 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m09:23:13.809774 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m09:23:14.047022 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:23:14.047745 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:23:14.121723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '93dec56c-d999-4581-9202-2050bced655a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae4266a6df0>]}
[0m09:23:14.342449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '93dec56c-d999-4581-9202-2050bced655a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae4265afb50>]}
[0m09:23:14.343363 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m09:23:14.345975 [info ] [MainThread]: 
[0m09:23:14.347118 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m09:23:14.359087 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m09:23:14.360248 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m09:23:14.387270 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:23:14.396489 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:23:18.115007 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m09:23:18.379954 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.26 seconds
[0m09:23:27.442696 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m09:23:27.760134 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m09:23:27.765393 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m09:23:27.766438 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m09:23:27.778784 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m09:23:27.783274 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m09:23:28.053221 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m09:23:29.053435 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 1.27 seconds
[0m09:23:29.058818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '93dec56c-d999-4581-9202-2050bced655a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae426111490>]}
[0m09:23:29.059927 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m09:23:29.060665 [info ] [MainThread]: 
[0m09:23:29.076092 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m09:23:29.078183 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m09:23:29.080280 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.mpg_standardized'
[0m09:23:29.081974 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m09:23:29.113339 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m09:23:29.115291 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m09:23:29.249840 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m09:23:33.978927 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  /*
  coalesce(
        horsepower,
        avg(horsepower) over (partition by cylinders)
    ) as horsepower_imputed,
  */
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
          )
        
        ...
[0m09:23:34.304103 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m09:23:34.320440 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m09:23:35.515830 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 1.19 seconds
[0m09:23:35.522760 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m09:23:35.524318 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  /*
  coalesce(
        horsepower,
        avg(horsepower) over (partition by cylinders)
    ) as horsepower_imputed,
  */
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
  ...
[0m09:23:35.841749 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m09:23:35.858930 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */
EXCHANGE TABLES `clean`.`mpg_standardized__dbt_backup` AND `clean`.`mpg_standardized` 
  
  ...
[0m09:23:36.174748 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m09:23:36.308599 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m09:23:36.625645 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m09:23:36.636116 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '93dec56c-d999-4581-9202-2050bced655a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae42975d7f0>]}
[0m09:23:36.638122 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized` ................... [[32mOK[0m in 7.55s]
[0m09:23:36.640383 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m09:23:36.642432 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m09:23:36.643625 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m09:23:36.644850 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m09:23:36.645813 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m09:23:36.652002 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m09:23:36.653382 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m09:23:36.704668 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m09:23:44.272408 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m09:23:44.273760 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin__dbt_tmp` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m09:23:45.569285 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 1.29 seconds
[0m09:23:45.584639 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m09:23:45.900710 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m09:23:45.903019 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin` to `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m09:23:46.217820 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m09:23:46.223697 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin` 
  
  ...
[0m09:23:46.538835 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m09:23:46.541073 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin__dbt_tmp` to `mart`.`cylinders_by_origin` 
  
  ...
[0m09:23:47.250741 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.71 seconds
[0m09:23:47.258787 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  ...
[0m09:23:48.433660 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 1.17 seconds
[0m09:23:48.436558 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '93dec56c-d999-4581-9202-2050bced655a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae42975d7f0>]}
[0m09:23:48.437849 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 11.79s]
[0m09:23:48.439260 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m09:23:48.441339 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:23:48.441995 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m09:23:48.442555 [debug] [MainThread]: On list__clean: Close
[0m09:23:48.443044 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m09:23:48.443551 [debug] [MainThread]: On list__mart: Close
[0m09:23:48.444122 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m09:23:48.444626 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m09:23:48.445137 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m09:23:48.445763 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m09:23:48.446729 [info ] [MainThread]: 
[0m09:23:48.447432 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 34.10 seconds (34.10s).
[0m09:23:48.449230 [debug] [MainThread]: Command end result
[0m09:23:48.503901 [info ] [MainThread]: 
[0m09:23:48.504875 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:23:48.505509 [info ] [MainThread]: 
[0m09:23:48.506317 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m09:23:48.507845 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 35.39579, "process_in_blocks": "0", "process_kernel_time": 0.659288, "process_mem_max_rss": "111440", "process_out_blocks": "9536", "process_user_time": 5.238289}
[0m09:23:48.508656 [debug] [MainThread]: Command `dbt build` succeeded at 09:23:48.508463 after 35.40 seconds
[0m09:23:48.509302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae42a1ca310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae4289741c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ae42c985880>]}
[0m09:23:48.509998 [debug] [MainThread]: Flushing usage events
[0m09:26:58.144683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a7b273d2310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a7b24035b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a7b240359d0>]}


============================== 09:26:58.160813 | fbde23a1-baa9-454a-b5be-233683ba01b6 ==============================
[0m09:26:58.160813 [info ] [MainThread]: Running with dbt=1.8.9
[0m09:26:58.162690 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'quiet': 'False', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'log_format': 'default', 'log_path': '/workdir/transforms/01_mpg/logs', 'use_experimental_parser': 'False', 'introspect': 'True', 'warn_error': 'None', 'debug': 'False', 'log_cache_events': 'False', 'empty': 'False', 'fail_fast': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'no_print': 'None', 'cache_selected_only': 'False', 'profiles_dir': '.', 'target_path': 'None', 'version_check': 'True', 'write_json': 'True'}
[0m09:26:58.497623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fbde23a1-baa9-454a-b5be-233683ba01b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a7b2697e3a0>]}
[0m09:26:58.615074 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fbde23a1-baa9-454a-b5be-233683ba01b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a7b2449d790>]}
[0m09:26:58.617112 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m09:26:58.809757 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m09:26:59.049638 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:26:59.050363 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:26:59.125812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fbde23a1-baa9-454a-b5be-233683ba01b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a7b238bbdf0>]}
[0m09:26:59.346015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fbde23a1-baa9-454a-b5be-233683ba01b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a7b237c3be0>]}
[0m09:26:59.346979 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m09:26:59.349658 [info ] [MainThread]: 
[0m09:26:59.350815 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m09:26:59.362881 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m09:26:59.364141 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m09:26:59.392348 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:26:59.401271 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:27:02.786835 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m09:27:02.830450 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m09:27:03.029488 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m09:27:03.073986 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m09:27:03.077409 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m09:27:03.078390 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m09:27:03.089911 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m09:27:03.093854 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m09:27:03.338426 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m09:27:03.339703 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m09:27:03.345220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fbde23a1-baa9-454a-b5be-233683ba01b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a7b236fd1f0>]}
[0m09:27:03.346343 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m09:27:03.347154 [info ] [MainThread]: 
[0m09:27:03.365114 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m09:27:03.366421 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m09:27:03.367543 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.mpg_standardized'
[0m09:27:03.368311 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m09:27:03.385130 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m09:27:03.386532 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m09:27:03.480644 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m09:27:06.189551 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  /*
  coalesce(
        horsepower,
        avg(horsepower) over (partition by cylinders)
    ) as horsepower_imputed,
  */
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
          )
        
        ...
[0m09:27:06.444377 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m09:27:06.461825 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m09:27:06.705853 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m09:27:06.712473 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m09:27:06.713977 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  /*
  coalesce(
        horsepower,
        avg(horsepower) over (partition by cylinders)
    ) as horsepower_imputed,
  */
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
  ...
[0m09:27:06.958306 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m09:27:06.966938 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */
EXCHANGE TABLES `clean`.`mpg_standardized__dbt_backup` AND `clean`.`mpg_standardized` 
  
  ...
[0m09:27:07.213160 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m09:27:07.326426 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m09:27:07.572884 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m09:27:07.579313 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fbde23a1-baa9-454a-b5be-233683ba01b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a7b269767f0>]}
[0m09:27:07.580605 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized` ................... [[32mOK[0m in 4.21s]
[0m09:27:07.581961 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m09:27:07.583458 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m09:27:07.584471 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m09:27:07.585677 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m09:27:07.586430 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m09:27:07.592636 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m09:27:07.593866 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m09:27:07.642307 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m09:27:10.346591 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m09:27:10.348716 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin__dbt_tmp` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m09:27:10.597326 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m09:27:10.619024 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m09:27:10.861377 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m09:27:10.864036 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin` to `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m09:27:11.106311 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m09:27:11.114452 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin` 
  
  ...
[0m09:27:11.360473 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m09:27:11.362681 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin__dbt_tmp` to `mart`.`cylinders_by_origin` 
  
  ...
[0m09:27:11.607842 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m09:27:11.623707 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  ...
[0m09:27:11.879259 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m09:27:11.884099 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fbde23a1-baa9-454a-b5be-233683ba01b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a7b23462d60>]}
[0m09:27:11.886329 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 4.30s]
[0m09:27:11.888895 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m09:27:11.896879 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:27:11.898260 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m09:27:11.899458 [debug] [MainThread]: On list__mart: Close
[0m09:27:11.900610 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m09:27:11.901787 [debug] [MainThread]: On list__clean: Close
[0m09:27:11.903087 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m09:27:11.904333 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m09:27:11.905549 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m09:27:11.906802 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m09:27:11.908907 [info ] [MainThread]: 
[0m09:27:11.910809 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 12.56 seconds (12.56s).
[0m09:27:11.915166 [debug] [MainThread]: Command end result
[0m09:27:12.027328 [info ] [MainThread]: 
[0m09:27:12.028990 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:27:12.030360 [info ] [MainThread]: 
[0m09:27:12.031802 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m09:27:12.034418 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 14.029943, "process_in_blocks": "48", "process_kernel_time": 0.697806, "process_mem_max_rss": "111412", "process_out_blocks": "9520", "process_user_time": 5.631438}
[0m09:27:12.036211 [debug] [MainThread]: Command `dbt build` succeeded at 09:27:12.035740 after 14.03 seconds
[0m09:27:12.037692 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a7b273d2310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a7b23462d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a7b2333f1f0>]}
[0m09:27:12.039122 [debug] [MainThread]: Flushing usage events
[0m04:38:19.610215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75456feca310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75456cb3db20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75456cb3d9d0>]}


============================== 04:38:19.635094 | 86b0bd29-3778-4197-8640-b2a92ffadaed ==============================
[0m04:38:19.635094 [info ] [MainThread]: Running with dbt=1.8.9
[0m04:38:19.636443 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'target_path': 'None', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'profiles_dir': '.', 'debug': 'False', 'quiet': 'False', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'cache_selected_only': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'log_cache_events': 'False', 'empty': 'False', 'write_json': 'True', 'printer_width': '80', 'log_path': '/workdir/transforms/01_mpg/logs', 'use_colors': 'True', 'introspect': 'True', 'warn_error': 'None', 'static_parser': 'True', 'no_print': 'None', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m04:38:19.933868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '86b0bd29-3778-4197-8640-b2a92ffadaed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75456cb9da30>]}
[0m04:38:20.041396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '86b0bd29-3778-4197-8640-b2a92ffadaed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75456cb11760>]}
[0m04:38:20.042752 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m04:38:20.210015 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m04:38:20.486849 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m04:38:20.488022 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m04:38:20.983874 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '86b0bd29-3778-4197-8640-b2a92ffadaed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75456b0d1130>]}
[0m04:38:21.193620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '86b0bd29-3778-4197-8640-b2a92ffadaed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75456af8d4f0>]}
[0m04:38:21.194485 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m04:38:21.197498 [info ] [MainThread]: 
[0m04:38:21.198653 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m04:38:21.210641 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m04:38:21.216990 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m04:38:21.237158 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:38:21.242395 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:38:24.531814 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m04:38:24.603909 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m04:38:24.769474 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:38:24.855151 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m04:38:24.867656 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m04:38:24.868751 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m04:38:24.888747 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m04:38:24.892867 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m04:38:25.130914 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:38:25.135042 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:38:25.138792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '86b0bd29-3778-4197-8640-b2a92ffadaed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75456aad5c70>]}
[0m04:38:25.139850 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m04:38:25.140587 [info ] [MainThread]: 
[0m04:38:25.161593 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m04:38:25.163180 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m04:38:25.164318 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__mart, now model.ex_01_mpg.mpg_standardized)
[0m04:38:25.165138 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m04:38:25.182312 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m04:38:25.183573 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m04:38:25.300076 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
-- where horsepower is not null
          )
        
        ...
[0m04:38:25.551635 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m04:38:25.569227 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m04:38:25.810838 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:38:25.821909 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m04:38:25.823934 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
-- where horsepower is not null
  ...
[0m04:38:26.072979 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m04:38:26.088875 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */
EXCHANGE TABLES `clean`.`mpg_standardized__dbt_backup` AND `clean`.`mpg_standardized` 
  
  ...
[0m04:38:26.330085 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:38:26.393538 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m04:38:26.636220 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:38:26.642481 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86b0bd29-3778-4197-8640-b2a92ffadaed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75456ab8c7f0>]}
[0m04:38:26.643738 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized` ................... [[32mOK[0m in 1.48s]
[0m04:38:26.645109 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m04:38:26.646686 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m04:38:26.647688 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m04:38:26.648766 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m04:38:26.649534 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m04:38:26.655253 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m04:38:26.656574 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m04:38:26.705767 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m04:38:29.375960 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m04:38:29.377569 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin__dbt_tmp` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m04:38:29.622288 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:38:29.635076 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m04:38:29.874755 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:38:29.877787 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin` to `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m04:38:30.118117 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:38:30.124142 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin` 
  
  ...
[0m04:38:30.364458 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:38:30.368076 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin__dbt_tmp` to `mart`.`cylinders_by_origin` 
  
  ...
[0m04:38:30.611673 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:38:30.623140 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  ...
[0m04:38:30.863791 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:38:30.868677 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86b0bd29-3778-4197-8640-b2a92ffadaed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75456ab92f10>]}
[0m04:38:30.870787 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 4.22s]
[0m04:38:30.873076 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m04:38:30.875704 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:38:30.876381 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m04:38:30.876942 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m04:38:30.877488 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m04:38:30.877980 [debug] [MainThread]: On list__clean: Close
[0m04:38:30.878500 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m04:38:30.878991 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m04:38:30.879820 [info ] [MainThread]: 
[0m04:38:30.880535 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 9.68 seconds (9.68s).
[0m04:38:30.882338 [debug] [MainThread]: Command end result
[0m04:38:30.982344 [info ] [MainThread]: 
[0m04:38:30.983825 [info ] [MainThread]: [32mCompleted successfully[0m
[0m04:38:30.984982 [info ] [MainThread]: 
[0m04:38:30.986184 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m04:38:30.988609 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 11.489199, "process_in_blocks": "56", "process_kernel_time": 0.646114, "process_mem_max_rss": "113896", "process_out_blocks": "10488", "process_user_time": 5.789029}
[0m04:38:30.990148 [debug] [MainThread]: Command `dbt build` succeeded at 04:38:30.989747 after 11.49 seconds
[0m04:38:30.991393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75456feca310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75456d6526d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75456d653c40>]}
[0m04:38:30.992608 [debug] [MainThread]: Flushing usage events
[0m04:40:19.932502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7146522ddd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71464ef443d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71464ef44520>]}


============================== 04:40:19.943690 | d8b49059-9890-49c1-a85e-acb5c3643533 ==============================
[0m04:40:19.943690 [info ] [MainThread]: Running with dbt=1.8.9
[0m04:40:19.944948 [debug] [MainThread]: running dbt with arguments {'empty': 'False', 'debug': 'False', 'write_json': 'True', 'version_check': 'True', 'quiet': 'False', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'printer_width': '80', 'introspect': 'True', 'log_cache_events': 'False', 'log_format': 'default', 'fail_fast': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'no_print': 'None', 'use_colors': 'True', 'target_path': 'None', 'profiles_dir': '.', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'static_parser': 'True', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'partial_parse': 'True'}
[0m04:40:20.242931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd8b49059-9890-49c1-a85e-acb5c3643533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71464ee2ec70>]}
[0m04:40:20.338135 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd8b49059-9890-49c1-a85e-acb5c3643533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7146524d2df0>]}
[0m04:40:20.339520 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m04:40:20.513429 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m04:40:20.732415 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m04:40:20.733477 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m04:40:21.178707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd8b49059-9890-49c1-a85e-acb5c3643533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71464d4e6130>]}
[0m04:40:21.390857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd8b49059-9890-49c1-a85e-acb5c3643533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71464d3a5760>]}
[0m04:40:21.391731 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m04:40:21.394463 [info ] [MainThread]: 
[0m04:40:21.395591 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m04:40:21.409404 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m04:40:21.410664 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m04:40:21.453096 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:40:21.458040 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:40:25.025608 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m04:40:25.153980 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m04:40:25.273666 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m04:40:25.423427 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:40:25.427119 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m04:40:25.428150 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m04:40:25.440731 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m04:40:25.447790 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m04:40:25.697451 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m04:40:25.719578 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:40:25.722896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd8b49059-9890-49c1-a85e-acb5c3643533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x714653ab35e0>]}
[0m04:40:25.724283 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m04:40:25.725225 [info ] [MainThread]: 
[0m04:40:25.744403 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m04:40:25.745645 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m04:40:25.746582 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__mart, now model.ex_01_mpg.mpg_standardized)
[0m04:40:25.747339 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m04:40:25.764360 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m04:40:25.765613 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m04:40:25.879020 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
 where horsepower is not null
          )
        
        ...
[0m04:40:26.156408 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m04:40:26.186542 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m04:40:26.457354 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:40:26.463947 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m04:40:26.465407 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  mpg,            -- Nullable(Float64)
  cylinders,      -- Nullable(Int64)
  displacement,   -- Nullable(Float64)
  horsepower,     -- Nullable(Float64)
  weight,         -- Nullable(Int64)
  acceleration,   -- Nullable(Float64)
  model_year,     -- Nullable(Int64)
  origin,         -- Nullable(String)
  name as make    -- Nullable(String)
from `raw`.`autompg___cars`
 where horsepower is not null
  ...
[0m04:40:26.735771 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:40:26.751771 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */
EXCHANGE TABLES `clean`.`mpg_standardized__dbt_backup` AND `clean`.`mpg_standardized` 
  
  ...
[0m04:40:27.020520 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:40:27.089556 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m04:40:27.358075 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:40:27.368743 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd8b49059-9890-49c1-a85e-acb5c3643533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71464c6c1d00>]}
[0m04:40:27.370814 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized` ................... [[32mOK[0m in 1.62s]
[0m04:40:27.372940 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m04:40:27.374744 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m04:40:27.376085 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m04:40:27.377346 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m04:40:27.378166 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m04:40:27.384673 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m04:40:27.386042 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m04:40:27.437066 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m04:40:30.423126 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m04:40:30.424768 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin__dbt_tmp` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m04:40:30.696858 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:40:30.710325 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m04:40:30.978534 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:40:30.980678 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin` to `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m04:40:31.248516 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:40:31.254738 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin` 
  
  ...
[0m04:40:31.521983 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:40:31.524101 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin__dbt_tmp` to `mart`.`cylinders_by_origin` 
  
  ...
[0m04:40:31.791610 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:40:31.805005 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  ...
[0m04:40:32.075852 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:40:32.080713 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd8b49059-9890-49c1-a85e-acb5c3643533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71464e7c1700>]}
[0m04:40:32.087093 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 4.70s]
[0m04:40:32.089642 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m04:40:32.102695 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:40:32.103891 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m04:40:32.105038 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m04:40:32.106106 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m04:40:32.107177 [debug] [MainThread]: On list__clean: Close
[0m04:40:32.108214 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m04:40:32.109346 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m04:40:32.111089 [info ] [MainThread]: 
[0m04:40:32.112771 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 10.72 seconds (10.72s).
[0m04:40:32.117466 [debug] [MainThread]: Command end result
[0m04:40:32.217331 [info ] [MainThread]: 
[0m04:40:32.218845 [info ] [MainThread]: [32mCompleted successfully[0m
[0m04:40:32.220021 [info ] [MainThread]: 
[0m04:40:32.221337 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m04:40:32.223839 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 12.395374, "process_in_blocks": "456", "process_kernel_time": 0.642731, "process_mem_max_rss": "113972", "process_out_blocks": "10504", "process_user_time": 5.715615}
[0m04:40:32.225541 [debug] [MainThread]: Command `dbt build` succeeded at 04:40:32.225017 after 12.40 seconds
[0m04:40:32.226803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7146522ddd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71464e599220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71465255fb20>]}
[0m04:40:32.228058 [debug] [MainThread]: Flushing usage events
[0m04:45:54.782026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c4afc8af310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c4af9518b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c4af9518a30>]}


============================== 04:45:54.791963 | 01fbea5a-e60e-4652-af4a-76d3122f4d96 ==============================
[0m04:45:54.791963 [info ] [MainThread]: Running with dbt=1.8.9
[0m04:45:54.793136 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'quiet': 'False', 'profiles_dir': '.', 'target_path': 'None', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'fail_fast': 'False', 'introspect': 'True', 'partial_parse': 'True', 'log_format': 'default', 'version_check': 'True', 'debug': 'False', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'log_path': '/workdir/transforms/01_mpg/logs', 'empty': 'False', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False', 'use_colors': 'True', 'warn_error': 'None', 'printer_width': '80', 'write_json': 'True'}
[0m04:45:55.091838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '01fbea5a-e60e-4652-af4a-76d3122f4d96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c4af94d0cd0>]}
[0m04:45:55.191020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '01fbea5a-e60e-4652-af4a-76d3122f4d96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c4af95d80a0>]}
[0m04:45:55.192809 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m04:45:55.365002 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m04:45:55.597113 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m04:45:55.598207 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m04:45:56.044562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '01fbea5a-e60e-4652-af4a-76d3122f4d96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c4af7ac1130>]}
[0m04:45:56.265824 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '01fbea5a-e60e-4652-af4a-76d3122f4d96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c4af797f400>]}
[0m04:45:56.266703 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m04:45:56.269705 [info ] [MainThread]: 
[0m04:45:56.270861 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m04:45:56.282886 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m04:45:56.284097 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m04:45:56.332815 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:45:56.331883 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:45:59.998078 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m04:46:00.267341 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:46:02.414357 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m04:46:02.707069 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m04:46:02.711952 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m04:46:02.712977 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m04:46:02.725539 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m04:46:02.729663 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m04:46:02.999149 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:46:03.008373 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m04:46:03.011785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '01fbea5a-e60e-4652-af4a-76d3122f4d96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c4af7456520>]}
[0m04:46:03.013254 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m04:46:03.014149 [info ] [MainThread]: 
[0m04:46:03.033391 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m04:46:03.034662 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m04:46:03.035712 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__clean, now model.ex_01_mpg.mpg_standardized)
[0m04:46:03.036482 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m04:46:03.053388 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m04:46:03.054641 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m04:46:03.166190 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64OrNull(mpg)          as mpg,
  toInt32OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt32OrNull(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
-- where horsepower is not null
          )
        
        ...
[0m04:46:03.455086 [debug] [Thread-1  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64OrNull(mpg)          as mpg,
  toInt32OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt32OrNull(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
-- where horsepower is not null
          )
        
        
[0m04:46:03.665554 [debug] [Thread-1  ]: Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 43
   Code: 43. DB::Exception: Illegal type Float64 of first argument of function toFloat64OrNull. Conversion functions with postfix 'OrZero' or 'OrNull' should take String argument: While processing toFloat64OrNull(mpg) AS mpg, toInt32OrNull(cylinders) AS cylinders, toFloat64OrNull(displacement) AS displacement, toFloat64OrNull(horsepower) AS horsepower, toInt32OrNull(weight) AS weight, toFloat64OrNull(acceleration) AS acceleration, toInt32OrNull(model_year) AS model_year, trimBoth(origin) AS origin, trimBoth(name) AS make. (ILLEGAL_TYPE_OF_ARGUMENT) (version 23.12.6.19 (official build))
[0m04:46:03.668576 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01fbea5a-e60e-4652-af4a-76d3122f4d96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c4afcaee910>]}
[0m04:46:03.669991 [error] [Thread-1  ]: 1 of 2 ERROR creating sql table model `clean`.`mpg_standardized` ............... [[31mERROR[0m in 0.63s]
[0m04:46:03.671632 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m04:46:03.673448 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m04:46:03.674469 [info ] [Thread-3  ]: 2 of 2 SKIP relation mart.cylinders_by_origin .................................. [[33mSKIP[0m]
[0m04:46:03.675654 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m04:46:03.677866 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:46:03.678580 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m04:46:03.679142 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m04:46:03.679693 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m04:46:03.680223 [debug] [MainThread]: On list__mart: Close
[0m04:46:03.681025 [info ] [MainThread]: 
[0m04:46:03.681788 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 7.41 seconds (7.41s).
[0m04:46:03.683222 [debug] [MainThread]: Command end result
[0m04:46:03.736644 [info ] [MainThread]: 
[0m04:46:03.737564 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m04:46:03.738144 [info ] [MainThread]: 
[0m04:46:03.738995 [error] [MainThread]:   Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 43
   Code: 43. DB::Exception: Illegal type Float64 of first argument of function toFloat64OrNull. Conversion functions with postfix 'OrZero' or 'OrNull' should take String argument: While processing toFloat64OrNull(mpg) AS mpg, toInt32OrNull(cylinders) AS cylinders, toFloat64OrNull(displacement) AS displacement, toFloat64OrNull(horsepower) AS horsepower, toInt32OrNull(weight) AS weight, toFloat64OrNull(acceleration) AS acceleration, toInt32OrNull(model_year) AS model_year, trimBoth(origin) AS origin, trimBoth(name) AS make. (ILLEGAL_TYPE_OF_ARGUMENT) (version 23.12.6.19 (official build))
[0m04:46:03.739708 [info ] [MainThread]: 
[0m04:46:03.740350 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
[0m04:46:03.741694 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 9.054285, "process_in_blocks": "320", "process_kernel_time": 0.675086, "process_mem_max_rss": "113984", "process_out_blocks": "10464", "process_user_time": 5.24367}
[0m04:46:03.742432 [debug] [MainThread]: Command `dbt build` failed at 04:46:03.742238 after 9.06 seconds
[0m04:46:03.743129 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c4afc8af310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c4afa7dd910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c4afca71e20>]}
[0m04:46:03.743781 [debug] [MainThread]: Flushing usage events
[0m04:48:25.244121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x723ae393f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x723ae05a4b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x723ae05a4a00>]}


============================== 04:48:25.254339 | 3c6bbd47-c496-4b22-9ff2-ab00caf91e11 ==============================
[0m04:48:25.254339 [info ] [MainThread]: Running with dbt=1.8.9
[0m04:48:25.255503 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'cache_selected_only': 'False', 'empty': 'False', 'log_format': 'default', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'version_check': 'True', 'static_parser': 'True', 'profiles_dir': '.', 'indirect_selection': 'eager', 'warn_error': 'None', 'write_json': 'True', 'log_path': '/workdir/transforms/01_mpg/logs', 'use_colors': 'True', 'quiet': 'False', 'target_path': 'None', 'no_print': 'None'}
[0m04:48:25.543323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3c6bbd47-c496-4b22-9ff2-ab00caf91e11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x723ae057f160>]}
[0m04:48:25.642893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3c6bbd47-c496-4b22-9ff2-ab00caf91e11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x723ae06aed60>]}
[0m04:48:25.644439 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m04:48:25.836053 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m04:48:26.072213 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m04:48:26.072927 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m04:48:26.145887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3c6bbd47-c496-4b22-9ff2-ab00caf91e11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x723adfe1d130>]}
[0m04:48:26.490127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3c6bbd47-c496-4b22-9ff2-ab00caf91e11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x723adfd65280>]}
[0m04:48:26.491716 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m04:48:26.496453 [info ] [MainThread]: 
[0m04:48:26.498397 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m04:48:26.520996 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m04:48:26.538165 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m04:48:26.610338 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:48:26.615461 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:48:30.059620 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m04:48:30.201404 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m04:48:30.302113 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:48:30.451735 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m04:48:30.455806 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m04:48:30.457190 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m04:48:30.477421 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m04:48:30.485466 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m04:48:30.734901 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m04:48:30.742188 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.26 seconds
[0m04:48:30.747840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3c6bbd47-c496-4b22-9ff2-ab00caf91e11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x723adf84a7f0>]}
[0m04:48:30.749042 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m04:48:30.749924 [info ] [MainThread]: 
[0m04:48:30.763896 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m04:48:30.765327 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m04:48:30.766842 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.mpg_standardized'
[0m04:48:30.767952 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m04:48:30.785906 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m04:48:30.787380 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m04:48:30.894214 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m04:48:33.680402 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64OrNull(mpg)          as mpg,
  toInt32OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt32OrNull(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
-- where horsepower is not null
          )
        
        ...
[0m04:48:33.932438 [debug] [Thread-1  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64OrNull(mpg)          as mpg,
  toInt32OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt32OrNull(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
-- where horsepower is not null
          )
        
        
[0m04:48:33.936659 [debug] [Thread-1  ]: Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 43
   Code: 43. DB::Exception: Illegal type Float64 of first argument of function toFloat64OrNull. Conversion functions with postfix 'OrZero' or 'OrNull' should take String argument: While processing toFloat64OrNull(mpg) AS mpg, toInt32OrNull(cylinders) AS cylinders, toFloat64OrNull(displacement) AS displacement, toFloat64OrNull(horsepower) AS horsepower, toInt32OrNull(weight) AS weight, toFloat64OrNull(acceleration) AS acceleration, toInt32OrNull(model_year) AS model_year, trimBoth(origin) AS origin, trimBoth(name) AS make. (ILLEGAL_TYPE_OF_ARGUMENT) (version 23.12.6.19 (official build))
[0m04:48:33.939284 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3c6bbd47-c496-4b22-9ff2-ab00caf91e11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x723adef8c790>]}
[0m04:48:33.940477 [error] [Thread-1  ]: 1 of 2 ERROR creating sql table model `clean`.`mpg_standardized` ............... [[31mERROR[0m in 3.17s]
[0m04:48:33.941904 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m04:48:33.943523 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m04:48:33.944397 [info ] [Thread-3  ]: 2 of 2 SKIP relation mart.cylinders_by_origin .................................. [[33mSKIP[0m]
[0m04:48:33.945306 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m04:48:33.947160 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:48:33.947838 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m04:48:33.948394 [debug] [MainThread]: On list__mart: Close
[0m04:48:33.949049 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m04:48:33.949575 [debug] [MainThread]: On list__clean: Close
[0m04:48:33.950063 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m04:48:33.950556 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m04:48:33.951352 [info ] [MainThread]: 
[0m04:48:33.951996 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 7.45 seconds (7.45s).
[0m04:48:33.953467 [debug] [MainThread]: Command end result
[0m04:48:34.074240 [info ] [MainThread]: 
[0m04:48:34.075131 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m04:48:34.075749 [info ] [MainThread]: 
[0m04:48:34.076595 [error] [MainThread]:   Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 43
   Code: 43. DB::Exception: Illegal type Float64 of first argument of function toFloat64OrNull. Conversion functions with postfix 'OrZero' or 'OrNull' should take String argument: While processing toFloat64OrNull(mpg) AS mpg, toInt32OrNull(cylinders) AS cylinders, toFloat64OrNull(displacement) AS displacement, toFloat64OrNull(horsepower) AS horsepower, toInt32OrNull(weight) AS weight, toFloat64OrNull(acceleration) AS acceleration, toInt32OrNull(model_year) AS model_year, trimBoth(origin) AS origin, trimBoth(name) AS make. (ILLEGAL_TYPE_OF_ARGUMENT) (version 23.12.6.19 (official build))
[0m04:48:34.077328 [info ] [MainThread]: 
[0m04:48:34.077978 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
[0m04:48:34.079322 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 8.929792, "process_in_blocks": "0", "process_kernel_time": 0.637605, "process_mem_max_rss": "111164", "process_out_blocks": "9488", "process_user_time": 5.013761}
[0m04:48:34.080310 [debug] [MainThread]: Command `dbt build` failed at 04:48:34.080046 after 8.93 seconds
[0m04:48:34.080967 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x723ae393f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x723ae17ee1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x723ae3b44070>]}
[0m04:48:34.081701 [debug] [MainThread]: Flushing usage events
[0m04:57:08.379284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74dfc96e2dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74dfc6338400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74dfc6338550>]}


============================== 04:57:08.389795 | d5f8e3f6-b6c9-4fda-ab01-10ea4829ced0 ==============================
[0m04:57:08.389795 [info ] [MainThread]: Running with dbt=1.8.9
[0m04:57:08.390985 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'indirect_selection': 'eager', 'write_json': 'True', 'printer_width': '80', 'log_cache_events': 'False', 'fail_fast': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'quiet': 'False', 'target_path': 'None', 'use_experimental_parser': 'False', 'log_format': 'default', 'partial_parse': 'True', 'no_print': 'None', 'empty': 'False', 'version_check': 'True', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'introspect': 'True', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'debug': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'profiles_dir': '.', 'use_colors': 'True'}
[0m04:57:08.714388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd5f8e3f6-b6c9-4fda-ab01-10ea4829ced0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74dfc8b71940>]}
[0m04:57:08.815926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd5f8e3f6-b6c9-4fda-ab01-10ea4829ced0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74dfc63ec220>]}
[0m04:57:08.817502 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m04:57:09.003912 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m04:57:09.226571 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m04:57:09.227311 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m04:57:09.300476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd5f8e3f6-b6c9-4fda-ab01-10ea4829ced0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74dfc5bb6130>]}
[0m04:57:09.763277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd5f8e3f6-b6c9-4fda-ab01-10ea4829ced0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74dfc5aff1f0>]}
[0m04:57:09.764121 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m04:57:09.766802 [info ] [MainThread]: 
[0m04:57:09.767934 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m04:57:09.779722 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m04:57:09.780831 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m04:57:09.818217 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:57:09.820344 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:57:13.138878 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m04:57:13.186531 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m04:57:13.376587 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:57:13.428184 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:57:13.431504 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m04:57:13.442654 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m04:57:13.443668 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m04:57:13.447709 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m04:57:13.689861 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:57:13.693568 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:57:13.696445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd5f8e3f6-b6c9-4fda-ab01-10ea4829ced0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74dfc5a8cf70>]}
[0m04:57:13.697397 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m04:57:13.698059 [info ] [MainThread]: 
[0m04:57:13.711980 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m04:57:13.713192 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m04:57:13.714412 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.mpg_standardized'
[0m04:57:13.715161 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m04:57:13.731865 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m04:57:13.733105 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m04:57:13.826389 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m04:57:16.564328 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64OrNull(mpg)          as mpg,
  toInt32OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt32OrNull(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
-- where horsepower is not null
          )
        
        ...
[0m04:57:16.815723 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m04:57:16.832228 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m04:57:17.075744 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:57:17.089071 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m04:57:17.091543 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64OrNull(mpg)          as mpg,
  toInt32OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt32OrNull(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
-- where horsepower is not null
  ...
[0m04:57:17.336573 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:57:17.345332 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */
EXCHANGE TABLES `clean`.`mpg_standardized__dbt_backup` AND `clean`.`mpg_standardized` 
  
  ...
[0m04:57:17.851818 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.51 seconds
[0m04:57:18.053501 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m04:57:18.296007 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:57:18.302270 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5f8e3f6-b6c9-4fda-ab01-10ea4829ced0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74dfcbea69a0>]}
[0m04:57:18.303519 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized` ................... [[32mOK[0m in 4.59s]
[0m04:57:18.304850 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m04:57:18.306415 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m04:57:18.307372 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m04:57:18.308616 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m04:57:18.309471 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m04:57:18.315446 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m04:57:18.316587 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m04:57:18.366891 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m04:57:21.048089 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m04:57:21.049551 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin__dbt_tmp` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m04:57:21.295488 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:57:21.308023 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m04:57:21.548884 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:57:21.551027 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin` to `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m04:57:21.792395 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:57:21.806373 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin` 
  
  ...
[0m04:57:22.048706 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:57:22.052366 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin__dbt_tmp` to `mart`.`cylinders_by_origin` 
  
  ...
[0m04:57:22.294427 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:57:22.306342 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  ...
[0m04:57:22.548479 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m04:57:22.551204 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5f8e3f6-b6c9-4fda-ab01-10ea4829ced0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74dfc61b7fd0>]}
[0m04:57:22.552458 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 4.24s]
[0m04:57:22.553845 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m04:57:22.555926 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:57:22.556530 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m04:57:22.557067 [debug] [MainThread]: On list__clean: Close
[0m04:57:22.557589 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m04:57:22.558064 [debug] [MainThread]: On list__mart: Close
[0m04:57:22.558538 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m04:57:22.559030 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m04:57:22.559510 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m04:57:22.560019 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m04:57:22.561027 [info ] [MainThread]: 
[0m04:57:22.561791 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 12.79 seconds (12.79s).
[0m04:57:22.563612 [debug] [MainThread]: Command end result
[0m04:57:22.625506 [info ] [MainThread]: 
[0m04:57:22.626513 [info ] [MainThread]: [32mCompleted successfully[0m
[0m04:57:22.627150 [info ] [MainThread]: 
[0m04:57:22.627896 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m04:57:22.629566 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 14.356609, "process_in_blocks": "976", "process_kernel_time": 0.640396, "process_mem_max_rss": "111264", "process_out_blocks": "9512", "process_user_time": 5.217084}
[0m04:57:22.630462 [debug] [MainThread]: Command `dbt build` succeeded at 04:57:22.630151 after 14.36 seconds
[0m04:57:22.631595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74dfc96e2dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74dfc563e310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74dfc755a490>]}
[0m04:57:22.632334 [debug] [MainThread]: Flushing usage events
[0m04:59:14.595363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74690a124310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x746906d85b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x746906d85a00>]}


============================== 04:59:14.605605 | 58982088-d5d1-4347-9152-1448b80b4045 ==============================
[0m04:59:14.605605 [info ] [MainThread]: Running with dbt=1.8.9
[0m04:59:14.606732 [debug] [MainThread]: running dbt with arguments {'log_cache_events': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'indirect_selection': 'eager', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'target_path': 'None', 'cache_selected_only': 'False', 'log_format': 'default', 'version_check': 'True', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'profiles_dir': '.', 'empty': 'False', 'debug': 'False', 'static_parser': 'True', 'write_json': 'True', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'fail_fast': 'False', 'partial_parse': 'True', 'no_print': 'None', 'quiet': 'False'}
[0m04:59:14.961321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '58982088-d5d1-4347-9152-1448b80b4045', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7469096c2ca0>]}
[0m04:59:15.071760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '58982088-d5d1-4347-9152-1448b80b4045', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74690789e670>]}
[0m04:59:15.073175 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m04:59:15.271627 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m04:59:15.493792 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m04:59:15.494845 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m04:59:15.922111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '58982088-d5d1-4347-9152-1448b80b4045', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x746905331130>]}
[0m04:59:16.163696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '58982088-d5d1-4347-9152-1448b80b4045', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7469051ec220>]}
[0m04:59:16.164975 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m04:59:16.167989 [info ] [MainThread]: 
[0m04:59:16.169262 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m04:59:16.181924 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m04:59:16.182997 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m04:59:16.230317 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:59:16.231170 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:59:19.806869 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m04:59:20.065856 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.26 seconds
[0m04:59:25.172158 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m04:59:25.448388 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:59:25.453443 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m04:59:25.454781 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m04:59:25.471139 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m04:59:25.476183 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m04:59:25.743895 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:59:25.755345 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m04:59:25.758490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '58982088-d5d1-4347-9152-1448b80b4045', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x746904d50130>]}
[0m04:59:25.759427 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m04:59:25.760070 [info ] [MainThread]: 
[0m04:59:25.772761 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m04:59:25.773994 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m04:59:25.774879 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__mart, now model.ex_01_mpg.mpg_standardized)
[0m04:59:25.775602 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m04:59:25.791988 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m04:59:25.793282 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m04:59:25.893722 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64OrNull(mpg)          as mpg,
  toInt32OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt32OrNull(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
where horsepower is not null
          )
        
        ...
[0m04:59:26.178078 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m04:59:26.194634 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m04:59:26.470532 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:59:26.477348 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m04:59:26.478705 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64OrNull(mpg)          as mpg,
  toInt32OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt32OrNull(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
where horsepower is not null
  ...
[0m04:59:26.756771 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m04:59:26.772806 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */
EXCHANGE TABLES `clean`.`mpg_standardized__dbt_backup` AND `clean`.`mpg_standardized` 
  
  ...
[0m04:59:27.048814 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:59:27.098099 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m04:59:27.373455 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:59:27.380195 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '58982088-d5d1-4347-9152-1448b80b4045', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74690451d4f0>]}
[0m04:59:27.381602 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized` ................... [[32mOK[0m in 1.60s]
[0m04:59:27.382996 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m04:59:27.384384 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m04:59:27.385571 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m04:59:27.386810 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m04:59:27.387569 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m04:59:27.393573 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m04:59:27.394783 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m04:59:27.443179 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m04:59:30.764211 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m04:59:30.765812 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin__dbt_tmp` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m04:59:31.046802 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m04:59:31.071088 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m04:59:31.347048 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:59:31.350734 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin` to `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m04:59:32.369224 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 1.02 seconds
[0m04:59:32.379320 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin` 
  
  ...
[0m04:59:32.654970 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:59:32.657112 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin__dbt_tmp` to `mart`.`cylinders_by_origin` 
  
  ...
[0m04:59:33.680720 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 1.02 seconds
[0m04:59:33.687710 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  ...
[0m04:59:33.962012 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m04:59:33.964614 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '58982088-d5d1-4347-9152-1448b80b4045', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7469044c1c40>]}
[0m04:59:33.965750 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 6.58s]
[0m04:59:33.967546 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m04:59:33.969868 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:59:33.970742 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m04:59:33.971614 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m04:59:33.972430 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m04:59:33.973245 [debug] [MainThread]: On list__clean: Close
[0m04:59:33.974040 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m04:59:33.974867 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m04:59:33.976219 [info ] [MainThread]: 
[0m04:59:33.977255 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 17.81 seconds (17.81s).
[0m04:59:33.980068 [debug] [MainThread]: Command end result
[0m04:59:34.046841 [info ] [MainThread]: 
[0m04:59:34.048122 [info ] [MainThread]: [32mCompleted successfully[0m
[0m04:59:34.049298 [info ] [MainThread]: 
[0m04:59:34.049960 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m04:59:34.051404 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 19.555983, "process_in_blocks": "0", "process_kernel_time": 0.694831, "process_mem_max_rss": "114080", "process_out_blocks": "10496", "process_user_time": 5.719614}
[0m04:59:34.052289 [debug] [MainThread]: Command `dbt build` succeeded at 04:59:34.052039 after 19.56 seconds
[0m04:59:34.053000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74690a124310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74690804dd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74690886aca0>]}
[0m04:59:34.053704 [debug] [MainThread]: Flushing usage events
[0m05:00:27.600178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73769378a310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7376903edaf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7376903ed9a0>]}


============================== 05:00:27.609784 | 94fc8902-cdd5-41b6-99cc-e65e346c4911 ==============================
[0m05:00:27.609784 [info ] [MainThread]: Running with dbt=1.8.9
[0m05:00:27.610936 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '.', 'printer_width': '80', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'introspect': 'True', 'quiet': 'False', 'no_print': 'None', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_format': 'default', 'write_json': 'True', 'log_path': '/workdir/transforms/01_mpg/logs', 'target_path': 'None', 'empty': 'False', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'log_cache_events': 'False', 'static_parser': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'debug': 'False', 'version_check': 'True'}
[0m05:00:27.929961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '94fc8902-cdd5-41b6-99cc-e65e346c4911', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x737695f4c880>]}
[0m05:00:28.038686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '94fc8902-cdd5-41b6-99cc-e65e346c4911', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x737690259af0>]}
[0m05:00:28.040012 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m05:00:28.213186 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m05:00:28.437607 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:00:28.438296 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:00:28.512007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '94fc8902-cdd5-41b6-99cc-e65e346c4911', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73768fc74df0>]}
[0m05:00:28.738244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '94fc8902-cdd5-41b6-99cc-e65e346c4911', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73768fb7cb50>]}
[0m05:00:28.739131 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m05:00:28.741805 [info ] [MainThread]: 
[0m05:00:28.742931 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m05:00:28.755359 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m05:00:28.756437 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m05:00:28.778864 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:00:28.783827 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:00:32.118011 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m05:00:32.155630 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m05:00:32.357609 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m05:00:32.397500 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m05:00:32.402759 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m05:00:32.404072 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m05:00:32.419787 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m05:00:32.424061 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m05:00:32.664423 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m05:00:32.668798 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m05:00:32.673330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '94fc8902-cdd5-41b6-99cc-e65e346c4911', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73768ef42fa0>]}
[0m05:00:32.674279 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m05:00:32.674900 [info ] [MainThread]: 
[0m05:00:32.688600 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m05:00:32.689733 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m05:00:32.690886 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.mpg_standardized'
[0m05:00:32.691699 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m05:00:32.710016 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m05:00:32.711250 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m05:00:32.804176 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m05:00:35.709757 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64OrNull(mpg)          as mpg,
  toInt32OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt32OrNull(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
where horsepower is not null
          )
        
        ...
[0m05:00:35.960994 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m05:00:35.977696 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m05:00:36.218819 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m05:00:36.225315 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m05:00:36.226826 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64OrNull(mpg)          as mpg,
  toInt32OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt32OrNull(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
where horsepower is not null
  ...
[0m05:00:36.469496 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m05:00:36.480496 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */
EXCHANGE TABLES `clean`.`mpg_standardized__dbt_backup` AND `clean`.`mpg_standardized` 
  
  ...
[0m05:00:36.721596 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m05:00:36.849905 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m05:00:37.089885 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m05:00:37.097908 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '94fc8902-cdd5-41b6-99cc-e65e346c4911', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x737692d2e7f0>]}
[0m05:00:37.099333 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized` ................... [[32mOK[0m in 4.40s]
[0m05:00:37.100685 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m05:00:37.102218 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m05:00:37.103258 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m05:00:37.104430 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m05:00:37.105182 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m05:00:37.111562 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m05:00:37.112796 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m05:00:37.162840 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m05:00:39.834335 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m05:00:39.835759 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin__dbt_tmp` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m05:00:40.079282 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m05:00:40.092036 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m05:00:40.331528 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m05:00:40.333791 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin` to `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m05:00:40.581444 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m05:00:40.588897 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin` 
  
  ...
[0m05:00:40.828294 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m05:00:40.830448 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin__dbt_tmp` to `mart`.`cylinders_by_origin` 
  
  ...
[0m05:00:41.069675 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m05:00:41.076374 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  ...
[0m05:00:41.317359 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m05:00:41.319968 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '94fc8902-cdd5-41b6-99cc-e65e346c4911', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73768eeee8e0>]}
[0m05:00:41.321090 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 4.22s]
[0m05:00:41.322595 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m05:00:41.324772 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:00:41.325326 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m05:00:41.325840 [debug] [MainThread]: On list__mart: Close
[0m05:00:41.326334 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m05:00:41.326825 [debug] [MainThread]: On list__clean: Close
[0m05:00:41.327311 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m05:00:41.327792 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m05:00:41.328266 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m05:00:41.328837 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m05:00:41.329761 [info ] [MainThread]: 
[0m05:00:41.330444 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 12.59 seconds (12.59s).
[0m05:00:41.332177 [debug] [MainThread]: Command end result
[0m05:00:41.388759 [info ] [MainThread]: 
[0m05:00:41.389687 [info ] [MainThread]: [32mCompleted successfully[0m
[0m05:00:41.390336 [info ] [MainThread]: 
[0m05:00:41.390934 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m05:00:41.392368 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 13.886416, "process_in_blocks": "0", "process_kernel_time": 0.651191, "process_mem_max_rss": "111260", "process_out_blocks": "9512", "process_user_time": 5.289554}
[0m05:00:41.393183 [debug] [MainThread]: Command `dbt build` succeeded at 05:00:41.392972 after 13.89 seconds
[0m05:00:41.393827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73769378a310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73768ef42fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73768fcb27c0>]}
[0m05:00:41.394438 [debug] [MainThread]: Flushing usage events
[0m05:10:46.151696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bca5055f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bca4d1c0af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bca4d1c09a0>]}


============================== 05:10:46.161983 | eba9b1aa-21f2-48d0-b62a-d34e18a9b39a ==============================
[0m05:10:46.161983 [info ] [MainThread]: Running with dbt=1.8.9
[0m05:10:46.163161 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'introspect': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'profiles_dir': '.', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'empty': 'False', 'quiet': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'static_parser': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'cache_selected_only': 'False', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'target_path': 'None'}
[0m05:10:46.467863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eba9b1aa-21f2-48d0-b62a-d34e18a9b39a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bca52d25880>]}
[0m05:10:46.566455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eba9b1aa-21f2-48d0-b62a-d34e18a9b39a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bca4d030af0>]}
[0m05:10:46.567801 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m05:10:46.754140 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m05:10:46.993464 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m05:10:46.994536 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m05:10:47.444229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eba9b1aa-21f2-48d0-b62a-d34e18a9b39a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bca4b765130>]}
[0m05:10:47.689805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eba9b1aa-21f2-48d0-b62a-d34e18a9b39a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bca4b625250>]}
[0m05:10:47.690750 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m05:10:47.693643 [info ] [MainThread]: 
[0m05:10:47.694816 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m05:10:47.706758 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m05:10:47.707881 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m05:10:47.732036 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:10:47.741696 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:10:50.978470 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m05:10:51.191434 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m05:10:51.216795 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m05:10:51.437915 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m05:10:51.442201 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m05:10:51.443207 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m05:10:51.454627 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m05:10:51.458612 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m05:10:51.694794 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.23 seconds
[0m05:10:51.708540 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m05:10:51.711676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eba9b1aa-21f2-48d0-b62a-d34e18a9b39a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bca4cafddf0>]}
[0m05:10:51.712561 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m05:10:51.713245 [info ] [MainThread]: 
[0m05:10:51.729400 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m05:10:51.730620 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m05:10:51.731532 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__clean, now model.ex_01_mpg.mpg_standardized)
[0m05:10:51.732253 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m05:10:51.749334 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m05:10:51.750631 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m05:10:51.855816 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64OrNull(mpg)          as mpg,
  toInt32OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt32OrNull(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
where horsepower is not null
  and isFinite(horsepower)
          )
        
        ...
[0m05:10:52.113550 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.26 seconds
[0m05:10:52.129750 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m05:10:52.381923 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m05:10:52.388557 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m05:10:52.390111 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64OrNull(mpg)          as mpg,
  toInt32OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt32OrNull(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
where horsepower is not null
  and isFinite(horsepower)
  ...
[0m05:10:52.639080 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m05:10:52.647818 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */
EXCHANGE TABLES `clean`.`mpg_standardized__dbt_backup` AND `clean`.`mpg_standardized` 
  
  ...
[0m05:10:52.896265 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m05:10:52.955700 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m05:10:53.202388 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m05:10:53.209122 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eba9b1aa-21f2-48d0-b62a-d34e18a9b39a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bca4a944eb0>]}
[0m05:10:53.210491 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized` ................... [[32mOK[0m in 1.48s]
[0m05:10:53.212011 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m05:10:53.213414 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m05:10:53.214703 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m05:10:53.215927 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m05:10:53.216824 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m05:10:53.223492 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m05:10:53.224940 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m05:10:53.279513 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m05:10:56.052764 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m05:10:56.054269 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin__dbt_tmp` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m05:10:56.306468 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m05:10:56.330116 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m05:10:56.577214 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m05:10:56.580895 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin` to `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m05:10:56.827404 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m05:10:56.834566 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin` 
  
  ...
[0m05:10:57.080554 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m05:10:57.082662 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin__dbt_tmp` to `mart`.`cylinders_by_origin` 
  
  ...
[0m05:10:57.333848 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m05:10:57.348714 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  ...
[0m05:10:57.599407 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.25 seconds
[0m05:10:57.602124 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eba9b1aa-21f2-48d0-b62a-d34e18a9b39a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bca4a944c70>]}
[0m05:10:57.603272 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 4.39s]
[0m05:10:57.604726 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m05:10:57.606695 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:10:57.607278 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m05:10:57.607819 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m05:10:57.608355 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m05:10:57.608856 [debug] [MainThread]: On list__mart: Close
[0m05:10:57.609388 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m05:10:57.609894 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m05:10:57.610787 [info ] [MainThread]: 
[0m05:10:57.611523 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 9.92 seconds (9.92s).
[0m05:10:57.613331 [debug] [MainThread]: Command end result
[0m05:10:57.665045 [info ] [MainThread]: 
[0m05:10:57.665912 [info ] [MainThread]: [32mCompleted successfully[0m
[0m05:10:57.666529 [info ] [MainThread]: 
[0m05:10:57.667139 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m05:10:57.668527 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 11.616769, "process_in_blocks": "0", "process_kernel_time": 0.660989, "process_mem_max_rss": "114384", "process_out_blocks": "10488", "process_user_time": 5.523912}
[0m05:10:57.669285 [debug] [MainThread]: Command `dbt build` succeeded at 05:10:57.669083 after 11.62 seconds
[0m05:10:57.669897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bca5055f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bca4b5a5520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7bca4ea521c0>]}
[0m05:10:57.670500 [debug] [MainThread]: Flushing usage events
[0m05:31:05.170216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7aa95c38c310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7aa958feaaf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7aa958fea9a0>]}


============================== 05:31:05.179909 | e29606fc-9793-40db-a9c5-d9565f3c3943 ==============================
[0m05:31:05.179909 [info ] [MainThread]: Running with dbt=1.8.9
[0m05:31:05.181036 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '.', 'invocation_command': 'dbt build --profiles-dir . --target local', 'partial_parse': 'True', 'debug': 'False', 'warn_error': 'None', 'write_json': 'True', 'introspect': 'True', 'log_path': '/workdir/transforms/01_mpg/logs', 'static_parser': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'no_print': 'None', 'use_colors': 'True', 'version_check': 'True', 'empty': 'False', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_cache_events': 'False', 'quiet': 'False'}
[0m05:31:05.473219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e29606fc-9793-40db-a9c5-d9565f3c3943', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7aa95b92f3a0>]}
[0m05:31:05.575783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e29606fc-9793-40db-a9c5-d9565f3c3943', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7aa9590ea910>]}
[0m05:31:05.577122 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m05:31:05.743327 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m05:31:05.933894 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m05:31:05.934828 [debug] [MainThread]: previous checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, current checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a
[0m05:31:05.935439 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m05:31:05.936070 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e29606fc-9793-40db-a9c5-d9565f3c3943', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7aa95a3246a0>]}
[0m05:31:08.139843 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.ex_01_mpg.cylinders_by_origin_myk' (models/mart/cylinders_by_origin_myk.sql) depends on a node named 'mpg_standardized' which was not found
[0m05:31:08.141574 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 3.0658424, "process_in_blocks": "8", "process_kernel_time": 0.551583, "process_mem_max_rss": "100492", "process_out_blocks": "6616", "process_user_time": 6.247282}
[0m05:31:08.142421 [debug] [MainThread]: Command `dbt build` failed at 05:31:08.142193 after 3.07 seconds
[0m05:31:08.143070 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7aa95c38c310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7aa9575e5d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7aa9589fed30>]}
[0m05:31:08.143715 [debug] [MainThread]: Flushing usage events
[0m05:33:13.052360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e8f2e171310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e8f2add9b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e8f2add9a00>]}


============================== 05:33:13.062291 | 2f45e745-ed2b-45ae-9e73-179233d4393f ==============================
[0m05:33:13.062291 [info ] [MainThread]: Running with dbt=1.8.9
[0m05:33:13.063414 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'partial_parse': 'True', 'no_print': 'None', 'static_parser': 'True', 'version_check': 'True', 'quiet': 'False', 'empty': 'False', 'debug': 'False', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'fail_fast': 'False', 'cache_selected_only': 'False', 'log_format': 'default', 'profiles_dir': '.', 'warn_error': 'None', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build --profiles-dir . --target local', 'printer_width': '80', 'use_experimental_parser': 'False', 'use_colors': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'log_path': '/workdir/transforms/01_mpg/logs'}
[0m05:33:13.477101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2f45e745-ed2b-45ae-9e73-179233d4393f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e8f2acd29a0>]}
[0m05:33:13.657499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2f45e745-ed2b-45ae-9e73-179233d4393f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e8f2aee4e50>]}
[0m05:33:13.659767 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m05:33:13.945701 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m05:33:14.140992 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m05:33:14.141828 [debug] [MainThread]: previous checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, current checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a
[0m05:33:14.142481 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m05:33:14.143161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2f45e745-ed2b-45ae-9e73-179233d4393f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e8f2c10d5b0>]}
[0m05:33:16.579303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2f45e745-ed2b-45ae-9e73-179233d4393f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e8f29285130>]}
[0m05:33:17.703143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2f45e745-ed2b-45ae-9e73-179233d4393f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e8f29322220>]}
[0m05:33:17.704507 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m05:33:17.708640 [info ] [MainThread]: 
[0m05:33:17.710111 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m05:33:17.731089 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m05:33:17.732146 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m05:33:17.752427 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:33:17.758652 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:33:18.021665 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m05:33:18.026673 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m05:33:18.028774 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m05:33:18.040127 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m05:33:18.057870 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m05:33:18.058843 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m05:33:18.076340 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m05:33:18.081766 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m05:33:18.088584 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m05:33:18.092075 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m05:33:18.104791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2f45e745-ed2b-45ae-9e73-179233d4393f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e8f28b57190>]}
[0m05:33:18.105797 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m05:33:18.106461 [info ] [MainThread]: 
[0m05:33:18.119590 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized_myk
[0m05:33:18.120738 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized_myk` .................... [RUN]
[0m05:33:18.121860 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.mpg_standardized_myk'
[0m05:33:18.122618 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized_myk
[0m05:33:18.139804 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized_myk"
[0m05:33:18.140939 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized_myk
[0m05:33:18.179768 [debug] [Thread-1  ]: Creating new relation mpg_standardized_myk
[0m05:33:18.234530 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m05:33:18.304047 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized_myk: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized_myk"} */

            

    
        create table `clean`.`mpg_standardized_myk`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64OrNull(mpg)          as mpg,
  toInt32OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt32OrNull(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
where horsepower is not null
  and isFinite(horsepower)
          )
        
        ...
[0m05:33:18.320424 [debug] [Thread-1  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized_myk"} */

            

    
        create table `clean`.`mpg_standardized_myk`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64OrNull(mpg)          as mpg,
  toInt32OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt32OrNull(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
where horsepower is not null
  and isFinite(horsepower)
          )
        
        
[0m05:33:18.327728 [debug] [Thread-1  ]: Database Error in model mpg_standardized_myk (models/clean/mpg_standardized_myk.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 43
   Code: 43. DB::Exception: Illegal type Float64 of first argument of function toFloat64OrNull. Conversion functions with postfix 'OrZero' or 'OrNull' should take String argument: While processing ((toFloat64OrNull(horsepower) AS horsepower) IS NOT NULL) AND isFinite(horsepower). (ILLEGAL_TYPE_OF_ARGUMENT) (version 23.12.6.19 (official build))
[0m05:33:18.332135 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2f45e745-ed2b-45ae-9e73-179233d4393f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e8f284e9700>]}
[0m05:33:18.333974 [error] [Thread-1  ]: 1 of 2 ERROR creating sql table model `clean`.`mpg_standardized_myk` ........... [[31mERROR[0m in 0.21s]
[0m05:33:18.336138 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized_myk
[0m05:33:18.338101 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin_myk
[0m05:33:18.338981 [info ] [Thread-3  ]: 2 of 2 SKIP relation mart.cylinders_by_origin_myk .............................. [[33mSKIP[0m]
[0m05:33:18.339987 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin_myk
[0m05:33:18.341937 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:33:18.342528 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m05:33:18.343051 [debug] [MainThread]: On list__mart: Close
[0m05:33:18.343582 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m05:33:18.344089 [debug] [MainThread]: On list__clean: Close
[0m05:33:18.344629 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized_myk' was left open.
[0m05:33:18.345129 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized_myk: Close
[0m05:33:18.345970 [info ] [MainThread]: 
[0m05:33:18.346661 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.64 seconds (0.64s).
[0m05:33:18.348100 [debug] [MainThread]: Command end result
[0m05:33:18.400891 [info ] [MainThread]: 
[0m05:33:18.401895 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m05:33:18.402530 [info ] [MainThread]: 
[0m05:33:18.403401 [error] [MainThread]:   Database Error in model mpg_standardized_myk (models/clean/mpg_standardized_myk.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 43
   Code: 43. DB::Exception: Illegal type Float64 of first argument of function toFloat64OrNull. Conversion functions with postfix 'OrZero' or 'OrNull' should take String argument: While processing ((toFloat64OrNull(horsepower) AS horsepower) IS NOT NULL) AND isFinite(horsepower). (ILLEGAL_TYPE_OF_ARGUMENT) (version 23.12.6.19 (official build))
[0m05:33:18.404069 [info ] [MainThread]: 
[0m05:33:18.404794 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
[0m05:33:18.406226 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 5.45023, "process_in_blocks": "40", "process_kernel_time": 0.639032, "process_mem_max_rss": "115292", "process_out_blocks": "10456", "process_user_time": 7.50438}
[0m05:33:18.407054 [debug] [MainThread]: Command `dbt build` failed at 05:33:18.406861 after 5.45 seconds
[0m05:33:18.407764 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e8f2e171310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e8f2acd29a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e8f2913cc70>]}
[0m05:33:18.408466 [debug] [MainThread]: Flushing usage events
[0m05:33:51.693126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5a4ccc3310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5a49924b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5a49924a30>]}


============================== 05:33:51.702890 | ff126753-76f0-40ca-bc60-b2369942de80 ==============================
[0m05:33:51.702890 [info ] [MainThread]: Running with dbt=1.8.9
[0m05:33:51.704057 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'static_parser': 'True', 'debug': 'False', 'target_path': 'None', 'quiet': 'False', 'write_json': 'True', 'version_check': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'partial_parse': 'True', 'profiles_dir': '.', 'invocation_command': 'dbt build --profiles-dir . --target local', 'log_path': '/workdir/transforms/01_mpg/logs', 'indirect_selection': 'eager', 'log_format': 'default', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'empty': 'False', 'printer_width': '80', 'log_cache_events': 'False'}
[0m05:33:52.034062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ff126753-76f0-40ca-bc60-b2369942de80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5a4c264ca0>]}
[0m05:33:52.216701 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ff126753-76f0-40ca-bc60-b2369942de80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5a49a269d0>]}
[0m05:33:52.218916 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m05:33:52.485531 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m05:33:52.745936 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m05:33:52.747031 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized_myk.sql
[0m05:33:53.045525 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.ex_01_mpg.mpg_standardized_myk' (models/clean/mpg_standardized_myk.sql) depends on a source named 'raw.autompg___cars_myk' which was not found
[0m05:33:53.047379 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 1.4484131, "process_in_blocks": "0", "process_kernel_time": 0.561164, "process_mem_max_rss": "99912", "process_out_blocks": "6616", "process_user_time": 4.519323}
[0m05:33:53.048542 [debug] [MainThread]: Command `dbt build` failed at 05:33:53.048254 after 1.45 seconds
[0m05:33:53.049503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5a4ccc3310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5a498de340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5a4cc0ce50>]}
[0m05:33:53.050365 [debug] [MainThread]: Flushing usage events
[0m05:35:52.862557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7125c340c310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7125c0069af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7125c00699a0>]}


============================== 05:35:52.872322 | 9854d7b6-6d0e-49f3-bd97-53f7eb5ac290 ==============================
[0m05:35:52.872322 [info ] [MainThread]: Running with dbt=1.8.9
[0m05:35:52.873410 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'profiles_dir': '.', 'printer_width': '80', 'log_format': 'default', 'warn_error': 'None', 'log_cache_events': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'use_experimental_parser': 'False', 'no_print': 'None', 'target_path': 'None', 'use_colors': 'True', 'indirect_selection': 'eager', 'write_json': 'True', 'empty': 'False', 'cache_selected_only': 'False', 'quiet': 'False', 'static_parser': 'True', 'invocation_command': 'dbt build --profiles-dir . --target local', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'debug': 'False', 'partial_parse': 'True'}
[0m05:35:53.159229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9854d7b6-6d0e-49f3-bd97-53f7eb5ac290', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7125c29b63a0>]}
[0m05:35:53.256171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9854d7b6-6d0e-49f3-bd97-53f7eb5ac290', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7125c0169910>]}
[0m05:35:53.257683 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m05:35:53.463900 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m05:35:53.689506 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m05:35:53.690595 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized_myk.sql
[0m05:35:54.004898 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.ex_01_mpg.mpg_standardized_myk' (models/clean/mpg_standardized_myk.sql) depends on a source named 'raw.autompg___cars_myk' which was not found
[0m05:35:54.007763 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 1.2417657, "process_in_blocks": "0", "process_kernel_time": 0.533695, "process_mem_max_rss": "99752", "process_out_blocks": "6616", "process_user_time": 4.372509}
[0m05:35:54.010485 [debug] [MainThread]: Command `dbt build` failed at 05:35:54.009708 after 1.24 seconds
[0m05:35:54.012817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7125c340c310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7125c33664c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7125c3371760>]}
[0m05:35:54.014868 [debug] [MainThread]: Flushing usage events
[0m05:37:11.926275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8978d7310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa89453c490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa89453c5e0>]}


============================== 05:37:11.936491 | ef6df7a7-73b0-4033-ac0b-098fb0b2f3ba ==============================
[0m05:37:11.936491 [info ] [MainThread]: Running with dbt=1.8.9
[0m05:37:11.937636 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'partial_parse': 'True', 'warn_error': 'None', 'empty': 'False', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'use_experimental_parser': 'False', 'profiles_dir': '.', 'printer_width': '80', 'log_cache_events': 'False', 'no_print': 'None', 'introspect': 'True', 'use_colors': 'True', 'static_parser': 'True', 'log_path': '/workdir/transforms/01_mpg/logs', 'cache_selected_only': 'False', 'quiet': 'False', 'version_check': 'True', 'log_format': 'default', 'indirect_selection': 'eager', 'target_path': 'None', 'invocation_command': 'dbt build --profiles-dir . --target local'}
[0m05:37:12.256305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ef6df7a7-73b0-4033-ac0b-098fb0b2f3ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8944439a0>]}
[0m05:37:12.370867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ef6df7a7-73b0-4033-ac0b-098fb0b2f3ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa894514760>]}
[0m05:37:12.372356 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m05:37:12.549389 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m05:37:12.779295 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m05:37:12.780497 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/sources.yml
[0m05:37:12.781077 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized_myk.sql
[0m05:37:13.444578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ef6df7a7-73b0-4033-ac0b-098fb0b2f3ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8927faee0>]}
[0m05:37:13.683632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ef6df7a7-73b0-4033-ac0b-098fb0b2f3ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa892752d60>]}
[0m05:37:13.684508 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m05:37:13.687231 [info ] [MainThread]: 
[0m05:37:13.688450 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m05:37:13.700811 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m05:37:13.712163 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m05:37:13.721161 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:37:13.726072 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:37:14.060382 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m05:37:14.064015 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m05:37:14.065500 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m05:37:14.070085 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m05:37:14.092099 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m05:37:14.093161 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m05:37:14.104685 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m05:37:14.108574 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m05:37:14.114904 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m05:37:14.123964 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m05:37:14.133626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ef6df7a7-73b0-4033-ac0b-098fb0b2f3ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa89253a040>]}
[0m05:37:14.134664 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m05:37:14.135325 [info ] [MainThread]: 
[0m05:37:14.148440 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized_myk
[0m05:37:14.149600 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized_myk` .................... [RUN]
[0m05:37:14.150506 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__mart, now model.ex_01_mpg.mpg_standardized_myk)
[0m05:37:14.151309 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized_myk
[0m05:37:14.169169 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized_myk"
[0m05:37:14.170470 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized_myk
[0m05:37:14.210818 [debug] [Thread-1  ]: Creating new relation mpg_standardized_myk
[0m05:37:14.262065 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized_myk: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized_myk"} */

            

    
        create table `clean`.`mpg_standardized_myk`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64OrNull(mpg)          as mpg,
  toInt32OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt32OrNull(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars_myk`
where horsepower is not null
  and isFinite(horsepower)
          )
        
        ...
[0m05:37:14.283896 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m05:37:14.300130 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized_myk: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized_myk"} */

    select name, type from system.columns where table = 'mpg_standardized_myk'
    
      and database = 'clean'
    
    order by position
  ...
[0m05:37:14.304962 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m05:37:14.311437 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized_myk"
[0m05:37:14.312696 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized_myk: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized_myk"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized_myk`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64OrNull(mpg)          as mpg,
  toInt32OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt32OrNull(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars_myk`
where horsepower is not null
  and isFinite(horsepower)
  ...
[0m05:37:14.319102 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m05:37:14.360711 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ef6df7a7-73b0-4033-ac0b-098fb0b2f3ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8926c5760>]}
[0m05:37:14.362082 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized_myk` ............... [[32mOK[0m in 0.21s]
[0m05:37:14.363912 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized_myk
[0m05:37:14.365612 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin_myk
[0m05:37:14.366885 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin_myk` ................... [RUN]
[0m05:37:14.368111 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin_myk'
[0m05:37:14.368899 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin_myk
[0m05:37:14.374866 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin_myk"
[0m05:37:14.375971 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin_myk
[0m05:37:14.403446 [debug] [Thread-3  ]: Creating new relation cylinders_by_origin_myk
[0m05:37:14.418391 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m05:37:14.482576 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin_myk"
[0m05:37:14.483817 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin_myk: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin_myk"} */


  create view `mart`.`cylinders_by_origin_myk` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized_myk`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m05:37:14.493964 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m05:37:14.497311 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ef6df7a7-73b0-4033-ac0b-098fb0b2f3ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa89576e520>]}
[0m05:37:14.498557 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin_myk` .............. [[32mOK[0m in 0.13s]
[0m05:37:14.500091 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin_myk
[0m05:37:14.502675 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:37:14.503478 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized_myk' was left open.
[0m05:37:14.504411 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized_myk: Close
[0m05:37:14.505187 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m05:37:14.505887 [debug] [MainThread]: On list__clean: Close
[0m05:37:14.506656 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin_myk' was left open.
[0m05:37:14.507355 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin_myk: Close
[0m05:37:14.508571 [info ] [MainThread]: 
[0m05:37:14.509451 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.82 seconds (0.82s).
[0m05:37:14.511759 [debug] [MainThread]: Command end result
[0m05:37:14.575587 [info ] [MainThread]: 
[0m05:37:14.576601 [info ] [MainThread]: [32mCompleted successfully[0m
[0m05:37:14.577257 [info ] [MainThread]: 
[0m05:37:14.577959 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m05:37:14.579486 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 2.7517333, "process_in_blocks": "0", "process_kernel_time": 0.652541, "process_mem_max_rss": "114544", "process_out_blocks": "10480", "process_user_time": 5.759948}
[0m05:37:14.580291 [debug] [MainThread]: Command `dbt build` succeeded at 05:37:14.580073 after 2.75 seconds
[0m05:37:14.580957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8978d7310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8957fe910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8944fbb50>]}
[0m05:37:14.581592 [debug] [MainThread]: Flushing usage events
[0m08:59:05.495798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b11e95e310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b11b5bfbb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b11b5bfa60>]}


============================== 08:59:05.505981 | f40e8302-1c27-44d2-b187-ee658e06c448 ==============================
[0m08:59:05.505981 [info ] [MainThread]: Running with dbt=1.8.9
[0m08:59:05.507100 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'debug': 'False', 'static_parser': 'True', 'printer_width': '80', 'quiet': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'version_check': 'True', 'log_cache_events': 'False', 'profiles_dir': '.', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'use_colors': 'True', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_experimental_parser': 'False', 'introspect': 'True', 'write_json': 'True', 'invocation_command': 'dbt build --profiles-dir . --target local', 'warn_error': 'None', 'no_print': 'None', 'indirect_selection': 'eager', 'partial_parse': 'True', 'empty': 'False', 'log_format': 'default'}
[0m08:59:05.798793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f40e8302-1c27-44d2-b187-ee658e06c448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b11df033a0>]}
[0m08:59:05.897829 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f40e8302-1c27-44d2-b187-ee658e06c448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b11d46c220>]}
[0m08:59:05.899221 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m08:59:06.066309 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m08:59:06.289918 [debug] [MainThread]: Partial parsing enabled: 2 files deleted, 2 files added, 1 files changed.
[0m08:59:06.290853 [debug] [MainThread]: Partial parsing: added file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m08:59:06.291454 [debug] [MainThread]: Partial parsing: added file: ex_01_mpg://models/mart/cylinders_by_origin.sql
[0m08:59:06.292173 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/sources.yml
[0m08:59:06.292742 [debug] [MainThread]: Partial parsing: deleted file: ex_01_mpg://models/clean/mpg_standardized_myk.sql
[0m08:59:06.293293 [debug] [MainThread]: Partial parsing: deleted file: ex_01_mpg://models/mart/cylinders_by_origin_myk.sql
[0m08:59:06.891816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f40e8302-1c27-44d2-b187-ee658e06c448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b119885ee0>]}
[0m08:59:07.106561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f40e8302-1c27-44d2-b187-ee658e06c448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b1197dd880>]}
[0m08:59:07.107494 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m08:59:07.110371 [info ] [MainThread]: 
[0m08:59:07.111581 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m08:59:07.123773 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m08:59:07.124946 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m08:59:07.167299 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:59:07.173426 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:59:07.536813 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m08:59:07.539035 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m08:59:07.541305 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:59:07.542460 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:59:07.566485 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m08:59:07.578200 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m08:59:07.579517 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m08:59:07.584142 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m08:59:07.592067 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:59:07.593568 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:59:07.610877 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f40e8302-1c27-44d2-b187-ee658e06c448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b119368cd0>]}
[0m08:59:07.611857 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m08:59:07.612450 [info ] [MainThread]: 
[0m08:59:07.626229 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m08:59:07.627410 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m08:59:07.628301 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__mart, now model.ex_01_mpg.mpg_standardized)
[0m08:59:07.628999 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m08:59:07.646267 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m08:59:07.647583 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m08:59:07.743698 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64(mpg)          as mpg,
  toInt32OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt32OrNull(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
where horsepower is not null
  and isFinite(horsepower)
          )
        
        ...
[0m08:59:07.748339 [debug] [Thread-1  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64(mpg)          as mpg,
  toInt32OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt32OrNull(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
where horsepower is not null
  and isFinite(horsepower)
          )
        
        
[0m08:59:07.758761 [debug] [Thread-1  ]: Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 43
   Code: 43. DB::Exception: Illegal type Float64 of first argument of function toFloat64OrNull. Conversion functions with postfix 'OrZero' or 'OrNull' should take String argument: While processing ((toFloat64OrNull(horsepower) AS horsepower) IS NOT NULL) AND isFinite(horsepower). (ILLEGAL_TYPE_OF_ARGUMENT) (version 23.12.6.19 (official build))
[0m08:59:07.761498 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f40e8302-1c27-44d2-b187-ee658e06c448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b11dd08a60>]}
[0m08:59:07.762697 [error] [Thread-1  ]: 1 of 2 ERROR creating sql table model `clean`.`mpg_standardized` ............... [[31mERROR[0m in 0.13s]
[0m08:59:07.764061 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m08:59:07.765505 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m08:59:07.766444 [info ] [Thread-3  ]: 2 of 2 SKIP relation mart.cylinders_by_origin .................................. [[33mSKIP[0m]
[0m08:59:07.767561 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m08:59:07.769371 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:59:07.769938 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m08:59:07.770482 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m08:59:07.770963 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m08:59:07.771459 [debug] [MainThread]: On list__clean: Close
[0m08:59:07.772219 [info ] [MainThread]: 
[0m08:59:07.772890 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.66 seconds (0.66s).
[0m08:59:07.774695 [debug] [MainThread]: Command end result
[0m08:59:07.831010 [info ] [MainThread]: 
[0m08:59:07.831903 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m08:59:07.832511 [info ] [MainThread]: 
[0m08:59:07.833345 [error] [MainThread]:   Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 43
   Code: 43. DB::Exception: Illegal type Float64 of first argument of function toFloat64OrNull. Conversion functions with postfix 'OrZero' or 'OrNull' should take String argument: While processing ((toFloat64OrNull(horsepower) AS horsepower) IS NOT NULL) AND isFinite(horsepower). (ILLEGAL_TYPE_OF_ARGUMENT) (version 23.12.6.19 (official build))
[0m08:59:07.833993 [info ] [MainThread]: 
[0m08:59:07.834654 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
[0m08:59:07.835984 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 2.4412987, "process_in_blocks": "1312", "process_kernel_time": 0.6246, "process_mem_max_rss": "114792", "process_out_blocks": "10464", "process_user_time": 5.439524}
[0m08:59:07.836737 [debug] [MainThread]: Command `dbt build` failed at 08:59:07.836546 after 2.44 seconds
[0m08:59:07.837440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b11e95e310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b11df033a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75b1197dd880>]}
[0m08:59:07.838042 [debug] [MainThread]: Flushing usage events
[0m09:01:13.861465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7995403a2310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79953d007ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79953d007970>]}


============================== 09:01:13.872084 | f172287e-ea25-473d-ba6c-f198561d176c ==============================
[0m09:01:13.872084 [info ] [MainThread]: Running with dbt=1.8.9
[0m09:01:13.873418 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'log_cache_events': 'False', 'write_json': 'True', 'log_path': '/workdir/transforms/01_mpg/logs', 'partial_parse': 'True', 'printer_width': '80', 'fail_fast': 'False', 'profiles_dir': '.', 'static_parser': 'True', 'use_colors': 'True', 'no_print': 'None', 'invocation_command': 'dbt build --profiles-dir . --target local', 'warn_error': 'None', 'quiet': 'False', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'log_format': 'default', 'use_experimental_parser': 'False', 'debug': 'False', 'target_path': 'None'}
[0m09:01:14.170591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f172287e-ea25-473d-ba6c-f198561d176c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79953ce88370>]}
[0m09:01:14.266614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f172287e-ea25-473d-ba6c-f198561d176c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7995405bd040>]}
[0m09:01:14.267946 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m09:01:14.457161 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m09:01:14.679284 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:01:14.680318 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m09:01:14.969311 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.ex_01_mpg.mpg_standardized' (models/clean/mpg_standardized.sql) depends on a source named 'raw.autompg___cars_myk' which was not found
[0m09:01:14.971052 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 1.204959, "process_in_blocks": "0", "process_kernel_time": 0.584628, "process_mem_max_rss": "100172", "process_out_blocks": "6608", "process_user_time": 4.45417}
[0m09:01:14.972046 [debug] [MainThread]: Command `dbt build` failed at 09:01:14.971788 after 1.21 seconds
[0m09:01:14.972878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7995403a2310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7995402f8ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79953cd18d00>]}
[0m09:01:14.973745 [debug] [MainThread]: Flushing usage events
[0m09:01:36.543301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79675dc6b310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79675a8c8b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79675a8c89d0>]}


============================== 09:01:36.552913 | 55a2c5e9-ce69-48c8-9fad-6f40f3858d9d ==============================
[0m09:01:36.552913 [info ] [MainThread]: Running with dbt=1.8.9
[0m09:01:36.554092 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt build --profiles-dir . --target local', 'static_parser': 'True', 'log_format': 'default', 'write_json': 'True', 'no_print': 'None', 'use_experimental_parser': 'False', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'log_cache_events': 'False', 'empty': 'False', 'version_check': 'True', 'indirect_selection': 'eager', 'log_path': '/workdir/transforms/01_mpg/logs', 'profiles_dir': '.', 'partial_parse': 'True', 'cache_selected_only': 'False', 'debug': 'False', 'fail_fast': 'False', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'quiet': 'False', 'use_colors': 'True'}
[0m09:01:36.876136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '55a2c5e9-ce69-48c8-9fad-6f40f3858d9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79675a7e3910>]}
[0m09:01:36.995005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '55a2c5e9-ce69-48c8-9fad-6f40f3858d9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79675a8047f0>]}
[0m09:01:36.996464 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m09:01:37.203157 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m09:01:37.434584 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m09:01:37.435922 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/sources.yml
[0m09:01:37.436618 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m09:01:38.055342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '55a2c5e9-ce69-48c8-9fad-6f40f3858d9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x796758b93ee0>]}
[0m09:01:38.294498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '55a2c5e9-ce69-48c8-9fad-6f40f3858d9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x796758aecd00>]}
[0m09:01:38.295416 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m09:01:38.298103 [info ] [MainThread]: 
[0m09:01:38.299281 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m09:01:38.310945 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m09:01:38.311968 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m09:01:38.330941 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:01:38.335832 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:01:38.792361 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m09:01:38.805255 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m09:01:38.807527 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m09:01:38.820559 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m09:01:38.857955 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m09:01:38.859964 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m09:01:38.899981 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m09:01:38.901760 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m09:01:38.916032 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m09:01:38.927053 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m09:01:38.955656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '55a2c5e9-ce69-48c8-9fad-6f40f3858d9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7967586b8ee0>]}
[0m09:01:38.957429 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m09:01:38.958615 [info ] [MainThread]: 
[0m09:01:38.988903 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m09:01:38.996395 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m09:01:38.998558 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__mart, now model.ex_01_mpg.mpg_standardized)
[0m09:01:39.000212 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m09:01:39.032694 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m09:01:39.035242 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m09:01:39.208935 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64(mpg)          as mpg,
  toInt32OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt32OrNull(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars_myk`
where horsepower is not null
  and isFinite(horsepower)
          )
        
        ...
[0m09:01:39.227582 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m09:01:39.244984 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m09:01:39.250811 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:01:39.257556 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m09:01:39.259003 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64(mpg)          as mpg,
  toInt32OrNull(cylinders)      as cylinders,
  toFloat64OrNull(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32OrNull(weight)         as weight,
  toFloat64OrNull(acceleration) as acceleration,
  toInt32OrNull(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars_myk`
where horsepower is not null
  and isFinite(horsepower)
  ...
[0m09:01:39.266512 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m09:01:39.275312 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */
EXCHANGE TABLES `clean`.`mpg_standardized__dbt_backup` AND `clean`.`mpg_standardized` 
  
  ...
[0m09:01:39.278511 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:01:39.325346 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m09:01:39.328632 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:01:39.334793 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55a2c5e9-ce69-48c8-9fad-6f40f3858d9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7967586b8ee0>]}
[0m09:01:39.336044 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized` ................... [[32mOK[0m in 0.34s]
[0m09:01:39.337517 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m09:01:39.339028 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m09:01:39.339995 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m09:01:39.341048 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m09:01:39.341824 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m09:01:39.349082 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m09:01:39.350299 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m09:01:39.399100 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m09:01:39.457401 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m09:01:39.459271 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin__dbt_tmp` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m09:01:39.468328 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m09:01:39.482811 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m09:01:39.486043 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:01:39.488217 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin` to `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m09:01:39.491566 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:01:39.498329 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin` 
  
  ...
[0m09:01:39.501711 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:01:39.504489 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin__dbt_tmp` to `mart`.`cylinders_by_origin` 
  
  ...
[0m09:01:39.508857 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:01:39.520151 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  ...
[0m09:01:39.524543 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:01:39.528822 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55a2c5e9-ce69-48c8-9fad-6f40f3858d9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79675baf0d90>]}
[0m09:01:39.530125 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 0.19s]
[0m09:01:39.531814 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m09:01:39.534862 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:01:39.535940 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m09:01:39.537393 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m09:01:39.538641 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m09:01:39.539637 [debug] [MainThread]: On list__clean: Close
[0m09:01:39.540501 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m09:01:39.541334 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m09:01:39.542910 [info ] [MainThread]: 
[0m09:01:39.544203 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.24 seconds (1.24s).
[0m09:01:39.547513 [debug] [MainThread]: Command end result
[0m09:01:39.602667 [info ] [MainThread]: 
[0m09:01:39.603622 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:01:39.604401 [info ] [MainThread]: 
[0m09:01:39.605085 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m09:01:39.606492 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 3.157528, "process_in_blocks": "0", "process_kernel_time": 0.63216, "process_mem_max_rss": "114568", "process_out_blocks": "10480", "process_user_time": 5.944509}
[0m09:01:39.607282 [debug] [MainThread]: Command `dbt build` succeeded at 09:01:39.607069 after 3.16 seconds
[0m09:01:39.607928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79675dc6b310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x796758723b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7967586d6c40>]}
[0m09:01:39.608564 [debug] [MainThread]: Flushing usage events
[0m09:02:23.348304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a2129716310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a2126370b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a2126370a30>]}


============================== 09:02:23.380204 | 80e31955-dd32-4da3-a210-714226038671 ==============================
[0m09:02:23.380204 [info ] [MainThread]: Running with dbt=1.8.9
[0m09:02:23.381544 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'introspect': 'True', 'use_colors': 'True', 'no_print': 'None', 'write_json': 'True', 'debug': 'False', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'use_experimental_parser': 'False', 'empty': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'printer_width': '80', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'indirect_selection': 'eager', 'warn_error': 'None', 'invocation_command': 'dbt build --profiles-dir . --target local', 'quiet': 'False', 'log_cache_events': 'False', 'version_check': 'True', 'partial_parse': 'True', 'profiles_dir': '.', 'target_path': 'None'}
[0m09:02:23.690223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '80e31955-dd32-4da3-a210-714226038671', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a2128cb4ca0>]}
[0m09:02:23.788105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '80e31955-dd32-4da3-a210-714226038671', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a212646a9d0>]}
[0m09:02:23.789474 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m09:02:23.962097 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m09:02:24.191862 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:02:24.192876 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m09:02:24.638997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '80e31955-dd32-4da3-a210-714226038671', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a212491e130>]}
[0m09:02:24.862301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '80e31955-dd32-4da3-a210-714226038671', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a21247d8130>]}
[0m09:02:24.863156 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m09:02:24.866082 [info ] [MainThread]: 
[0m09:02:24.867225 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m09:02:24.879049 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m09:02:24.880092 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m09:02:24.905571 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:02:24.915585 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:02:25.182764 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m09:02:25.187727 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:02:25.189770 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m09:02:25.193459 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:02:25.284654 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m09:02:25.285949 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m09:02:25.311090 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m09:02:25.313485 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m09:02:25.320384 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m09:02:25.329531 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m09:02:25.338149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '80e31955-dd32-4da3-a210-714226038671', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a212432cb50>]}
[0m09:02:25.339177 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m09:02:25.339886 [info ] [MainThread]: 
[0m09:02:25.353413 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m09:02:25.354542 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m09:02:25.355454 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__mart, now model.ex_01_mpg.mpg_standardized)
[0m09:02:25.356158 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m09:02:25.372634 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m09:02:25.373928 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m09:02:25.471804 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64(mpg)          as mpg,
  toInt32(cylinders)      as cylinders,
  toFloat64(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32(weight)         as weight,
  toFloat64(acceleration) as acceleration,
  toInt32(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars_myk`
where horsepower is not null
  and isFinite(horsepower)
          )
        
        ...
[0m09:02:25.489515 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m09:02:25.511547 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m09:02:25.517059 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:02:25.523870 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m09:02:25.525262 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64(mpg)          as mpg,
  toInt32(cylinders)      as cylinders,
  toFloat64(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32(weight)         as weight,
  toFloat64(acceleration) as acceleration,
  toInt32(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars_myk`
where horsepower is not null
  and isFinite(horsepower)
  ...
[0m09:02:25.532625 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m09:02:25.541927 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */
EXCHANGE TABLES `clean`.`mpg_standardized__dbt_backup` AND `clean`.`mpg_standardized` 
  
  ...
[0m09:02:25.545183 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:02:25.596051 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m09:02:25.599479 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:02:25.605947 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '80e31955-dd32-4da3-a210-714226038671', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a2123c23580>]}
[0m09:02:25.607250 [info ] [Thread-1  ]: 1 of 2 OK created sql table model `clean`.`mpg_standardized` ................... [[32mOK[0m in 0.25s]
[0m09:02:25.608612 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m09:02:25.610123 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m09:02:25.611124 [info ] [Thread-3  ]: 2 of 2 START sql view model `mart`.`cylinders_by_origin` ....................... [RUN]
[0m09:02:25.612224 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m09:02:25.613035 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m09:02:25.618940 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m09:02:25.620161 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m09:02:25.671219 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m09:02:25.726005 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m09:02:25.727327 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin__dbt_tmp` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m09:02:25.736063 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m09:02:25.748872 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m09:02:25.751800 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:02:25.753826 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin` to `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m09:02:25.756572 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:02:25.762664 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin` 
  
  ...
[0m09:02:25.765573 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:02:25.767620 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin__dbt_tmp` to `mart`.`cylinders_by_origin` 
  
  ...
[0m09:02:25.770688 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:02:25.777368 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  ...
[0m09:02:25.780357 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m09:02:25.782948 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '80e31955-dd32-4da3-a210-714226038671', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a21242ab4c0>]}
[0m09:02:25.784085 [info ] [Thread-3  ]: 2 of 2 OK created sql view model `mart`.`cylinders_by_origin` .................. [[32mOK[0m in 0.17s]
[0m09:02:25.785554 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m09:02:25.787485 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:02:25.788057 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m09:02:25.788627 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m09:02:25.789137 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m09:02:25.789669 [debug] [MainThread]: On list__clean: Close
[0m09:02:25.790163 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was left open.
[0m09:02:25.790699 [debug] [MainThread]: On model.ex_01_mpg.cylinders_by_origin: Close
[0m09:02:25.791537 [info ] [MainThread]: 
[0m09:02:25.792240 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.92 seconds (0.92s).
[0m09:02:25.793953 [debug] [MainThread]: Command end result
[0m09:02:25.848558 [info ] [MainThread]: 
[0m09:02:25.849475 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:02:25.850085 [info ] [MainThread]: 
[0m09:02:25.850773 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m09:02:25.852500 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 2.6108758, "process_in_blocks": "1432", "process_kernel_time": 0.643114, "process_mem_max_rss": "114156", "process_out_blocks": "10488", "process_user_time": 5.648002}
[0m09:02:25.853280 [debug] [MainThread]: Command `dbt build` succeeded at 09:02:25.853065 after 2.61 seconds
[0m09:02:25.853904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a2129716310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a212762a190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a212763b220>]}
[0m09:02:25.854532 [debug] [MainThread]: Flushing usage events
[0m20:21:17.907161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72b8561e7310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72b852e33c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72b852e33af0>]}


============================== 20:21:17.916725 | e621214e-f57c-47d5-b42a-a742e62049b2 ==============================
[0m20:21:17.916725 [info ] [MainThread]: Running with dbt=1.8.9
[0m20:21:17.917822 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt docs serve --profiles-dir . --target local --host 0.0.0.0 --port 8080', 'debug': 'False', 'profiles_dir': '.', 'use_experimental_parser': 'False', 'warn_error': 'None', 'introspect': 'True', 'use_colors': 'True', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_cache_events': 'False', 'log_format': 'default', 'cache_selected_only': 'False', 'version_check': 'True', 'write_json': 'True', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'partial_parse': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'log_path': '/workdir/transforms/01_mpg/logs'}
[0m20:21:18.246477 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e621214e-f57c-47d5-b42a-a742e62049b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72b85577a3a0>]}
[0m20:21:18.356954 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e621214e-f57c-47d5-b42a-a742e62049b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72b852d1bbe0>]}
[0m20:21:43.222146 [error] [MainThread]: Encountered an error:

[0m20:21:43.514805 [error] [MainThread]: Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 101, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 218, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 247, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 294, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/main.py", line 303, in docs_serve
    results = task.run()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/docs/serve.py", line 29, in run
    httpd.serve_forever()
  File "/usr/local/lib/python3.9/socketserver.py", line 232, in serve_forever
    ready = selector.select(poll_interval)
  File "/usr/local/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt

[0m20:21:43.516621 [debug] [MainThread]: Resource report: {"command_name": "serve", "command_success": false, "command_wall_clock_time": 25.725277, "process_in_blocks": "4352", "process_kernel_time": 0.51611, "process_mem_max_rss": "95272", "process_out_blocks": "9744", "process_user_time": 3.899282}
[0m20:21:43.517840 [debug] [MainThread]: Command `dbt docs serve` failed at 20:21:43.517564 after 25.73 seconds
[0m20:21:43.518689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72b8561e7310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72b852adf280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72b85292f790>]}
[0m20:21:43.519481 [debug] [MainThread]: Flushing usage events
[0m20:21:57.990967 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77773d8aa310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77773a5043a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77773a504430>]}


============================== 20:21:58.000683 | 1ee5117f-5552-48f0-a3f3-77005b76e8f3 ==============================
[0m20:21:58.000683 [info ] [MainThread]: Running with dbt=1.8.9
[0m20:21:58.001959 [debug] [MainThread]: running dbt with arguments {'profiles_dir': 'transforms/01_mpg', 'invocation_command': 'dbt docs serve --project-dir transforms/01_mpg --profiles-dir transforms/01_mpg --target local --host 0.0.0.0 --port 8080', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'version_check': 'True', 'fail_fast': 'False', 'cache_selected_only': 'False', 'log_path': 'transforms/01_mpg/logs', 'target_path': 'None', 'debug': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'static_parser': 'True', 'introspect': 'True', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'use_colors': 'True', 'log_format': 'default', 'write_json': 'True', 'no_print': 'None', 'log_cache_events': 'False'}
[0m20:21:58.293756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1ee5117f-5552-48f0-a3f3-77005b76e8f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77773ce45fd0>]}
[0m20:21:58.392270 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1ee5117f-5552-48f0-a3f3-77005b76e8f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77773a4b9af0>]}
[0m20:22:25.352193 [error] [MainThread]: Encountered an error:

[0m20:22:25.355195 [error] [MainThread]: Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 101, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 218, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 247, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 294, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/main.py", line 303, in docs_serve
    results = task.run()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/docs/serve.py", line 29, in run
    httpd.serve_forever()
  File "/usr/local/lib/python3.9/socketserver.py", line 237, in serve_forever
    self._handle_request_noblock()
  File "/usr/local/lib/python3.9/socketserver.py", line 316, in _handle_request_noblock
    self.process_request(request, client_address)
  File "/usr/local/lib/python3.9/socketserver.py", line 347, in process_request
    self.finish_request(request, client_address)
  File "/usr/local/lib/python3.9/socketserver.py", line 360, in finish_request
    self.RequestHandlerClass(request, client_address, self)
  File "/usr/local/lib/python3.9/http/server.py", line 668, in __init__
    super().__init__(*args, **kwargs)
  File "/usr/local/lib/python3.9/socketserver.py", line 747, in __init__
    self.handle()
  File "/usr/local/lib/python3.9/http/server.py", line 433, in handle
    self.handle_one_request()
  File "/usr/local/lib/python3.9/http/server.py", line 401, in handle_one_request
    self.raw_requestline = self.rfile.readline(65537)
  File "/usr/local/lib/python3.9/socket.py", line 716, in readinto
    return self._sock.recv_into(b)
KeyboardInterrupt

[0m20:22:25.356931 [debug] [MainThread]: Resource report: {"command_name": "serve", "command_success": false, "command_wall_clock_time": 27.46037, "process_in_blocks": "0", "process_kernel_time": 0.504336, "process_mem_max_rss": "95324", "process_out_blocks": "9744", "process_user_time": 3.965507}
[0m20:22:25.357975 [debug] [MainThread]: Command `dbt docs serve` failed at 20:22:25.357714 after 27.46 seconds
[0m20:22:25.358886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77773d8aa310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77773a3570a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77773a357550>]}
[0m20:22:25.359737 [debug] [MainThread]: Flushing usage events
[0m20:23:21.798418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e2881516310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e287e1814c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e287e181610>]}


============================== 20:23:21.808002 | 973c8a65-3c6f-41d9-a569-067a4f152a1d ==============================
[0m20:23:21.808002 [info ] [MainThread]: Running with dbt=1.8.9
[0m20:23:21.809167 [debug] [MainThread]: running dbt with arguments {'log_cache_events': 'False', 'version_check': 'True', 'empty': 'None', 'log_path': '/workdir/transforms/01_mpg/logs', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'static_parser': 'True', 'debug': 'False', 'partial_parse': 'True', 'warn_error': 'None', 'write_json': 'True', 'log_format': 'default', 'use_colors': 'True', 'printer_width': '80', 'invocation_command': 'dbt docs generate --profiles-dir . --target local', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'profiles_dir': '.', 'fail_fast': 'False', 'introspect': 'True', 'target_path': 'None', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m20:23:22.114468 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '973c8a65-3c6f-41d9-a569-067a4f152a1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e287e150be0>]}
[0m20:23:22.209141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '973c8a65-3c6f-41d9-a569-067a4f152a1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e287e0780d0>]}
[0m20:23:22.210914 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m20:23:22.392796 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m20:23:22.777651 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m20:23:22.779937 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/sources.yml
[0m20:23:22.781395 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m20:23:23.484286 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '973c8a65-3c6f-41d9-a569-067a4f152a1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e287c440130>]}
[0m20:23:23.519650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '973c8a65-3c6f-41d9-a569-067a4f152a1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e287c4b4a00>]}
[0m20:23:23.520535 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m20:23:23.521250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '973c8a65-3c6f-41d9-a569-067a4f152a1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e287c4b4ac0>]}
[0m20:23:23.524708 [info ] [MainThread]: 
[0m20:23:23.526357 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m20:23:23.528148 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__clean'
[0m20:23:23.529073 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__mart'
[0m20:23:23.556669 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:23:23.565813 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:23:23.885228 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m20:23:23.889776 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m20:23:23.892553 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:23:23.899097 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:23:24.015405 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '973c8a65-3c6f-41d9-a569-067a4f152a1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e287c5609a0>]}
[0m20:23:24.016393 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m20:23:24.017049 [info ] [MainThread]: 
[0m20:23:24.031980 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m20:23:24.033213 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__clean, now model.ex_01_mpg.mpg_standardized)
[0m20:23:24.034090 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m20:23:24.051646 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m20:23:24.052920 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m20:23:24.054502 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m20:23:24.056067 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m20:23:24.057093 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m20:23:24.057870 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m20:23:24.063516 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m20:23:24.064800 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m20:23:24.066580 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m20:23:24.068316 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:23:24.068861 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m20:23:24.069410 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m20:23:24.069899 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m20:23:24.070408 [debug] [MainThread]: On list__mart: Close
[0m20:23:24.070867 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was properly closed.
[0m20:23:24.072609 [debug] [MainThread]: Command end result
[0m20:23:24.247081 [debug] [MainThread]: Acquiring new clickhouse connection 'generate_catalog'
[0m20:23:24.247719 [info ] [MainThread]: Building catalog
[0m20:23:24.260419 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:23:24.323403 [debug] [MainThread]: dbt_clickhouse adapter: On generate_catalog: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "generate_catalog"} */
select
      '' as table_database,
      columns.database as table_schema,
      columns.table as table_name,
      if(tables.engine not in ('MaterializedView', 'View'), 'table', 'view') as table_type,
      nullIf(tables.comment, '') as table_comment,
      columns.name as column_name,
      columns.position as column_index,
      columns.type as column_type,
      nullIf(columns.comment, '') as column_comment,
      null as table_owner
    from system.columns as columns
    join system.tables as tables on tables.database = columns.database and tables.name = columns.table
    where database != 'system' and
    (columns.database = 'clean' or columns.database = 'mart' or columns.database = 'raw')
    order by columns.database, columns.table, columns.position...
[0m20:23:24.342667 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m20:23:24.472695 [info ] [MainThread]: Catalog written to /workdir/transforms/01_mpg/target/catalog.json
[0m20:23:24.474275 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 2.7696035, "process_in_blocks": "6480", "process_kernel_time": 0.697906, "process_mem_max_rss": "113788", "process_out_blocks": "13416", "process_user_time": 5.374277}
[0m20:23:24.475167 [debug] [MainThread]: Command `dbt docs generate` succeeded at 20:23:24.474960 after 2.77 seconds
[0m20:23:24.475757 [debug] [MainThread]: Connection 'generate_catalog' was left open.
[0m20:23:24.476312 [debug] [MainThread]: On generate_catalog: Close
[0m20:23:24.477141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e2881516310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e287c4ae670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e287c554100>]}
[0m20:23:24.477857 [debug] [MainThread]: Flushing usage events
[0m20:23:34.445010 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa53e308310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa53af48cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa53af48b80>]}


============================== 20:23:34.455329 | 4a688cef-2a7f-4f10-af56-3b19582ce9bd ==============================
[0m20:23:34.455329 [info ] [MainThread]: Running with dbt=1.8.9
[0m20:23:34.456652 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'version_check': 'True', 'invocation_command': 'dbt docs serve --profiles-dir . --target local --host 0.0.0.0 --port 8080', 'profiles_dir': '.', 'target_path': 'None', 'empty': 'None', 'partial_parse': 'True', 'cache_selected_only': 'False', 'introspect': 'True', 'use_experimental_parser': 'False', 'warn_error': 'None', 'use_colors': 'True', 'static_parser': 'True', 'write_json': 'True', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'log_path': '/workdir/transforms/01_mpg/logs', 'quiet': 'False', 'indirect_selection': 'eager'}
[0m20:23:34.776820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4a688cef-2a7f-4f10-af56-3b19582ce9bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa53ae31580>]}
[0m20:23:34.873300 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4a688cef-2a7f-4f10-af56-3b19582ce9bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa53b3b6820>]}
[0m20:25:16.488365 [error] [MainThread]: Encountered an error:

[0m20:25:16.492653 [error] [MainThread]: Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 101, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 218, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 247, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 294, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/main.py", line 303, in docs_serve
    results = task.run()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/docs/serve.py", line 29, in run
    httpd.serve_forever()
  File "/usr/local/lib/python3.9/socketserver.py", line 237, in serve_forever
    self._handle_request_noblock()
  File "/usr/local/lib/python3.9/socketserver.py", line 316, in _handle_request_noblock
    self.process_request(request, client_address)
  File "/usr/local/lib/python3.9/socketserver.py", line 347, in process_request
    self.finish_request(request, client_address)
  File "/usr/local/lib/python3.9/socketserver.py", line 360, in finish_request
    self.RequestHandlerClass(request, client_address, self)
  File "/usr/local/lib/python3.9/http/server.py", line 668, in __init__
    super().__init__(*args, **kwargs)
  File "/usr/local/lib/python3.9/socketserver.py", line 747, in __init__
    self.handle()
  File "/usr/local/lib/python3.9/http/server.py", line 433, in handle
    self.handle_one_request()
  File "/usr/local/lib/python3.9/http/server.py", line 401, in handle_one_request
    self.raw_requestline = self.rfile.readline(65537)
  File "/usr/local/lib/python3.9/socket.py", line 716, in readinto
    return self._sock.recv_into(b)
KeyboardInterrupt

[0m20:25:16.495391 [debug] [MainThread]: Resource report: {"command_name": "serve", "command_success": false, "command_wall_clock_time": 102.151886, "process_in_blocks": "0", "process_kernel_time": 0.514146, "process_mem_max_rss": "95024", "process_out_blocks": "9736", "process_user_time": 3.668021}
[0m20:25:16.496905 [debug] [MainThread]: Command `dbt docs serve` failed at 20:25:16.496605 after 102.15 seconds
[0m20:25:16.497813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa53e308310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa53abe2d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa53abe2e20>]}
[0m20:25:16.498656 [debug] [MainThread]: Flushing usage events
[0m20:28:02.344603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5e81472310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5e7e0d3b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5e7e0d3a30>]}


============================== 20:28:02.354145 | 93985561-0b0b-4516-a391-5430bfd95aac ==============================
[0m20:28:02.354145 [info ] [MainThread]: Running with dbt=1.8.9
[0m20:28:02.355338 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'no_print': 'None', 'write_json': 'True', 'version_check': 'True', 'quiet': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'log_cache_events': 'False', 'invocation_command': 'dbt docs generate --profiles-dir . --target local --select resource_type:source,resource_type:model', 'partial_parse': 'True', 'warn_error': 'None', 'log_format': 'default', 'profiles_dir': '.', 'debug': 'False', 'empty': 'None', 'target_path': 'None', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'use_colors': 'True', 'introspect': 'True', 'static_parser': 'True', 'fail_fast': 'False', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m20:28:02.644676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '93985561-0b0b-4516-a391-5430bfd95aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5e7e0980a0>]}
[0m20:28:02.741738 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '93985561-0b0b-4516-a391-5430bfd95aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5e7dfc27f0>]}
[0m20:28:02.743128 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m20:28:02.930482 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m20:28:03.168371 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:28:03.169058 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:28:03.246888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '93985561-0b0b-4516-a391-5430bfd95aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5e7d959df0>]}
[0m20:28:03.716490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '93985561-0b0b-4516-a391-5430bfd95aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5e7d8c0e50>]}
[0m20:28:03.717423 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m20:28:03.718276 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '93985561-0b0b-4516-a391-5430bfd95aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5e7d8c0d90>]}
[0m20:28:03.719445 [warn ] [MainThread]: The selection criterion 'resource_type:source,resource_type:model' does not match any enabled nodes
[0m20:28:03.721084 [info ] [MainThread]: 
[0m20:28:03.721903 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m20:28:03.725578 [debug] [MainThread]: Command end result
[0m20:28:03.906464 [debug] [MainThread]: Acquiring new clickhouse connection 'generate_catalog'
[0m20:28:03.907142 [info ] [MainThread]: Building catalog
[0m20:28:03.908142 [warn ] [MainThread]: The selection criterion 'resource_type:source,resource_type:model' does not match any enabled nodes
[0m20:28:03.950478 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:28:04.191754 [debug] [MainThread]: dbt_clickhouse adapter: On generate_catalog: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "generate_catalog"} */
select
      '' as table_database,
      columns.database as table_schema,
      columns.table as table_name,
      if(tables.engine not in ('MaterializedView', 'View'), 'table', 'view') as table_type,
      nullIf(tables.comment, '') as table_comment,
      columns.name as column_name,
      columns.position as column_index,
      columns.type as column_type,
      nullIf(columns.comment, '') as column_comment,
      null as table_owner
    from system.columns as columns
    join system.tables as tables on tables.database = columns.database and tables.name = columns.table
    where database != 'system' and
    (columns.database = 'clean' or columns.database = 'mart' or columns.database = 'raw')
    order by columns.database, columns.table, columns.position...
[0m20:28:04.213740 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m20:28:04.326926 [info ] [MainThread]: Catalog written to /workdir/transforms/01_mpg/target/catalog.json
[0m20:28:04.328691 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 2.0759108, "process_in_blocks": "0", "process_kernel_time": 0.664557, "process_mem_max_rss": "107424", "process_out_blocks": "12360", "process_user_time": 4.72685}
[0m20:28:04.329582 [debug] [MainThread]: Command `dbt docs generate` succeeded at 20:28:04.329353 after 2.08 seconds
[0m20:28:04.330228 [debug] [MainThread]: Connection 'generate_catalog' was left open.
[0m20:28:04.330797 [debug] [MainThread]: On generate_catalog: Close
[0m20:28:04.331431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5e81472310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5e7d92ba30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a5e7dfc27f0>]}
[0m20:28:04.332041 [debug] [MainThread]: Flushing usage events
[0m20:28:39.083415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71bedffd9e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71bedcc414f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71bedcc41640>]}


============================== 20:28:39.093181 | b18ac47a-a52b-4577-ac63-08ea990dc13c ==============================
[0m20:28:39.093181 [info ] [MainThread]: Running with dbt=1.8.9
[0m20:28:39.094360 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'debug': 'False', 'target_path': 'None', 'quiet': 'False', 'cache_selected_only': 'False', 'log_format': 'default', 'partial_parse': 'True', 'write_json': 'True', 'use_colors': 'True', 'profiles_dir': '.', 'invocation_command': 'dbt docs generate --profiles-dir . --target local', 'empty': 'None', 'indirect_selection': 'eager', 'log_path': '/workdir/transforms/01_mpg/logs', 'printer_width': '80', 'warn_error': 'None', 'use_experimental_parser': 'False', 'version_check': 'True', 'introspect': 'True', 'static_parser': 'True'}
[0m20:28:39.392346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b18ac47a-a52b-4577-ac63-08ea990dc13c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71bedf476910>]}
[0m20:28:39.505290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b18ac47a-a52b-4577-ac63-08ea990dc13c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71bedcc146d0>]}
[0m20:28:39.506727 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m20:28:39.679028 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m20:28:39.974224 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:28:39.975402 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:28:40.114130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b18ac47a-a52b-4577-ac63-08ea990dc13c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71bedc447df0>]}
[0m20:28:40.185178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b18ac47a-a52b-4577-ac63-08ea990dc13c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71bedc3f9e50>]}
[0m20:28:40.187111 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m20:28:40.188525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b18ac47a-a52b-4577-ac63-08ea990dc13c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71bedc3f9d90>]}
[0m20:28:40.193070 [info ] [MainThread]: 
[0m20:28:40.195241 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m20:28:40.202074 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__clean'
[0m20:28:40.220223 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__mart'
[0m20:28:40.300801 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:28:40.302517 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:28:40.630582 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m20:28:40.636155 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m20:28:40.637674 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:28:40.645346 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:28:40.677086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b18ac47a-a52b-4577-ac63-08ea990dc13c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71bedc3f9df0>]}
[0m20:28:40.678170 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m20:28:40.678810 [info ] [MainThread]: 
[0m20:28:40.692354 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m20:28:40.693378 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__mart, now model.ex_01_mpg.mpg_standardized)
[0m20:28:40.694079 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m20:28:40.711436 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m20:28:40.712693 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m20:28:40.714147 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m20:28:40.715779 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m20:28:40.717386 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m20:28:40.718208 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m20:28:40.724062 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m20:28:40.725301 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m20:28:40.726774 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m20:28:40.728336 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:28:40.728902 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m20:28:40.729459 [debug] [MainThread]: On list__clean: Close
[0m20:28:40.729933 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m20:28:40.730452 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m20:28:40.730904 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was properly closed.
[0m20:28:40.732670 [debug] [MainThread]: Command end result
[0m20:28:40.953110 [debug] [MainThread]: Acquiring new clickhouse connection 'generate_catalog'
[0m20:28:40.953996 [info ] [MainThread]: Building catalog
[0m20:28:40.967967 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:28:41.038960 [debug] [MainThread]: dbt_clickhouse adapter: On generate_catalog: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "generate_catalog"} */
select
      '' as table_database,
      columns.database as table_schema,
      columns.table as table_name,
      if(tables.engine not in ('MaterializedView', 'View'), 'table', 'view') as table_type,
      nullIf(tables.comment, '') as table_comment,
      columns.name as column_name,
      columns.position as column_index,
      columns.type as column_type,
      nullIf(columns.comment, '') as column_comment,
      null as table_owner
    from system.columns as columns
    join system.tables as tables on tables.database = columns.database and tables.name = columns.table
    where database != 'system' and
    (columns.database = 'raw' or columns.database = 'mart' or columns.database = 'clean')
    order by columns.database, columns.table, columns.position...
[0m20:28:41.065373 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m20:28:41.255791 [info ] [MainThread]: Catalog written to /workdir/transforms/01_mpg/target/catalog.json
[0m20:28:41.257449 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 2.2809627, "process_in_blocks": "8", "process_kernel_time": 0.656476, "process_mem_max_rss": "108644", "process_out_blocks": "12448", "process_user_time": 5.05497}
[0m20:28:41.258318 [debug] [MainThread]: Command `dbt docs generate` succeeded at 20:28:41.258107 after 2.28 seconds
[0m20:28:41.258960 [debug] [MainThread]: Connection 'generate_catalog' was left open.
[0m20:28:41.259524 [debug] [MainThread]: On generate_catalog: Close
[0m20:28:41.260176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71bedffd9e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71bedc8d3520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71bedc682400>]}
[0m20:28:41.260808 [debug] [MainThread]: Flushing usage events
[0m20:29:03.221029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x782f5a416310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x782f57067d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x782f57067bb0>]}


============================== 20:29:03.230724 | b15c6353-10dc-4519-b7ad-7eb2b8d6467b ==============================
[0m20:29:03.230724 [info ] [MainThread]: Running with dbt=1.8.9
[0m20:29:03.231864 [debug] [MainThread]: running dbt with arguments {'log_cache_events': 'False', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'write_json': 'True', 'quiet': 'False', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs serve --profiles-dir . --target local --host 0.0.0.0 --port 8080', 'log_path': '/workdir/transforms/01_mpg/logs', 'printer_width': '80', 'log_format': 'default', 'empty': 'None', 'profiles_dir': '.', 'debug': 'False', 'indirect_selection': 'eager', 'warn_error': 'None', 'no_print': 'None', 'introspect': 'True', 'use_experimental_parser': 'False'}
[0m20:29:03.530444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b15c6353-10dc-4519-b7ad-7eb2b8d6467b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x782f570c9730>]}
[0m20:29:03.631143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b15c6353-10dc-4519-b7ad-7eb2b8d6467b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x782f56ede490>]}
[0m20:30:15.124847 [error] [MainThread]: Encountered an error:

[0m20:30:15.130498 [error] [MainThread]: Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 101, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 218, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 247, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 294, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/main.py", line 303, in docs_serve
    results = task.run()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/docs/serve.py", line 29, in run
    httpd.serve_forever()
  File "/usr/local/lib/python3.9/socketserver.py", line 237, in serve_forever
    self._handle_request_noblock()
  File "/usr/local/lib/python3.9/socketserver.py", line 316, in _handle_request_noblock
    self.process_request(request, client_address)
  File "/usr/local/lib/python3.9/socketserver.py", line 347, in process_request
    self.finish_request(request, client_address)
  File "/usr/local/lib/python3.9/socketserver.py", line 360, in finish_request
    self.RequestHandlerClass(request, client_address, self)
  File "/usr/local/lib/python3.9/http/server.py", line 668, in __init__
    super().__init__(*args, **kwargs)
  File "/usr/local/lib/python3.9/socketserver.py", line 747, in __init__
    self.handle()
  File "/usr/local/lib/python3.9/http/server.py", line 433, in handle
    self.handle_one_request()
  File "/usr/local/lib/python3.9/http/server.py", line 401, in handle_one_request
    self.raw_requestline = self.rfile.readline(65537)
  File "/usr/local/lib/python3.9/socket.py", line 716, in readinto
    return self._sock.recv_into(b)
KeyboardInterrupt

[0m20:30:15.133843 [debug] [MainThread]: Resource report: {"command_name": "serve", "command_success": false, "command_wall_clock_time": 72.00927, "process_in_blocks": "0", "process_kernel_time": 0.512378, "process_mem_max_rss": "95504", "process_out_blocks": "9744", "process_user_time": 3.882293}
[0m20:30:15.136013 [debug] [MainThread]: Command `dbt docs serve` failed at 20:30:15.135465 after 72.01 seconds
[0m20:30:15.138046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x782f5a416310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x782f56d0ea90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x782f56bec1c0>]}
[0m20:30:15.139697 [debug] [MainThread]: Flushing usage events
[0m20:32:47.165251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790c01822310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790bfe478b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790bfe478a00>]}


============================== 20:32:47.174820 | bcec04ec-86c1-421c-8583-404808c60749 ==============================
[0m20:32:47.174820 [info ] [MainThread]: Running with dbt=1.8.9
[0m20:32:47.175932 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'empty': 'False', 'fail_fast': 'False', 'invocation_command': 'dbt build --profiles-dir . --target local', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_colors': 'True', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '.', 'log_path': '/workdir/transforms/01_mpg/logs', 'quiet': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'static_parser': 'True', 'log_format': 'default', 'cache_selected_only': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'target_path': 'None', 'warn_error': 'None', 'introspect': 'True', 'log_cache_events': 'False', 'version_check': 'True', 'write_json': 'True'}
[0m20:32:47.459915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bcec04ec-86c1-421c-8583-404808c60749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790bfe3bf340>]}
[0m20:32:47.556011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bcec04ec-86c1-421c-8583-404808c60749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790bfe4423a0>]}
[0m20:32:47.557409 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m20:32:47.741015 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m20:32:47.963512 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m20:32:47.964852 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/sources.yml
[0m20:32:48.759876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bcec04ec-86c1-421c-8583-404808c60749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790bfc741130>]}
[0m20:32:48.979891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bcec04ec-86c1-421c-8583-404808c60749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790bfc695970>]}
[0m20:32:48.980800 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m20:32:48.983557 [info ] [MainThread]: 
[0m20:32:48.984678 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m20:32:48.996847 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m20:32:48.997928 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m20:32:49.028142 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:32:49.032619 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:32:49.362530 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m20:32:49.366784 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m20:32:49.367963 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:32:49.375702 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:32:49.395042 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m20:32:49.396129 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m20:32:49.408671 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m20:32:49.412673 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m20:32:49.418576 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m20:32:49.425947 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:32:49.435908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bcec04ec-86c1-421c-8583-404808c60749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790bfc62a370>]}
[0m20:32:49.436938 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m20:32:49.437628 [info ] [MainThread]: 
[0m20:32:49.450754 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m20:32:49.451906 [info ] [Thread-1  ]: 1 of 2 START sql table model `clean`.`mpg_standardized` ........................ [RUN]
[0m20:32:49.452798 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__clean, now model.ex_01_mpg.mpg_standardized)
[0m20:32:49.453517 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m20:32:49.470559 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m20:32:49.471799 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m20:32:49.569072 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64(mpg)          as mpg,
  toInt32(cylinders)      as cylinders,
  toFloat64(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32(weight)         as weight,
  toFloat64(acceleration) as acceleration,
  toInt32(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
-- where horsepower is not null
  -- and isFinite(horsepower)
          )
        
        ...
[0m20:32:49.574995 [debug] [Thread-1  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64(mpg)          as mpg,
  toInt32(cylinders)      as cylinders,
  toFloat64(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32(weight)         as weight,
  toFloat64(acceleration) as acceleration,
  toInt32(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
-- where horsepower is not null
  -- and isFinite(horsepower)
          )
        
        
[0m20:32:49.585179 [debug] [Thread-1  ]: Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 43
   Code: 43. DB::Exception: Illegal type Float64 of first argument of function toFloat64OrNull. Conversion functions with postfix 'OrZero' or 'OrNull' should take String argument: While processing toFloat64(mpg) AS mpg, toInt32(cylinders) AS cylinders, toFloat64(displacement) AS displacement, toFloat64OrNull(horsepower) AS horsepower, toInt32(weight) AS weight, toFloat64(acceleration) AS acceleration, toInt32(model_year) AS model_year, trimBoth(origin) AS origin, trimBoth(name) AS make. (ILLEGAL_TYPE_OF_ARGUMENT) (version 23.12.6.19 (official build))
[0m20:32:49.587948 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bcec04ec-86c1-421c-8583-404808c60749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790bfdcf74f0>]}
[0m20:32:49.589141 [error] [Thread-1  ]: 1 of 2 ERROR creating sql table model `clean`.`mpg_standardized` ............... [[31mERROR[0m in 0.13s]
[0m20:32:49.590587 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m20:32:49.592075 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m20:32:49.592975 [info ] [Thread-3  ]: 2 of 2 SKIP relation mart.cylinders_by_origin .................................. [[33mSKIP[0m]
[0m20:32:49.593969 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m20:32:49.595813 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:32:49.596410 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m20:32:49.596968 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m20:32:49.597506 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m20:32:49.598026 [debug] [MainThread]: On list__mart: Close
[0m20:32:49.598877 [info ] [MainThread]: 
[0m20:32:49.599661 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.61 seconds (0.61s).
[0m20:32:49.601252 [debug] [MainThread]: Command end result
[0m20:32:49.659147 [info ] [MainThread]: 
[0m20:32:49.660140 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m20:32:49.660774 [info ] [MainThread]: 
[0m20:32:49.661615 [error] [MainThread]:   Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 43
   Code: 43. DB::Exception: Illegal type Float64 of first argument of function toFloat64OrNull. Conversion functions with postfix 'OrZero' or 'OrNull' should take String argument: While processing toFloat64(mpg) AS mpg, toInt32(cylinders) AS cylinders, toFloat64(displacement) AS displacement, toFloat64OrNull(horsepower) AS horsepower, toInt32(weight) AS weight, toFloat64(acceleration) AS acceleration, toInt32(model_year) AS model_year, trimBoth(origin) AS origin, trimBoth(name) AS make. (ILLEGAL_TYPE_OF_ARGUMENT) (version 23.12.6.19 (official build))
[0m20:32:49.662269 [info ] [MainThread]: 
[0m20:32:49.662879 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
[0m20:32:49.664203 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 2.593437, "process_in_blocks": "1832", "process_kernel_time": 0.606935, "process_mem_max_rss": "114784", "process_out_blocks": "10456", "process_user_time": 5.427421}
[0m20:32:49.665129 [debug] [MainThread]: Command `dbt build` failed at 20:32:49.664825 after 2.59 seconds
[0m20:32:49.666064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790c01822310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790bfe3bf340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x790bfc6959a0>]}
[0m20:32:49.666714 [debug] [MainThread]: Flushing usage events
[0m20:33:55.605126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78ca919f2310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78ca8e653b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78ca8e6539d0>]}


============================== 20:33:55.614621 | a5e87d60-5a58-4016-846a-ab6509ea3920 ==============================
[0m20:33:55.614621 [info ] [MainThread]: Running with dbt=1.8.9
[0m20:33:55.615752 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'fail_fast': 'False', 'debug': 'False', 'version_check': 'True', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'partial_parse': 'True', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'log_path': '/workdir/transforms/01_mpg/logs', 'warn_error': 'None', 'use_experimental_parser': 'False', 'target_path': 'None', 'invocation_command': 'dbt docs generate --profiles-dir . --target local', 'empty': 'None', 'cache_selected_only': 'False', 'no_print': 'None', 'static_parser': 'True', 'use_colors': 'True', 'introspect': 'True', 'profiles_dir': '.', 'quiet': 'False'}
[0m20:33:55.905887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a5e87d60-5a58-4016-846a-ab6509ea3920', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78ca90f92ca0>]}
[0m20:33:56.008946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a5e87d60-5a58-4016-846a-ab6509ea3920', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78ca8e519d90>]}
[0m20:33:56.010317 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m20:33:56.179548 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m20:33:56.411120 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:33:56.411780 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:33:56.487549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a5e87d60-5a58-4016-846a-ab6509ea3920', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78ca8de5ce50>]}
[0m20:33:56.517094 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a5e87d60-5a58-4016-846a-ab6509ea3920', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78ca8de0ceb0>]}
[0m20:33:56.517955 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m20:33:56.518600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a5e87d60-5a58-4016-846a-ab6509ea3920', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78ca8de0cdf0>]}
[0m20:33:56.520994 [info ] [MainThread]: 
[0m20:33:56.522064 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m20:33:56.523544 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__mart'
[0m20:33:56.524668 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__clean'
[0m20:33:56.565601 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:33:56.569109 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:33:56.836418 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m20:33:56.840596 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m20:33:56.843786 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:33:56.847144 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m20:33:56.882957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a5e87d60-5a58-4016-846a-ab6509ea3920', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78ca8de2db50>]}
[0m20:33:56.884036 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m20:33:56.884775 [info ] [MainThread]: 
[0m20:33:56.897622 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m20:33:56.898613 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__clean, now model.ex_01_mpg.mpg_standardized)
[0m20:33:56.899321 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m20:33:56.915747 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m20:33:56.916957 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m20:33:56.918403 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m20:33:56.920037 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m20:33:56.920994 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m20:33:56.921735 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m20:33:56.927149 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m20:33:56.928356 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m20:33:56.929685 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m20:33:56.931368 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:33:56.931941 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m20:33:56.932518 [debug] [MainThread]: On list__mart: Close
[0m20:33:56.932999 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m20:33:56.933553 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m20:33:56.934014 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was properly closed.
[0m20:33:56.935806 [debug] [MainThread]: Command end result
[0m20:33:57.115068 [debug] [MainThread]: Acquiring new clickhouse connection 'generate_catalog'
[0m20:33:57.115757 [info ] [MainThread]: Building catalog
[0m20:33:57.128333 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:33:57.184980 [debug] [MainThread]: dbt_clickhouse adapter: On generate_catalog: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "generate_catalog"} */
select
      '' as table_database,
      columns.database as table_schema,
      columns.table as table_name,
      if(tables.engine not in ('MaterializedView', 'View'), 'table', 'view') as table_type,
      nullIf(tables.comment, '') as table_comment,
      columns.name as column_name,
      columns.position as column_index,
      columns.type as column_type,
      nullIf(columns.comment, '') as column_comment,
      null as table_owner
    from system.columns as columns
    join system.tables as tables on tables.database = columns.database and tables.name = columns.table
    where database != 'system' and
    (columns.database = 'mart' or columns.database = 'raw' or columns.database = 'clean')
    order by columns.database, columns.table, columns.position...
[0m20:33:57.221644 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m20:33:57.431157 [info ] [MainThread]: Catalog written to /workdir/transforms/01_mpg/target/catalog.json
[0m20:33:57.432772 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 1.9231273, "process_in_blocks": "0", "process_kernel_time": 0.596537, "process_mem_max_rss": "108528", "process_out_blocks": "12440", "process_user_time": 4.868223}
[0m20:33:57.433720 [debug] [MainThread]: Command `dbt docs generate` succeeded at 20:33:57.433453 after 1.92 seconds
[0m20:33:57.434356 [debug] [MainThread]: Connection 'generate_catalog' was left open.
[0m20:33:57.434980 [debug] [MainThread]: On generate_catalog: Close
[0m20:33:57.435727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78ca919f2310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78ca8de2fb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78ca8d7dedc0>]}
[0m20:33:57.436408 [debug] [MainThread]: Flushing usage events
[0m20:34:04.932161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c44dcfc0310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c44d9c1e340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c44d9c1e490>]}


============================== 20:34:04.942277 | a1c28965-2b35-4554-a920-023b4926cb42 ==============================
[0m20:34:04.942277 [info ] [MainThread]: Running with dbt=1.8.9
[0m20:34:04.943483 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'use_experimental_parser': 'False', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'profiles_dir': '.', 'use_colors': 'True', 'empty': 'None', 'log_path': '/workdir/transforms/01_mpg/logs', 'partial_parse': 'True', 'introspect': 'True', 'invocation_command': 'dbt docs serve --profiles-dir . --target local --host 0.0.0.0 --port 8080', 'write_json': 'True', 'static_parser': 'True', 'warn_error': 'None', 'log_format': 'default', 'log_cache_events': 'False', 'no_print': 'None', 'indirect_selection': 'eager', 'debug': 'False', 'version_check': 'True', 'cache_selected_only': 'False'}
[0m20:34:05.229976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a1c28965-2b35-4554-a920-023b4926cb42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c44dc55db80>]}
[0m20:34:05.329251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a1c28965-2b35-4554-a920-023b4926cb42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c44da06c7f0>]}
[0m00:23:18.857879 [error] [MainThread]: Encountered an error:

[0m00:23:19.078484 [error] [MainThread]: Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 101, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 218, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 247, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/requires.py", line 294, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/cli/main.py", line 303, in docs_serve
    results = task.run()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/docs/serve.py", line 29, in run
    httpd.serve_forever()
  File "/usr/local/lib/python3.9/socketserver.py", line 237, in serve_forever
    self._handle_request_noblock()
  File "/usr/local/lib/python3.9/socketserver.py", line 316, in _handle_request_noblock
    self.process_request(request, client_address)
  File "/usr/local/lib/python3.9/socketserver.py", line 347, in process_request
    self.finish_request(request, client_address)
  File "/usr/local/lib/python3.9/socketserver.py", line 360, in finish_request
    self.RequestHandlerClass(request, client_address, self)
  File "/usr/local/lib/python3.9/http/server.py", line 668, in __init__
    super().__init__(*args, **kwargs)
  File "/usr/local/lib/python3.9/socketserver.py", line 747, in __init__
    self.handle()
  File "/usr/local/lib/python3.9/http/server.py", line 433, in handle
    self.handle_one_request()
  File "/usr/local/lib/python3.9/http/server.py", line 401, in handle_one_request
    self.raw_requestline = self.rfile.readline(65537)
  File "/usr/local/lib/python3.9/socket.py", line 716, in readinto
    return self._sock.recv_into(b)
KeyboardInterrupt

[0m00:23:19.080958 [debug] [MainThread]: Resource report: {"command_name": "serve", "command_success": false, "command_wall_clock_time": 13754.242, "process_in_blocks": "344", "process_kernel_time": 0.48153, "process_mem_max_rss": "95208", "process_out_blocks": "9736", "process_user_time": 3.942159}
[0m00:23:19.082024 [debug] [MainThread]: Command `dbt docs serve` failed at 00:23:19.081751 after 13754.24 seconds
[0m00:23:19.082846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c44dcfc0310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c44d98c33d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7c44d97a3130>]}
[0m00:23:19.083616 [debug] [MainThread]: Flushing usage events
[0m00:24:12.678677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72eecf95f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72eecc5c5490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72eecc5c55e0>]}


============================== 00:24:12.688870 | fe5d6148-2cee-42d6-b0a2-83f9f522a955 ==============================
[0m00:24:12.688870 [info ] [MainThread]: Running with dbt=1.8.9
[0m00:24:12.689989 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'partial_parse': 'True', 'warn_error': 'None', 'log_format': 'default', 'profiles_dir': '.', 'write_json': 'True', 'quiet': 'False', 'introspect': 'True', 'fail_fast': 'False', 'invocation_command': 'dbt docs generate --profiles-dir . --target local --static', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'printer_width': '80', 'log_path': '/workdir/transforms/01_mpg/logs', 'debug': 'False', 'empty': 'None', 'use_experimental_parser': 'False', 'use_colors': 'True', 'target_path': 'None'}
[0m00:24:12.990488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fe5d6148-2cee-42d6-b0a2-83f9f522a955', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72eecc6cf880>]}
[0m00:24:13.095396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fe5d6148-2cee-42d6-b0a2-83f9f522a955', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72eecc4c37c0>]}
[0m00:24:13.097478 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m00:24:13.279654 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m00:24:13.603616 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:24:13.604639 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:24:13.684302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fe5d6148-2cee-42d6-b0a2-83f9f522a955', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72eecbdcddc0>]}
[0m00:24:13.733292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fe5d6148-2cee-42d6-b0a2-83f9f522a955', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72eecbd7fe20>]}
[0m00:24:13.734183 [info ] [MainThread]: Found 2 models, 1 source, 471 macros
[0m00:24:13.734881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fe5d6148-2cee-42d6-b0a2-83f9f522a955', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72eecbd7fd60>]}
[0m00:24:13.737391 [info ] [MainThread]: 
[0m00:24:13.738696 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m00:24:13.740447 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__clean'
[0m00:24:13.741502 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__mart'
[0m00:24:13.782347 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:24:13.787665 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:24:14.124839 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m00:24:14.131741 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m00:24:14.133100 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m00:24:14.140387 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m00:24:14.190173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fe5d6148-2cee-42d6-b0a2-83f9f522a955', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72eecbd9d040>]}
[0m00:24:14.191690 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m00:24:14.192688 [info ] [MainThread]: 
[0m00:24:14.207120 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m00:24:14.208179 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__clean, now model.ex_01_mpg.mpg_standardized)
[0m00:24:14.208996 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m00:24:14.226605 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m00:24:14.227895 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m00:24:14.229474 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m00:24:14.230965 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m00:24:14.232297 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m00:24:14.233071 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m00:24:14.238826 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m00:24:14.240111 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m00:24:14.241590 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m00:24:14.243320 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:24:14.244254 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m00:24:14.245087 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m00:24:14.245915 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m00:24:14.246768 [debug] [MainThread]: On list__mart: Close
[0m00:24:14.247548 [debug] [MainThread]: Connection 'model.ex_01_mpg.cylinders_by_origin' was properly closed.
[0m00:24:14.250501 [debug] [MainThread]: Command end result
[0m00:24:14.460674 [debug] [MainThread]: Acquiring new clickhouse connection 'generate_catalog'
[0m00:24:14.461374 [info ] [MainThread]: Building catalog
[0m00:24:14.473798 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:24:14.533224 [debug] [MainThread]: dbt_clickhouse adapter: On generate_catalog: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "generate_catalog"} */
select
      '' as table_database,
      columns.database as table_schema,
      columns.table as table_name,
      if(tables.engine not in ('MaterializedView', 'View'), 'table', 'view') as table_type,
      nullIf(tables.comment, '') as table_comment,
      columns.name as column_name,
      columns.position as column_index,
      columns.type as column_type,
      nullIf(columns.comment, '') as column_comment,
      null as table_owner
    from system.columns as columns
    join system.tables as tables on tables.database = columns.database and tables.name = columns.table
    where database != 'system' and
    (columns.database = 'mart' or columns.database = 'raw' or columns.database = 'clean')
    order by columns.database, columns.table, columns.position...
[0m00:24:14.551285 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m00:24:14.765496 [info ] [MainThread]: Catalog written to /workdir/transforms/01_mpg/target/catalog.json
[0m00:24:14.767621 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 2.1991792, "process_in_blocks": "44624", "process_kernel_time": 0.778691, "process_mem_max_rss": "115852", "process_out_blocks": "16368", "process_user_time": 5.088118}
[0m00:24:14.768540 [debug] [MainThread]: Command `dbt docs generate` succeeded at 00:24:14.768323 after 2.20 seconds
[0m00:24:14.769158 [debug] [MainThread]: Connection 'generate_catalog' was left open.
[0m00:24:14.769710 [debug] [MainThread]: On generate_catalog: Close
[0m00:24:14.770378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72eecf95f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72eeceb9bc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72eecc008460>]}
[0m00:24:14.770960 [debug] [MainThread]: Flushing usage events
[0m07:09:59.963071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d87fea9edc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d87fb6fc430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d87fb6fc580>]}


============================== 07:10:00.000108 | f8cfd97a-6158-40c5-9dde-7b2002b29f92 ==============================
[0m07:10:00.000108 [info ] [MainThread]: Running with dbt=1.8.9
[0m07:10:00.001526 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '.', 'log_format': 'default', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'warn_error': 'None', 'invocation_command': 'dbt docs generate --profiles-dir . --target local', 'debug': 'False', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'log_path': '/workdir/transforms/01_mpg/logs', 'write_json': 'True', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'introspect': 'True', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'target_path': 'None', 'static_parser': 'True', 'use_colors': 'True', 'quiet': 'False', 'printer_width': '80', 'empty': 'None', 'fail_fast': 'False'}
[0m07:10:00.305884 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f8cfd97a-6158-40c5-9dde-7b2002b29f92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d87fb6c4550>]}
[0m07:10:00.401128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f8cfd97a-6158-40c5-9dde-7b2002b29f92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d87fc222430>]}
[0m07:10:00.403340 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m07:10:00.584766 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m07:10:00.912179 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
[0m07:10:00.913234 [debug] [MainThread]: Partial parsing: added file: ex_01_mpg://models/clean/schema.yml
[0m07:10:00.913914 [debug] [MainThread]: Partial parsing: added file: ex_01_mpg://models/mart/schema.yml
[0m07:10:01.023043 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m07:10:01.023985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'f8cfd97a-6158-40c5-9dde-7b2002b29f92', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d87fb276190>]}
[0m07:10:01.332593 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'mpg_by_origin' in the 'models' section of file 'models/mart/schema.yml'
[0m07:10:01.344378 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.ex_01_mpg.not_null_mpg_by_origin_origin.ce18a72897' (models/mart/schema.yml) depends on a node named 'mpg_by_origin' in package '' which was not found
[0m07:10:01.345336 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.ex_01_mpg.accepted_values_mpg_by_origin_origin__usa__europe__japan.5abbbc6ce1' (models/mart/schema.yml) depends on a node named 'mpg_by_origin' in package '' which was not found
[0m07:10:01.530987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f8cfd97a-6158-40c5-9dde-7b2002b29f92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d87fabad130>]}
[0m07:10:01.607207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f8cfd97a-6158-40c5-9dde-7b2002b29f92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d87fab22610>]}
[0m07:10:01.608282 [info ] [MainThread]: Found 2 models, 9 data tests, 1 source, 471 macros
[0m07:10:01.609041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f8cfd97a-6158-40c5-9dde-7b2002b29f92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d87fab226a0>]}
[0m07:10:01.612504 [info ] [MainThread]: 
[0m07:10:01.613812 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m07:10:01.615736 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__clean'
[0m07:10:01.617144 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__mart'
[0m07:10:01.644693 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:10:01.656964 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:10:02.340613 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m07:10:02.342834 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m07:10:02.346732 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:10:02.351395 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:10:02.399159 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f8cfd97a-6158-40c5-9dde-7b2002b29f92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d87fab22430>]}
[0m07:10:02.400209 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m07:10:02.400917 [info ] [MainThread]: 
[0m07:10:02.414605 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m07:10:02.415557 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__clean, now model.ex_01_mpg.mpg_standardized)
[0m07:10:02.416254 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m07:10:02.433072 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m07:10:02.455227 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m07:10:02.456850 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m07:10:02.529685 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m07:10:02.531244 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:10:02.532653 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m07:10:02.533640 [debug] [Thread-2  ]: Began running node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:10:02.534444 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:10:02.535694 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed'
[0m07:10:02.536764 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m07:10:02.537911 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d'
[0m07:10:02.538848 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_mpg.mpg_standardized, now test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae)
[0m07:10:02.539688 [debug] [Thread-4  ]: Began compiling node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:10:02.545712 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m07:10:02.546759 [debug] [Thread-2  ]: Began compiling node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:10:02.547591 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:10:02.554435 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed"
[0m07:10:02.561998 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d"
[0m07:10:02.568346 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m07:10:02.578521 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae"
[0m07:10:02.580546 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m07:10:02.581871 [debug] [Thread-3  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:10:02.582782 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly model.ex_01_mpg.cylinders_by_origin, now test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc)
[0m07:10:02.583543 [debug] [Thread-3  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:10:02.590404 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc"
[0m07:10:02.612570 [debug] [Thread-4  ]: Began executing node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:10:02.613982 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:10:02.614708 [debug] [Thread-2  ]: Began executing node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:10:02.616905 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:10:02.618058 [debug] [Thread-3  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:10:02.619561 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:10:02.621091 [debug] [Thread-2  ]: Finished running node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:10:02.622278 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:10:02.624048 [debug] [Thread-3  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:10:02.625049 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:10:02.625995 [debug] [Thread-2  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:10:02.626822 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed, now test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0)
[0m07:10:02.627630 [debug] [Thread-3  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:10:02.628412 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae, now test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904)
[0m07:10:02.629213 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d, now test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231)
[0m07:10:02.629977 [debug] [Thread-4  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:10:02.630741 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc, now test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a)
[0m07:10:02.631450 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:10:02.632223 [debug] [Thread-2  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:10:02.640426 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0"
[0m07:10:02.641392 [debug] [Thread-3  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:10:02.648203 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904"
[0m07:10:02.654925 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231"
[0m07:10:02.662543 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a"
[0m07:10:02.663421 [debug] [Thread-4  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:10:02.664672 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:10:02.665680 [debug] [Thread-2  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:10:02.667250 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:10:02.668108 [debug] [Thread-3  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:10:02.669494 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:10:02.671085 [debug] [Thread-2  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:10:02.672080 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:10:02.673517 [debug] [Thread-3  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:10:02.674915 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0, now test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05)
[0m07:10:02.675884 [debug] [Thread-4  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:10:02.682537 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05"
[0m07:10:02.683841 [debug] [Thread-4  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:10:02.685335 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:10:02.687173 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:10:02.687764 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904' was left open.
[0m07:10:02.688313 [debug] [MainThread]: On test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904: Close
[0m07:10:02.688813 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m07:10:02.689312 [debug] [MainThread]: On list__mart: Close
[0m07:10:02.689793 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a' was properly closed.
[0m07:10:02.690262 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05' was properly closed.
[0m07:10:02.690747 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231' was properly closed.
[0m07:10:02.697649 [debug] [MainThread]: Command end result
[0m07:10:02.969042 [debug] [MainThread]: Acquiring new clickhouse connection 'generate_catalog'
[0m07:10:02.969741 [info ] [MainThread]: Building catalog
[0m07:10:02.981910 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:10:03.042559 [debug] [MainThread]: dbt_clickhouse adapter: On generate_catalog: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "generate_catalog"} */
select
      '' as table_database,
      columns.database as table_schema,
      columns.table as table_name,
      if(tables.engine not in ('MaterializedView', 'View'), 'table', 'view') as table_type,
      nullIf(tables.comment, '') as table_comment,
      columns.name as column_name,
      columns.position as column_index,
      columns.type as column_type,
      nullIf(columns.comment, '') as column_comment,
      null as table_owner
    from system.columns as columns
    join system.tables as tables on tables.database = columns.database and tables.name = columns.table
    where database != 'system' and
    (columns.database = 'clean' or columns.database = 'mart' or columns.database = 'raw')
    order by columns.database, columns.table, columns.position...
[0m07:10:03.101181 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m07:10:03.229147 [info ] [MainThread]: Catalog written to /workdir/transforms/01_mpg/target/catalog.json
[0m07:10:03.230844 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 3.4045649, "process_in_blocks": "12872", "process_kernel_time": 0.640906, "process_mem_max_rss": "112244", "process_out_blocks": "13672", "process_user_time": 5.456204}
[0m07:10:03.231650 [debug] [MainThread]: Command `dbt docs generate` succeeded at 07:10:03.231446 after 3.41 seconds
[0m07:10:03.232213 [debug] [MainThread]: Connection 'generate_catalog' was left open.
[0m07:10:03.232804 [debug] [MainThread]: On generate_catalog: Close
[0m07:10:03.233532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d87fea9edc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d87fc222430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d87fb6fcf10>]}
[0m07:10:03.234150 [debug] [MainThread]: Flushing usage events
[0m07:15:34.553993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23f23e3310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23ef052340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23ef052490>]}


============================== 07:15:34.563758 | 2093881f-261d-4d1d-a4ff-e6b12d428a4c ==============================
[0m07:15:34.563758 [info ] [MainThread]: Running with dbt=1.8.9
[0m07:15:34.564884 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'introspect': 'True', 'no_print': 'None', 'quiet': 'False', 'cache_selected_only': 'False', 'version_check': 'True', 'debug': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'target_path': 'None', 'warn_error': 'None', 'use_experimental_parser': 'False', 'write_json': 'True', 'log_cache_events': 'False', 'static_parser': 'True', 'invocation_command': 'dbt test --profiles-dir . --target local', 'profiles_dir': '.', 'printer_width': '80', 'log_path': '/workdir/transforms/01_mpg/logs', 'log_format': 'default', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_colors': 'True'}
[0m07:15:34.861129 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2093881f-261d-4d1d-a4ff-e6b12d428a4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23ef036400>]}
[0m07:15:34.960386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2093881f-261d-4d1d-a4ff-e6b12d428a4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23ef02ce20>]}
[0m07:15:34.961780 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m07:15:35.138966 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m07:15:35.409313 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m07:15:35.410481 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/mart/schema.yml
[0m07:15:35.512051 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m07:15:35.513025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '2093881f-261d-4d1d-a4ff-e6b12d428a4c', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23eeedf100>]}
[0m07:15:35.933565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2093881f-261d-4d1d-a4ff-e6b12d428a4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23ee4f4130>]}
[0m07:15:36.189686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2093881f-261d-4d1d-a4ff-e6b12d428a4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23ee253340>]}
[0m07:15:36.190586 [info ] [MainThread]: Found 2 models, 11 data tests, 1 source, 471 macros
[0m07:15:36.191208 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2093881f-261d-4d1d-a4ff-e6b12d428a4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23ef498970>]}
[0m07:15:36.194547 [info ] [MainThread]: 
[0m07:15:36.195712 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m07:15:36.197729 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__clean'
[0m07:15:36.198670 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__mart'
[0m07:15:36.230962 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:15:36.234212 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:15:36.499115 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m07:15:36.506174 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:15:36.507343 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m07:15:36.583926 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.08 seconds
[0m07:15:36.612005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2093881f-261d-4d1d-a4ff-e6b12d428a4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23ee253a00>]}
[0m07:15:36.613044 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m07:15:36.613680 [info ] [MainThread]: 
[0m07:15:36.627275 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m07:15:36.628161 [debug] [Thread-2  ]: Began running node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:15:36.628944 [debug] [Thread-3  ]: Began running node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:15:36.629810 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m07:15:36.630638 [info ] [Thread-1  ]: 1 of 11 START test accepted_values_cylinders_by_origin_origin__usa__europe__japan  [RUN]
[0m07:15:36.631637 [info ] [Thread-2  ]: 2 of 11 START test accepted_values_mpg_standardized_cylinders__3__4__5__6__8 ... [RUN]
[0m07:15:36.632601 [info ] [Thread-3  ]: 3 of 11 START test accepted_values_mpg_standardized_origin__usa__europe__japan . [RUN]
[0m07:15:36.633533 [info ] [Thread-4  ]: 4 of 11 START test not_null_cylinders_by_origin_origin ......................... [RUN]
[0m07:15:36.634517 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__clean, now test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2)
[0m07:15:36.635591 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed'
[0m07:15:36.636704 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d'
[0m07:15:36.637729 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9'
[0m07:15:36.638658 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m07:15:36.639495 [debug] [Thread-2  ]: Began compiling node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:15:36.640382 [debug] [Thread-3  ]: Began compiling node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:15:36.641160 [debug] [Thread-4  ]: Began compiling node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m07:15:36.663985 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2"
[0m07:15:36.666630 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed"
[0m07:15:36.673905 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d"
[0m07:15:36.689342 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9"
[0m07:15:36.690878 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m07:15:36.691632 [debug] [Thread-2  ]: Began executing node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:15:36.697918 [debug] [Thread-3  ]: Began executing node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:15:36.698758 [debug] [Thread-4  ]: Began executing node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m07:15:36.751790 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2"
[0m07:15:36.759145 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed"
[0m07:15:36.775757 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9"
[0m07:15:36.777190 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d"
[0m07:15:36.779051 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m07:15:36.779868 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m07:15:36.780697 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        origin as value_field,
        count(*) as n_records

    from `mart`.`cylinders_by_origin`
    group by origin

)

select *
from all_values
where value_field not in (
    'usa','europe','japan'
)



    ) dbt_internal_test...
[0m07:15:36.782603 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m07:15:36.895642 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        cylinders as value_field,
        count(*) as n_records

    from `clean`.`mpg_standardized`
    group by cylinders

)

select *
from all_values
where value_field not in (
    '3','4','5','6','8'
)



    ) dbt_internal_test...
[0m07:15:36.917093 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select origin
from `mart`.`cylinders_by_origin`
where origin is null



    ) dbt_internal_test...
[0m07:15:36.923861 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        origin as value_field,
        count(*) as n_records

    from `clean`.`mpg_standardized`
    group by origin

)

select *
from all_values
where value_field not in (
    'usa','europe','japan'
)



    ) dbt_internal_test...
[0m07:15:37.032283 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.14 seconds
[0m07:15:37.034233 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.11 seconds
[0m07:15:37.044251 [info ] [Thread-2  ]: 2 of 11 PASS accepted_values_mpg_standardized_cylinders__3__4__5__6__8 ......... [[32mPASS[0m in 0.41s]
[0m07:15:37.047744 [info ] [Thread-4  ]: 4 of 11 PASS not_null_cylinders_by_origin_origin ............................... [[32mPASS[0m in 0.41s]
[0m07:15:37.049538 [debug] [Thread-2  ]: Finished running node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:15:37.051061 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m07:15:37.052294 [debug] [Thread-2  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:15:37.053347 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:15:37.054399 [info ] [Thread-2  ]: 5 of 11 START test not_null_mpg_standardized_acceleration ...................... [RUN]
[0m07:15:37.055521 [info ] [Thread-4  ]: 6 of 11 START test not_null_mpg_standardized_cylinders ......................... [RUN]
[0m07:15:37.056533 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed, now test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae)
[0m07:15:37.057333 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9, now test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc)
[0m07:15:37.058222 [debug] [Thread-2  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:15:37.059011 [debug] [Thread-4  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:15:37.066937 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae"
[0m07:15:37.075401 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc"
[0m07:15:37.077097 [debug] [Thread-2  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:15:37.077996 [debug] [Thread-4  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:15:37.082588 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae"
[0m07:15:37.087384 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc"
[0m07:15:37.089049 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select acceleration
from `clean`.`mpg_standardized`
where acceleration is null



    ) dbt_internal_test...
[0m07:15:37.091042 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select cylinders
from `clean`.`mpg_standardized`
where cylinders is null



    ) dbt_internal_test...
[0m07:15:37.409806 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m07:15:37.411635 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m07:15:37.413168 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.49 seconds
[0m07:15:37.414974 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.63 seconds
[0m07:15:37.418281 [info ] [Thread-4  ]: 6 of 11 PASS not_null_mpg_standardized_cylinders ............................... [[32mPASS[0m in 0.36s]
[0m07:15:37.421619 [info ] [Thread-2  ]: 5 of 11 PASS not_null_mpg_standardized_acceleration ............................ [[32mPASS[0m in 0.36s]
[0m07:15:37.426750 [info ] [Thread-3  ]: 3 of 11 PASS accepted_values_mpg_standardized_origin__usa__europe__japan ....... [[32mPASS[0m in 0.79s]
[0m07:15:37.430797 [info ] [Thread-1  ]: 1 of 11 PASS accepted_values_cylinders_by_origin_origin__usa__europe__japan .... [[32mPASS[0m in 0.80s]
[0m07:15:37.433321 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:15:37.435589 [debug] [Thread-2  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:15:37.437428 [debug] [Thread-3  ]: Finished running node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:15:37.439133 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m07:15:37.440661 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:15:37.441947 [debug] [Thread-2  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:15:37.443081 [debug] [Thread-3  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:15:37.444343 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:15:37.445423 [info ] [Thread-4  ]: 7 of 11 START test not_null_mpg_standardized_displacement ...................... [RUN]
[0m07:15:37.446675 [info ] [Thread-2  ]: 8 of 11 START test not_null_mpg_standardized_model_year ........................ [RUN]
[0m07:15:37.447758 [info ] [Thread-3  ]: 9 of 11 START test not_null_mpg_standardized_mpg ............................... [RUN]
[0m07:15:37.448955 [info ] [Thread-1  ]: 10 of 11 START test not_null_mpg_standardized_origin ........................... [RUN]
[0m07:15:37.450099 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc, now test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0)
[0m07:15:37.451111 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae, now test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904)
[0m07:15:37.452027 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d, now test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231)
[0m07:15:37.453037 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2, now test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a)
[0m07:15:37.453965 [debug] [Thread-4  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:15:37.455036 [debug] [Thread-2  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:15:37.456254 [debug] [Thread-3  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:15:37.460237 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:15:37.482027 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0"
[0m07:15:37.518256 [debug] [Thread-4  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:15:37.489715 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904"
[0m07:15:37.503801 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231"
[0m07:15:37.529071 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a"
[0m07:15:37.535097 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0"
[0m07:15:37.538594 [debug] [Thread-2  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:15:37.540570 [debug] [Thread-3  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:15:37.542240 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:15:37.544318 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select displacement
from `clean`.`mpg_standardized`
where displacement is null



    ) dbt_internal_test...
[0m07:15:37.562000 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904"
[0m07:15:37.566746 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231"
[0m07:15:37.587367 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select model_year
from `clean`.`mpg_standardized`
where model_year is null



    ) dbt_internal_test...
[0m07:15:37.584285 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a"
[0m07:15:37.589721 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select mpg
from `clean`.`mpg_standardized`
where mpg is null



    ) dbt_internal_test...
[0m07:15:37.594230 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m07:15:37.596728 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select origin
from `clean`.`mpg_standardized`
where origin is null



    ) dbt_internal_test...
[0m07:15:37.603979 [info ] [Thread-4  ]: 7 of 11 PASS not_null_mpg_standardized_displacement ............................ [[32mPASS[0m in 0.15s]
[0m07:15:37.608922 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:15:37.610912 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:15:37.615956 [info ] [Thread-4  ]: 11 of 11 START test not_null_mpg_standardized_weight ........................... [RUN]
[0m07:15:37.623571 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m07:15:37.621133 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m07:15:37.613529 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m07:15:37.625073 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0, now test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05)
[0m07:15:37.638591 [info ] [Thread-1  ]: 10 of 11 PASS not_null_mpg_standardized_origin ................................. [[32mPASS[0m in 0.18s]
[0m07:15:37.630651 [info ] [Thread-2  ]: 8 of 11 PASS not_null_mpg_standardized_model_year .............................. [[32mPASS[0m in 0.18s]
[0m07:15:37.644526 [info ] [Thread-3  ]: 9 of 11 PASS not_null_mpg_standardized_mpg ..................................... [[32mPASS[0m in 0.19s]
[0m07:15:37.646171 [debug] [Thread-4  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:15:37.651303 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:15:37.653888 [debug] [Thread-2  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:15:37.656614 [debug] [Thread-3  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:15:37.670759 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05"
[0m07:15:37.677427 [debug] [Thread-4  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:15:37.685926 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05"
[0m07:15:37.688024 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select weight
from `clean`.`mpg_standardized`
where weight is null



    ) dbt_internal_test...
[0m07:15:37.700417 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:15:37.707925 [info ] [Thread-4  ]: 11 of 11 PASS not_null_mpg_standardized_weight ................................. [[32mPASS[0m in 0.08s]
[0m07:15:37.710433 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:15:37.717105 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:15:37.718231 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a' was left open.
[0m07:15:37.719264 [debug] [MainThread]: On test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a: Close
[0m07:15:37.720250 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m07:15:37.721223 [debug] [MainThread]: On list__mart: Close
[0m07:15:37.722220 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904' was left open.
[0m07:15:37.723234 [debug] [MainThread]: On test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904: Close
[0m07:15:37.725132 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231' was left open.
[0m07:15:37.726182 [debug] [MainThread]: On test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231: Close
[0m07:15:37.729441 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05' was left open.
[0m07:15:37.730542 [debug] [MainThread]: On test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05: Close
[0m07:15:37.732801 [info ] [MainThread]: 
[0m07:15:37.734345 [info ] [MainThread]: Finished running 11 data tests in 0 hours 0 minutes and 1.54 seconds (1.54s).
[0m07:15:37.748122 [debug] [MainThread]: Command end result
[0m07:15:37.856302 [info ] [MainThread]: 
[0m07:15:37.857709 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:15:37.858890 [info ] [MainThread]: 
[0m07:15:37.860107 [info ] [MainThread]: Done. PASS=11 WARN=0 ERROR=0 SKIP=0 TOTAL=11
[0m07:15:37.862440 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 3.4051766, "process_in_blocks": "1472", "process_kernel_time": 0.670017, "process_mem_max_rss": "113992", "process_out_blocks": "10832", "process_user_time": 6.008156}
[0m07:15:37.863996 [debug] [MainThread]: Command `dbt test` succeeded at 07:15:37.863591 after 3.41 seconds
[0m07:15:37.865228 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23f23e3310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23ef02ce20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23efb68bb0>]}
[0m07:15:37.866399 [debug] [MainThread]: Flushing usage events
[0m07:22:06.894340 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71666b3dae20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x716668046430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x716668046580>]}


============================== 07:22:06.904343 | aa7bb17e-81c6-4ab0-947c-d23470cb1b56 ==============================
[0m07:22:06.904343 [info ] [MainThread]: Running with dbt=1.8.9
[0m07:22:06.905472 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'write_json': 'True', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'version_check': 'True', 'debug': 'False', 'empty': 'None', 'profiles_dir': '.', 'log_path': '/workdir/transforms/01_mpg/logs', 'log_format': 'default', 'use_colors': 'True', 'target_path': 'None', 'partial_parse': 'True', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs generate --profiles-dir . --target local --static', 'no_print': 'None', 'static_parser': 'True', 'log_cache_events': 'False', 'warn_error': 'None'}
[0m07:22:07.194494 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'aa7bb17e-81c6-4ab0-947c-d23470cb1b56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71666a871910>]}
[0m07:22:07.290862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'aa7bb17e-81c6-4ab0-947c-d23470cb1b56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7166680150d0>]}
[0m07:22:07.292182 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m07:22:07.464184 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m07:22:07.821535 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:22:07.822530 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:22:07.942557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aa7bb17e-81c6-4ab0-947c-d23470cb1b56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7166677ec130>]}
[0m07:22:08.161959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aa7bb17e-81c6-4ab0-947c-d23470cb1b56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71666779aa30>]}
[0m07:22:08.162889 [info ] [MainThread]: Found 2 models, 11 data tests, 1 source, 471 macros
[0m07:22:08.163518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aa7bb17e-81c6-4ab0-947c-d23470cb1b56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71666779aac0>]}
[0m07:22:08.166536 [info ] [MainThread]: 
[0m07:22:08.167679 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m07:22:08.169299 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__clean'
[0m07:22:08.170683 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__mart'
[0m07:22:08.215733 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:22:08.219171 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:22:08.551503 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m07:22:08.557163 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:22:08.565617 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m07:22:08.577087 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:22:08.603557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aa7bb17e-81c6-4ab0-947c-d23470cb1b56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7166677dd310>]}
[0m07:22:08.604749 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m07:22:08.605436 [info ] [MainThread]: 
[0m07:22:08.619747 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m07:22:08.620756 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__clean, now model.ex_01_mpg.mpg_standardized)
[0m07:22:08.621537 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m07:22:08.640989 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m07:22:08.642352 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m07:22:08.643877 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m07:22:08.646853 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m07:22:08.647861 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:22:08.648741 [debug] [Thread-2  ]: Began running node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:22:08.649833 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:22:08.660365 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_mpg.mpg_standardized, now test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae)
[0m07:22:08.653649 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed'
[0m07:22:08.651548 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m07:22:08.661746 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:22:08.658739 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d'
[0m07:22:08.663459 [debug] [Thread-4  ]: Began compiling node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:22:08.664851 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m07:22:08.687482 [debug] [Thread-2  ]: Began compiling node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:22:08.690805 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae"
[0m07:22:08.721290 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed"
[0m07:22:08.722769 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m07:22:08.733528 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d"
[0m07:22:08.735345 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:22:08.736774 [debug] [Thread-4  ]: Began executing node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:22:08.737551 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m07:22:08.739563 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:22:08.741614 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:22:08.742711 [debug] [Thread-2  ]: Began executing node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:22:08.744732 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m07:22:08.746083 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:22:08.747202 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:22:08.749127 [debug] [Thread-2  ]: Finished running node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:22:08.750295 [debug] [Thread-3  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:22:08.751486 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae, now test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc)
[0m07:22:08.752247 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed, now test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0)
[0m07:22:08.753207 [debug] [Thread-2  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:22:08.754060 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly model.ex_01_mpg.cylinders_by_origin, now test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904)
[0m07:22:08.754908 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:22:08.755848 [debug] [Thread-4  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:22:08.756916 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d, now test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231)
[0m07:22:08.757644 [debug] [Thread-3  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:22:08.766433 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc"
[0m07:22:08.775133 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0"
[0m07:22:08.776301 [debug] [Thread-2  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:22:08.784186 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904"
[0m07:22:08.790866 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:22:08.795175 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231"
[0m07:22:08.796307 [debug] [Thread-4  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:22:08.798247 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:22:08.800734 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:22:08.802055 [debug] [Thread-3  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:22:08.803111 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:22:08.803912 [debug] [Thread-2  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:22:08.805091 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:22:08.806963 [debug] [Thread-3  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:22:08.807963 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc, now test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a)
[0m07:22:08.809569 [debug] [Thread-2  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:22:08.810807 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0, now test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05)
[0m07:22:08.811979 [debug] [Thread-3  ]: Began running node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m07:22:08.812958 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:22:08.813841 [debug] [Thread-2  ]: Began running node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m07:22:08.814845 [debug] [Thread-4  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:22:08.815970 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904, now test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2)
[0m07:22:08.824094 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a"
[0m07:22:08.825093 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231, now test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9)
[0m07:22:08.836486 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05"
[0m07:22:08.837669 [debug] [Thread-3  ]: Began compiling node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m07:22:08.838771 [debug] [Thread-2  ]: Began compiling node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m07:22:08.840091 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:22:08.847610 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2"
[0m07:22:08.854915 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9"
[0m07:22:08.856534 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:22:08.857560 [debug] [Thread-4  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:22:08.858752 [debug] [Thread-3  ]: Began executing node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m07:22:08.860311 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:22:08.861157 [debug] [Thread-2  ]: Began executing node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m07:22:08.862435 [debug] [Thread-3  ]: Finished running node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m07:22:08.864153 [debug] [Thread-2  ]: Finished running node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m07:22:08.866082 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:22:08.866689 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a' was left open.
[0m07:22:08.867216 [debug] [MainThread]: On test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a: Close
[0m07:22:08.867718 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m07:22:08.868192 [debug] [MainThread]: On list__mart: Close
[0m07:22:08.868678 [debug] [MainThread]: Connection 'test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2' was properly closed.
[0m07:22:08.869155 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05' was properly closed.
[0m07:22:08.869637 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9' was properly closed.
[0m07:22:08.875570 [debug] [MainThread]: Command end result
[0m07:22:09.164334 [debug] [MainThread]: Acquiring new clickhouse connection 'generate_catalog'
[0m07:22:09.164970 [info ] [MainThread]: Building catalog
[0m07:22:09.177682 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:22:09.238365 [debug] [MainThread]: dbt_clickhouse adapter: On generate_catalog: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "generate_catalog"} */
select
      '' as table_database,
      columns.database as table_schema,
      columns.table as table_name,
      if(tables.engine not in ('MaterializedView', 'View'), 'table', 'view') as table_type,
      nullIf(tables.comment, '') as table_comment,
      columns.name as column_name,
      columns.position as column_index,
      columns.type as column_type,
      nullIf(columns.comment, '') as column_comment,
      null as table_owner
    from system.columns as columns
    join system.tables as tables on tables.database = columns.database and tables.name = columns.table
    where database != 'system' and
    (columns.database = 'raw' or columns.database = 'clean' or columns.database = 'mart')
    order by columns.database, columns.table, columns.position...
[0m07:22:09.260312 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m07:22:09.441658 [info ] [MainThread]: Catalog written to /workdir/transforms/01_mpg/target/catalog.json
[0m07:22:09.443662 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 2.6425815, "process_in_blocks": "8", "process_kernel_time": 0.660671, "process_mem_max_rss": "116308", "process_out_blocks": "16688", "process_user_time": 5.426303}
[0m07:22:09.444502 [debug] [MainThread]: Command `dbt docs generate` succeeded at 07:22:09.444281 after 2.64 seconds
[0m07:22:09.445073 [debug] [MainThread]: Connection 'generate_catalog' was left open.
[0m07:22:09.445637 [debug] [MainThread]: On generate_catalog: Close
[0m07:22:09.446302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71666b3dae20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71666847af10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7166679f6970>]}
[0m07:22:09.446946 [debug] [MainThread]: Flushing usage events
[0m07:25:18.073045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x725ad7808dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x725ad445d460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x725ad445d5b0>]}


============================== 07:25:18.082716 | 3730345f-7a50-4630-80fa-1154cc0cdc44 ==============================
[0m07:25:18.082716 [info ] [MainThread]: Running with dbt=1.8.9
[0m07:25:18.083832 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'printer_width': '80', 'warn_error': 'None', 'debug': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'indirect_selection': 'eager', 'empty': 'None', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'write_json': 'True', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'no_print': 'None', 'invocation_command': 'dbt docs generate --static --profiles-dir . --target local', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'partial_parse': 'True', 'log_cache_events': 'False', 'log_format': 'default', 'version_check': 'True', 'profiles_dir': '.'}
[0m07:25:18.489310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3730345f-7a50-4630-80fa-1154cc0cdc44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x725ad439a790>]}
[0m07:25:18.617532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3730345f-7a50-4630-80fa-1154cc0cdc44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x725ad4326d00>]}
[0m07:25:18.618978 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m07:25:18.793561 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m07:25:19.064527 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:25:19.065547 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:25:19.170009 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3730345f-7a50-4630-80fa-1154cc0cdc44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x725ad3c04130>]}
[0m07:25:19.204406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3730345f-7a50-4630-80fa-1154cc0cdc44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x725ad3bbcbb0>]}
[0m07:25:19.205295 [info ] [MainThread]: Found 2 models, 11 data tests, 1 source, 471 macros
[0m07:25:19.206039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3730345f-7a50-4630-80fa-1154cc0cdc44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x725ad3bbcb20>]}
[0m07:25:19.208939 [info ] [MainThread]: 
[0m07:25:19.210046 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m07:25:19.211546 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__clean'
[0m07:25:19.212619 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__mart'
[0m07:25:19.254605 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:25:19.257367 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:25:19.531227 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m07:25:19.535846 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m07:25:19.538391 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:25:19.543239 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:25:19.575700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3730345f-7a50-4630-80fa-1154cc0cdc44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x725ad3be4e20>]}
[0m07:25:19.576740 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m07:25:19.577425 [info ] [MainThread]: 
[0m07:25:19.590596 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m07:25:19.591562 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__clean, now model.ex_01_mpg.mpg_standardized)
[0m07:25:19.592286 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m07:25:19.608992 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m07:25:19.610304 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m07:25:19.611828 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m07:25:19.613744 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m07:25:19.614760 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m07:25:19.615573 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:25:19.616398 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m07:25:19.617164 [debug] [Thread-2  ]: Began running node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:25:19.618210 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed'
[0m07:25:19.619021 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:25:19.624999 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m07:25:19.626204 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d'
[0m07:25:19.627118 [debug] [Thread-4  ]: Began compiling node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:25:19.627934 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_mpg.mpg_standardized, now test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae)
[0m07:25:19.628964 [debug] [Thread-2  ]: Began compiling node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:25:19.635083 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m07:25:19.650555 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed"
[0m07:25:19.651353 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:25:19.661083 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d"
[0m07:25:19.662793 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m07:25:19.680498 [debug] [Thread-4  ]: Began executing node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:25:19.686563 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae"
[0m07:25:19.689202 [debug] [Thread-3  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:25:19.691214 [debug] [Thread-2  ]: Began executing node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:25:19.694368 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:25:19.697282 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly model.ex_01_mpg.cylinders_by_origin, now test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc)
[0m07:25:19.698996 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:25:19.702837 [debug] [Thread-2  ]: Finished running node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:25:19.705103 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:25:19.706293 [debug] [Thread-3  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:25:19.708954 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:25:19.710873 [debug] [Thread-2  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:25:19.712247 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed, now test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0)
[0m07:25:19.727971 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc"
[0m07:25:19.729694 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:25:19.731076 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d, now test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904)
[0m07:25:19.732127 [debug] [Thread-4  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:25:19.733589 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae, now test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231)
[0m07:25:19.735071 [debug] [Thread-2  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:25:19.741683 [debug] [Thread-3  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:25:19.754336 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0"
[0m07:25:19.756264 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:25:19.767124 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904"
[0m07:25:19.769805 [debug] [Thread-3  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:25:19.779779 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231"
[0m07:25:19.781056 [debug] [Thread-4  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:25:19.782929 [debug] [Thread-3  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:25:19.784342 [debug] [Thread-2  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:25:19.786934 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:25:19.788609 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc, now test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a)
[0m07:25:19.789721 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:25:19.791637 [debug] [Thread-2  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:25:19.794873 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:25:19.796252 [debug] [Thread-3  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:25:19.798447 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:25:19.799859 [debug] [Thread-2  ]: Began running node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m07:25:19.800895 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0, now test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05)
[0m07:25:19.808211 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a"
[0m07:25:19.809450 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m07:25:19.810685 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904, now test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2)
[0m07:25:19.811634 [debug] [Thread-4  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:25:19.813017 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231, now test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9)
[0m07:25:19.814069 [debug] [Thread-2  ]: Began compiling node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m07:25:19.820169 [debug] [Thread-3  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:25:19.826597 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05"
[0m07:25:19.827799 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m07:25:19.835155 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2"
[0m07:25:19.837384 [debug] [Thread-3  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:25:19.845067 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9"
[0m07:25:19.846512 [debug] [Thread-4  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:25:19.848036 [debug] [Thread-2  ]: Began executing node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m07:25:19.850222 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:25:19.852208 [debug] [Thread-2  ]: Finished running node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m07:25:19.853056 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m07:25:19.855549 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m07:25:19.857588 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:25:19.858168 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9' was left open.
[0m07:25:19.858879 [debug] [MainThread]: On test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9: Close
[0m07:25:19.859408 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m07:25:19.859952 [debug] [MainThread]: On list__mart: Close
[0m07:25:19.860438 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a' was properly closed.
[0m07:25:19.860936 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05' was properly closed.
[0m07:25:19.861408 [debug] [MainThread]: Connection 'test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2' was properly closed.
[0m07:25:19.867522 [debug] [MainThread]: Command end result
[0m07:25:20.207769 [debug] [MainThread]: Acquiring new clickhouse connection 'generate_catalog'
[0m07:25:20.208485 [info ] [MainThread]: Building catalog
[0m07:25:20.221245 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:25:20.277807 [debug] [MainThread]: dbt_clickhouse adapter: On generate_catalog: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "generate_catalog"} */
select
      '' as table_database,
      columns.database as table_schema,
      columns.table as table_name,
      if(tables.engine not in ('MaterializedView', 'View'), 'table', 'view') as table_type,
      nullIf(tables.comment, '') as table_comment,
      columns.name as column_name,
      columns.position as column_index,
      columns.type as column_type,
      nullIf(columns.comment, '') as column_comment,
      null as table_owner
    from system.columns as columns
    join system.tables as tables on tables.database = columns.database and tables.name = columns.table
    where database != 'system' and
    (columns.database = 'clean' or columns.database = 'raw' or columns.database = 'mart')
    order by columns.database, columns.table, columns.position...
[0m07:25:20.295702 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m07:25:20.512283 [info ] [MainThread]: Catalog written to /workdir/transforms/01_mpg/target/catalog.json
[0m07:25:20.515335 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 2.5376587, "process_in_blocks": "0", "process_kernel_time": 0.626204, "process_mem_max_rss": "116276", "process_out_blocks": "16696", "process_user_time": 5.55381}
[0m07:25:20.517039 [debug] [MainThread]: Command `dbt docs generate` succeeded at 07:25:20.516619 after 2.54 seconds
[0m07:25:20.518165 [debug] [MainThread]: Connection 'generate_catalog' was left open.
[0m07:25:20.519230 [debug] [MainThread]: On generate_catalog: Close
[0m07:25:20.520563 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x725ad7808dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x725ad439a790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x725ad570e970>]}
[0m07:25:20.521811 [debug] [MainThread]: Flushing usage events
[0m07:33:47.613945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x714a48fcc310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x714a45c343a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x714a45c344f0>]}


============================== 07:33:47.623914 | 32d9fc76-a634-4892-9f7b-dcc65ca3ae0e ==============================
[0m07:33:47.623914 [info ] [MainThread]: Running with dbt=1.8.9
[0m07:33:47.624990 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'quiet': 'False', 'debug': 'False', 'partial_parse': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'empty': 'None', 'printer_width': '80', 'use_colors': 'True', 'indirect_selection': 'eager', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'warn_error': 'None', 'target_path': 'None', 'log_format': 'default', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_path': '/workdir/transforms/01_mpg/logs', 'introspect': 'True', 'cache_selected_only': 'False', 'invocation_command': 'dbt test --profiles-dir . --target local', 'fail_fast': 'False', 'profiles_dir': '.'}
[0m07:33:47.934850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '32d9fc76-a634-4892-9f7b-dcc65ca3ae0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x714a45d3af10>]}
[0m07:33:48.032475 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '32d9fc76-a634-4892-9f7b-dcc65ca3ae0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x714a45c7f910>]}
[0m07:33:48.033825 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m07:33:48.208393 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m07:33:48.467567 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:33:48.468227 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:33:48.573835 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '32d9fc76-a634-4892-9f7b-dcc65ca3ae0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x714a453d7130>]}
[0m07:33:48.839241 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '32d9fc76-a634-4892-9f7b-dcc65ca3ae0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x714a451dee20>]}
[0m07:33:48.840108 [info ] [MainThread]: Found 2 models, 11 data tests, 1 source, 471 macros
[0m07:33:48.840781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '32d9fc76-a634-4892-9f7b-dcc65ca3ae0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x714a45348a00>]}
[0m07:33:48.843916 [info ] [MainThread]: 
[0m07:33:48.845074 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m07:33:48.846779 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__clean'
[0m07:33:48.857056 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__mart'
[0m07:33:48.876897 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:33:48.884988 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:33:49.151538 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m07:33:49.157323 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:33:49.166691 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m07:33:49.174807 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:33:49.200790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '32d9fc76-a634-4892-9f7b-dcc65ca3ae0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x714a45137490>]}
[0m07:33:49.201826 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m07:33:49.202504 [info ] [MainThread]: 
[0m07:33:49.217159 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m07:33:49.218146 [debug] [Thread-2  ]: Began running node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:33:49.219107 [debug] [Thread-3  ]: Began running node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:33:49.221081 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m07:33:49.220252 [info ] [Thread-1  ]: 1 of 11 START test accepted_values_cylinders_by_origin_origin__usa__europe__japan  [RUN]
[0m07:33:49.222119 [info ] [Thread-2  ]: 2 of 11 START test accepted_values_mpg_standardized_cylinders__3__4__5__6__8 ... [RUN]
[0m07:33:49.223320 [info ] [Thread-3  ]: 3 of 11 START test accepted_values_mpg_standardized_origin__usa__europe__japan . [RUN]
[0m07:33:49.224555 [info ] [Thread-4  ]: 4 of 11 START test not_null_cylinders_by_origin_origin ......................... [RUN]
[0m07:33:49.225539 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__clean, now test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2)
[0m07:33:49.226820 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed'
[0m07:33:49.228160 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d'
[0m07:33:49.229238 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9'
[0m07:33:49.230087 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m07:33:49.231078 [debug] [Thread-2  ]: Began compiling node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:33:49.232142 [debug] [Thread-3  ]: Began compiling node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:33:49.232952 [debug] [Thread-4  ]: Began compiling node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m07:33:49.287918 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed"
[0m07:33:49.285220 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2"
[0m07:33:49.300874 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d"
[0m07:33:49.317317 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9"
[0m07:33:49.318950 [debug] [Thread-2  ]: Began executing node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:33:49.320108 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m07:33:49.326646 [debug] [Thread-3  ]: Began executing node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:33:49.341779 [debug] [Thread-4  ]: Began executing node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m07:33:49.446009 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed"
[0m07:33:49.455794 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d"
[0m07:33:49.463209 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2"
[0m07:33:49.467834 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9"
[0m07:33:49.469530 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m07:33:49.470632 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m07:33:49.472024 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        origin as value_field,
        count(*) as n_records

    from `mart`.`cylinders_by_origin`
    group by origin

)

select *
from all_values
where value_field not in (
    'usa','europe','japan'
)



    ) dbt_internal_test...
[0m07:33:49.474781 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m07:33:49.497379 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m07:33:49.527767 [info ] [Thread-1  ]: 1 of 11 PASS accepted_values_cylinders_by_origin_origin__usa__europe__japan .... [[32mPASS[0m in 0.30s]
[0m07:33:49.532497 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m07:33:49.534800 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:33:49.538409 [info ] [Thread-1  ]: 5 of 11 START test not_null_mpg_standardized_acceleration ...................... [RUN]
[0m07:33:49.545069 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2, now test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae)
[0m07:33:49.547270 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:33:49.555168 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae"
[0m07:33:49.556359 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:33:49.560799 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae"
[0m07:33:49.562257 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select acceleration
from `clean`.`mpg_standardized`
where acceleration is null



    ) dbt_internal_test...
[0m07:33:49.568069 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:33:49.571095 [info ] [Thread-1  ]: 5 of 11 PASS not_null_mpg_standardized_acceleration ............................ [[32mPASS[0m in 0.03s]
[0m07:33:49.575138 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:33:49.576839 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:33:49.579265 [info ] [Thread-1  ]: 6 of 11 START test not_null_mpg_standardized_cylinders ......................... [RUN]
[0m07:33:49.580560 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae, now test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc)
[0m07:33:49.582098 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:33:49.591779 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc"
[0m07:33:49.593353 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:33:49.598070 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc"
[0m07:33:49.601018 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select cylinders
from `clean`.`mpg_standardized`
where cylinders is null



    ) dbt_internal_test...
[0m07:33:49.609603 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:33:49.612191 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select origin
from `mart`.`cylinders_by_origin`
where origin is null



    ) dbt_internal_test...
[0m07:33:49.615217 [info ] [Thread-1  ]: 6 of 11 PASS not_null_mpg_standardized_cylinders ............................... [[32mPASS[0m in 0.03s]
[0m07:33:49.617946 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        origin as value_field,
        count(*) as n_records

    from `clean`.`mpg_standardized`
    group by origin

)

select *
from all_values
where value_field not in (
    'usa','europe','japan'
)



    ) dbt_internal_test...
[0m07:33:49.621824 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:33:49.627024 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:33:49.628923 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        cylinders as value_field,
        count(*) as n_records

    from `clean`.`mpg_standardized`
    group by cylinders

)

select *
from all_values
where value_field not in (
    '3','4','5','6','8'
)



    ) dbt_internal_test...
[0m07:33:49.630253 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:33:49.633670 [info ] [Thread-4  ]: 4 of 11 PASS not_null_cylinders_by_origin_origin ............................... [[32mPASS[0m in 0.40s]
[0m07:33:49.635372 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:33:49.637640 [info ] [Thread-1  ]: 7 of 11 START test not_null_mpg_standardized_displacement ...................... [RUN]
[0m07:33:49.639315 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m07:33:49.644377 [info ] [Thread-3  ]: 3 of 11 PASS accepted_values_mpg_standardized_origin__usa__europe__japan ....... [[32mPASS[0m in 0.42s]
[0m07:33:49.646252 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:33:49.647121 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc, now test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0)
[0m07:33:49.648092 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:33:49.649930 [debug] [Thread-3  ]: Finished running node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:33:49.653510 [info ] [Thread-2  ]: 2 of 11 PASS accepted_values_mpg_standardized_cylinders__3__4__5__6__8 ......... [[32mPASS[0m in 0.43s]
[0m07:33:49.654513 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:33:49.655300 [info ] [Thread-4  ]: 8 of 11 START test not_null_mpg_standardized_model_year ........................ [RUN]
[0m07:33:49.656279 [debug] [Thread-3  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:33:49.657702 [debug] [Thread-2  ]: Finished running node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:33:49.665049 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0"
[0m07:33:49.665977 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9, now test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904)
[0m07:33:49.666850 [info ] [Thread-3  ]: 9 of 11 START test not_null_mpg_standardized_mpg ............................... [RUN]
[0m07:33:49.668013 [debug] [Thread-2  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:33:49.669006 [debug] [Thread-4  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:33:49.669997 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d, now test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231)
[0m07:33:49.670985 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:33:49.671813 [info ] [Thread-2  ]: 10 of 11 START test not_null_mpg_standardized_origin ........................... [RUN]
[0m07:33:49.680513 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904"
[0m07:33:49.681686 [debug] [Thread-3  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:33:49.686545 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0"
[0m07:33:49.687519 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed, now test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a)
[0m07:33:49.699923 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231"
[0m07:33:49.701187 [debug] [Thread-4  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:33:49.702290 [debug] [Thread-2  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:33:49.703446 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select displacement
from `clean`.`mpg_standardized`
where displacement is null



    ) dbt_internal_test...
[0m07:33:49.708725 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904"
[0m07:33:49.715003 [debug] [Thread-3  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:33:49.717507 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a"
[0m07:33:49.724099 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231"
[0m07:33:49.725762 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:33:49.726848 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select model_year
from `clean`.`mpg_standardized`
where model_year is null



    ) dbt_internal_test...
[0m07:33:49.730293 [info ] [Thread-1  ]: 7 of 11 PASS not_null_mpg_standardized_displacement ............................ [[32mPASS[0m in 0.08s]
[0m07:33:49.731315 [debug] [Thread-2  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:33:49.732383 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select mpg
from `clean`.`mpg_standardized`
where mpg is null



    ) dbt_internal_test...
[0m07:33:49.734778 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:33:49.741535 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a"
[0m07:33:49.743081 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:33:49.745130 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:33:49.748791 [info ] [Thread-4  ]: 8 of 11 PASS not_null_mpg_standardized_model_year .............................. [[32mPASS[0m in 0.08s]
[0m07:33:49.749928 [info ] [Thread-1  ]: 11 of 11 START test not_null_mpg_standardized_weight ........................... [RUN]
[0m07:33:49.750854 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select origin
from `clean`.`mpg_standardized`
where origin is null



    ) dbt_internal_test...
[0m07:33:49.752210 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:33:49.754023 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:33:49.755327 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0, now test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05)
[0m07:33:49.759284 [info ] [Thread-3  ]: 9 of 11 PASS not_null_mpg_standardized_mpg ..................................... [[32mPASS[0m in 0.09s]
[0m07:33:49.760829 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:33:49.762247 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:33:49.763946 [debug] [Thread-3  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:33:49.771660 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05"
[0m07:33:49.774578 [info ] [Thread-2  ]: 10 of 11 PASS not_null_mpg_standardized_origin ................................. [[32mPASS[0m in 0.09s]
[0m07:33:49.776454 [debug] [Thread-2  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:33:49.777518 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:33:49.781912 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05"
[0m07:33:49.783424 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select weight
from `clean`.`mpg_standardized`
where weight is null



    ) dbt_internal_test...
[0m07:33:49.789491 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:33:49.792364 [info ] [Thread-1  ]: 11 of 11 PASS not_null_mpg_standardized_weight ................................. [[32mPASS[0m in 0.04s]
[0m07:33:49.793808 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:33:49.795751 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:33:49.796332 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05' was left open.
[0m07:33:49.796890 [debug] [MainThread]: On test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05: Close
[0m07:33:49.797377 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m07:33:49.798101 [debug] [MainThread]: On list__mart: Close
[0m07:33:49.798608 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a' was left open.
[0m07:33:49.799121 [debug] [MainThread]: On test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a: Close
[0m07:33:49.799710 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231' was left open.
[0m07:33:49.800220 [debug] [MainThread]: On test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231: Close
[0m07:33:49.800718 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904' was left open.
[0m07:33:49.801227 [debug] [MainThread]: On test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904: Close
[0m07:33:49.802268 [info ] [MainThread]: 
[0m07:33:49.802968 [info ] [MainThread]: Finished running 11 data tests in 0 hours 0 minutes and 0.96 seconds (0.96s).
[0m07:33:49.808126 [debug] [MainThread]: Command end result
[0m07:33:49.867533 [info ] [MainThread]: 
[0m07:33:49.868438 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:33:49.869048 [info ] [MainThread]: 
[0m07:33:49.869714 [info ] [MainThread]: Done. PASS=11 WARN=0 ERROR=0 SKIP=0 TOTAL=11
[0m07:33:49.871048 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 2.363543, "process_in_blocks": "1512", "process_kernel_time": 0.649188, "process_mem_max_rss": "111916", "process_out_blocks": "9824", "process_user_time": 5.323547}
[0m07:33:49.871792 [debug] [MainThread]: Command `dbt test` succeeded at 07:33:49.871597 after 2.36 seconds
[0m07:33:49.872400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x714a48fcc310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x714a45c7f910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x714a453489d0>]}
[0m07:33:49.873000 [debug] [MainThread]: Flushing usage events
[0m07:34:45.281852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75996fbc5e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75996c827430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75996c827580>]}


============================== 07:34:45.297670 | 02941955-2ebc-46a3-95ee-fc08c659acb1 ==============================
[0m07:34:45.297670 [info ] [MainThread]: Running with dbt=1.8.9
[0m07:34:45.299533 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'fail_fast': 'False', 'printer_width': '80', 'log_cache_events': 'False', 'empty': 'None', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'log_path': '/workdir/transforms/01_mpg/logs', 'introspect': 'True', 'profiles_dir': '.', 'cache_selected_only': 'False', 'log_format': 'default', 'version_check': 'True', 'use_experimental_parser': 'False', 'static_parser': 'True', 'partial_parse': 'True', 'invocation_command': 'dbt docs generate --static --profiles-dir . --target local', 'warn_error': 'None', 'debug': 'False', 'quiet': 'False', 'use_colors': 'True', 'target_path': 'None'}
[0m07:34:45.615759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '02941955-2ebc-46a3-95ee-fc08c659acb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75996c7e5ee0>]}
[0m07:34:45.722834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '02941955-2ebc-46a3-95ee-fc08c659acb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75996d3158b0>]}
[0m07:34:45.724993 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m07:34:46.018173 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m07:34:46.362225 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:34:46.363254 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:34:46.472054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '02941955-2ebc-46a3-95ee-fc08c659acb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75996bfde130>]}
[0m07:34:46.505843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '02941955-2ebc-46a3-95ee-fc08c659acb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75996bf8da30>]}
[0m07:34:46.506759 [info ] [MainThread]: Found 2 models, 11 data tests, 1 source, 471 macros
[0m07:34:46.507377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '02941955-2ebc-46a3-95ee-fc08c659acb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75996bf8dac0>]}
[0m07:34:46.510311 [info ] [MainThread]: 
[0m07:34:46.511596 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m07:34:46.513187 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__mart'
[0m07:34:46.514159 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__clean'
[0m07:34:46.551018 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:34:46.558739 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:34:46.814893 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m07:34:46.820708 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:46.827522 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m07:34:46.833777 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:34:46.874332 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '02941955-2ebc-46a3-95ee-fc08c659acb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75996bf8d970>]}
[0m07:34:46.875826 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m07:34:46.876770 [info ] [MainThread]: 
[0m07:34:46.894528 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m07:34:46.896001 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.mpg_standardized'
[0m07:34:46.897116 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m07:34:46.914025 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m07:34:46.915235 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m07:34:46.916828 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m07:34:46.918874 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m07:34:46.919962 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:34:46.921374 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'model.ex_01_mpg.cylinders_by_origin'
[0m07:34:46.922492 [debug] [Thread-2  ]: Began running node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:34:46.923266 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:34:46.924193 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed'
[0m07:34:46.925211 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m07:34:46.926495 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d'
[0m07:34:46.927263 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_mpg.mpg_standardized, now test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae)
[0m07:34:46.928115 [debug] [Thread-4  ]: Began compiling node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:34:46.937674 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m07:34:46.938922 [debug] [Thread-2  ]: Began compiling node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:34:46.939696 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:34:46.960041 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed"
[0m07:34:46.970005 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d"
[0m07:34:46.976346 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m07:34:46.987114 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae"
[0m07:34:46.989800 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m07:34:46.991185 [debug] [Thread-2  ]: Began executing node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:34:46.992277 [debug] [Thread-3  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:34:46.993287 [debug] [Thread-4  ]: Began executing node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:34:46.995176 [debug] [Thread-2  ]: Finished running node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m07:34:46.995966 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:34:46.996937 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly model.ex_01_mpg.cylinders_by_origin, now test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc)
[0m07:34:46.998660 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m07:34:46.999662 [debug] [Thread-2  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:34:47.001199 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m07:34:47.002370 [debug] [Thread-3  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:34:47.003551 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:34:47.004481 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d, now test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0)
[0m07:34:47.005347 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:34:47.017209 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc"
[0m07:34:47.018406 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed, now test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904)
[0m07:34:47.019292 [debug] [Thread-2  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:34:47.020098 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae, now test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231)
[0m07:34:47.021200 [debug] [Thread-4  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:34:47.027421 [debug] [Thread-3  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:34:47.030255 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0"
[0m07:34:47.031227 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:34:47.038376 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904"
[0m07:34:47.040439 [debug] [Thread-3  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m07:34:47.048362 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231"
[0m07:34:47.049768 [debug] [Thread-3  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:34:47.050882 [debug] [Thread-2  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:34:47.051877 [debug] [Thread-4  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:34:47.052876 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc, now test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a)
[0m07:34:47.054604 [debug] [Thread-2  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m07:34:47.056058 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m07:34:47.058782 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:34:47.059807 [debug] [Thread-3  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:34:47.060979 [debug] [Thread-2  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:34:47.061940 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m07:34:47.063498 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m07:34:47.075130 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a"
[0m07:34:47.076421 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0, now test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05)
[0m07:34:47.077287 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904, now test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2)
[0m07:34:47.078503 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m07:34:47.079502 [debug] [Thread-2  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:34:47.080401 [debug] [Thread-4  ]: Began compiling node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m07:34:47.081256 [debug] [Thread-3  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:34:47.082091 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231, now test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9)
[0m07:34:47.089336 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05"
[0m07:34:47.096842 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2"
[0m07:34:47.098428 [debug] [Thread-3  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m07:34:47.099331 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m07:34:47.100886 [debug] [Thread-2  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:34:47.101703 [debug] [Thread-4  ]: Began executing node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m07:34:47.108836 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9"
[0m07:34:47.110560 [debug] [Thread-2  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m07:34:47.112089 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m07:34:47.113588 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m07:34:47.115064 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m07:34:47.116543 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:34:47.117135 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m07:34:47.117721 [debug] [MainThread]: On list__mart: Close
[0m07:34:47.118315 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m07:34:47.118860 [debug] [MainThread]: On list__clean: Close
[0m07:34:47.119400 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9' was properly closed.
[0m07:34:47.120144 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a' was properly closed.
[0m07:34:47.120915 [debug] [MainThread]: Connection 'test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2' was properly closed.
[0m07:34:47.121625 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05' was properly closed.
[0m07:34:47.131358 [debug] [MainThread]: Command end result
[0m07:34:47.417586 [debug] [MainThread]: Acquiring new clickhouse connection 'generate_catalog'
[0m07:34:47.418252 [info ] [MainThread]: Building catalog
[0m07:34:47.431251 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:34:47.494760 [debug] [MainThread]: dbt_clickhouse adapter: On generate_catalog: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "generate_catalog"} */
select
      '' as table_database,
      columns.database as table_schema,
      columns.table as table_name,
      if(tables.engine not in ('MaterializedView', 'View'), 'table', 'view') as table_type,
      nullIf(tables.comment, '') as table_comment,
      columns.name as column_name,
      columns.position as column_index,
      columns.type as column_type,
      nullIf(columns.comment, '') as column_comment,
      null as table_owner
    from system.columns as columns
    join system.tables as tables on tables.database = columns.database and tables.name = columns.table
    where database != 'system' and
    (columns.database = 'clean' or columns.database = 'raw' or columns.database = 'mart')
    order by columns.database, columns.table, columns.position...
[0m07:34:47.514688 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m07:34:47.668701 [info ] [MainThread]: Catalog written to /workdir/transforms/01_mpg/target/catalog.json
[0m07:34:47.670671 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 2.4850957, "process_in_blocks": "0", "process_kernel_time": 0.686843, "process_mem_max_rss": "116168", "process_out_blocks": "16688", "process_user_time": 5.265131}
[0m07:34:47.671450 [debug] [MainThread]: Command `dbt docs generate` succeeded at 07:34:47.671262 after 2.49 seconds
[0m07:34:47.672073 [debug] [MainThread]: Connection 'generate_catalog' was left open.
[0m07:34:47.672665 [debug] [MainThread]: On generate_catalog: Close
[0m07:34:47.673369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75996fbc5e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75996d3158b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75996eb0ee80>]}
[0m07:34:47.674103 [debug] [MainThread]: Flushing usage events
[0m08:00:28.885789 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72890c643310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7289092a3b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7289092a39d0>]}


============================== 08:00:28.895815 | 27136fda-88e6-44fe-b805-9351c3dcee3a ==============================
[0m08:00:28.895815 [info ] [MainThread]: Running with dbt=1.8.9
[0m08:00:28.896974 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'log_cache_events': 'False', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/workdir/transforms/01_mpg/logs', 'static_parser': 'True', 'write_json': 'True', 'invocation_command': 'dbt build --profiles-dir . --target local', 'use_colors': 'True', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'warn_error': 'None', 'empty': 'False', 'profiles_dir': '.', 'quiet': 'False', 'no_print': 'None', 'indirect_selection': 'eager', 'printer_width': '80', 'partial_parse': 'True', 'target_path': 'None'}
[0m08:00:29.189836 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '27136fda-88e6-44fe-b805-9351c3dcee3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72890926da30>]}
[0m08:00:29.290547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '27136fda-88e6-44fe-b805-9351c3dcee3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7289093b14f0>]}
[0m08:00:29.292301 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m08:00:29.469075 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m08:00:29.768536 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 3 files added, 0 files changed.
[0m08:00:29.769649 [debug] [MainThread]: Partial parsing: added file: ex_01_mpg://models/mart/dq/dq_mpg_summary.sql
[0m08:00:29.770268 [debug] [MainThread]: Partial parsing: added file: ex_01_mpg://models/mart/dq/dq_mpg_anomalies.sql
[0m08:00:29.771006 [debug] [MainThread]: Partial parsing: added file: ex_01_mpg://models/mart/dq/schema.yml
[0m08:00:30.365890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '27136fda-88e6-44fe-b805-9351c3dcee3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7289075bdee0>]}
[0m08:00:30.636836 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '27136fda-88e6-44fe-b805-9351c3dcee3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72890750b940>]}
[0m08:00:30.637792 [info ] [MainThread]: Found 4 models, 11 data tests, 1 source, 471 macros
[0m08:00:30.642655 [info ] [MainThread]: 
[0m08:00:30.644091 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m08:00:30.656985 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m08:00:30.658376 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m08:00:30.705620 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:00:30.707080 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:00:31.050911 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m08:00:31.054996 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:00:31.070570 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m08:00:31.075729 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:00:31.090328 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m08:00:31.091370 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m08:00:31.103632 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m08:00:31.110537 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m08:00:31.116620 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:00:31.124547 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:00:31.137354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '27136fda-88e6-44fe-b805-9351c3dcee3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7289074cd4c0>]}
[0m08:00:31.138675 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m08:00:31.139412 [info ] [MainThread]: 
[0m08:00:31.153986 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m08:00:31.155136 [info ] [Thread-1  ]: 1 of 15 START sql table model `clean`.`mpg_standardized` ....................... [RUN]
[0m08:00:31.155993 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__clean, now model.ex_01_mpg.mpg_standardized)
[0m08:00:31.156748 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m08:00:31.174201 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m08:00:31.175457 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m08:00:31.270436 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64(mpg)          as mpg,
  toInt32(cylinders)      as cylinders,
  toFloat64(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32(weight)         as weight,
  toFloat64(acceleration) as acceleration,
  toInt32(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
-- where horsepower is not null
  -- and isFinite(horsepower)
          )
        
        ...
[0m08:00:31.411362 [debug] [Thread-1  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64(mpg)          as mpg,
  toInt32(cylinders)      as cylinders,
  toFloat64(displacement) as displacement,
  toFloat64OrNull(horsepower)   as horsepower,
  toInt32(weight)         as weight,
  toFloat64(acceleration) as acceleration,
  toInt32(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
-- where horsepower is not null
  -- and isFinite(horsepower)
          )
        
        
[0m08:00:31.421197 [debug] [Thread-1  ]: Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 43
   Code: 43. DB::Exception: Illegal type Float64 of first argument of function toFloat64OrNull. Conversion functions with postfix 'OrZero' or 'OrNull' should take String argument: While processing toFloat64(mpg) AS mpg, toInt32(cylinders) AS cylinders, toFloat64(displacement) AS displacement, toFloat64OrNull(horsepower) AS horsepower, toInt32(weight) AS weight, toFloat64(acceleration) AS acceleration, toInt32(model_year) AS model_year, trimBoth(origin) AS origin, trimBoth(name) AS make. (ILLEGAL_TYPE_OF_ARGUMENT) (version 23.12.6.19 (official build))
[0m08:00:31.423985 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27136fda-88e6-44fe-b805-9351c3dcee3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x728906a285b0>]}
[0m08:00:31.425308 [error] [Thread-1  ]: 1 of 15 ERROR creating sql table model `clean`.`mpg_standardized` .............. [[31mERROR[0m in 0.27s]
[0m08:00:31.426784 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m08:00:31.428974 [debug] [Thread-3  ]: Began running node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m08:00:31.429928 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m08:00:31.430994 [debug] [Thread-2  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m08:00:31.431992 [info ] [Thread-3  ]: 2 of 15 SKIP test accepted_values_mpg_standardized_cylinders__3__4__5__6__8 .... [[33mSKIP[0m]
[0m08:00:31.432844 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m08:00:31.433756 [info ] [Thread-4  ]: 3 of 15 SKIP test accepted_values_mpg_standardized_origin__usa__europe__japan .. [[33mSKIP[0m]
[0m08:00:31.434749 [info ] [Thread-2  ]: 4 of 15 SKIP test not_null_mpg_standardized_acceleration ....................... [[33mSKIP[0m]
[0m08:00:31.435804 [debug] [Thread-3  ]: Finished running node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m08:00:31.437022 [info ] [Thread-1  ]: 5 of 15 SKIP test not_null_mpg_standardized_cylinders .......................... [[33mSKIP[0m]
[0m08:00:31.438112 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m08:00:31.439173 [debug] [Thread-2  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m08:00:31.440297 [debug] [Thread-3  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m08:00:31.441511 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m08:00:31.442551 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m08:00:31.443701 [debug] [Thread-2  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m08:00:31.444794 [info ] [Thread-3  ]: 6 of 15 SKIP test not_null_mpg_standardized_displacement ....................... [[33mSKIP[0m]
[0m08:00:31.446172 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m08:00:31.447665 [info ] [Thread-4  ]: 7 of 15 SKIP test not_null_mpg_standardized_model_year ......................... [[33mSKIP[0m]
[0m08:00:31.449053 [info ] [Thread-2  ]: 8 of 15 SKIP test not_null_mpg_standardized_mpg ................................ [[33mSKIP[0m]
[0m08:00:31.450561 [debug] [Thread-3  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m08:00:31.451803 [info ] [Thread-1  ]: 9 of 15 SKIP test not_null_mpg_standardized_origin ............................. [[33mSKIP[0m]
[0m08:00:31.453357 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m08:00:31.454782 [debug] [Thread-2  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m08:00:31.456154 [debug] [Thread-3  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m08:00:31.457529 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m08:00:31.459414 [info ] [Thread-3  ]: 10 of 15 SKIP test not_null_mpg_standardized_weight ............................ [[33mSKIP[0m]
[0m08:00:31.461016 [debug] [Thread-3  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m08:00:31.462680 [debug] [Thread-4  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m08:00:31.463886 [debug] [Thread-2  ]: Began running node model.ex_01_mpg.dq_mpg_anomalies
[0m08:00:31.465230 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.dq_mpg_summary
[0m08:00:31.466540 [info ] [Thread-4  ]: 11 of 15 SKIP relation mart.cylinders_by_origin ................................ [[33mSKIP[0m]
[0m08:00:31.467822 [info ] [Thread-2  ]: 12 of 15 SKIP relation mart.dq_mpg_anomalies ................................... [[33mSKIP[0m]
[0m08:00:31.469202 [info ] [Thread-1  ]: 13 of 15 SKIP relation mart.dq_mpg_summary ..................................... [[33mSKIP[0m]
[0m08:00:31.470796 [debug] [Thread-4  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m08:00:31.471904 [debug] [Thread-2  ]: Finished running node model.ex_01_mpg.dq_mpg_anomalies
[0m08:00:31.472973 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.dq_mpg_summary
[0m08:00:31.474661 [debug] [Thread-3  ]: Began running node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m08:00:31.475827 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m08:00:31.477388 [info ] [Thread-3  ]: 14 of 15 SKIP test accepted_values_cylinders_by_origin_origin__usa__europe__japan  [[33mSKIP[0m]
[0m08:00:31.478841 [info ] [Thread-4  ]: 15 of 15 SKIP test not_null_cylinders_by_origin_origin ......................... [[33mSKIP[0m]
[0m08:00:31.480305 [debug] [Thread-3  ]: Finished running node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m08:00:31.481664 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m08:00:31.484848 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:00:31.485668 [debug] [MainThread]: Connection 'model.ex_01_mpg.mpg_standardized' was left open.
[0m08:00:31.486310 [debug] [MainThread]: On model.ex_01_mpg.mpg_standardized: Close
[0m08:00:31.486913 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m08:00:31.487458 [debug] [MainThread]: On list__mart: Close
[0m08:00:31.488475 [info ] [MainThread]: 
[0m08:00:31.489303 [info ] [MainThread]: Finished running 1 table model, 11 data tests, 3 view models in 0 hours 0 minutes and 0.84 seconds (0.84s).
[0m08:00:31.492098 [debug] [MainThread]: Command end result
[0m08:00:31.555702 [info ] [MainThread]: 
[0m08:00:31.556589 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m08:00:31.557208 [info ] [MainThread]: 
[0m08:00:31.558031 [error] [MainThread]:   Database Error in model mpg_standardized (models/clean/mpg_standardized.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 43
   Code: 43. DB::Exception: Illegal type Float64 of first argument of function toFloat64OrNull. Conversion functions with postfix 'OrZero' or 'OrNull' should take String argument: While processing toFloat64(mpg) AS mpg, toInt32(cylinders) AS cylinders, toFloat64(displacement) AS displacement, toFloat64OrNull(horsepower) AS horsepower, toInt32(weight) AS weight, toFloat64(acceleration) AS acceleration, toInt32(model_year) AS model_year, trimBoth(origin) AS origin, trimBoth(name) AS make. (ILLEGAL_TYPE_OF_ARGUMENT) (version 23.12.6.19 (official build))
[0m08:00:31.558706 [info ] [MainThread]: 
[0m08:00:31.559307 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=14 TOTAL=15
[0m08:00:31.560656 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 2.77012, "process_in_blocks": "608", "process_kernel_time": 0.677834, "process_mem_max_rss": "115040", "process_out_blocks": "10704", "process_user_time": 5.917288}
[0m08:00:31.561404 [debug] [MainThread]: Command `dbt build` failed at 08:00:31.561216 after 2.77 seconds
[0m08:00:31.562073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72890c643310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x728908a8bd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x728909191520>]}
[0m08:00:31.562804 [debug] [MainThread]: Flushing usage events
[0m08:03:34.958454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a3fc9b54dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a3fc67b8430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a3fc67b8580>]}


============================== 08:03:34.968606 | e27e2702-cdb7-458b-89b8-e71c54a7b088 ==============================
[0m08:03:34.968606 [info ] [MainThread]: Running with dbt=1.8.9
[0m08:03:34.969818 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'target_path': 'None', 'cache_selected_only': 'False', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/workdir/transforms/01_mpg/logs', 'quiet': 'False', 'write_json': 'True', 'debug': 'False', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'use_colors': 'True', 'printer_width': '80', 'introspect': 'True', 'indirect_selection': 'eager', 'profiles_dir': '.', 'no_print': 'None', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'empty': 'False', 'invocation_command': 'dbt build --profiles-dir . --target local', 'version_check': 'True', 'static_parser': 'True', 'log_cache_events': 'False'}
[0m08:03:35.265592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e27e2702-cdb7-458b-89b8-e71c54a7b088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a3fc677bee0>]}
[0m08:03:35.370064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e27e2702-cdb7-458b-89b8-e71c54a7b088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a3fc6850460>]}
[0m08:03:35.371532 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m08:03:35.539690 [debug] [MainThread]: checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979, vars: {}, profile: , target: local, version: 1.8.9
[0m08:03:35.815055 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:03:35.816284 [debug] [MainThread]: Partial parsing: updated file: ex_01_mpg://models/clean/mpg_standardized.sql
[0m08:03:36.202575 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m08:03:36.203514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'e27e2702-cdb7-458b-89b8-e71c54a7b088', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a3fc6001130>]}
[0m08:03:36.592166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e27e2702-cdb7-458b-89b8-e71c54a7b088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a3fc48e3f40>]}
[0m08:03:36.842754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e27e2702-cdb7-458b-89b8-e71c54a7b088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a3fc46e2550>]}
[0m08:03:36.843692 [info ] [MainThread]: Found 4 models, 11 data tests, 1 source, 471 macros
[0m08:03:36.848098 [info ] [MainThread]: 
[0m08:03:36.849520 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m08:03:36.862237 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m08:03:36.873882 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m08:03:36.884022 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:03:36.888929 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:03:37.211419 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m08:03:37.214948 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:03:37.223743 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m08:03:37.229211 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:03:37.248483 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m08:03:37.249826 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m08:03:37.265610 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m08:03:37.270755 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m08:03:37.279929 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:03:37.282663 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:03:37.308345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e27e2702-cdb7-458b-89b8-e71c54a7b088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a3fc6283910>]}
[0m08:03:37.310108 [info ] [MainThread]: Concurrency: 4 threads (target='local')
[0m08:03:37.311154 [info ] [MainThread]: 
[0m08:03:37.325178 [debug] [Thread-1  ]: Began running node model.ex_01_mpg.mpg_standardized
[0m08:03:37.326479 [info ] [Thread-1  ]: 1 of 15 START sql table model `clean`.`mpg_standardized` ....................... [RUN]
[0m08:03:37.327563 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__mart, now model.ex_01_mpg.mpg_standardized)
[0m08:03:37.328400 [debug] [Thread-1  ]: Began compiling node model.ex_01_mpg.mpg_standardized
[0m08:03:37.345874 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_mpg.mpg_standardized"
[0m08:03:37.347229 [debug] [Thread-1  ]: Began executing node model.ex_01_mpg.mpg_standardized
[0m08:03:37.442217 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

            

    
        create table `clean`.`mpg_standardized__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64(mpg)          as mpg,
  toInt32(cylinders)      as cylinders,
  toFloat64(displacement) as displacement,
  CAST(horsepower AS Nullable(Float64)) as horsepower,
  toInt32(weight)         as weight,
  toFloat64(acceleration) as acceleration,
  toInt32(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
-- where horsepower is not null
  -- and isFinite(horsepower)
          )
        
        ...
[0m08:03:37.478049 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m08:03:37.494889 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    select name, type from system.columns where table = 'mpg_standardized__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m08:03:37.500984 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:03:37.507409 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_mpg.mpg_standardized"
[0m08:03:37.508961 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

  
    
    
    
        
         


        insert into `clean`.`mpg_standardized__dbt_backup`
        ("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "make")

-- Source columns are already Nullable with correct types.
-- Keep them as-is to preserve nullability and avoid insert errors.

select
  toFloat64(mpg)          as mpg,
  toInt32(cylinders)      as cylinders,
  toFloat64(displacement) as displacement,
  CAST(horsepower AS Nullable(Float64)) as horsepower,
  toInt32(weight)         as weight,
  toFloat64(acceleration) as acceleration,
  toInt32(model_year)     as model_year,
  trim(origin)                  as origin,
  trim(name)                    as make
from `raw`.`autompg___cars`
-- where horsepower is not null
  -- and isFinite(horsepower)
  ...
[0m08:03:37.538045 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m08:03:37.546996 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */
EXCHANGE TABLES `clean`.`mpg_standardized__dbt_backup` AND `clean`.`mpg_standardized` 
  
  ...
[0m08:03:37.552771 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:03:37.601355 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_mpg.mpg_standardized: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.mpg_standardized"} */

    drop table if exists `clean`.`mpg_standardized__dbt_backup` 
  ...
[0m08:03:37.604969 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:03:37.611183 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e27e2702-cdb7-458b-89b8-e71c54a7b088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a3fc9064be0>]}
[0m08:03:37.612524 [info ] [Thread-1  ]: 1 of 15 OK created sql table model `clean`.`mpg_standardized` .................. [[32mOK[0m in 0.28s]
[0m08:03:37.614013 [debug] [Thread-1  ]: Finished running node model.ex_01_mpg.mpg_standardized
[0m08:03:37.615881 [debug] [Thread-3  ]: Began running node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m08:03:37.616838 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m08:03:37.618021 [info ] [Thread-3  ]: 2 of 15 START test accepted_values_mpg_standardized_cylinders__3__4__5__6__8 ... [RUN]
[0m08:03:37.618969 [debug] [Thread-2  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m08:03:37.619979 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m08:03:37.621092 [info ] [Thread-4  ]: 3 of 15 START test accepted_values_mpg_standardized_origin__usa__europe__japan . [RUN]
[0m08:03:37.622311 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed'
[0m08:03:37.623167 [info ] [Thread-2  ]: 4 of 15 START test not_null_mpg_standardized_acceleration ...................... [RUN]
[0m08:03:37.624292 [info ] [Thread-1  ]: 5 of 15 START test not_null_mpg_standardized_cylinders ......................... [RUN]
[0m08:03:37.625747 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d'
[0m08:03:37.626628 [debug] [Thread-3  ]: Began compiling node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m08:03:37.627583 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae'
[0m08:03:37.628440 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_mpg.mpg_standardized, now test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc)
[0m08:03:37.629522 [debug] [Thread-4  ]: Began compiling node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m08:03:37.636713 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed"
[0m08:03:37.637620 [debug] [Thread-2  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m08:03:37.638679 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m08:03:37.645934 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d"
[0m08:03:37.662017 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae"
[0m08:03:37.668209 [debug] [Thread-3  ]: Began executing node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m08:03:37.675062 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc"
[0m08:03:37.687005 [debug] [Thread-4  ]: Began executing node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m08:03:37.693403 [debug] [Thread-2  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m08:03:37.711202 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed"
[0m08:03:37.722682 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m08:03:37.721978 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d"
[0m08:03:37.730819 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae"
[0m08:03:37.735747 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc"
[0m08:03:37.736972 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m08:03:37.738145 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m08:03:37.739199 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m08:03:37.741851 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select cylinders
from `clean`.`mpg_standardized`
where cylinders is null



    ) dbt_internal_test...
[0m08:03:37.770167 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m08:03:37.781083 [info ] [Thread-1  ]: 5 of 15 PASS not_null_mpg_standardized_cylinders ............................... [[32mPASS[0m in 0.15s]
[0m08:03:37.792002 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc
[0m08:03:37.798292 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m08:03:37.801784 [info ] [Thread-1  ]: 6 of 15 START test not_null_mpg_standardized_displacement ...................... [RUN]
[0m08:03:37.804815 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_cylinders.b01f130acc, now test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0)
[0m08:03:37.808472 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m08:03:37.825937 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0"
[0m08:03:37.828946 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m08:03:37.835100 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0"
[0m08:03:37.836457 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select displacement
from `clean`.`mpg_standardized`
where displacement is null



    ) dbt_internal_test...
[0m08:03:37.842873 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:03:37.846249 [info ] [Thread-1  ]: 6 of 15 PASS not_null_mpg_standardized_displacement ............................ [[32mPASS[0m in 0.04s]
[0m08:03:37.850250 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0
[0m08:03:37.851957 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m08:03:37.853248 [info ] [Thread-1  ]: 7 of 15 START test not_null_mpg_standardized_model_year ........................ [RUN]
[0m08:03:37.854690 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_displacement.68b13a28b0, now test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904)
[0m08:03:37.855659 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m08:03:37.864919 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904"
[0m08:03:37.871033 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m08:03:37.877854 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904"
[0m08:03:37.884216 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        cylinders as value_field,
        count(*) as n_records

    from `clean`.`mpg_standardized`
    group by cylinders

)

select *
from all_values
where value_field not in (
    '3','4','5','6','8'
)



    ) dbt_internal_test...
[0m08:03:37.886914 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select model_year
from `clean`.`mpg_standardized`
where model_year is null



    ) dbt_internal_test...
[0m08:03:37.888423 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select acceleration
from `clean`.`mpg_standardized`
where acceleration is null



    ) dbt_internal_test...
[0m08:03:37.891518 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        origin as value_field,
        count(*) as n_records

    from `clean`.`mpg_standardized`
    group by origin

)

select *
from all_values
where value_field not in (
    'usa','europe','japan'
)



    ) dbt_internal_test...
[0m08:03:37.897551 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:03:37.901043 [info ] [Thread-3  ]: 2 of 15 PASS accepted_values_mpg_standardized_cylinders__3__4__5__6__8 ......... [[32mPASS[0m in 0.28s]
[0m08:03:37.902824 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:03:37.904068 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:03:37.905411 [debug] [Thread-3  ]: Finished running node test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed
[0m08:03:37.906783 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:03:37.909851 [info ] [Thread-2  ]: 4 of 15 PASS not_null_mpg_standardized_acceleration ............................ [[32mPASS[0m in 0.28s]
[0m08:03:37.913215 [info ] [Thread-1  ]: 7 of 15 PASS not_null_mpg_standardized_model_year .............................. [[32mPASS[0m in 0.06s]
[0m08:03:37.914321 [debug] [Thread-3  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m08:03:37.917492 [info ] [Thread-4  ]: 3 of 15 PASS accepted_values_mpg_standardized_origin__usa__europe__japan ....... [[32mPASS[0m in 0.29s]
[0m08:03:37.919009 [debug] [Thread-2  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae
[0m08:03:37.920375 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904
[0m08:03:37.921472 [info ] [Thread-3  ]: 8 of 15 START test not_null_mpg_standardized_mpg ............................... [RUN]
[0m08:03:37.922885 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d
[0m08:03:37.923981 [debug] [Thread-2  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m08:03:37.924981 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m08:03:37.925981 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.accepted_values_mpg_standardized_cylinders__3__4__5__6__8.e4e8ce25ed, now test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231)
[0m08:03:37.927084 [info ] [Thread-2  ]: 9 of 15 START test not_null_mpg_standardized_origin ............................ [RUN]
[0m08:03:37.928024 [info ] [Thread-1  ]: 10 of 15 START test not_null_mpg_standardized_weight ........................... [RUN]
[0m08:03:37.928889 [debug] [Thread-3  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m08:03:37.929656 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_acceleration.9ff1644aae, now test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a)
[0m08:03:37.930403 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_model_year.ca032ab904, now test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05)
[0m08:03:37.937615 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231"
[0m08:03:37.938570 [debug] [Thread-2  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m08:03:37.939342 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m08:03:37.946762 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a"
[0m08:03:37.952845 [debug] [Thread-3  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m08:03:37.955097 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05"
[0m08:03:37.961331 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231"
[0m08:03:37.962930 [debug] [Thread-2  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m08:03:37.967124 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a"
[0m08:03:37.967994 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m08:03:37.969389 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select mpg
from `clean`.`mpg_standardized`
where mpg is null



    ) dbt_internal_test...
[0m08:03:37.974172 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05"
[0m08:03:37.977160 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select origin
from `clean`.`mpg_standardized`
where origin is null



    ) dbt_internal_test...
[0m08:03:37.978215 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select weight
from `clean`.`mpg_standardized`
where weight is null



    ) dbt_internal_test...
[0m08:03:37.983006 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:03:37.986660 [info ] [Thread-3  ]: 8 of 15 PASS not_null_mpg_standardized_mpg ..................................... [[32mPASS[0m in 0.06s]
[0m08:03:37.988564 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:03:37.990056 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:03:37.991418 [debug] [Thread-3  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231
[0m08:03:37.994765 [info ] [Thread-2  ]: 9 of 15 PASS not_null_mpg_standardized_origin .................................. [[32mPASS[0m in 0.06s]
[0m08:03:37.998103 [info ] [Thread-1  ]: 10 of 15 PASS not_null_mpg_standardized_weight ................................. [[32mPASS[0m in 0.07s]
[0m08:03:38.000117 [debug] [Thread-2  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a
[0m08:03:38.002530 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05
[0m08:03:38.004804 [debug] [Thread-4  ]: Began running node model.ex_01_mpg.cylinders_by_origin
[0m08:03:38.005606 [debug] [Thread-3  ]: Began running node model.ex_01_mpg.dq_mpg_anomalies
[0m08:03:38.007510 [debug] [Thread-2  ]: Began running node model.ex_01_mpg.dq_mpg_summary
[0m08:03:38.006653 [info ] [Thread-4  ]: 11 of 15 START sql view model `mart`.`cylinders_by_origin` ..................... [RUN]
[0m08:03:38.008580 [info ] [Thread-3  ]: 12 of 15 START sql view model `mart`.`dq_mpg_anomalies` ........................ [RUN]
[0m08:03:38.009792 [info ] [Thread-2  ]: 13 of 15 START sql view model `mart`.`dq_mpg_summary` .......................... [RUN]
[0m08:03:38.011180 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.accepted_values_mpg_standardized_origin__usa__europe__japan.59743c9a2d, now model.ex_01_mpg.cylinders_by_origin)
[0m08:03:38.012542 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_mpg.3592ad3231, now model.ex_01_mpg.dq_mpg_anomalies)
[0m08:03:38.013659 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_origin.b3c0df5b4a, now model.ex_01_mpg.dq_mpg_summary)
[0m08:03:38.014844 [debug] [Thread-4  ]: Began compiling node model.ex_01_mpg.cylinders_by_origin
[0m08:03:38.015653 [debug] [Thread-3  ]: Began compiling node model.ex_01_mpg.dq_mpg_anomalies
[0m08:03:38.016617 [debug] [Thread-2  ]: Began compiling node model.ex_01_mpg.dq_mpg_summary
[0m08:03:38.023263 [debug] [Thread-4  ]: Writing injected SQL for node "model.ex_01_mpg.cylinders_by_origin"
[0m08:03:38.029231 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_mpg.dq_mpg_anomalies"
[0m08:03:38.040777 [debug] [Thread-2  ]: Writing injected SQL for node "model.ex_01_mpg.dq_mpg_summary"
[0m08:03:38.042633 [debug] [Thread-4  ]: Began executing node model.ex_01_mpg.cylinders_by_origin
[0m08:03:38.088709 [debug] [Thread-2  ]: Began executing node model.ex_01_mpg.dq_mpg_summary
[0m08:03:38.096045 [debug] [Thread-4  ]: Writing runtime sql for node "model.ex_01_mpg.cylinders_by_origin"
[0m08:03:38.104085 [debug] [Thread-2  ]: Creating new relation dq_mpg_summary
[0m08:03:38.105181 [debug] [Thread-3  ]: Began executing node model.ex_01_mpg.dq_mpg_anomalies
[0m08:03:38.107593 [debug] [Thread-2  ]: Writing runtime sql for node "model.ex_01_mpg.dq_mpg_summary"
[0m08:03:38.112317 [debug] [Thread-3  ]: Creating new relation dq_mpg_anomalies
[0m08:03:38.113344 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */


  create view `mart`.`cylinders_by_origin__dbt_tmp` 
  
    
    
  as (
    

select
  origin,
  avg(cylinders) as avg_cylinders,
  count()        as n
from `clean`.`mpg_standardized`
group by origin
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m08:03:38.115160 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_mpg.dq_mpg_anomalies"
[0m08:03:38.116371 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_mpg.dq_mpg_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.dq_mpg_summary"} */


  create view `mart`.`dq_mpg_summary` 
  
    
    
  as (
    

-- Inputs:
--   raw table:   raw.autompg___cars           (as loaded by dlt)
--   clean model: `clean`.`mpg_standardized` (typed/trimmed)

with src as (
  select * from `raw`.`autompg___cars`
),
cln as (
  select * from `clean`.`mpg_standardized`
),

counts as (
  select
    (select count() from src)  as row_count_raw,
    (select count() from cln)  as row_count_clean
),
nulls as (
  select
    round(100.0 * countIf(horsepower is null) / nullif(count(),0), 2) as pct_null_horsepower
  from cln
),
domains as (
  select
    -- cylinders domain: {3,4,5,6,8}
    countIf(cylinders not in (3,4,5,6,8)) as invalid_cylinders,
    -- origin domain: {"usa","europe","japan"} (case-insensitive trim assumed in clean)
    countIf(lower(origin) not in ('usa','europe','japan')) as invalid_origin
  from cln
),
bounds as (
  select
    countIf(mpg <= 0)           as nonpositive_mpg,
    countIf(displacement <= 0)  as nonpositive_displacement,
    countIf(weight <= 0)        as nonpositive_weight,
    countIf(acceleration <= 0)  as nonpositive_acceleration,
    -- UCI Auto MPG years are 70..82 (1970..1982) in this dataset
    countIf(model_year < 70 or model_year > 82) as out_of_range_model_year
  from cln
),
joined as (
  select
    counts.row_count_raw,
    counts.row_count_clean,
    (counts.row_count_raw - counts.row_count_clean) as dropped_rows,

    nulls.pct_null_horsepower,

    domains.invalid_cylinders,
    domains.invalid_origin,

    bounds.nonpositive_mpg,
    bounds.nonpositive_displacement,
    bounds.nonpositive_weight,
    bounds.nonpositive_acceleration,
    bounds.out_of_range_model_year
  from counts
  cross join nulls
  cross join domains
  cross join bounds
)

select * from joined
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m08:03:38.120729 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_mpg.dq_mpg_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.dq_mpg_anomalies"} */


  create view `mart`.`dq_mpg_anomalies` 
  
    
    
  as (
    

-- Row-level drilldown of “obviously wrong” records based on simple rules.
-- LIMIT for demo-friendliness; remove in real pipelines.

with cln as (
  select * from `clean`.`mpg_standardized`
),
violations as (
  select
    -- NOTE: this dataset has no native PK; include a synthetic row_number if needed.
    -- ClickHouse: use monotonicallyIncreasingId() isn't stable; we’ll show columns directly.
    mpg, cylinders, displacement, horsepower, weight, acceleration, model_year, origin, make,

    multiIf(
      mpg <= 0,                      'nonpositive_mpg',
      displacement <= 0,             'nonpositive_displacement',
      weight <= 0,                   'nonpositive_weight',
      acceleration <= 0,             'nonpositive_acceleration',
      cylinders not in (3,4,5,6,8),  'invalid_cylinders',
      lower(origin) not in ('usa','europe','japan'), 'invalid_origin',
      model_year < 70 or model_year > 82, 'out_of_range_model_year',
      horsepower is null,            'null_horsepower',
      'ok'
    ) as dq_issue
  from cln
)
select *
from violations
where dq_issue != 'ok'
limit 50
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m08:03:38.146045 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m08:03:38.159129 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m08:03:38.162144 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:03:38.164211 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin` to `mart`.`cylinders_by_origin__dbt_backup` 
  
  ...
[0m08:03:38.167080 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:03:38.173408 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin` 
  
  ...
[0m08:03:38.176560 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:03:38.178644 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    rename table `mart`.`cylinders_by_origin__dbt_tmp` to `mart`.`cylinders_by_origin` 
  
  ...
[0m08:03:38.182131 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:03:38.190852 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_mpg.cylinders_by_origin: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "model.ex_01_mpg.cylinders_by_origin"} */

    drop table if exists `mart`.`cylinders_by_origin__dbt_backup` 
  ...
[0m08:03:38.194028 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:03:38.196604 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e27e2702-cdb7-458b-89b8-e71c54a7b088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a3fc4cba460>]}
[0m08:03:38.197774 [info ] [Thread-4  ]: 11 of 15 OK created sql view model `mart`.`cylinders_by_origin` ................ [[32mOK[0m in 0.19s]
[0m08:03:38.199269 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.08 seconds
[0m08:03:38.200742 [debug] [Thread-4  ]: Finished running node model.ex_01_mpg.cylinders_by_origin
[0m08:03:38.205636 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e27e2702-cdb7-458b-89b8-e71c54a7b088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a3fc367e400>]}
[0m08:03:38.208137 [info ] [Thread-3  ]: 12 of 15 OK created sql view model `mart`.`dq_mpg_anomalies` ................... [[32mOK[0m in 0.19s]
[0m08:03:38.209644 [debug] [Thread-1  ]: Began running node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m08:03:38.210701 [debug] [Thread-4  ]: Began running node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m08:03:38.212049 [debug] [Thread-3  ]: Finished running node model.ex_01_mpg.dq_mpg_anomalies
[0m08:03:38.213211 [info ] [Thread-1  ]: 14 of 15 START test accepted_values_cylinders_by_origin_origin__usa__europe__japan  [RUN]
[0m08:03:38.214577 [info ] [Thread-4  ]: 15 of 15 START test not_null_cylinders_by_origin_origin ........................ [RUN]
[0m08:03:38.216038 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_mpg.not_null_mpg_standardized_weight.5050df3d05, now test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2)
[0m08:03:38.217144 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly model.ex_01_mpg.cylinders_by_origin, now test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9)
[0m08:03:38.218110 [debug] [Thread-1  ]: Began compiling node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m08:03:38.219299 [debug] [Thread-4  ]: Began compiling node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m08:03:38.234323 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2"
[0m08:03:38.241769 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9"
[0m08:03:38.243562 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.12 seconds
[0m08:03:38.249073 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e27e2702-cdb7-458b-89b8-e71c54a7b088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a3fc3684b50>]}
[0m08:03:38.250150 [debug] [Thread-1  ]: Began executing node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m08:03:38.251635 [info ] [Thread-2  ]: 13 of 15 OK created sql view model `mart`.`dq_mpg_summary` ..................... [[32mOK[0m in 0.24s]
[0m08:03:38.256773 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2"
[0m08:03:38.257692 [debug] [Thread-4  ]: Began executing node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m08:03:38.258951 [debug] [Thread-2  ]: Finished running node model.ex_01_mpg.dq_mpg_summary
[0m08:03:38.263736 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9"
[0m08:03:38.265487 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        origin as value_field,
        count(*) as n_records

    from `mart`.`cylinders_by_origin`
    group by origin

)

select *
from all_values
where value_field not in (
    'usa','europe','japan'
)



    ) dbt_internal_test...
[0m08:03:38.269017 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "local", "node_id": "test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select origin
from `mart`.`cylinders_by_origin`
where origin is null



    ) dbt_internal_test...
[0m08:03:38.275806 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:03:38.277607 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:03:38.280629 [info ] [Thread-4  ]: 15 of 15 PASS not_null_cylinders_by_origin_origin .............................. [[32mPASS[0m in 0.06s]
[0m08:03:38.283595 [info ] [Thread-1  ]: 14 of 15 PASS accepted_values_cylinders_by_origin_origin__usa__europe__japan ... [[32mPASS[0m in 0.07s]
[0m08:03:38.285073 [debug] [Thread-4  ]: Finished running node test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9
[0m08:03:38.286412 [debug] [Thread-1  ]: Finished running node test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2
[0m08:03:38.288745 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:03:38.289415 [debug] [MainThread]: Connection 'test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2' was left open.
[0m08:03:38.290079 [debug] [MainThread]: On test.ex_01_mpg.accepted_values_cylinders_by_origin_origin__usa__europe__japan.61e009b3f2: Close
[0m08:03:38.290623 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m08:03:38.291205 [debug] [MainThread]: On list__clean: Close
[0m08:03:38.291873 [debug] [MainThread]: Connection 'model.ex_01_mpg.dq_mpg_anomalies' was left open.
[0m08:03:38.292410 [debug] [MainThread]: On model.ex_01_mpg.dq_mpg_anomalies: Close
[0m08:03:38.292907 [debug] [MainThread]: Connection 'test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9' was left open.
[0m08:03:38.293527 [debug] [MainThread]: On test.ex_01_mpg.not_null_cylinders_by_origin_origin.9a9d6e89e9: Close
[0m08:03:38.294012 [debug] [MainThread]: Connection 'model.ex_01_mpg.dq_mpg_summary' was left open.
[0m08:03:38.294540 [debug] [MainThread]: On model.ex_01_mpg.dq_mpg_summary: Close
[0m08:03:38.295641 [info ] [MainThread]: 
[0m08:03:38.296391 [info ] [MainThread]: Finished running 1 table model, 11 data tests, 3 view models in 0 hours 0 minutes and 1.45 seconds (1.45s).
[0m08:03:38.304155 [debug] [MainThread]: Command end result
[0m08:03:38.363298 [info ] [MainThread]: 
[0m08:03:38.364433 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:03:38.365064 [info ] [MainThread]: 
[0m08:03:38.365761 [info ] [MainThread]: Done. PASS=15 WARN=0 ERROR=0 SKIP=0 TOTAL=15
[0m08:03:38.367143 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 3.5228753, "process_in_blocks": "144", "process_kernel_time": 0.679484, "process_mem_max_rss": "118012", "process_out_blocks": "11008", "process_user_time": 6.436593}
[0m08:03:38.367934 [debug] [MainThread]: Command `dbt build` succeeded at 08:03:38.367724 after 3.52 seconds
[0m08:03:38.368557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a3fc9b54dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a3fc6850460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a3fc72ddd60>]}
[0m08:03:38.369161 [debug] [MainThread]: Flushing usage events
[0m18:02:26.417795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72defb203310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72def7e63af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72def7e639a0>]}


============================== 18:02:26.434696 | a6ccf88f-4025-4a7f-b1a7-56fd8073fb84 ==============================
[0m18:02:26.434696 [info ] [MainThread]: Running with dbt=1.8.9
[0m18:02:26.436814 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'warn_error': 'None', 'profiles_dir': '.', 'target_path': 'None', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'log_path': '/workdir/transforms/01_instacart/logs', 'no_print': 'None', 'empty': 'False', 'introspect': 'True', 'debug': 'False', 'static_parser': 'True', 'quiet': 'False', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'log_format': 'default', 'printer_width': '80', 'write_json': 'True', 'use_colors': 'True'}
[0m18:02:26.820554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a6ccf88f-4025-4a7f-b1a7-56fd8073fb84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72def7e4ad00>]}
[0m18:02:26.933839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a6ccf88f-4025-4a7f-b1a7-56fd8073fb84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72def7f1e8b0>]}
[0m18:02:26.936197 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m18:02:27.148897 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m18:02:27.433145 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m18:02:27.434407 [debug] [MainThread]: previous checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, current checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979
[0m18:02:27.435974 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m18:02:27.437430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a6ccf88f-4025-4a7f-b1a7-56fd8073fb84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72def919b670>]}
[0m18:02:30.290692 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m18:02:30.292188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'a6ccf88f-4025-4a7f-b1a7-56fd8073fb84', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72def64069a0>]}
[0m18:02:30.641785 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.ex_01_mpg.g1_dq_insta_users_summary' (models/mart/dq/g1_dq_insta_users_summary.sql) depends on a source named 'raw.raw___insta_orders' which was not found
[0m18:02:30.645481 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 4.350918, "process_in_blocks": "71040", "process_kernel_time": 1.741766, "process_mem_max_rss": "102160", "process_out_blocks": "6616", "process_user_time": 7.863388}
[0m18:02:30.646567 [debug] [MainThread]: Command `dbt build` failed at 18:02:30.646302 after 4.35 seconds
[0m18:02:30.647338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72defb203310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72def7707ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x72def9b78850>]}
[0m18:02:30.648123 [debug] [MainThread]: Flushing usage events
[0m18:08:08.618136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x764697dc6310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x764694a27b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x764694a27a00>]}


============================== 18:08:08.633201 | 7b7f0049-f5a9-4ad1-ad08-9358ceb5d5fa ==============================
[0m18:08:08.633201 [info ] [MainThread]: Running with dbt=1.8.9
[0m18:08:08.635150 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'no_print': 'None', 'indirect_selection': 'eager', 'write_json': 'True', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'target_path': 'None', 'static_parser': 'True', 'log_path': '/workdir/transforms/01_instacart/logs', 'empty': 'False', 'version_check': 'True', 'quiet': 'False', 'warn_error': 'None', 'log_cache_events': 'False', 'use_colors': 'True', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'partial_parse': 'True', 'fail_fast': 'False', 'debug': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'profiles_dir': '.'}
[0m18:08:08.977426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7b7f0049-f5a9-4ad1-ad08-9358ceb5d5fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x764697362ca0>]}
[0m18:08:09.089048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7b7f0049-f5a9-4ad1-ad08-9358ceb5d5fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x764694e610d0>]}
[0m18:08:09.090807 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m18:08:09.305898 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m18:08:09.602146 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m18:08:09.603306 [debug] [MainThread]: previous checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, current checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979
[0m18:08:09.605212 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m18:08:09.606597 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m18:08:09.608467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '7b7f0049-f5a9-4ad1-ad08-9358ceb5d5fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x764695d5d5b0>]}
[0m18:08:12.554319 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m18:08:12.556117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '7b7f0049-f5a9-4ad1-ad08-9358ceb5d5fa', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x764694a06a90>]}
[0m18:08:12.882254 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.ex_01_instacart.g1_dq_insta_users_anomalies' (models/mart/dq/g1_dq_insta_users_anomalies.sql) depends on a node named 'mpg_standardized' which was not found
[0m18:08:12.884847 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 4.390617, "process_in_blocks": "0", "process_kernel_time": 1.520837, "process_mem_max_rss": "102688", "process_out_blocks": "6608", "process_user_time": 7.728254}
[0m18:08:12.886128 [debug] [MainThread]: Command `dbt build` failed at 18:08:12.885825 after 4.39 seconds
[0m18:08:12.887265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x764697dc6310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x764694073850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x764692d22ac0>]}
[0m18:08:12.888104 [debug] [MainThread]: Flushing usage events
[0m18:10:37.728457 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78acb3729310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78acb0389bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78acb0389a60>]}


============================== 18:10:37.744107 | 5abd8ebb-62fa-4bbb-8ba4-2f998171d90c ==============================
[0m18:10:37.744107 [info ] [MainThread]: Running with dbt=1.8.9
[0m18:10:37.745748 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'write_json': 'True', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'no_print': 'None', 'partial_parse': 'True', 'target_path': 'None', 'log_path': '/workdir/transforms/01_instacart/logs', 'static_parser': 'True', 'log_cache_events': 'False', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True', 'cache_selected_only': 'False', 'profiles_dir': '.', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'indirect_selection': 'eager', 'log_format': 'default'}
[0m18:10:38.107717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5abd8ebb-62fa-4bbb-8ba4-2f998171d90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78acb028a820>]}
[0m18:10:38.218068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5abd8ebb-62fa-4bbb-8ba4-2f998171d90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78acb395a4c0>]}
[0m18:10:38.219629 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m18:10:38.428186 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m18:10:38.683998 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m18:10:38.684978 [debug] [MainThread]: previous checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, current checksum: 134c0f7b96382cc6938697739bc32fb1adc530b177e30f60cebddf61dbd7e979
[0m18:10:38.685966 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m18:10:38.686852 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m18:10:38.688118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5abd8ebb-62fa-4bbb-8ba4-2f998171d90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78acb16502b0>]}
[0m18:10:41.388406 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m18:10:41.389841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '5abd8ebb-62fa-4bbb-8ba4-2f998171d90c', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78acae908400>]}
[0m18:10:41.881158 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ex_01_mpg.clean
- models.ex_01_mpg.mart
[0m18:10:41.911288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5abd8ebb-62fa-4bbb-8ba4-2f998171d90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78acae5c8ee0>]}
[0m18:10:42.277812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5abd8ebb-62fa-4bbb-8ba4-2f998171d90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78acae618400>]}
[0m18:10:42.278967 [info ] [MainThread]: Found 6 models, 13 data tests, 1 source, 471 macros
[0m18:10:42.285187 [info ] [MainThread]: 
[0m18:10:42.286727 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:10:42.307844 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:10:42.310202 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:10:42.361692 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:10:42.370182 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:10:46.776105 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:10:46.782507 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:10:47.297899 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.52 seconds
[0m18:10:47.299808 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.52 seconds
[0m18:10:47.352807 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m18:10:47.354774 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m18:10:47.376848 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m18:10:47.382139 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m18:10:47.670109 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:10:47.676085 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:10:48.069454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5abd8ebb-62fa-4bbb-8ba4-2f998171d90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78acae8d89d0>]}
[0m18:10:48.071430 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m18:10:48.073112 [info ] [MainThread]: 
[0m18:10:48.098617 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:10:48.100548 [info ] [Thread-1  ]: 1 of 19 START sql table model `clean`.`g1_stg_insta_orders` .................... [RUN]
[0m18:10:48.102619 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__clean, now model.ex_01_instacart.g1_stg_insta_orders)
[0m18:10:48.104777 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_orders
[0m18:10:48.136961 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:10:48.141249 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_orders
[0m18:10:48.188162 [debug] [Thread-1  ]: Creating new relation g1_stg_insta_orders
[0m18:10:48.249523 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

            

    
        create table `clean`.`g1_stg_insta_orders`
        
  
        
  engine = MergeTree()
        order by (order_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
          )
        
        ...
[0m18:10:48.533262 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:10:48.551780 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    select name, type from system.columns where table = 'g1_stg_insta_orders'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:10:48.866410 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:10:48.874888 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:10:48.878852 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_orders`
        ("order_id", "user_id", "eval_set", "order_number", "order_dow", "order_hour_of_day", "days_since_prior_order")

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
  ...
[0m18:10:51.907200 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 3.03 seconds
[0m18:10:51.961249 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5abd8ebb-62fa-4bbb-8ba4-2f998171d90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78acafa9f400>]}
[0m18:10:51.962828 [info ] [Thread-1  ]: 1 of 19 OK created sql table model `clean`.`g1_stg_insta_orders` ............... [[32mOK[0m in 3.86s]
[0m18:10:51.964789 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:10:51.968964 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:10:51.970503 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:10:51.974223 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:10:51.972480 [info ] [Thread-3  ]: 2 of 19 START test accepted_values_g1_stg_insta_orders_eval_set__prior__train__test  [RUN]
[0m18:10:51.977280 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:10:51.978971 [info ] [Thread-4  ]: 3 of 19 START test accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [RUN]
[0m18:10:51.981707 [info ] [Thread-2  ]: 4 of 19 START test accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [RUN]
[0m18:10:51.984790 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5'
[0m18:10:51.986266 [info ] [Thread-1  ]: 5 of 19 START test not_null_g1_stg_insta_orders_eval_set ....................... [RUN]
[0m18:10:51.988841 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145'
[0m18:10:51.991279 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly list__mart, now test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1)
[0m18:10:51.993983 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:10:51.996250 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_orders, now test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7)
[0m18:10:51.998380 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:10:52.000241 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:10:52.016067 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:10:52.017630 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:10:52.041168 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:10:52.044472 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:10:52.070495 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:10:52.072309 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:10:52.076778 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:10:52.078202 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:10:52.150486 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:10:52.151688 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:10:52.160330 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:10:52.162195 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:10:52.165374 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m18:10:52.172432 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:10:52.173697 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:10:52.175426 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_hour_of_day as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_hour_of_day

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23'
)



    ) dbt_internal_test...
[0m18:10:52.184315 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select eval_set
from `clean`.`g1_stg_insta_orders`
where eval_set is null



    ) dbt_internal_test...
[0m18:10:52.775066 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.59 seconds
[0m18:10:52.785430 [info ] [Thread-2  ]: 4 of 19 PASS accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [[32mPASS[0m in 0.79s]
[0m18:10:52.787738 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:10:52.789412 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:10:52.790876 [info ] [Thread-2  ]: 6 of 19 START test not_null_g1_stg_insta_orders_order_dow ...................... [RUN]
[0m18:10:52.792412 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240)
[0m18:10:52.793717 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:10:52.806089 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:10:52.808834 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.62 seconds
[0m18:10:52.811700 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:10:52.817847 [info ] [Thread-1  ]: 5 of 19 PASS not_null_g1_stg_insta_orders_eval_set ............................. [[32mPASS[0m in 0.82s]
[0m18:10:52.826691 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:10:52.829361 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:10:52.832108 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:10:52.834305 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_dow
from `clean`.`g1_stg_insta_orders`
where order_dow is null



    ) dbt_internal_test...
[0m18:10:52.835997 [info ] [Thread-1  ]: 7 of 19 START test not_null_g1_stg_insta_orders_order_hour_of_day .............. [RUN]
[0m18:10:52.840346 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576)
[0m18:10:52.842233 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:10:52.855670 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:10:52.857279 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:10:52.864736 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:10:52.867136 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_hour_of_day
from `clean`.`g1_stg_insta_orders`
where order_hour_of_day is null



    ) dbt_internal_test...
[0m18:10:53.138509 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:10:53.141051 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:10:53.145368 [info ] [Thread-2  ]: 6 of 19 PASS not_null_g1_stg_insta_orders_order_dow ............................ [[32mPASS[0m in 0.35s]
[0m18:10:53.149827 [info ] [Thread-1  ]: 7 of 19 PASS not_null_g1_stg_insta_orders_order_hour_of_day .................... [[32mPASS[0m in 0.31s]
[0m18:10:53.152864 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:10:53.155280 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:10:53.157814 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:10:53.160465 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:10:53.162489 [info ] [Thread-2  ]: 8 of 19 START test not_null_g1_stg_insta_orders_order_id ....................... [RUN]
[0m18:10:53.165125 [info ] [Thread-1  ]: 9 of 19 START test not_null_g1_stg_insta_orders_order_number ................... [RUN]
[0m18:10:53.167274 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600)
[0m18:10:53.169607 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619)
[0m18:10:53.172225 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:10:53.174715 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:10:53.186128 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:10:53.198457 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:10:53.201152 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:10:53.208276 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:10:53.210249 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:10:53.216835 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:10:53.219800 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from `clean`.`g1_stg_insta_orders`
where order_id is null



    ) dbt_internal_test...
[0m18:10:53.223156 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_number
from `clean`.`g1_stg_insta_orders`
where order_number is null



    ) dbt_internal_test...
[0m18:10:53.513339 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:10:53.527360 [info ] [Thread-2  ]: 8 of 19 PASS not_null_g1_stg_insta_orders_order_id ............................. [[32mPASS[0m in 0.36s]
[0m18:10:53.531410 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:10:53.534129 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:10:53.536674 [info ] [Thread-2  ]: 10 of 19 START test not_null_g1_stg_insta_orders_user_id ....................... [RUN]
[0m18:10:53.548041 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600, now test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64)
[0m18:10:53.550332 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:10:53.555635 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:10:53.577846 [info ] [Thread-1  ]: 9 of 19 PASS not_null_g1_stg_insta_orders_order_number ......................... [[32mPASS[0m in 0.41s]
[0m18:10:53.604501 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:10:53.607996 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:10:53.610300 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:10:53.612803 [info ] [Thread-1  ]: 11 of 19 START test unique_g1_stg_insta_orders_order_id ........................ [RUN]
[0m18:10:53.617435 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619, now test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57)
[0m18:10:53.620184 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:10:53.623091 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:10:53.649374 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:10:53.671804 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:10:53.685803 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_orders`
where user_id is null



    ) dbt_internal_test...
[0m18:10:53.688917 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:10:53.708713 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:10:53.711348 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_orders`
where order_id is not null
group by order_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:10:54.012626 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:10:54.017077 [info ] [Thread-2  ]: 10 of 19 PASS not_null_g1_stg_insta_orders_user_id ............................. [[32mPASS[0m in 0.47s]
[0m18:10:54.018884 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:10:54.423897 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.71 seconds
[0m18:10:54.428347 [info ] [Thread-1  ]: 11 of 19 PASS unique_g1_stg_insta_orders_order_id .............................. [[32mPASS[0m in 0.81s]
[0m18:10:54.432401 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:10:55.838283 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_dow as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_dow

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6'
)



    ) dbt_internal_test...
[0m18:10:55.840803 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        eval_set as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by eval_set

)

select *
from all_values
where value_field not in (
    'prior','train','test'
)



    ) dbt_internal_test...
[0m18:10:56.225404 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m18:10:56.229947 [info ] [Thread-4  ]: 3 of 19 PASS accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [[32mPASS[0m in 4.24s]
[0m18:10:56.233108 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.39 seconds
[0m18:10:56.235664 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:10:56.240677 [info ] [Thread-3  ]: 2 of 19 PASS accepted_values_g1_stg_insta_orders_eval_set__prior__train__test .. [[32mPASS[0m in 4.26s]
[0m18:10:56.244189 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:10:56.246606 [debug] [Thread-2  ]: Began running node model.ex_01_instacart.g1_stg_insta_users
[0m18:10:56.248683 [info ] [Thread-2  ]: 12 of 19 START sql table model `clean`.`g1_stg_insta_users` .................... [RUN]
[0m18:10:56.251272 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64, now model.ex_01_instacart.g1_stg_insta_users)
[0m18:10:56.253072 [debug] [Thread-2  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_users
[0m18:10:56.264278 [debug] [Thread-2  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:10:56.266542 [debug] [Thread-2  ]: Began executing node model.ex_01_instacart.g1_stg_insta_users
[0m18:10:56.275155 [debug] [Thread-2  ]: Creating new relation g1_stg_insta_users
[0m18:10:56.278667 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

            

    
        create table `clean`.`g1_stg_insta_users`
        
  
        
  engine = MergeTree()
        order by (user_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
          )
        
        ...
[0m18:10:56.609792 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:10:56.617853 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    select name, type from system.columns where table = 'g1_stg_insta_users'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:10:56.912264 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:10:56.916744 [debug] [Thread-2  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:10:56.918640 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_users`
        ("user_id")

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
  ...
[0m18:10:57.430638 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.51 seconds
[0m18:10:57.435254 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5abd8ebb-62fa-4bbb-8ba4-2f998171d90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78acad116100>]}
[0m18:10:57.436955 [info ] [Thread-2  ]: 12 of 19 OK created sql table model `clean`.`g1_stg_insta_users` ............... [[32mOK[0m in 1.18s]
[0m18:10:57.438890 [debug] [Thread-2  ]: Finished running node model.ex_01_instacart.g1_stg_insta_users
[0m18:10:57.444389 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:10:57.447765 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:10:57.446248 [info ] [Thread-4  ]: 13 of 19 START test not_null_g1_stg_insta_users_user_id ........................ [RUN]
[0m18:10:57.450467 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:10:57.451991 [info ] [Thread-3  ]: 14 of 19 START test relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [RUN]
[0m18:10:57.454794 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145, now test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935)
[0m18:10:57.456930 [info ] [Thread-1  ]: 15 of 19 START test unique_g1_stg_insta_users_user_id .......................... [RUN]
[0m18:10:57.458937 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5, now test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726)
[0m18:10:57.460564 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:10:57.463227 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57, now test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f)
[0m18:10:57.465450 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:10:57.478275 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:10:57.479699 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:10:57.493401 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:10:57.501220 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:10:57.506811 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:10:57.516195 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:10:57.517583 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:10:57.525602 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_users`
where user_id is null



    ) dbt_internal_test...
[0m18:10:57.527825 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:10:57.529186 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:10:57.539617 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:10:57.541817 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select user_id as from_field
    from `clean`.`g1_stg_insta_orders`
    where user_id is not null
),

parent as (
    select user_id as to_field
    from `clean`.`g1_stg_insta_users`
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null
-- end_of_sql
settings join_use_nulls = 1



    ) dbt_internal_test...
[0m18:10:57.545083 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    user_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_users`
where user_id is not null
group by user_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:10:57.851859 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:10:57.856069 [info ] [Thread-4  ]: 13 of 19 PASS not_null_g1_stg_insta_users_user_id .............................. [[32mPASS[0m in 0.40s]
[0m18:10:57.859609 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:10:57.939059 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.39 seconds
[0m18:10:57.943348 [info ] [Thread-1  ]: 15 of 19 PASS unique_g1_stg_insta_users_user_id ................................ [[32mPASS[0m in 0.48s]
[0m18:10:57.945405 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:10:58.217850 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.67 seconds
[0m18:10:58.222119 [info ] [Thread-3  ]: 14 of 19 PASS relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [[32mPASS[0m in 0.76s]
[0m18:10:58.224989 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:10:58.228613 [debug] [Thread-2  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:10:58.230052 [debug] [Thread-4  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:10:58.233555 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:10:58.235445 [debug] [Thread-3  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:10:58.231754 [info ] [Thread-2  ]: 16 of 19 START sql view model `mart`.`g1_dq_insta_orders_anomalies` ............ [RUN]
[0m18:10:58.237890 [info ] [Thread-4  ]: 17 of 19 START sql view model `mart`.`g1_dq_insta_orders_summary` .............. [RUN]
[0m18:10:58.240664 [info ] [Thread-1  ]: 18 of 19 START sql view model `mart`.`g1_dq_insta_users_anomalies` ............. [RUN]
[0m18:10:58.243375 [info ] [Thread-3  ]: 19 of 19 START sql view model `mart`.`g1_dq_insta_users_summary` ............... [RUN]
[0m18:10:58.246191 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_users, now model.ex_01_instacart.g1_dq_insta_orders_anomalies)
[0m18:10:58.248919 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935, now model.ex_01_instacart.g1_dq_insta_orders_summary)
[0m18:10:58.251035 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f, now model.ex_01_instacart.g1_dq_insta_users_anomalies)
[0m18:10:58.253116 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726, now model.ex_01_instacart.g1_dq_insta_users_summary)
[0m18:10:58.254588 [debug] [Thread-2  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:10:58.256252 [debug] [Thread-4  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:10:58.257710 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:10:58.260125 [debug] [Thread-3  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:10:58.271283 [debug] [Thread-2  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:10:58.289035 [debug] [Thread-4  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:10:58.293205 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:10:58.307387 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:10:58.313215 [debug] [Thread-4  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:10:58.320461 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:10:58.327551 [debug] [Thread-3  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:10:58.328808 [debug] [Thread-2  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:10:58.386222 [debug] [Thread-3  ]: Creating new relation g1_dq_insta_users_summary
[0m18:10:58.381184 [debug] [Thread-4  ]: Creating new relation g1_dq_insta_orders_summary
[0m18:10:58.411796 [debug] [Thread-1  ]: Creating new relation g1_dq_insta_users_anomalies
[0m18:10:58.416524 [debug] [Thread-2  ]: Creating new relation g1_dq_insta_orders_anomalies
[0m18:10:58.448415 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:10:58.450381 [debug] [Thread-4  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:10:58.453134 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:10:58.455835 [debug] [Thread-2  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:10:58.461144 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  -- Distinct user IDs extracted from raw orders
  select distinct user_id
  from `raw`.`raw___insta_orders`
),

cln as (
  -- Cleaned users table
  select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage
nulls as (
  select
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
  from cln
),

-- Duplicate Users Check
dupes as (
  select
    countIf(cnt > 1) as duplicate_user_ids
  from (
    select user_id, count() as cnt
    from cln
    group by user_id
  )
),

-- Referential Integrity Checks
-- Ensure all users in orders exist in users, and all users in users appear in at least one order
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_in_orders,
    countIf(u.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_orders`)) as user_without_orders
  from `clean`.`g1_stg_insta_orders` o
  cross join `clean`.`g1_stg_insta_users` u
),

-- Join all metrics
joined as (
  select
    counts.row_count_raw,
    counts.row_count_clean,
    (counts.row_count_raw - counts.row_count_clean) as dropped_rows,

    nulls.null_pct_user_id,
    dupes.duplicate_user_ids,

    referential_integrity.invalid_user_in_orders,
    referential_integrity.user_without_orders
  from counts
  cross join nulls
  cross join dupes
  cross join referential_integrity
)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:10:58.463903 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */


  create view `mart`.`g1_dq_insta_users_anomalies` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Users

with cln as (
  select * from `clean`.`g1_stg_insta_users`
),
violations as (
  select
    user_id,

    multiIf(
      user_id is null, 'null_user_id',
      user_id <= 0, 'invalid_user_id',
      'ok'
    ) as dq_issue
  from cln
)
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:10:58.467821 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */


  create view `mart`.`g1_dq_insta_orders_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Orders
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  select * from `raw`.`raw___insta_orders`
),

cln as (
  select * from `clean`.`g1_stg_insta_orders`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage Check
nulls as (
  select
    round(100.0 * countIf(order_id is null) / nullif(count(),0), 2) as null_pct_order_id,
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id,
    round(100.0 * countIf(eval_set is null) / nullif(count(),0), 2) as null_pct_eval_set,
    round(100.0 * countIf(order_number is null) / nullif(count(),0), 2) as null_pct_order_number,
    round(100.0 * countIf(order_dow is null) / nullif(count(),0), 2) as null_pct_order_dow,
    round(100.0 * countIf(order_hour_of_day is null) / nullif(count(),0), 2) as null_pct_order_hour_of_day,
    round(100.0 * countIf(days_since_prior_order is null) / nullif(count(),0), 2) as null_pct_days_since_prior_order
  from cln
),

-- Duplicate Orders
dupes as (
  select
    countIf(cnt > 1) as duplicate_orders
  from (
    select order_id, count() as cnt
    from cln
    group by order_id
  )
),

-- Referential Integrity
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_id
  from `clean`.`g1_stg_insta_orders` o
),

-- Value Range Checks
value_ranges as (
  select
    countIf(order_number < 1) as invalid_order_number,
    countIf(order_hour_of_day < 0 or order_hour_of_day > 23) as invalid_order_hour,
    countIf(days_since_prior_order < 0 or days_since_prior_order > 30) as invalid_days_since_prior_order
  from cln
),

-- Join all metrics
joined as (
  select
    counts.row_count_raw,
    counts.row_count_clean,
    (counts.row_count_raw - counts.row_count_clean) as dropped_rows,

    nulls.*,
    dupes.duplicate_orders,
    referential_integrity.invalid_user_id,
    value_ranges.invalid_order_number,
    value_ranges.invalid_order_hour,
    value_ranges.invalid_days_since_prior_order
  from counts
  cross join nulls
  cross join dupes
  cross join referential_integrity
  cross join value_ranges
)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:10:58.469918 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */


  create view `mart`.`g1_dq_insta_orders_anomalies` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Orders
with cln as (
  -- Source cleaned orders data
  select * 
  from `clean`.`g1_stg_insta_orders`
),

users as (
  -- Reference users table for FK validation
  select user_id 
  from `clean`.`g1_stg_insta_users`
),

violations as (
  select
    order_id,
    user_id,
    eval_set,
    order_number,
    order_dow,
    order_hour_of_day,
    days_since_prior_order,

    -- Data Quality Issue Classification
    multiIf(
      order_id is null, 'null_order_id',
      user_id is null, 'null_user_id',
      user_id not in (select user_id from users), 'missing_user_ref',
      order_number < 1, 'invalid_order_number'
      order_dow not in (0,1,2,3,4,5,6), 'invalid_order_dow',
      order_hour_of_day < 0 or order_hour_of_day > 23, 'invalid_order_hour',
      days_since_prior_order < 0, 'negative_days_since_prior_order',
      'ok'
    ) as dq_issue

  from cln
)

-- Return only rows with detected anomalies
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:10:58.781791 [debug] [Thread-3  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  -- Distinct user IDs extracted from raw orders
  select distinct user_id
  from `raw`.`raw___insta_orders`
),

cln as (
  -- Cleaned users table
  select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage
nulls as (
  select
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
  from cln
),

-- Duplicate Users Check
dupes as (
  select
    countIf(cnt > 1) as duplicate_user_ids
  from (
    select user_id, count() as cnt
    from cln
    group by user_id
  )
),

-- Referential Integrity Checks
-- Ensure all users in orders exist in users, and all users in users appear in at least one order
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_in_orders,
    countIf(u.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_orders`)) as user_without_orders
  from `clean`.`g1_stg_insta_orders` o
  cross join `clean`.`g1_stg_insta_users` u
),

-- Join all metrics
joined as (
  select
    counts.row_count_raw,
    counts.row_count_clean,
    (counts.row_count_raw - counts.row_count_clean) as dropped_rows,

    nulls.null_pct_user_id,
    dupes.duplicate_user_ids,

    referential_integrity.invalid_user_in_orders,
    referential_integrity.user_without_orders
  from counts
  cross join nulls
  cross join dupes
  cross join referential_integrity
)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m18:10:58.784768 [debug] [Thread-2  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */


  create view `mart`.`g1_dq_insta_orders_anomalies` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Orders
with cln as (
  -- Source cleaned orders data
  select * 
  from `clean`.`g1_stg_insta_orders`
),

users as (
  -- Reference users table for FK validation
  select user_id 
  from `clean`.`g1_stg_insta_users`
),

violations as (
  select
    order_id,
    user_id,
    eval_set,
    order_number,
    order_dow,
    order_hour_of_day,
    days_since_prior_order,

    -- Data Quality Issue Classification
    multiIf(
      order_id is null, 'null_order_id',
      user_id is null, 'null_user_id',
      user_id not in (select user_id from users), 'missing_user_ref',
      order_number < 1, 'invalid_order_number'
      order_dow not in (0,1,2,3,4,5,6), 'invalid_order_dow',
      order_hour_of_day < 0 or order_hour_of_day > 23, 'invalid_order_hour',
      days_since_prior_order < 0, 'negative_days_since_prior_order',
      'ok'
    ) as dq_issue

  from cln
)

-- Return only rows with detected anomalies
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m18:10:58.787242 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:10:58.791129 [debug] [Thread-4  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */


  create view `mart`.`g1_dq_insta_orders_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Orders
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  select * from `raw`.`raw___insta_orders`
),

cln as (
  select * from `clean`.`g1_stg_insta_orders`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage Check
nulls as (
  select
    round(100.0 * countIf(order_id is null) / nullif(count(),0), 2) as null_pct_order_id,
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id,
    round(100.0 * countIf(eval_set is null) / nullif(count(),0), 2) as null_pct_eval_set,
    round(100.0 * countIf(order_number is null) / nullif(count(),0), 2) as null_pct_order_number,
    round(100.0 * countIf(order_dow is null) / nullif(count(),0), 2) as null_pct_order_dow,
    round(100.0 * countIf(order_hour_of_day is null) / nullif(count(),0), 2) as null_pct_order_hour_of_day,
    round(100.0 * countIf(days_since_prior_order is null) / nullif(count(),0), 2) as null_pct_days_since_prior_order
  from cln
),

-- Duplicate Orders
dupes as (
  select
    countIf(cnt > 1) as duplicate_orders
  from (
    select order_id, count() as cnt
    from cln
    group by order_id
  )
),

-- Referential Integrity
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_id
  from `clean`.`g1_stg_insta_orders` o
),

-- Value Range Checks
value_ranges as (
  select
    countIf(order_number < 1) as invalid_order_number,
    countIf(order_hour_of_day < 0 or order_hour_of_day > 23) as invalid_order_hour,
    countIf(days_since_prior_order < 0 or days_since_prior_order > 30) as invalid_days_since_prior_order
  from cln
),

-- Join all metrics
joined as (
  select
    counts.row_count_raw,
    counts.row_count_clean,
    (counts.row_count_raw - counts.row_count_clean) as dropped_rows,

    nulls.*,
    dupes.duplicate_orders,
    referential_integrity.invalid_user_id,
    value_ranges.invalid_order_number,
    value_ranges.invalid_order_hour,
    value_ranges.invalid_days_since_prior_order
  from counts
  cross join nulls
  cross join dupes
  cross join referential_integrity
  cross join value_ranges
)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m18:10:58.798764 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5abd8ebb-62fa-4bbb-8ba4-2f998171d90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78acad12bcd0>]}
[0m18:10:58.805543 [info ] [Thread-1  ]: 18 of 19 OK created sql view model `mart`.`g1_dq_insta_users_anomalies` ........ [[32mOK[0m in 0.55s]
[0m18:10:58.809591 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:10:58.829136 [debug] [Thread-2  ]: Database Error in model g1_dq_insta_orders_anomalies (models/mart/dq/g1_dq_insta_orders_anomalies.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 920 ('order_dow') (line 40, col 7): order_dow not in (0,1,2,3,4,5,6), 'invalid_order_dow',
        order_hour_of_day < 0 or order_hour_of_day > 23, 'invalid_order_hour',
        days_since_prior_order. Expected one of: token, DoubleColon, Comma, ClosingRoundBracket, OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_orders_anomalies.sql
[0m18:10:58.832725 [debug] [Thread-4  ]: Database Error in model g1_dq_insta_orders_summary (models/mart/dq/g1_dq_insta_orders_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 2578 (end of query) (line 89, col 21): ;
      
    )
        
        
                      -- end_of_sql
                      
                      . Expected one of: token, Dot, OpeningRoundBracket, UUID, alias, AS, identifier, FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_orders_summary.sql
[0m18:10:58.836258 [debug] [Thread-3  ]: Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1952 (end of query) (line 78, col 21): ;
      
    )
        
        
                      -- end_of_sql
                      
                      . Expected one of: token, Dot, OpeningRoundBracket, UUID, alias, AS, identifier, FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:10:58.838230 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5abd8ebb-62fa-4bbb-8ba4-2f998171d90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78acad0c4580>]}
[0m18:10:58.839907 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5abd8ebb-62fa-4bbb-8ba4-2f998171d90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78acae278910>]}
[0m18:10:58.841434 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5abd8ebb-62fa-4bbb-8ba4-2f998171d90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78acad16d5b0>]}
[0m18:10:58.843622 [error] [Thread-2  ]: 16 of 19 ERROR creating sql view model `mart`.`g1_dq_insta_orders_anomalies` ... [[31mERROR[0m in 0.59s]
[0m18:10:58.846453 [error] [Thread-4  ]: 17 of 19 ERROR creating sql view model `mart`.`g1_dq_insta_orders_summary` ..... [[31mERROR[0m in 0.59s]
[0m18:10:58.849411 [error] [Thread-3  ]: 19 of 19 ERROR creating sql view model `mart`.`g1_dq_insta_users_summary` ...... [[31mERROR[0m in 0.59s]
[0m18:10:58.853083 [debug] [Thread-2  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:10:58.856142 [debug] [Thread-4  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:10:58.858932 [debug] [Thread-3  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:10:58.866592 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:10:58.867869 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_anomalies' was left open.
[0m18:10:58.869450 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_anomalies: Close
[0m18:10:58.870955 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_anomalies' was left open.
[0m18:10:58.872527 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: Close
[0m18:10:58.873827 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_summary' was left open.
[0m18:10:58.874615 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_summary: Close
[0m18:10:58.875365 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_summary' was left open.
[0m18:10:58.876302 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_summary: Close
[0m18:10:58.878909 [info ] [MainThread]: 
[0m18:10:58.880332 [info ] [MainThread]: Finished running 2 table models, 13 data tests, 4 view models in 0 hours 0 minutes and 16.59 seconds (16.59s).
[0m18:10:58.894759 [debug] [MainThread]: Command end result
[0m18:10:58.984420 [info ] [MainThread]: 
[0m18:10:58.985944 [info ] [MainThread]: [31mCompleted with 3 errors and 0 warnings:[0m
[0m18:10:58.987636 [info ] [MainThread]: 
[0m18:10:58.989204 [error] [MainThread]:   Database Error in model g1_dq_insta_orders_anomalies (models/mart/dq/g1_dq_insta_orders_anomalies.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 920 ('order_dow') (line 40, col 7): order_dow not in (0,1,2,3,4,5,6), 'invalid_order_dow',
        order_hour_of_day < 0 or order_hour_of_day > 23, 'invalid_order_hour',
        days_since_prior_order. Expected one of: token, DoubleColon, Comma, ClosingRoundBracket, OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, alias, AS. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_orders_anomalies.sql
[0m18:10:58.990386 [info ] [MainThread]: 
[0m18:10:58.992040 [error] [MainThread]:   Database Error in model g1_dq_insta_orders_summary (models/mart/dq/g1_dq_insta_orders_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 2578 (end of query) (line 89, col 21): ;
      
    )
        
        
                      -- end_of_sql
                      
                      . Expected one of: token, Dot, OpeningRoundBracket, UUID, alias, AS, identifier, FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_orders_summary.sql
[0m18:10:58.994355 [info ] [MainThread]: 
[0m18:10:58.996651 [error] [MainThread]:   Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1952 (end of query) (line 78, col 21): ;
      
    )
        
        
                      -- end_of_sql
                      
                      . Expected one of: token, Dot, OpeningRoundBracket, UUID, alias, AS, identifier, FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:10:58.998456 [info ] [MainThread]: 
[0m18:10:59.000600 [info ] [MainThread]: Done. PASS=16 WARN=0 ERROR=3 SKIP=0 TOTAL=19
[0m18:10:59.004150 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 21.403967, "process_in_blocks": "7664", "process_kernel_time": 1.840738, "process_mem_max_rss": "119252", "process_out_blocks": "11296", "process_user_time": 10.296884}
[0m18:10:59.005624 [debug] [MainThread]: Command `dbt build` failed at 18:10:59.005195 after 21.41 seconds
[0m18:10:59.007023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78acb3729310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78acb16c03a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78acae421160>]}
[0m18:10:59.008362 [debug] [MainThread]: Flushing usage events
[0m18:20:52.464066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d17c11b310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d178d74b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d178d749d0>]}


============================== 18:20:52.480694 | a5d1fd0b-6f69-4d0a-a112-dbeb5e8a1371 ==============================
[0m18:20:52.480694 [info ] [MainThread]: Running with dbt=1.8.9
[0m18:20:52.482816 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'profiles_dir': '.', 'empty': 'False', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'no_print': 'None', 'static_parser': 'True', 'introspect': 'True', 'printer_width': '80', 'version_check': 'True', 'warn_error': 'None', 'debug': 'False', 'indirect_selection': 'eager', 'fail_fast': 'False', 'partial_parse': 'True', 'log_format': 'default', 'use_experimental_parser': 'False', 'quiet': 'False', 'target_path': 'None', 'use_colors': 'True', 'log_path': '/workdir/transforms/01_instacart/logs', 'write_json': 'True', 'cache_selected_only': 'False', 'log_cache_events': 'False'}
[0m18:20:52.847837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a5d1fd0b-6f69-4d0a-a112-dbeb5e8a1371', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d17b6c03a0>]}
[0m18:20:52.966647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a5d1fd0b-6f69-4d0a-a112-dbeb5e8a1371', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d1791db790>]}
[0m18:20:52.968611 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m18:20:53.189180 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m18:20:53.519898 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m18:20:53.521592 [debug] [MainThread]: Partial parsing: updated file: ex_01_instacart://models/mart/dq/g1_dq_insta_orders_summary.sql
[0m18:20:53.523032 [debug] [MainThread]: Partial parsing: updated file: ex_01_instacart://models/mart/dq/g1_dq_insta_orders_anomalies.sql
[0m18:20:53.524485 [debug] [MainThread]: Partial parsing: updated file: ex_01_instacart://models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:20:54.304976 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ex_01_mpg.mart
- models.ex_01_mpg.clean
[0m18:20:54.346165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a5d1fd0b-6f69-4d0a-a112-dbeb5e8a1371', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d1770c5130>]}
[0m18:20:54.658467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a5d1fd0b-6f69-4d0a-a112-dbeb5e8a1371', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d176f62f10>]}
[0m18:20:54.659663 [info ] [MainThread]: Found 6 models, 13 data tests, 1 source, 471 macros
[0m18:20:54.667066 [info ] [MainThread]: 
[0m18:20:54.669202 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:20:54.687538 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:20:54.690932 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:20:54.735842 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:20:54.740568 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:20:58.807410 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:20:58.924365 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:20:59.099937 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:20:59.213990 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:20:59.222036 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m18:20:59.224109 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m18:20:59.254013 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m18:20:59.259021 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m18:20:59.556870 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:20:59.562764 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:20:59.904924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a5d1fd0b-6f69-4d0a-a112-dbeb5e8a1371', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d176b49280>]}
[0m18:20:59.906676 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m18:20:59.907932 [info ] [MainThread]: 
[0m18:20:59.936747 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:20:59.939396 [info ] [Thread-1  ]: 1 of 19 START sql table model `clean`.`g1_stg_insta_orders` .................... [RUN]
[0m18:20:59.942657 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_instacart.g1_stg_insta_orders'
[0m18:20:59.944794 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_orders
[0m18:20:59.976698 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:20:59.978729 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_orders
[0m18:21:00.111540 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m18:21:03.719946 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

            

    
        create table `clean`.`g1_stg_insta_orders__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (order_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
          )
        
        ...
[0m18:21:04.044853 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:21:04.065992 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    select name, type from system.columns where table = 'g1_stg_insta_orders__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:21:04.345833 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:21:04.356809 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:21:04.359000 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_orders__dbt_backup`
        ("order_id", "user_id", "eval_set", "order_number", "order_dow", "order_hour_of_day", "days_since_prior_order")

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
  ...
[0m18:21:07.822366 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 3.46 seconds
[0m18:21:07.833544 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_orders__dbt_backup` AND `clean`.`g1_stg_insta_orders` 
  
  ...
[0m18:21:08.122037 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:21:08.244232 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    drop table if exists `clean`.`g1_stg_insta_orders__dbt_backup` 
  ...
[0m18:21:08.521112 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:21:08.530113 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5d1fd0b-6f69-4d0a-a112-dbeb5e8a1371', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d176cd29d0>]}
[0m18:21:08.531959 [info ] [Thread-1  ]: 1 of 19 OK created sql table model `clean`.`g1_stg_insta_orders` ............... [[32mOK[0m in 8.59s]
[0m18:21:08.534826 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:21:08.538955 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:21:08.540819 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:21:08.543449 [info ] [Thread-3  ]: 2 of 19 START test accepted_values_g1_stg_insta_orders_eval_set__prior__train__test  [RUN]
[0m18:21:08.546292 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:21:08.549750 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:21:08.555031 [info ] [Thread-4  ]: 3 of 19 START test accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [RUN]
[0m18:21:08.558569 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5'
[0m18:21:08.561182 [info ] [Thread-2  ]: 4 of 19 START test accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [RUN]
[0m18:21:08.564037 [info ] [Thread-1  ]: 5 of 19 START test not_null_g1_stg_insta_orders_eval_set ....................... [RUN]
[0m18:21:08.567474 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145'
[0m18:21:08.570189 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:21:08.573756 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1'
[0m18:21:08.575939 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_orders, now test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7)
[0m18:21:08.578484 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:21:08.603813 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:21:08.625312 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:21:08.627061 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:21:08.639795 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:21:08.657740 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:21:08.679324 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:21:08.681854 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:21:08.683596 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:21:08.685088 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:21:08.714539 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:21:08.773879 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:21:08.766650 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:21:08.771772 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:21:08.783335 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:21:08.786213 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:21:08.787352 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m18:21:08.789517 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m18:21:08.794144 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select eval_set
from `clean`.`g1_stg_insta_orders`
where eval_set is null



    ) dbt_internal_test...
[0m18:21:09.337115 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.54 seconds
[0m18:21:09.345423 [info ] [Thread-1  ]: 5 of 19 PASS not_null_g1_stg_insta_orders_eval_set ............................. [[32mPASS[0m in 0.77s]
[0m18:21:09.348321 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:21:09.350654 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:21:09.359371 [info ] [Thread-1  ]: 6 of 19 START test not_null_g1_stg_insta_orders_order_dow ...................... [RUN]
[0m18:21:09.365309 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240)
[0m18:21:09.368122 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:21:09.383854 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:21:09.386326 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:21:09.392727 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:21:09.394919 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_dow
from `clean`.`g1_stg_insta_orders`
where order_dow is null



    ) dbt_internal_test...
[0m18:21:09.658392 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.26 seconds
[0m18:21:09.663328 [info ] [Thread-1  ]: 6 of 19 PASS not_null_g1_stg_insta_orders_order_dow ............................ [[32mPASS[0m in 0.30s]
[0m18:21:09.665742 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:21:09.667326 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:21:09.668842 [info ] [Thread-1  ]: 7 of 19 START test not_null_g1_stg_insta_orders_order_hour_of_day .............. [RUN]
[0m18:21:09.670274 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576)
[0m18:21:09.672186 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:21:09.684621 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:21:09.686413 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:21:09.693873 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:21:09.695741 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_hour_of_day
from `clean`.`g1_stg_insta_orders`
where order_hour_of_day is null



    ) dbt_internal_test...
[0m18:21:09.988765 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:21:09.993316 [info ] [Thread-1  ]: 7 of 19 PASS not_null_g1_stg_insta_orders_order_hour_of_day .................... [[32mPASS[0m in 0.32s]
[0m18:21:09.995107 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:21:09.996574 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:21:09.997826 [info ] [Thread-1  ]: 8 of 19 START test not_null_g1_stg_insta_orders_order_id ....................... [RUN]
[0m18:21:09.999013 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600)
[0m18:21:10.000149 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:21:10.010447 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:21:10.012232 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:21:10.018744 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:21:10.020995 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from `clean`.`g1_stg_insta_orders`
where order_id is null



    ) dbt_internal_test...
[0m18:21:10.317766 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:21:10.322504 [info ] [Thread-1  ]: 8 of 19 PASS not_null_g1_stg_insta_orders_order_id ............................. [[32mPASS[0m in 0.32s]
[0m18:21:10.324681 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:21:10.326329 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:21:10.327519 [info ] [Thread-1  ]: 9 of 19 START test not_null_g1_stg_insta_orders_order_number ................... [RUN]
[0m18:21:10.328914 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619)
[0m18:21:10.330180 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:21:10.340575 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:21:10.342332 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:21:10.349037 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:21:10.351420 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_number
from `clean`.`g1_stg_insta_orders`
where order_number is null



    ) dbt_internal_test...
[0m18:21:10.652876 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:21:10.657439 [info ] [Thread-1  ]: 9 of 19 PASS not_null_g1_stg_insta_orders_order_number ......................... [[32mPASS[0m in 0.33s]
[0m18:21:10.659218 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:21:10.660748 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:21:10.662369 [info ] [Thread-1  ]: 10 of 19 START test not_null_g1_stg_insta_orders_user_id ....................... [RUN]
[0m18:21:10.663656 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619, now test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64)
[0m18:21:10.665073 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:21:10.677611 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:21:10.679289 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:21:10.686103 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:21:10.688017 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_orders`
where user_id is null



    ) dbt_internal_test...
[0m18:21:10.984144 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:21:10.989691 [info ] [Thread-1  ]: 10 of 19 PASS not_null_g1_stg_insta_orders_user_id ............................. [[32mPASS[0m in 0.33s]
[0m18:21:10.992726 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:21:10.994397 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:21:10.996348 [info ] [Thread-1  ]: 11 of 19 START test unique_g1_stg_insta_orders_order_id ........................ [RUN]
[0m18:21:10.998737 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64, now test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57)
[0m18:21:11.000456 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:21:11.023605 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:21:11.027197 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:21:11.038332 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:21:11.041591 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_orders`
where order_id is not null
group by order_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:21:11.789083 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.75 seconds
[0m18:21:11.793483 [info ] [Thread-1  ]: 11 of 19 PASS unique_g1_stg_insta_orders_order_id .............................. [[32mPASS[0m in 0.80s]
[0m18:21:11.795426 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:21:12.380261 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        eval_set as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by eval_set

)

select *
from all_values
where value_field not in (
    'prior','train','test'
)



    ) dbt_internal_test...
[0m18:21:12.382616 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_hour_of_day as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_hour_of_day

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23'
)



    ) dbt_internal_test...
[0m18:21:12.619981 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_dow as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_dow

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6'
)



    ) dbt_internal_test...
[0m18:21:12.742955 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m18:21:12.747387 [info ] [Thread-2  ]: 4 of 19 PASS accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [[32mPASS[0m in 4.17s]
[0m18:21:12.749703 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:21:12.784242 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.40 seconds
[0m18:21:12.788200 [info ] [Thread-3  ]: 2 of 19 PASS accepted_values_g1_stg_insta_orders_eval_set__prior__train__test .. [[32mPASS[0m in 4.23s]
[0m18:21:12.790609 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:21:12.957081 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m18:21:12.961001 [info ] [Thread-4  ]: 3 of 19 PASS accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [[32mPASS[0m in 4.39s]
[0m18:21:12.963498 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:21:12.965838 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_users
[0m18:21:12.968301 [info ] [Thread-1  ]: 12 of 19 START sql table model `clean`.`g1_stg_insta_users` .................... [RUN]
[0m18:21:12.970969 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57, now model.ex_01_instacart.g1_stg_insta_users)
[0m18:21:12.972803 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_users
[0m18:21:12.981868 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:21:12.983747 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_users
[0m18:21:12.998014 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

            

    
        create table `clean`.`g1_stg_insta_users__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (user_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
          )
        
        ...
[0m18:21:13.299386 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:21:13.307808 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    select name, type from system.columns where table = 'g1_stg_insta_users__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:21:13.619871 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:21:13.623693 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:21:13.625902 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_users__dbt_backup`
        ("user_id")

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
  ...
[0m18:21:14.100741 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.47 seconds
[0m18:21:14.104050 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_users__dbt_backup` AND `clean`.`g1_stg_insta_users` 
  
  ...
[0m18:21:14.386608 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:21:14.395870 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    drop table if exists `clean`.`g1_stg_insta_users__dbt_backup` 
  ...
[0m18:21:14.694371 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:21:14.699102 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5d1fd0b-6f69-4d0a-a112-dbeb5e8a1371', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d175c5dd60>]}
[0m18:21:14.700717 [info ] [Thread-1  ]: 12 of 19 OK created sql table model `clean`.`g1_stg_insta_users` ............... [[32mOK[0m in 1.73s]
[0m18:21:14.702573 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_users
[0m18:21:14.705635 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:21:14.707136 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:21:14.710655 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:21:14.708478 [info ] [Thread-3  ]: 13 of 19 START test not_null_g1_stg_insta_users_user_id ........................ [RUN]
[0m18:21:14.713719 [info ] [Thread-4  ]: 14 of 19 START test relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [RUN]
[0m18:21:14.715876 [info ] [Thread-2  ]: 15 of 19 START test unique_g1_stg_insta_users_user_id .......................... [RUN]
[0m18:21:14.718694 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5, now test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935)
[0m18:21:14.720394 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145, now test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726)
[0m18:21:14.722112 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1, now test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f)
[0m18:21:14.724183 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:21:14.725778 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:21:14.727552 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:21:14.740129 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:21:14.768951 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:21:14.774560 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:21:14.777317 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:21:14.784926 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:21:14.786472 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:21:14.794285 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:21:14.798401 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:21:14.804525 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:21:14.807251 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_users`
where user_id is null



    ) dbt_internal_test...
[0m18:21:14.811896 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    user_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_users`
where user_id is not null
group by user_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:21:14.813670 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select user_id as from_field
    from `clean`.`g1_stg_insta_orders`
    where user_id is not null
),

parent as (
    select user_id as to_field
    from `clean`.`g1_stg_insta_users`
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null
-- end_of_sql
settings join_use_nulls = 1



    ) dbt_internal_test...
[0m18:21:15.116149 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:21:15.120816 [info ] [Thread-3  ]: 13 of 19 PASS not_null_g1_stg_insta_users_user_id .............................. [[32mPASS[0m in 0.40s]
[0m18:21:15.122763 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:21:15.205753 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.39 seconds
[0m18:21:15.212527 [info ] [Thread-2  ]: 15 of 19 PASS unique_g1_stg_insta_users_user_id ................................ [[32mPASS[0m in 0.49s]
[0m18:21:15.217323 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:21:15.454817 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.64 seconds
[0m18:21:15.458949 [info ] [Thread-4  ]: 14 of 19 PASS relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [[32mPASS[0m in 0.74s]
[0m18:21:15.460927 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:21:15.464201 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:21:15.465605 [debug] [Thread-3  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:21:15.466956 [debug] [Thread-2  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:21:15.470393 [debug] [Thread-4  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:21:15.469088 [info ] [Thread-1  ]: 16 of 19 START sql view model `mart`.`g1_dq_insta_orders_anomalies` ............ [RUN]
[0m18:21:15.472639 [info ] [Thread-3  ]: 17 of 19 START sql view model `mart`.`g1_dq_insta_orders_summary` .............. [RUN]
[0m18:21:15.474908 [info ] [Thread-2  ]: 18 of 19 START sql view model `mart`.`g1_dq_insta_users_anomalies` ............. [RUN]
[0m18:21:15.478024 [info ] [Thread-4  ]: 19 of 19 START sql view model `mart`.`g1_dq_insta_users_summary` ............... [RUN]
[0m18:21:15.481013 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_users, now model.ex_01_instacart.g1_dq_insta_orders_anomalies)
[0m18:21:15.482535 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935, now model.ex_01_instacart.g1_dq_insta_orders_summary)
[0m18:21:15.484253 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f, now model.ex_01_instacart.g1_dq_insta_users_anomalies)
[0m18:21:15.486059 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726, now model.ex_01_instacart.g1_dq_insta_users_summary)
[0m18:21:15.487980 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:21:15.489956 [debug] [Thread-3  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:21:15.491411 [debug] [Thread-2  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:21:15.494115 [debug] [Thread-4  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:21:15.504923 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:21:15.517643 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:21:15.527343 [debug] [Thread-2  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:21:15.541285 [debug] [Thread-4  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:21:15.544259 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:21:15.546593 [debug] [Thread-3  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:21:15.548262 [debug] [Thread-2  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:21:15.560930 [debug] [Thread-4  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:21:15.625505 [debug] [Thread-1  ]: Creating new relation g1_dq_insta_orders_anomalies
[0m18:21:15.686759 [debug] [Thread-3  ]: Creating new relation g1_dq_insta_orders_summary
[0m18:21:15.761494 [debug] [Thread-2  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:21:15.763996 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:21:15.765289 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:21:15.769697 [debug] [Thread-4  ]: Creating new relation g1_dq_insta_users_summary
[0m18:21:15.772713 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */


  create view `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Users

with cln as (
  select * from `clean`.`g1_stg_insta_users`
),
violations as (
  select
    user_id,

    multiIf(
      user_id is null, 'null_user_id',
      user_id <= 0, 'invalid_user_id',
      'ok'
    ) as dq_issue
  from cln
)
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:21:15.775305 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */


  create view `mart`.`g1_dq_insta_orders_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Orders
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  select * from `raw`.`raw___insta_orders`
),

cln as (
  select * from `clean`.`g1_stg_insta_orders`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage Check
nulls as (
  select
    round(100.0 * countIf(order_id is null) / nullif(count(),0), 2) as null_pct_order_id,
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id,
    round(100.0 * countIf(eval_set is null) / nullif(count(),0), 2) as null_pct_eval_set,
    round(100.0 * countIf(order_number is null) / nullif(count(),0), 2) as null_pct_order_number,
    round(100.0 * countIf(order_dow is null) / nullif(count(),0), 2) as null_pct_order_dow,
    round(100.0 * countIf(order_hour_of_day is null) / nullif(count(),0), 2) as null_pct_order_hour_of_day,
    round(100.0 * countIf(days_since_prior_order is null) / nullif(count(),0), 2) as null_pct_days_since_prior_order
  from cln
),

-- Duplicate Orders
dupes as (
  select
    countIf(cnt > 1) as duplicate_orders
  from (
    select order_id, count() as cnt
    from cln
    group by order_id
  )
),

-- Referential Integrity
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_id
  from `clean`.`g1_stg_insta_orders` o
),

-- Value Range Checks
value_ranges as (
  select
    countIf(order_number < 1) as invalid_order_number,
    countIf(order_hour_of_day < 0 or order_hour_of_day > 23) as invalid_order_hour,
    countIf(days_since_prior_order < 0 or days_since_prior_order > 30) as invalid_days_since_prior_order
  from cln
),

-- Join all metrics
joined as (
    select
        counts.row_count_raw,
        counts.row_count_clean,
        (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
        nulls.*,
        dupes.duplicate_orders,
        referential_integrity.invalid_user_id,
        value_ranges.invalid_order_number,
        value_ranges.invalid_order_hour,
        value_ranges.invalid_days_since_prior_order
    from counts
    cross join nulls
    cross join dupes
    cross join referential_integrity
    cross join value_ranges
)

select * from joined
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:21:15.778455 [debug] [Thread-4  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:21:15.780732 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */


  create view `mart`.`g1_dq_insta_orders_anomalies` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Orders
with cln as (
  -- Source cleaned orders data
  select * 
  from `clean`.`g1_stg_insta_orders`
),

users as (
  -- Reference users table for FK validation
  select user_id 
  from `clean`.`g1_stg_insta_users`
),

violations as (
  select
    order_id,
    user_id,
    eval_set,
    order_number,
    order_dow,
    order_hour_of_day,
    days_since_prior_order,

    -- Data Quality Issue Classification
    multiIf(
      order_id is null, 'null_order_id',
      user_id is null, 'null_user_id',
      user_id not in (select user_id from users), 'missing_user_ref',
      order_number < 1, 'invalid_order_number',
      order_dow not in (0,1,2,3,4,5,6), 'invalid_order_dow',
      order_hour_of_day < 0 or order_hour_of_day > 23, 'invalid_order_hour',
      days_since_prior_order < 0, 'negative_days_since_prior_order',
      'ok'
    ) as dq_issue

  from cln
)

-- Return only rows with detected anomalies
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:21:15.789377 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  -- Distinct user IDs extracted from raw orders
  select distinct user_id
  from `raw`.`raw___insta_orders`
),

cln as (
  -- Cleaned users table
  select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage
nulls as (
  select
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
  from cln
),

-- Duplicate Users Check
dupes as (
  select
    countIf(cnt > 1) as duplicate_user_ids
  from (
    select user_id, count() as cnt
    from cln
    group by user_id
  )
),

-- Referential Integrity Checks
-- Ensure all users in orders exist in users, and all users in users appear in at least one order
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_in_orders,
    countIf(u.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_orders`)) as user_without_orders
  from `clean`.`g1_stg_insta_orders` o
  cross join `clean`.`g1_stg_insta_users` u
),

-- Join all metrics
joined as (
  select
    counts.row_count_raw,
    counts.row_count_clean,
    (counts.row_count_raw - counts.row_count_clean) as dropped_rows,

    nulls.null_pct_user_id,
    dupes.duplicate_user_ids,

    referential_integrity.invalid_user_in_orders,
    referential_integrity.user_without_orders
  from counts
  cross join nulls
  cross join dupes
  cross join referential_integrity
)

select * from joined;

joined as (
    select
        counts.row_count_raw,
        counts.row_count_clean,
        (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
        nulls.*,
        dupes.duplicate_orders,
        referential_integrity.invalid_user_id,
        value_ranges.invalid_order_number,
        value_ranges.invalid_order_hour,
        value_ranges.invalid_days_since_prior_order
    from counts
    cross join nulls
    cross join dupes
    cross join referential_integrity
    cross join value_ranges
)

select * from joined
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:21:16.071119 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:21:16.073366 [debug] [Thread-4  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  -- Distinct user IDs extracted from raw orders
  select distinct user_id
  from `raw`.`raw___insta_orders`
),

cln as (
  -- Cleaned users table
  select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage
nulls as (
  select
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
  from cln
),

-- Duplicate Users Check
dupes as (
  select
    countIf(cnt > 1) as duplicate_user_ids
  from (
    select user_id, count() as cnt
    from cln
    group by user_id
  )
),

-- Referential Integrity Checks
-- Ensure all users in orders exist in users, and all users in users appear in at least one order
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_in_orders,
    countIf(u.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_orders`)) as user_without_orders
  from `clean`.`g1_stg_insta_orders` o
  cross join `clean`.`g1_stg_insta_users` u
),

-- Join all metrics
joined as (
  select
    counts.row_count_raw,
    counts.row_count_clean,
    (counts.row_count_raw - counts.row_count_clean) as dropped_rows,

    nulls.null_pct_user_id,
    dupes.duplicate_user_ids,

    referential_integrity.invalid_user_in_orders,
    referential_integrity.user_without_orders
  from counts
  cross join nulls
  cross join dupes
  cross join referential_integrity
)

select * from joined;

joined as (
    select
        counts.row_count_raw,
        counts.row_count_clean,
        (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
        nulls.*,
        dupes.duplicate_orders,
        referential_integrity.invalid_user_id,
        value_ranges.invalid_order_number,
        value_ranges.invalid_order_hour,
        value_ranges.invalid_days_since_prior_order
    from counts
    cross join nulls
    cross join dupes
    cross join referential_integrity
    cross join value_ranges
)

select * from joined
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m18:21:16.081876 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:21:16.096098 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m18:21:16.101840 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5d1fd0b-6f69-4d0a-a112-dbeb5e8a1371', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d175b2cf40>]}
[0m18:21:16.107523 [info ] [Thread-1  ]: 16 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_anomalies` ....... [[32mOK[0m in 0.62s]
[0m18:21:16.110778 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:21:16.118983 [debug] [Thread-4  ]: Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1952 (end of query) (line 78, col 21): ;
  
  joined as (
      select
          counts.row_count_raw,
          counts.row_count_clean,
          (counts.row_count_raw - counts.row_count_clean) as dropped_rows,. Expected one of: token, Dot, OpeningRoundBracket, UUID, alias, AS, identifier, FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:21:16.121453 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5d1fd0b-6f69-4d0a-a112-dbeb5e8a1371', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d176c697c0>]}
[0m18:21:16.123572 [error] [Thread-4  ]: 19 of 19 ERROR creating sql view model `mart`.`g1_dq_insta_users_summary` ...... [[31mERROR[0m in 0.64s]
[0m18:21:16.127600 [debug] [Thread-4  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:21:16.140881 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m18:21:16.147450 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5d1fd0b-6f69-4d0a-a112-dbeb5e8a1371', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d176d2af10>]}
[0m18:21:16.149432 [info ] [Thread-3  ]: 17 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_summary` ......... [[32mOK[0m in 0.67s]
[0m18:21:16.152752 [debug] [Thread-3  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:21:16.401156 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:21:16.404336 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies` to `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m18:21:16.709965 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:21:16.718395 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m18:21:17.012945 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:21:17.017678 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m18:21:17.302686 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:21:17.318280 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  ...
[0m18:21:17.612619 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:21:17.617305 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5d1fd0b-6f69-4d0a-a112-dbeb5e8a1371', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d176c694f0>]}
[0m18:21:17.619443 [info ] [Thread-2  ]: 18 of 19 OK created sql view model `mart`.`g1_dq_insta_users_anomalies` ........ [[32mOK[0m in 2.13s]
[0m18:21:17.622748 [debug] [Thread-2  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:21:17.627389 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:21:17.628985 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m18:21:17.630580 [debug] [MainThread]: On list__clean: Close
[0m18:21:17.632040 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m18:21:17.633563 [debug] [MainThread]: On list__mart: Close
[0m18:21:17.634983 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_anomalies' was left open.
[0m18:21:17.636222 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: Close
[0m18:21:17.637445 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_summary' was left open.
[0m18:21:17.638738 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_summary: Close
[0m18:21:17.639955 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_summary' was left open.
[0m18:21:17.641431 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_summary: Close
[0m18:21:17.643172 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_anomalies' was left open.
[0m18:21:17.644549 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_anomalies: Close
[0m18:21:17.646960 [info ] [MainThread]: 
[0m18:21:17.648545 [info ] [MainThread]: Finished running 2 table models, 13 data tests, 4 view models in 0 hours 0 minutes and 22.98 seconds (22.98s).
[0m18:21:17.669674 [debug] [MainThread]: Command end result
[0m18:21:17.756557 [info ] [MainThread]: 
[0m18:21:17.758261 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m18:21:17.759919 [info ] [MainThread]: 
[0m18:21:17.762009 [error] [MainThread]:   Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1952 (end of query) (line 78, col 21): ;
  
  joined as (
      select
          counts.row_count_raw,
          counts.row_count_clean,
          (counts.row_count_raw - counts.row_count_clean) as dropped_rows,. Expected one of: token, Dot, OpeningRoundBracket, UUID, alias, AS, identifier, FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:21:17.763599 [info ] [MainThread]: 
[0m18:21:17.765071 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m18:21:17.769271 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 25.452333, "process_in_blocks": "0", "process_kernel_time": 2.149105, "process_mem_max_rss": "119152", "process_out_blocks": "11320", "process_user_time": 8.508212}
[0m18:21:17.771098 [debug] [MainThread]: Command `dbt build` failed at 18:21:17.770557 after 25.45 seconds
[0m18:21:17.772379 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d17c11b310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d176cd26d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79d179fae5e0>]}
[0m18:21:17.773426 [debug] [MainThread]: Flushing usage events
[0m18:25:49.858265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7511af7f0310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7511ac451af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7511ac4519a0>]}


============================== 18:25:49.874988 | c3fb0a46-68cb-41e3-ab2c-08dc6e8eaed0 ==============================
[0m18:25:49.874988 [info ] [MainThread]: Running with dbt=1.8.9
[0m18:25:49.876622 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'static_parser': 'True', 'printer_width': '80', 'use_colors': 'True', 'cache_selected_only': 'False', 'write_json': 'True', 'version_check': 'True', 'partial_parse': 'True', 'warn_error': 'None', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'no_print': 'None', 'indirect_selection': 'eager', 'fail_fast': 'False', 'target_path': 'None', 'log_cache_events': 'False', 'empty': 'False', 'debug': 'False', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'profiles_dir': '.', 'log_path': '/workdir/transforms/01_instacart/logs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True'}
[0m18:25:50.245728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c3fb0a46-68cb-41e3-ab2c-08dc6e8eaed0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7511aed983a0>]}
[0m18:25:50.357977 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c3fb0a46-68cb-41e3-ab2c-08dc6e8eaed0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7511ad78feb0>]}
[0m18:25:50.359645 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m18:25:50.558570 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m18:25:50.898638 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m18:25:50.900731 [debug] [MainThread]: Partial parsing: updated file: ex_01_instacart://models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:25:51.572542 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ex_01_mpg.clean
- models.ex_01_mpg.mart
[0m18:25:51.608816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c3fb0a46-68cb-41e3-ab2c-08dc6e8eaed0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7511aa733130>]}
[0m18:25:51.906387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c3fb0a46-68cb-41e3-ab2c-08dc6e8eaed0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7511abbac700>]}
[0m18:25:51.907500 [info ] [MainThread]: Found 6 models, 13 data tests, 1 source, 471 macros
[0m18:25:51.914334 [info ] [MainThread]: 
[0m18:25:51.916794 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:25:51.945296 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:25:51.947888 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:25:51.997785 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:25:52.008899 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:25:56.215116 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:25:56.338553 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:25:56.538470 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:25:56.639364 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:25:56.649803 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m18:25:56.664501 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m18:25:56.701750 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m18:25:56.707627 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m18:25:56.993603 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:25:57.027637 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:25:57.557817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c3fb0a46-68cb-41e3-ab2c-08dc6e8eaed0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7511aec0c970>]}
[0m18:25:57.560192 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m18:25:57.561582 [info ] [MainThread]: 
[0m18:25:57.603101 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:25:57.605891 [info ] [Thread-1  ]: 1 of 19 START sql table model `clean`.`g1_stg_insta_orders` .................... [RUN]
[0m18:25:57.609354 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_instacart.g1_stg_insta_orders'
[0m18:25:57.616074 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_orders
[0m18:25:57.664409 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:25:57.667518 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_orders
[0m18:25:57.856469 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m18:26:01.497315 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

            

    
        create table `clean`.`g1_stg_insta_orders__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (order_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
          )
        
        ...
[0m18:26:01.823055 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:26:01.849484 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    select name, type from system.columns where table = 'g1_stg_insta_orders__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:26:02.143493 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:26:02.153250 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:26:02.154979 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_orders__dbt_backup`
        ("order_id", "user_id", "eval_set", "order_number", "order_dow", "order_hour_of_day", "days_since_prior_order")

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
  ...
[0m18:26:05.067710 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 2.91 seconds
[0m18:26:05.081393 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_orders__dbt_backup` AND `clean`.`g1_stg_insta_orders` 
  
  ...
[0m18:26:05.366721 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:26:05.423043 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    drop table if exists `clean`.`g1_stg_insta_orders__dbt_backup` 
  ...
[0m18:26:05.725550 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:26:05.742428 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3fb0a46-68cb-41e3-ab2c-08dc6e8eaed0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7511abb58040>]}
[0m18:26:05.745642 [info ] [Thread-1  ]: 1 of 19 OK created sql table model `clean`.`g1_stg_insta_orders` ............... [[32mOK[0m in 8.13s]
[0m18:26:05.749668 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:26:05.755199 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:26:05.758641 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:26:05.761732 [info ] [Thread-3  ]: 2 of 19 START test accepted_values_g1_stg_insta_orders_eval_set__prior__train__test  [RUN]
[0m18:26:05.765287 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:26:05.768224 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:26:05.777763 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5'
[0m18:26:05.771463 [info ] [Thread-4  ]: 3 of 19 START test accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [RUN]
[0m18:26:05.781256 [info ] [Thread-2  ]: 4 of 19 START test accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [RUN]
[0m18:26:05.785198 [info ] [Thread-1  ]: 5 of 19 START test not_null_g1_stg_insta_orders_eval_set ....................... [RUN]
[0m18:26:05.790937 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:26:05.796060 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145'
[0m18:26:05.800092 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1'
[0m18:26:05.803080 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_orders, now test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7)
[0m18:26:05.811162 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:26:05.824687 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:26:05.840791 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:26:05.971224 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:26:05.958948 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:26:05.964405 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:26:05.998763 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:26:06.010177 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:26:06.011940 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:26:06.018859 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:26:06.060241 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:26:06.083133 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:26:06.097457 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:26:06.101058 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:26:06.111024 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:26:06.114198 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:26:06.117053 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m18:26:06.118341 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m18:26:06.121774 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select eval_set
from `clean`.`g1_stg_insta_orders`
where eval_set is null



    ) dbt_internal_test...
[0m18:26:06.727673 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.60 seconds
[0m18:26:06.737499 [info ] [Thread-1  ]: 5 of 19 PASS not_null_g1_stg_insta_orders_eval_set ............................. [[32mPASS[0m in 0.93s]
[0m18:26:06.739785 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:26:06.741355 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:26:06.742782 [info ] [Thread-1  ]: 6 of 19 START test not_null_g1_stg_insta_orders_order_dow ...................... [RUN]
[0m18:26:06.744566 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240)
[0m18:26:06.746216 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:26:06.758513 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:26:06.760623 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:26:06.768003 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:26:06.770303 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_dow
from `clean`.`g1_stg_insta_orders`
where order_dow is null



    ) dbt_internal_test...
[0m18:26:07.048794 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:26:07.053391 [info ] [Thread-1  ]: 6 of 19 PASS not_null_g1_stg_insta_orders_order_dow ............................ [[32mPASS[0m in 0.31s]
[0m18:26:07.055344 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:26:07.056900 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:26:07.058190 [info ] [Thread-1  ]: 7 of 19 START test not_null_g1_stg_insta_orders_order_hour_of_day .............. [RUN]
[0m18:26:07.059534 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576)
[0m18:26:07.060937 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:26:07.071834 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:26:07.073712 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:26:07.082014 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:26:07.084850 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_hour_of_day
from `clean`.`g1_stg_insta_orders`
where order_hour_of_day is null



    ) dbt_internal_test...
[0m18:26:07.380344 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:26:07.384797 [info ] [Thread-1  ]: 7 of 19 PASS not_null_g1_stg_insta_orders_order_hour_of_day .................... [[32mPASS[0m in 0.33s]
[0m18:26:07.387152 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:26:07.388800 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:26:07.390634 [info ] [Thread-1  ]: 8 of 19 START test not_null_g1_stg_insta_orders_order_id ....................... [RUN]
[0m18:26:07.392286 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600)
[0m18:26:07.394006 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:26:07.409363 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:26:07.412142 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:26:07.419042 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:26:07.421106 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from `clean`.`g1_stg_insta_orders`
where order_id is null



    ) dbt_internal_test...
[0m18:26:07.731088 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:26:07.735835 [info ] [Thread-1  ]: 8 of 19 PASS not_null_g1_stg_insta_orders_order_id ............................. [[32mPASS[0m in 0.34s]
[0m18:26:07.737820 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:26:07.739238 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:26:07.740670 [info ] [Thread-1  ]: 9 of 19 START test not_null_g1_stg_insta_orders_order_number ................... [RUN]
[0m18:26:07.741878 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619)
[0m18:26:07.743244 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:26:07.754814 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:26:07.756641 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:26:07.763171 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:26:07.764841 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_number
from `clean`.`g1_stg_insta_orders`
where order_number is null



    ) dbt_internal_test...
[0m18:26:08.054119 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:26:08.058654 [info ] [Thread-1  ]: 9 of 19 PASS not_null_g1_stg_insta_orders_order_number ......................... [[32mPASS[0m in 0.32s]
[0m18:26:08.060653 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:26:08.062305 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:26:08.064753 [info ] [Thread-1  ]: 10 of 19 START test not_null_g1_stg_insta_orders_user_id ....................... [RUN]
[0m18:26:08.066804 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619, now test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64)
[0m18:26:08.068483 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:26:08.080186 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:26:08.081825 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:26:08.092214 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:26:08.094367 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_orders`
where user_id is null



    ) dbt_internal_test...
[0m18:26:08.385081 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:26:08.389410 [info ] [Thread-1  ]: 10 of 19 PASS not_null_g1_stg_insta_orders_user_id ............................. [[32mPASS[0m in 0.32s]
[0m18:26:08.391296 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:26:08.392933 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:26:08.394489 [info ] [Thread-1  ]: 11 of 19 START test unique_g1_stg_insta_orders_order_id ........................ [RUN]
[0m18:26:08.395817 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64, now test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57)
[0m18:26:08.397087 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:26:08.413279 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:26:08.415283 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:26:08.422122 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:26:08.424016 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_orders`
where order_id is not null
group by order_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:26:09.197765 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.77 seconds
[0m18:26:09.206823 [info ] [Thread-1  ]: 11 of 19 PASS unique_g1_stg_insta_orders_order_id .............................. [[32mPASS[0m in 0.81s]
[0m18:26:09.213040 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:26:09.687099 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        eval_set as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by eval_set

)

select *
from all_values
where value_field not in (
    'prior','train','test'
)



    ) dbt_internal_test...
[0m18:26:09.770837 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_hour_of_day as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_hour_of_day

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23'
)



    ) dbt_internal_test...
[0m18:26:10.134374 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.45 seconds
[0m18:26:10.136890 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_dow as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_dow

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6'
)



    ) dbt_internal_test...
[0m18:26:10.142058 [info ] [Thread-3  ]: 2 of 19 PASS accepted_values_g1_stg_insta_orders_eval_set__prior__train__test .. [[32mPASS[0m in 4.37s]
[0m18:26:10.144745 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.37 seconds
[0m18:26:10.149373 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:26:10.155548 [info ] [Thread-2  ]: 4 of 19 PASS accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [[32mPASS[0m in 4.36s]
[0m18:26:10.159584 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:26:10.488055 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m18:26:10.492601 [info ] [Thread-4  ]: 3 of 19 PASS accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [[32mPASS[0m in 4.70s]
[0m18:26:10.494521 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:26:10.497321 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_users
[0m18:26:10.499921 [info ] [Thread-1  ]: 12 of 19 START sql table model `clean`.`g1_stg_insta_users` .................... [RUN]
[0m18:26:10.501647 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57, now model.ex_01_instacart.g1_stg_insta_users)
[0m18:26:10.503268 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_users
[0m18:26:10.512235 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:26:10.513954 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_users
[0m18:26:10.526275 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

            

    
        create table `clean`.`g1_stg_insta_users__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (user_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
          )
        
        ...
[0m18:26:10.846155 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:26:10.855084 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    select name, type from system.columns where table = 'g1_stg_insta_users__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:26:11.142567 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:26:11.146723 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:26:11.148976 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_users__dbt_backup`
        ("user_id")

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
  ...
[0m18:26:11.553718 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.40 seconds
[0m18:26:11.557438 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_users__dbt_backup` AND `clean`.`g1_stg_insta_users` 
  
  ...
[0m18:26:11.865452 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:26:11.875272 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    drop table if exists `clean`.`g1_stg_insta_users__dbt_backup` 
  ...
[0m18:26:12.157984 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:26:12.162088 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3fb0a46-68cb-41e3-ab2c-08dc6e8eaed0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7511aa374a60>]}
[0m18:26:12.163763 [info ] [Thread-1  ]: 12 of 19 OK created sql table model `clean`.`g1_stg_insta_users` ............... [[32mOK[0m in 1.66s]
[0m18:26:12.165535 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_users
[0m18:26:12.168597 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:26:12.170034 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:26:12.171586 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:26:12.173161 [info ] [Thread-2  ]: 13 of 19 START test not_null_g1_stg_insta_users_user_id ........................ [RUN]
[0m18:26:12.175727 [info ] [Thread-4  ]: 14 of 19 START test relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [RUN]
[0m18:26:12.178211 [info ] [Thread-3  ]: 15 of 19 START test unique_g1_stg_insta_users_user_id .......................... [RUN]
[0m18:26:12.180284 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1, now test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935)
[0m18:26:12.181802 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145, now test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726)
[0m18:26:12.183562 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5, now test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f)
[0m18:26:12.185360 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:26:12.187026 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:26:12.189256 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:26:12.205387 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:26:12.243902 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:26:12.245229 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:26:12.248269 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:26:12.255325 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:26:12.258294 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:26:12.265188 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:26:12.267585 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:26:12.275839 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:26:12.277536 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_users`
where user_id is null



    ) dbt_internal_test...
[0m18:26:12.279792 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select user_id as from_field
    from `clean`.`g1_stg_insta_orders`
    where user_id is not null
),

parent as (
    select user_id as to_field
    from `clean`.`g1_stg_insta_users`
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null
-- end_of_sql
settings join_use_nulls = 1



    ) dbt_internal_test...
[0m18:26:12.281643 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    user_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_users`
where user_id is not null
group by user_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:26:12.583416 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:26:12.587929 [info ] [Thread-2  ]: 13 of 19 PASS not_null_g1_stg_insta_users_user_id .............................. [[32mPASS[0m in 0.41s]
[0m18:26:12.589924 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:26:12.617403 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:26:12.621739 [info ] [Thread-3  ]: 15 of 19 PASS unique_g1_stg_insta_users_user_id ................................ [[32mPASS[0m in 0.44s]
[0m18:26:12.623729 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:26:12.932234 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.65 seconds
[0m18:26:12.936700 [info ] [Thread-4  ]: 14 of 19 PASS relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [[32mPASS[0m in 0.75s]
[0m18:26:12.939125 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:26:12.942463 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:26:12.944315 [debug] [Thread-2  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:26:12.946237 [debug] [Thread-3  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:26:12.948185 [info ] [Thread-1  ]: 16 of 19 START sql view model `mart`.`g1_dq_insta_orders_anomalies` ............ [RUN]
[0m18:26:12.950746 [debug] [Thread-4  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:26:12.953069 [info ] [Thread-2  ]: 17 of 19 START sql view model `mart`.`g1_dq_insta_orders_summary` .............. [RUN]
[0m18:26:12.956041 [info ] [Thread-3  ]: 18 of 19 START sql view model `mart`.`g1_dq_insta_users_anomalies` ............. [RUN]
[0m18:26:12.958504 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_users, now model.ex_01_instacart.g1_dq_insta_orders_anomalies)
[0m18:26:12.960790 [info ] [Thread-4  ]: 19 of 19 START sql view model `mart`.`g1_dq_insta_users_summary` ............... [RUN]
[0m18:26:12.963432 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935, now model.ex_01_instacart.g1_dq_insta_orders_summary)
[0m18:26:12.965326 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f, now model.ex_01_instacart.g1_dq_insta_users_anomalies)
[0m18:26:12.967745 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:26:12.970538 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726, now model.ex_01_instacart.g1_dq_insta_users_summary)
[0m18:26:12.972709 [debug] [Thread-2  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:26:12.974701 [debug] [Thread-3  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:26:12.989102 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:26:12.990594 [debug] [Thread-4  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:26:13.001959 [debug] [Thread-2  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:26:13.011010 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:26:13.023805 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:26:13.026484 [debug] [Thread-4  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:26:13.029494 [debug] [Thread-2  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:26:13.036625 [debug] [Thread-3  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:26:13.086418 [debug] [Thread-4  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:26:13.159013 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:26:13.165375 [debug] [Thread-4  ]: Creating new relation g1_dq_insta_users_summary
[0m18:26:13.172320 [debug] [Thread-4  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:26:13.182474 [debug] [Thread-2  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:26:13.177719 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:26:13.185465 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */


  create view `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Orders
with cln as (
  -- Source cleaned orders data
  select * 
  from `clean`.`g1_stg_insta_orders`
),

users as (
  -- Reference users table for FK validation
  select user_id 
  from `clean`.`g1_stg_insta_users`
),

violations as (
  select
    order_id,
    user_id,
    eval_set,
    order_number,
    order_dow,
    order_hour_of_day,
    days_since_prior_order,

    -- Data Quality Issue Classification
    multiIf(
      order_id is null, 'null_order_id',
      user_id is null, 'null_user_id',
      user_id not in (select user_id from users), 'missing_user_ref',
      order_number < 1, 'invalid_order_number',
      order_dow not in (0,1,2,3,4,5,6), 'invalid_order_dow',
      order_hour_of_day < 0 or order_hour_of_day > 23, 'invalid_order_hour',
      days_since_prior_order < 0, 'negative_days_since_prior_order',
      'ok'
    ) as dq_issue

  from cln
)

-- Return only rows with detected anomalies
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:26:13.187983 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  -- Distinct user IDs extracted from raw orders
  select distinct user_id
  from `raw`.`raw___insta_orders`
),

cln as (
  -- Cleaned users table
  select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage
nulls as (
  select
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
  from cln
),

-- Duplicate Users Check
dupes as (
  select
    countIf(cnt > 1) as duplicate_user_ids
  from (
    select user_id, count() as cnt
    from cln
    group by user_id
  )
),

-- Referential Integrity Checks
-- Ensure all users in orders exist in users, and all users in users appear in at least one order
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_in_orders,
    countIf(u.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_orders`)) as user_without_orders
  from `clean`.`g1_stg_insta_orders` o
  cross join `clean`.`g1_stg_insta_users` u
),

-- Join all metrics
joined as (
  select
    counts.row_count_raw,
    counts.row_count_clean,
    (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
    nulls.null_pct_user_id,
    dupes.duplicate_user_ids,
    referential_integrity.invalid_user_in_orders,
    referential_integrity.user_without_orders
  from counts
  cross join nulls
  cross join dupes
  cross join referential_integrity
)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:26:13.191916 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */


  create view `mart`.`g1_dq_insta_orders_summary__dbt_tmp` 
  
    
    
  as (
    

-- Data Quality Summary for Orders
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  select * from `raw`.`raw___insta_orders`
),

cln as (
  select * from `clean`.`g1_stg_insta_orders`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage Check
nulls as (
  select
    round(100.0 * countIf(order_id is null) / nullif(count(),0), 2) as null_pct_order_id,
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id,
    round(100.0 * countIf(eval_set is null) / nullif(count(),0), 2) as null_pct_eval_set,
    round(100.0 * countIf(order_number is null) / nullif(count(),0), 2) as null_pct_order_number,
    round(100.0 * countIf(order_dow is null) / nullif(count(),0), 2) as null_pct_order_dow,
    round(100.0 * countIf(order_hour_of_day is null) / nullif(count(),0), 2) as null_pct_order_hour_of_day,
    round(100.0 * countIf(days_since_prior_order is null) / nullif(count(),0), 2) as null_pct_days_since_prior_order
  from cln
),

-- Duplicate Orders
dupes as (
  select
    countIf(cnt > 1) as duplicate_orders
  from (
    select order_id, count() as cnt
    from cln
    group by order_id
  )
),

-- Referential Integrity
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_id
  from `clean`.`g1_stg_insta_orders` o
),

-- Value Range Checks
value_ranges as (
  select
    countIf(order_number < 1) as invalid_order_number,
    countIf(order_hour_of_day < 0 or order_hour_of_day > 23) as invalid_order_hour,
    countIf(days_since_prior_order < 0 or days_since_prior_order > 30) as invalid_days_since_prior_order
  from cln
),

-- Join all metrics
joined as (
    select
        counts.row_count_raw,
        counts.row_count_clean,
        (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
        nulls.*,
        dupes.duplicate_orders,
        referential_integrity.invalid_user_id,
        value_ranges.invalid_order_number,
        value_ranges.invalid_order_hour,
        value_ranges.invalid_days_since_prior_order
    from counts
    cross join nulls
    cross join dupes
    cross join referential_integrity
    cross join value_ranges
)

select * from joined
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:26:13.194372 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */


  create view `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Users

with cln as (
  select * from `clean`.`g1_stg_insta_users`
),
violations as (
  select
    user_id,

    multiIf(
      user_id is null, 'null_user_id',
      user_id <= 0, 'invalid_user_id',
      'ok'
    ) as dq_issue
  from cln
)
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:26:13.492176 [debug] [Thread-4  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  -- Distinct user IDs extracted from raw orders
  select distinct user_id
  from `raw`.`raw___insta_orders`
),

cln as (
  -- Cleaned users table
  select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage
nulls as (
  select
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
  from cln
),

-- Duplicate Users Check
dupes as (
  select
    countIf(cnt > 1) as duplicate_user_ids
  from (
    select user_id, count() as cnt
    from cln
    group by user_id
  )
),

-- Referential Integrity Checks
-- Ensure all users in orders exist in users, and all users in users appear in at least one order
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_in_orders,
    countIf(u.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_orders`)) as user_without_orders
  from `clean`.`g1_stg_insta_orders` o
  cross join `clean`.`g1_stg_insta_users` u
),

-- Join all metrics
joined as (
  select
    counts.row_count_raw,
    counts.row_count_clean,
    (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
    nulls.null_pct_user_id,
    dupes.duplicate_user_ids,
    referential_integrity.invalid_user_in_orders,
    referential_integrity.user_without_orders
  from counts
  cross join nulls
  cross join dupes
  cross join referential_integrity
)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m18:26:13.494985 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:26:13.497521 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:26:13.532492 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m18:26:13.538239 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m18:26:13.547850 [debug] [Thread-4  ]: Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1950 (end of query) (line 76, col 21): ;
      
    )
        
        
                      -- end_of_sql
                      
                      . Expected one of: token, Dot, OpeningRoundBracket, UUID, alias, AS, identifier, FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:26:13.549295 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3fb0a46-68cb-41e3-ab2c-08dc6e8eaed0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7511a925cfa0>]}
[0m18:26:13.551254 [error] [Thread-4  ]: 19 of 19 ERROR creating sql view model `mart`.`g1_dq_insta_users_summary` ...... [[31mERROR[0m in 0.58s]
[0m18:26:13.554257 [debug] [Thread-4  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:26:13.556806 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m18:26:13.569545 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m18:26:13.863651 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:26:13.869176 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:26:13.866303 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:26:13.872738 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies` to `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m18:26:13.876238 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary` to `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m18:26:13.879509 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies` to `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m18:26:14.210150 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:26:14.212858 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:26:14.215487 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:26:14.226047 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m18:26:14.236032 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m18:26:14.244637 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m18:26:14.564737 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:26:14.567388 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:26:14.569365 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:26:14.573340 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m18:26:14.577166 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m18:26:14.580852 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary__dbt_tmp` to `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m18:26:14.883770 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:26:14.893868 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  ...
[0m18:26:14.939890 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:26:14.942150 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m18:26:14.952356 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  ...
[0m18:26:14.964334 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  ...
[0m18:26:15.176790 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:26:15.180931 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3fb0a46-68cb-41e3-ab2c-08dc6e8eaed0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7511a91a5f10>]}
[0m18:26:15.182476 [info ] [Thread-1  ]: 16 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_anomalies` ....... [[32mOK[0m in 2.22s]
[0m18:26:15.184363 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:26:15.239766 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:26:15.243373 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3fb0a46-68cb-41e3-ab2c-08dc6e8eaed0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7511a9257eb0>]}
[0m18:26:15.245085 [info ] [Thread-2  ]: 17 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_summary` ......... [[32mOK[0m in 2.28s]
[0m18:26:15.247742 [debug] [Thread-2  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:26:15.265089 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:26:15.269291 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3fb0a46-68cb-41e3-ab2c-08dc6e8eaed0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7511a925c2e0>]}
[0m18:26:15.271139 [info ] [Thread-3  ]: 18 of 19 OK created sql view model `mart`.`g1_dq_insta_users_anomalies` ........ [[32mOK[0m in 2.30s]
[0m18:26:15.274035 [debug] [Thread-3  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:26:15.279281 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:26:15.280512 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m18:26:15.281755 [debug] [MainThread]: On list__clean: Close
[0m18:26:15.283484 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m18:26:15.284649 [debug] [MainThread]: On list__mart: Close
[0m18:26:15.285606 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_anomalies' was left open.
[0m18:26:15.286655 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: Close
[0m18:26:15.287451 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_anomalies' was left open.
[0m18:26:15.288272 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_anomalies: Close
[0m18:26:15.289332 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_summary' was left open.
[0m18:26:15.290456 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_summary: Close
[0m18:26:15.291357 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_summary' was left open.
[0m18:26:15.292174 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_summary: Close
[0m18:26:15.294249 [info ] [MainThread]: 
[0m18:26:15.295765 [info ] [MainThread]: Finished running 2 table models, 13 data tests, 4 view models in 0 hours 0 minutes and 23.38 seconds (23.38s).
[0m18:26:15.310178 [debug] [MainThread]: Command end result
[0m18:26:15.395382 [info ] [MainThread]: 
[0m18:26:15.396619 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m18:26:15.398126 [info ] [MainThread]: 
[0m18:26:15.399969 [error] [MainThread]:   Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1950 (end of query) (line 76, col 21): ;
      
    )
        
        
                      -- end_of_sql
                      
                      . Expected one of: token, Dot, OpeningRoundBracket, UUID, alias, AS, identifier, FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:26:15.401353 [info ] [MainThread]: 
[0m18:26:15.402798 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m18:26:15.405353 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 25.688198, "process_in_blocks": "0", "process_kernel_time": 1.859456, "process_mem_max_rss": "119520", "process_out_blocks": "11320", "process_user_time": 8.706914}
[0m18:26:15.406949 [debug] [MainThread]: Command `dbt build` failed at 18:26:15.406524 after 25.69 seconds
[0m18:26:15.408199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7511af7f0310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7511aa83e070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7511ad78f850>]}
[0m18:26:15.409396 [debug] [MainThread]: Flushing usage events
[0m18:33:41.258484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70fa4d2ba310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70fa49f0ca90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70fa49f0c940>]}


============================== 18:33:41.272192 | 90069e4c-d7a8-440d-a58d-ef4991e038f8 ==============================
[0m18:33:41.272192 [info ] [MainThread]: Running with dbt=1.8.9
[0m18:33:41.273969 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'debug': 'False', 'partial_parse': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False', 'fail_fast': 'False', 'log_cache_events': 'False', 'no_print': 'None', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'introspect': 'True', 'target_path': 'None', 'write_json': 'True', 'log_format': 'default', 'profiles_dir': '.', 'version_check': 'True', 'warn_error': 'None', 'empty': 'False', 'printer_width': '80', 'log_path': '/workdir/transforms/01_instacart/logs'}
[0m18:33:41.638244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '90069e4c-d7a8-440d-a58d-ef4991e038f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70fa4c84efd0>]}
[0m18:33:41.822870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '90069e4c-d7a8-440d-a58d-ef4991e038f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70fa4a9e7430>]}
[0m18:33:41.824542 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m18:33:42.047929 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m18:33:42.477484 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m18:33:42.479582 [debug] [MainThread]: Partial parsing: updated file: ex_01_instacart://models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:33:43.288190 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ex_01_mpg.clean
- models.ex_01_mpg.mart
[0m18:33:43.330344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '90069e4c-d7a8-440d-a58d-ef4991e038f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70fa481ed130>]}
[0m18:33:43.668724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '90069e4c-d7a8-440d-a58d-ef4991e038f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70fa481744f0>]}
[0m18:33:43.669965 [info ] [MainThread]: Found 6 models, 13 data tests, 1 source, 471 macros
[0m18:33:43.679246 [info ] [MainThread]: 
[0m18:33:43.682828 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:33:43.706166 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:33:43.719438 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:33:43.760070 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:33:43.769450 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:33:48.057737 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:33:48.085660 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:33:48.387880 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:33:48.390013 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:33:48.432645 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m18:33:48.434958 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m18:33:48.455668 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m18:33:48.462431 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m18:33:48.821995 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m18:33:48.828980 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.37 seconds
[0m18:33:49.197549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '90069e4c-d7a8-440d-a58d-ef4991e038f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70fa48096f10>]}
[0m18:33:49.198914 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m18:33:49.199969 [info ] [MainThread]: 
[0m18:33:49.223276 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:33:49.225582 [info ] [Thread-1  ]: 1 of 19 START sql table model `clean`.`g1_stg_insta_orders` .................... [RUN]
[0m18:33:49.228606 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_instacart.g1_stg_insta_orders'
[0m18:33:49.230548 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_orders
[0m18:33:49.257383 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:33:49.260345 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_orders
[0m18:33:49.379202 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m18:33:53.532295 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

            

    
        create table `clean`.`g1_stg_insta_orders__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (order_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
          )
        
        ...
[0m18:33:53.847544 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:33:53.891442 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    select name, type from system.columns where table = 'g1_stg_insta_orders__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:33:54.170974 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:33:54.188794 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:33:54.192366 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_orders__dbt_backup`
        ("order_id", "user_id", "eval_set", "order_number", "order_dow", "order_hour_of_day", "days_since_prior_order")

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
  ...
[0m18:33:57.836503 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 3.64 seconds
[0m18:33:57.846335 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_orders__dbt_backup` AND `clean`.`g1_stg_insta_orders` 
  
  ...
[0m18:33:58.144852 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:33:58.198398 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    drop table if exists `clean`.`g1_stg_insta_orders__dbt_backup` 
  ...
[0m18:33:58.484418 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:33:58.493491 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90069e4c-d7a8-440d-a58d-ef4991e038f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70fa47e616a0>]}
[0m18:33:58.495104 [info ] [Thread-1  ]: 1 of 19 OK created sql table model `clean`.`g1_stg_insta_orders` ............... [[32mOK[0m in 9.26s]
[0m18:33:58.496804 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:33:58.500062 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:33:58.501415 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:33:58.503548 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:33:58.506820 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:33:58.504890 [info ] [Thread-3  ]: 2 of 19 START test accepted_values_g1_stg_insta_orders_eval_set__prior__train__test  [RUN]
[0m18:33:58.509656 [info ] [Thread-4  ]: 3 of 19 START test accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [RUN]
[0m18:33:58.511974 [info ] [Thread-2  ]: 4 of 19 START test accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [RUN]
[0m18:33:58.514318 [info ] [Thread-1  ]: 5 of 19 START test not_null_g1_stg_insta_orders_eval_set ....................... [RUN]
[0m18:33:58.517822 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5'
[0m18:33:58.519993 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145'
[0m18:33:58.522000 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1'
[0m18:33:58.524356 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_orders, now test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7)
[0m18:33:58.526465 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:33:58.528095 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:33:58.529812 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:33:58.531397 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:33:58.599212 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:33:58.604127 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:33:58.606176 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:33:58.633544 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:33:58.635218 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:33:58.637388 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:33:58.638745 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:33:58.646998 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:33:58.752632 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:33:58.754871 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:33:58.768023 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:33:58.770468 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:33:58.773700 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m18:33:58.776005 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:33:58.779087 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select eval_set
from `clean`.`g1_stg_insta_orders`
where eval_set is null



    ) dbt_internal_test...
[0m18:33:58.782968 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m18:33:59.370523 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.58 seconds
[0m18:33:59.382465 [info ] [Thread-1  ]: 5 of 19 PASS not_null_g1_stg_insta_orders_eval_set ............................. [[32mPASS[0m in 0.86s]
[0m18:33:59.385933 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:33:59.388013 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:33:59.389749 [info ] [Thread-1  ]: 6 of 19 START test not_null_g1_stg_insta_orders_order_dow ...................... [RUN]
[0m18:33:59.391824 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240)
[0m18:33:59.394502 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:33:59.407542 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:33:59.409580 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:33:59.416337 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:33:59.418246 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_dow
from `clean`.`g1_stg_insta_orders`
where order_dow is null



    ) dbt_internal_test...
[0m18:33:59.733874 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:33:59.738078 [info ] [Thread-1  ]: 6 of 19 PASS not_null_g1_stg_insta_orders_order_dow ............................ [[32mPASS[0m in 0.35s]
[0m18:33:59.739985 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:33:59.741378 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:33:59.742954 [info ] [Thread-1  ]: 7 of 19 START test not_null_g1_stg_insta_orders_order_hour_of_day .............. [RUN]
[0m18:33:59.744618 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576)
[0m18:33:59.745991 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:33:59.756281 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:33:59.757792 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:33:59.764194 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:33:59.766124 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_hour_of_day
from `clean`.`g1_stg_insta_orders`
where order_hour_of_day is null



    ) dbt_internal_test...
[0m18:34:00.054399 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:34:00.058587 [info ] [Thread-1  ]: 7 of 19 PASS not_null_g1_stg_insta_orders_order_hour_of_day .................... [[32mPASS[0m in 0.31s]
[0m18:34:00.060436 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:34:00.062047 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:34:00.063337 [info ] [Thread-1  ]: 8 of 19 START test not_null_g1_stg_insta_orders_order_id ....................... [RUN]
[0m18:34:00.064522 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600)
[0m18:34:00.065651 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:34:00.076069 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:34:00.077943 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:34:00.084527 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:34:00.086359 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from `clean`.`g1_stg_insta_orders`
where order_id is null



    ) dbt_internal_test...
[0m18:34:00.363444 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:34:00.370030 [info ] [Thread-1  ]: 8 of 19 PASS not_null_g1_stg_insta_orders_order_id ............................. [[32mPASS[0m in 0.30s]
[0m18:34:00.373492 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:34:00.375799 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:34:00.378828 [info ] [Thread-1  ]: 9 of 19 START test not_null_g1_stg_insta_orders_order_number ................... [RUN]
[0m18:34:00.380589 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619)
[0m18:34:00.382130 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:34:00.393876 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:34:00.397366 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:34:00.404985 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:34:00.406849 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_number
from `clean`.`g1_stg_insta_orders`
where order_number is null



    ) dbt_internal_test...
[0m18:34:00.711853 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:34:00.716222 [info ] [Thread-1  ]: 9 of 19 PASS not_null_g1_stg_insta_orders_order_number ......................... [[32mPASS[0m in 0.34s]
[0m18:34:00.718788 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:34:00.720481 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:34:00.722215 [info ] [Thread-1  ]: 10 of 19 START test not_null_g1_stg_insta_orders_user_id ....................... [RUN]
[0m18:34:00.724043 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619, now test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64)
[0m18:34:00.725406 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:34:00.736337 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:34:00.737899 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:34:00.747998 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:34:00.750129 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_orders`
where user_id is null



    ) dbt_internal_test...
[0m18:34:01.066741 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:34:01.073620 [info ] [Thread-1  ]: 10 of 19 PASS not_null_g1_stg_insta_orders_user_id ............................. [[32mPASS[0m in 0.35s]
[0m18:34:01.076770 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:34:01.078430 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:34:01.080027 [info ] [Thread-1  ]: 11 of 19 START test unique_g1_stg_insta_orders_order_id ........................ [RUN]
[0m18:34:01.082038 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64, now test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57)
[0m18:34:01.084876 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:34:01.103207 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:34:01.105113 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:34:01.112182 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:34:01.114393 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_orders`
where order_id is not null
group by order_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:34:01.790930 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.68 seconds
[0m18:34:01.795334 [info ] [Thread-1  ]: 11 of 19 PASS unique_g1_stg_insta_orders_order_id .............................. [[32mPASS[0m in 0.71s]
[0m18:34:01.797325 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:34:02.305458 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_dow as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_dow

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6'
)



    ) dbt_internal_test...
[0m18:34:02.538929 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_hour_of_day as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_hour_of_day

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23'
)



    ) dbt_internal_test...
[0m18:34:02.541363 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        eval_set as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by eval_set

)

select *
from all_values
where value_field not in (
    'prior','train','test'
)



    ) dbt_internal_test...
[0m18:34:02.626686 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:34:02.630844 [info ] [Thread-4  ]: 3 of 19 PASS accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [[32mPASS[0m in 4.11s]
[0m18:34:02.632936 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:34:02.901232 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m18:34:02.906037 [info ] [Thread-2  ]: 4 of 19 PASS accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [[32mPASS[0m in 4.38s]
[0m18:34:02.908365 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:34:02.910418 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.37 seconds
[0m18:34:02.915405 [info ] [Thread-3  ]: 2 of 19 PASS accepted_values_g1_stg_insta_orders_eval_set__prior__train__test .. [[32mPASS[0m in 4.40s]
[0m18:34:02.918445 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:34:02.921932 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_users
[0m18:34:02.923911 [info ] [Thread-1  ]: 12 of 19 START sql table model `clean`.`g1_stg_insta_users` .................... [RUN]
[0m18:34:02.925781 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57, now model.ex_01_instacart.g1_stg_insta_users)
[0m18:34:02.927137 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_users
[0m18:34:02.937316 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:34:02.938997 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_users
[0m18:34:02.950899 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

            

    
        create table `clean`.`g1_stg_insta_users__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (user_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
          )
        
        ...
[0m18:34:03.240825 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:34:03.247934 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    select name, type from system.columns where table = 'g1_stg_insta_users__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:34:03.542151 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:34:03.546528 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:34:03.548131 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_users__dbt_backup`
        ("user_id")

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
  ...
[0m18:34:03.948047 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.40 seconds
[0m18:34:03.951530 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_users__dbt_backup` AND `clean`.`g1_stg_insta_users` 
  
  ...
[0m18:34:04.239803 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:34:04.250277 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    drop table if exists `clean`.`g1_stg_insta_users__dbt_backup` 
  ...
[0m18:34:04.540409 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:34:04.543966 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90069e4c-d7a8-440d-a58d-ef4991e038f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70fa47d16280>]}
[0m18:34:04.545809 [info ] [Thread-1  ]: 12 of 19 OK created sql table model `clean`.`g1_stg_insta_users` ............... [[32mOK[0m in 1.62s]
[0m18:34:04.548942 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_users
[0m18:34:04.551934 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:34:04.553398 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:34:04.557563 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:34:04.555228 [info ] [Thread-2  ]: 13 of 19 START test not_null_g1_stg_insta_users_user_id ........................ [RUN]
[0m18:34:04.560223 [info ] [Thread-3  ]: 14 of 19 START test relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [RUN]
[0m18:34:04.564988 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1, now test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935)
[0m18:34:04.562523 [info ] [Thread-4  ]: 15 of 19 START test unique_g1_stg_insta_users_user_id .......................... [RUN]
[0m18:34:04.567616 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5, now test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726)
[0m18:34:04.569248 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:34:04.570897 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145, now test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f)
[0m18:34:04.572922 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:34:04.588065 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:34:04.589755 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:34:04.614336 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:34:04.626574 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:34:04.625459 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:34:04.634619 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:34:04.636525 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:34:04.645308 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:34:04.646845 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_users`
where user_id is null



    ) dbt_internal_test...
[0m18:34:04.648202 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:34:04.659941 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:34:04.662040 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select user_id as from_field
    from `clean`.`g1_stg_insta_orders`
    where user_id is not null
),

parent as (
    select user_id as to_field
    from `clean`.`g1_stg_insta_users`
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null
-- end_of_sql
settings join_use_nulls = 1



    ) dbt_internal_test...
[0m18:34:04.663869 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    user_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_users`
where user_id is not null
group by user_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:34:04.934924 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:34:04.939662 [info ] [Thread-2  ]: 13 of 19 PASS not_null_g1_stg_insta_users_user_id .............................. [[32mPASS[0m in 0.37s]
[0m18:34:04.941837 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:34:05.049586 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m18:34:05.053905 [info ] [Thread-4  ]: 15 of 19 PASS unique_g1_stg_insta_users_user_id ................................ [[32mPASS[0m in 0.48s]
[0m18:34:05.055812 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:34:05.525625 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.86 seconds
[0m18:34:05.530121 [info ] [Thread-3  ]: 14 of 19 PASS relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [[32mPASS[0m in 0.96s]
[0m18:34:05.532750 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:34:05.536683 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:34:05.538781 [debug] [Thread-2  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:34:05.544123 [debug] [Thread-4  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:34:05.541416 [info ] [Thread-1  ]: 16 of 19 START sql view model `mart`.`g1_dq_insta_orders_anomalies` ............ [RUN]
[0m18:34:05.546919 [debug] [Thread-3  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:34:05.550029 [info ] [Thread-2  ]: 17 of 19 START sql view model `mart`.`g1_dq_insta_orders_summary` .............. [RUN]
[0m18:34:05.553727 [info ] [Thread-4  ]: 18 of 19 START sql view model `mart`.`g1_dq_insta_users_anomalies` ............. [RUN]
[0m18:34:05.556450 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_users, now model.ex_01_instacart.g1_dq_insta_orders_anomalies)
[0m18:34:05.559163 [info ] [Thread-3  ]: 19 of 19 START sql view model `mart`.`g1_dq_insta_users_summary` ............... [RUN]
[0m18:34:05.562175 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935, now model.ex_01_instacart.g1_dq_insta_orders_summary)
[0m18:34:05.564898 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f, now model.ex_01_instacart.g1_dq_insta_users_anomalies)
[0m18:34:05.567739 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:34:05.570926 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726, now model.ex_01_instacart.g1_dq_insta_users_summary)
[0m18:34:05.573834 [debug] [Thread-2  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:34:05.576315 [debug] [Thread-4  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:34:05.591884 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:34:05.594123 [debug] [Thread-3  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:34:05.609034 [debug] [Thread-2  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:34:05.620526 [debug] [Thread-4  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:34:05.635674 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:34:05.638766 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:34:05.641799 [debug] [Thread-2  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:34:05.649632 [debug] [Thread-4  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:34:05.673790 [debug] [Thread-3  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:34:05.843482 [debug] [Thread-3  ]: Creating new relation g1_dq_insta_users_summary
[0m18:34:05.970063 [debug] [Thread-2  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:34:05.973951 [debug] [Thread-4  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:34:05.977709 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:34:05.981626 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */


  create view `mart`.`g1_dq_insta_orders_summary__dbt_tmp` 
  
    
    
  as (
    

-- Data Quality Summary for Orders
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  select * from `raw`.`raw___insta_orders`
),

cln as (
  select * from `clean`.`g1_stg_insta_orders`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage Check
nulls as (
  select
    round(100.0 * countIf(order_id is null) / nullif(count(),0), 2) as null_pct_order_id,
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id,
    round(100.0 * countIf(eval_set is null) / nullif(count(),0), 2) as null_pct_eval_set,
    round(100.0 * countIf(order_number is null) / nullif(count(),0), 2) as null_pct_order_number,
    round(100.0 * countIf(order_dow is null) / nullif(count(),0), 2) as null_pct_order_dow,
    round(100.0 * countIf(order_hour_of_day is null) / nullif(count(),0), 2) as null_pct_order_hour_of_day,
    round(100.0 * countIf(days_since_prior_order is null) / nullif(count(),0), 2) as null_pct_days_since_prior_order
  from cln
),

-- Duplicate Orders
dupes as (
  select
    countIf(cnt > 1) as duplicate_orders
  from (
    select order_id, count() as cnt
    from cln
    group by order_id
  )
),

-- Referential Integrity
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_id
  from `clean`.`g1_stg_insta_orders` o
),

-- Value Range Checks
value_ranges as (
  select
    countIf(order_number < 1) as invalid_order_number,
    countIf(order_hour_of_day < 0 or order_hour_of_day > 23) as invalid_order_hour,
    countIf(days_since_prior_order < 0 or days_since_prior_order > 30) as invalid_days_since_prior_order
  from cln
),

-- Join all metrics
joined as (
    select
        counts.row_count_raw,
        counts.row_count_clean,
        (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
        nulls.*,
        dupes.duplicate_orders,
        referential_integrity.invalid_user_id,
        value_ranges.invalid_order_number,
        value_ranges.invalid_order_hour,
        value_ranges.invalid_days_since_prior_order
    from counts
    cross join nulls
    cross join dupes
    cross join referential_integrity
    cross join value_ranges
)

select * from joined
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:34:05.983415 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:34:05.991721 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */


  create view `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Users

with cln as (
  select * from `clean`.`g1_stg_insta_users`
),
violations as (
  select
    user_id,

    multiIf(
      user_id is null, 'null_user_id',
      user_id <= 0, 'invalid_user_id',
      'ok'
    ) as dq_issue
  from cln
)
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:34:05.996063 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */


  create view `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Orders
with cln as (
  -- Source cleaned orders data
  select * 
  from `clean`.`g1_stg_insta_orders`
),

users as (
  -- Reference users table for FK validation
  select user_id 
  from `clean`.`g1_stg_insta_users`
),

violations as (
  select
    order_id,
    user_id,
    eval_set,
    order_number,
    order_dow,
    order_hour_of_day,
    days_since_prior_order,

    -- Data Quality Issue Classification
    multiIf(
      order_id is null, 'null_order_id',
      user_id is null, 'null_user_id',
      user_id not in (select user_id from users), 'missing_user_ref',
      order_number < 1, 'invalid_order_number',
      order_dow not in (0,1,2,3,4,5,6), 'invalid_order_dow',
      order_hour_of_day < 0 or order_hour_of_day > 23, 'invalid_order_hour',
      days_since_prior_order < 0, 'negative_days_since_prior_order',
      'ok'
    ) as dq_issue

  from cln
)

-- Return only rows with detected anomalies
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:34:06.002549 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  -- Distinct user IDs extracted from raw orders
  select distinct user_id
  from `raw`.`raw___insta_orders`
),

cln as (
  -- Cleaned users table
  select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage
nulls as (
  select
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
  from cln
),

-- Duplicate Users Check
dupes as (
  select
    countIf(cnt > 1) as duplicate_user_ids
  from (
    select user_id, count() as cnt
    from cln
    group by user_id
  )
),

-- Referential Integrity
invalid_user_in_orders as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),

user_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

-- Join all metrics
joined as (
  select
    counts.row_count_raw,
    counts.row_count_clean,
    (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
    nulls.null_pct_user_id,
    dupes.duplicate_user_ids,
    referential_integrity.invalid_user_in_orders,
    referential_integrity.user_without_orders
  from counts
  cross join nulls
  cross join dupes
  cross join referential_integrity
)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:34:06.294126 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:34:06.297352 [debug] [Thread-3  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  -- Distinct user IDs extracted from raw orders
  select distinct user_id
  from `raw`.`raw___insta_orders`
),

cln as (
  -- Cleaned users table
  select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage
nulls as (
  select
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
  from cln
),

-- Duplicate Users Check
dupes as (
  select
    countIf(cnt > 1) as duplicate_user_ids
  from (
    select user_id, count() as cnt
    from cln
    group by user_id
  )
),

-- Referential Integrity
invalid_user_in_orders as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),

user_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

-- Join all metrics
joined as (
  select
    counts.row_count_raw,
    counts.row_count_clean,
    (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
    nulls.null_pct_user_id,
    dupes.duplicate_user_ids,
    referential_integrity.invalid_user_in_orders,
    referential_integrity.user_without_orders
  from counts
  cross join nulls
  cross join dupes
  cross join referential_integrity
)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m18:34:06.320796 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m18:34:06.328505 [debug] [Thread-3  ]: Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1412 ('joined') (line 64, col 1): joined as (
    select
      counts.row_count_raw,
      counts.row_count_clean,
      (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
      nulls.null_p. Expected one of: token, Comma, FROM, SELECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:34:06.329934 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90069e4c-d7a8-440d-a58d-ef4991e038f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70fa46bfd400>]}
[0m18:34:06.331587 [error] [Thread-3  ]: 19 of 19 ERROR creating sql view model `mart`.`g1_dq_insta_users_summary` ...... [[31mERROR[0m in 0.76s]
[0m18:34:06.333674 [debug] [Thread-3  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:34:06.357890 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:34:06.366441 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m18:34:06.371031 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m18:34:06.382703 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m18:34:06.619509 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:34:06.622966 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies` to `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m18:34:06.666810 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:34:06.668765 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:34:06.671921 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies` to `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m18:34:06.675295 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary` to `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m18:34:06.901422 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:34:06.913864 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m18:34:06.996535 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:34:06.998246 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:34:07.007857 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m18:34:07.016641 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m18:34:07.208109 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:34:07.211220 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m18:34:07.353699 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:34:07.356272 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m18:34:07.359894 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m18:34:07.363765 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary__dbt_tmp` to `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m18:34:07.555086 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m18:34:07.565778 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  ...
[0m18:34:07.716010 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:34:07.723373 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m18:34:07.729286 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  ...
[0m18:34:07.740571 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  ...
[0m18:34:08.016902 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.45 seconds
[0m18:34:08.021001 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90069e4c-d7a8-440d-a58d-ef4991e038f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70fa46c8c7f0>]}
[0m18:34:08.022789 [info ] [Thread-4  ]: 18 of 19 OK created sql view model `mart`.`g1_dq_insta_users_anomalies` ........ [[32mOK[0m in 2.46s]
[0m18:34:08.024960 [debug] [Thread-4  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:34:08.152335 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:34:08.155820 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:34:08.163503 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90069e4c-d7a8-440d-a58d-ef4991e038f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70fa46b49f10>]}
[0m18:34:08.172408 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90069e4c-d7a8-440d-a58d-ef4991e038f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70fa46c8cdc0>]}
[0m18:34:08.175393 [info ] [Thread-1  ]: 16 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_anomalies` ....... [[32mOK[0m in 2.61s]
[0m18:34:08.178167 [info ] [Thread-2  ]: 17 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_summary` ......... [[32mOK[0m in 2.61s]
[0m18:34:08.180941 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:34:08.183310 [debug] [Thread-2  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:34:08.189857 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:34:08.190905 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m18:34:08.191882 [debug] [MainThread]: On list__mart: Close
[0m18:34:08.192873 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m18:34:08.194006 [debug] [MainThread]: On list__clean: Close
[0m18:34:08.195375 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_anomalies' was left open.
[0m18:34:08.196430 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: Close
[0m18:34:08.197624 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_summary' was left open.
[0m18:34:08.198519 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_summary: Close
[0m18:34:08.199574 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_anomalies' was left open.
[0m18:34:08.201472 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_anomalies: Close
[0m18:34:08.202562 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_summary' was left open.
[0m18:34:08.203728 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_summary: Close
[0m18:34:08.206107 [info ] [MainThread]: 
[0m18:34:08.207516 [info ] [MainThread]: Finished running 2 table models, 13 data tests, 4 view models in 0 hours 0 minutes and 24.52 seconds (24.52s).
[0m18:34:08.221177 [debug] [MainThread]: Command end result
[0m18:34:08.304619 [info ] [MainThread]: 
[0m18:34:08.305748 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m18:34:08.306901 [info ] [MainThread]: 
[0m18:34:08.308681 [error] [MainThread]:   Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1412 ('joined') (line 64, col 1): joined as (
    select
      counts.row_count_raw,
      counts.row_count_clean,
      (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
      nulls.null_p. Expected one of: token, Comma, FROM, SELECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:34:08.310511 [info ] [MainThread]: 
[0m18:34:08.311718 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m18:34:08.314392 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 27.250475, "process_in_blocks": "0", "process_kernel_time": 2.262686, "process_mem_max_rss": "120284", "process_out_blocks": "11312", "process_user_time": 9.870616}
[0m18:34:08.315844 [debug] [MainThread]: Command `dbt build` failed at 18:34:08.315488 after 27.25 seconds
[0m18:34:08.316945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70fa4d2ba310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70fa48426430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70fa4b1d0f10>]}
[0m18:34:08.318366 [debug] [MainThread]: Flushing usage events
[0m18:37:49.263476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74457ae95310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x744577b0a460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x744577b0a5b0>]}


============================== 18:37:49.277513 | 11bc4c96-0bde-44d2-ad74-394c87a4f713 ==============================
[0m18:37:49.277513 [info ] [MainThread]: Running with dbt=1.8.9
[0m18:37:49.279461 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'printer_width': '80', 'profiles_dir': '.', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'target_path': 'None', 'debug': 'False', 'static_parser': 'True', 'cache_selected_only': 'False', 'log_path': '/workdir/transforms/01_instacart/logs', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'empty': 'False', 'use_experimental_parser': 'False', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'no_print': 'None', 'indirect_selection': 'eager', 'quiet': 'False', 'introspect': 'True', 'partial_parse': 'True', 'log_cache_events': 'False'}
[0m18:37:49.762212 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '11bc4c96-0bde-44d2-ad74-394c87a4f713', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74457a423b80>]}
[0m18:37:49.875259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '11bc4c96-0bde-44d2-ad74-394c87a4f713', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x744577bf35e0>]}
[0m18:37:49.877427 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m18:37:50.076011 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m18:37:50.394073 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m18:37:50.395700 [debug] [MainThread]: Partial parsing: updated file: ex_01_instacart://models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:37:51.282368 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ex_01_mpg.mart
- models.ex_01_mpg.clean
[0m18:37:51.327833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '11bc4c96-0bde-44d2-ad74-394c87a4f713', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x744575e04eb0>]}
[0m18:37:51.643666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '11bc4c96-0bde-44d2-ad74-394c87a4f713', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x744575d49820>]}
[0m18:37:51.644810 [info ] [MainThread]: Found 6 models, 13 data tests, 1 source, 471 macros
[0m18:37:51.653417 [info ] [MainThread]: 
[0m18:37:51.655457 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:37:51.677733 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:37:51.685641 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:37:51.732583 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:37:51.734454 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:37:55.794454 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:37:55.817226 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:37:56.072318 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:37:56.093229 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:37:56.120345 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m18:37:56.122438 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m18:37:56.146522 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m18:37:56.158400 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m18:37:56.441123 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:37:56.486744 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:37:56.900699 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '11bc4c96-0bde-44d2-ad74-394c87a4f713', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7445758a7730>]}
[0m18:37:56.903087 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m18:37:56.905502 [info ] [MainThread]: 
[0m18:37:56.936964 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:37:56.939606 [info ] [Thread-1  ]: 1 of 19 START sql table model `clean`.`g1_stg_insta_orders` .................... [RUN]
[0m18:37:56.942175 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_instacart.g1_stg_insta_orders'
[0m18:37:56.944398 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_orders
[0m18:37:56.983995 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:37:56.986197 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_orders
[0m18:37:57.133192 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m18:38:00.748255 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

            

    
        create table `clean`.`g1_stg_insta_orders__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (order_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
          )
        
        ...
[0m18:38:01.124474 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.37 seconds
[0m18:38:01.144254 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    select name, type from system.columns where table = 'g1_stg_insta_orders__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:38:01.494421 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:38:01.502838 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:38:01.504705 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_orders__dbt_backup`
        ("order_id", "user_id", "eval_set", "order_number", "order_dow", "order_hour_of_day", "days_since_prior_order")

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
  ...
[0m18:38:04.872331 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 3.37 seconds
[0m18:38:04.889295 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_orders__dbt_backup` AND `clean`.`g1_stg_insta_orders` 
  
  ...
[0m18:38:05.191796 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:38:05.296138 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    drop table if exists `clean`.`g1_stg_insta_orders__dbt_backup` 
  ...
[0m18:38:05.591469 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:38:05.602193 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11bc4c96-0bde-44d2-ad74-394c87a4f713', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7445759fa7f0>]}
[0m18:38:05.605234 [info ] [Thread-1  ]: 1 of 19 OK created sql table model `clean`.`g1_stg_insta_orders` ............... [[32mOK[0m in 8.66s]
[0m18:38:05.609527 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:38:05.615094 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:38:05.620063 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:38:05.624707 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:38:05.628045 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:38:05.631765 [info ] [Thread-3  ]: 2 of 19 START test accepted_values_g1_stg_insta_orders_eval_set__prior__train__test  [RUN]
[0m18:38:05.635056 [info ] [Thread-4  ]: 3 of 19 START test accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [RUN]
[0m18:38:05.638434 [info ] [Thread-2  ]: 4 of 19 START test accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [RUN]
[0m18:38:05.641241 [info ] [Thread-1  ]: 5 of 19 START test not_null_g1_stg_insta_orders_eval_set ....................... [RUN]
[0m18:38:05.645175 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5'
[0m18:38:05.649165 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145'
[0m18:38:05.652731 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1'
[0m18:38:05.655816 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_orders, now test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7)
[0m18:38:05.658010 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:38:05.660528 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:38:05.662736 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:38:05.665158 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:38:05.786758 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:38:05.793769 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:38:05.792388 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:38:05.809341 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:38:05.812435 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:38:05.814218 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:38:05.815763 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:38:05.822776 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:38:05.901227 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:38:05.917448 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:38:05.929123 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:38:05.941669 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:38:05.944853 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:38:05.946717 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m18:38:05.950725 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select eval_set
from `clean`.`g1_stg_insta_orders`
where eval_set is null



    ) dbt_internal_test...
[0m18:38:05.954781 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m18:38:06.553735 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.59 seconds
[0m18:38:06.561753 [info ] [Thread-1  ]: 5 of 19 PASS not_null_g1_stg_insta_orders_eval_set ............................. [[32mPASS[0m in 0.91s]
[0m18:38:06.565390 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:38:06.566913 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:38:06.568378 [info ] [Thread-1  ]: 6 of 19 START test not_null_g1_stg_insta_orders_order_dow ...................... [RUN]
[0m18:38:06.570007 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240)
[0m18:38:06.571415 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:38:06.583005 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:38:06.584599 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:38:06.599544 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:38:06.602315 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_dow
from `clean`.`g1_stg_insta_orders`
where order_dow is null



    ) dbt_internal_test...
[0m18:38:06.912343 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:38:06.917053 [info ] [Thread-1  ]: 6 of 19 PASS not_null_g1_stg_insta_orders_order_dow ............................ [[32mPASS[0m in 0.35s]
[0m18:38:06.919691 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:38:06.921609 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:38:06.923604 [info ] [Thread-1  ]: 7 of 19 START test not_null_g1_stg_insta_orders_order_hour_of_day .............. [RUN]
[0m18:38:06.925752 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576)
[0m18:38:06.927282 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:38:06.940745 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:38:06.942508 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:38:06.952939 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:38:06.955423 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_hour_of_day
from `clean`.`g1_stg_insta_orders`
where order_hour_of_day is null



    ) dbt_internal_test...
[0m18:38:07.233551 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:38:07.241034 [info ] [Thread-1  ]: 7 of 19 PASS not_null_g1_stg_insta_orders_order_hour_of_day .................... [[32mPASS[0m in 0.31s]
[0m18:38:07.248120 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:38:07.250730 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:38:07.253692 [info ] [Thread-1  ]: 8 of 19 START test not_null_g1_stg_insta_orders_order_id ....................... [RUN]
[0m18:38:07.258435 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600)
[0m18:38:07.260383 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:38:07.276302 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:38:07.278371 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:38:07.286318 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:38:07.289380 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from `clean`.`g1_stg_insta_orders`
where order_id is null



    ) dbt_internal_test...
[0m18:38:07.575438 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:38:07.582098 [info ] [Thread-1  ]: 8 of 19 PASS not_null_g1_stg_insta_orders_order_id ............................. [[32mPASS[0m in 0.32s]
[0m18:38:07.585680 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:38:07.588035 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:38:07.590650 [info ] [Thread-1  ]: 9 of 19 START test not_null_g1_stg_insta_orders_order_number ................... [RUN]
[0m18:38:07.593428 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619)
[0m18:38:07.595630 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:38:07.615797 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:38:07.618375 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:38:07.633459 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:38:07.636103 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_number
from `clean`.`g1_stg_insta_orders`
where order_number is null



    ) dbt_internal_test...
[0m18:38:07.941110 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:38:07.945959 [info ] [Thread-1  ]: 9 of 19 PASS not_null_g1_stg_insta_orders_order_number ......................... [[32mPASS[0m in 0.35s]
[0m18:38:07.947879 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:38:07.949301 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:38:07.950423 [info ] [Thread-1  ]: 10 of 19 START test not_null_g1_stg_insta_orders_user_id ....................... [RUN]
[0m18:38:07.951916 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619, now test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64)
[0m18:38:07.953812 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:38:07.966807 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:38:07.969248 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:38:07.978864 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:38:07.980933 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_orders`
where user_id is null



    ) dbt_internal_test...
[0m18:38:08.280536 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:38:08.286458 [info ] [Thread-1  ]: 10 of 19 PASS not_null_g1_stg_insta_orders_user_id ............................. [[32mPASS[0m in 0.33s]
[0m18:38:08.289569 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:38:08.291451 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:38:08.293966 [info ] [Thread-1  ]: 11 of 19 START test unique_g1_stg_insta_orders_order_id ........................ [RUN]
[0m18:38:08.300321 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64, now test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57)
[0m18:38:08.302324 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:38:08.344047 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:38:08.353081 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:38:08.361617 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:38:08.363665 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_orders`
where order_id is not null
group by order_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:38:09.051325 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.69 seconds
[0m18:38:09.056019 [info ] [Thread-1  ]: 11 of 19 PASS unique_g1_stg_insta_orders_order_id .............................. [[32mPASS[0m in 0.76s]
[0m18:38:09.058295 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:38:09.560204 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_dow as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_dow

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6'
)



    ) dbt_internal_test...
[0m18:38:09.663100 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        eval_set as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by eval_set

)

select *
from all_values
where value_field not in (
    'prior','train','test'
)



    ) dbt_internal_test...
[0m18:38:09.898175 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_hour_of_day as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_hour_of_day

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23'
)



    ) dbt_internal_test...
[0m18:38:09.931425 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.37 seconds
[0m18:38:09.935597 [info ] [Thread-4  ]: 3 of 19 PASS accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [[32mPASS[0m in 4.29s]
[0m18:38:09.937823 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:38:10.021282 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m18:38:10.025696 [info ] [Thread-3  ]: 2 of 19 PASS accepted_values_g1_stg_insta_orders_eval_set__prior__train__test .. [[32mPASS[0m in 4.38s]
[0m18:38:10.027696 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:38:10.256708 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m18:38:10.261542 [info ] [Thread-2  ]: 4 of 19 PASS accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [[32mPASS[0m in 4.61s]
[0m18:38:10.263866 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:38:10.267048 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_users
[0m18:38:10.269044 [info ] [Thread-1  ]: 12 of 19 START sql table model `clean`.`g1_stg_insta_users` .................... [RUN]
[0m18:38:10.271048 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57, now model.ex_01_instacart.g1_stg_insta_users)
[0m18:38:10.272897 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_users
[0m18:38:10.281829 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:38:10.283601 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_users
[0m18:38:10.297795 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

            

    
        create table `clean`.`g1_stg_insta_users__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (user_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
          )
        
        ...
[0m18:38:10.610472 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:38:10.617186 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    select name, type from system.columns where table = 'g1_stg_insta_users__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:38:10.894543 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:38:10.898516 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:38:10.900393 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_users__dbt_backup`
        ("user_id")

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
  ...
[0m18:38:11.409722 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.51 seconds
[0m18:38:11.415279 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_users__dbt_backup` AND `clean`.`g1_stg_insta_users` 
  
  ...
[0m18:38:11.754958 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:38:11.764478 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    drop table if exists `clean`.`g1_stg_insta_users__dbt_backup` 
  ...
[0m18:38:12.143962 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m18:38:12.148148 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11bc4c96-0bde-44d2-ad74-394c87a4f713', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7445759c6160>]}
[0m18:38:12.149735 [info ] [Thread-1  ]: 12 of 19 OK created sql table model `clean`.`g1_stg_insta_users` ............... [[32mOK[0m in 1.88s]
[0m18:38:12.151518 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_users
[0m18:38:12.154521 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:38:12.155905 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:38:12.159968 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:38:12.157541 [info ] [Thread-3  ]: 13 of 19 START test not_null_g1_stg_insta_users_user_id ........................ [RUN]
[0m18:38:12.162624 [info ] [Thread-2  ]: 14 of 19 START test relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [RUN]
[0m18:38:12.164846 [info ] [Thread-4  ]: 15 of 19 START test unique_g1_stg_insta_users_user_id .......................... [RUN]
[0m18:38:12.166950 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5, now test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935)
[0m18:38:12.169311 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1, now test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726)
[0m18:38:12.171039 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145, now test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f)
[0m18:38:12.172879 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:38:12.174494 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:38:12.176098 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:38:12.192384 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:38:12.223077 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:38:12.228727 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:38:12.231359 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:38:12.233355 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:38:12.241084 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:38:12.242351 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:38:12.249299 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:38:12.257049 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:38:12.258844 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_users`
where user_id is null



    ) dbt_internal_test...
[0m18:38:12.263934 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    user_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_users`
where user_id is not null
group by user_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:38:12.266216 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select user_id as from_field
    from `clean`.`g1_stg_insta_orders`
    where user_id is not null
),

parent as (
    select user_id as to_field
    from `clean`.`g1_stg_insta_users`
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null
-- end_of_sql
settings join_use_nulls = 1



    ) dbt_internal_test...
[0m18:38:12.551826 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:38:12.556739 [info ] [Thread-3  ]: 13 of 19 PASS not_null_g1_stg_insta_users_user_id .............................. [[32mPASS[0m in 0.39s]
[0m18:38:12.560023 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:38:12.589878 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:38:12.594140 [info ] [Thread-4  ]: 15 of 19 PASS unique_g1_stg_insta_users_user_id ................................ [[32mPASS[0m in 0.42s]
[0m18:38:12.597508 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:38:12.898831 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.63 seconds
[0m18:38:12.903050 [info ] [Thread-2  ]: 14 of 19 PASS relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [[32mPASS[0m in 0.73s]
[0m18:38:12.905110 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:38:12.908503 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:38:12.910303 [debug] [Thread-3  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:38:12.911822 [info ] [Thread-1  ]: 16 of 19 START sql view model `mart`.`g1_dq_insta_orders_anomalies` ............ [RUN]
[0m18:38:12.913671 [debug] [Thread-4  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:38:12.915690 [debug] [Thread-2  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:38:12.918303 [info ] [Thread-3  ]: 17 of 19 START sql view model `mart`.`g1_dq_insta_orders_summary` .............. [RUN]
[0m18:38:12.921141 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_users, now model.ex_01_instacart.g1_dq_insta_orders_anomalies)
[0m18:38:12.923799 [info ] [Thread-4  ]: 18 of 19 START sql view model `mart`.`g1_dq_insta_users_anomalies` ............. [RUN]
[0m18:38:12.926923 [info ] [Thread-2  ]: 19 of 19 START sql view model `mart`.`g1_dq_insta_users_summary` ............... [RUN]
[0m18:38:12.929256 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935, now model.ex_01_instacart.g1_dq_insta_orders_summary)
[0m18:38:12.931414 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:38:12.933379 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f, now model.ex_01_instacart.g1_dq_insta_users_anomalies)
[0m18:38:12.935396 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726, now model.ex_01_instacart.g1_dq_insta_users_summary)
[0m18:38:12.937328 [debug] [Thread-3  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:38:12.950768 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:38:12.952702 [debug] [Thread-4  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:38:12.954596 [debug] [Thread-2  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:38:12.966187 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:38:12.976735 [debug] [Thread-4  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:38:12.978619 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:38:12.992162 [debug] [Thread-2  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:38:12.994301 [debug] [Thread-3  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:38:13.001507 [debug] [Thread-4  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:38:13.048772 [debug] [Thread-2  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:38:13.133911 [debug] [Thread-4  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:38:13.135998 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:38:13.139403 [debug] [Thread-2  ]: Creating new relation g1_dq_insta_users_summary
[0m18:38:13.141763 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:38:13.145602 [debug] [Thread-2  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:38:13.147163 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */


  create view `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Users

with cln as (
  select * from `clean`.`g1_stg_insta_users`
),
violations as (
  select
    user_id,

    multiIf(
      user_id is null, 'null_user_id',
      user_id <= 0, 'invalid_user_id',
      'ok'
    ) as dq_issue
  from cln
)
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:38:13.149297 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */


  create view `mart`.`g1_dq_insta_orders_summary__dbt_tmp` 
  
    
    
  as (
    

-- Data Quality Summary for Orders
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  select * from `raw`.`raw___insta_orders`
),

cln as (
  select * from `clean`.`g1_stg_insta_orders`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage Check
nulls as (
  select
    round(100.0 * countIf(order_id is null) / nullif(count(),0), 2) as null_pct_order_id,
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id,
    round(100.0 * countIf(eval_set is null) / nullif(count(),0), 2) as null_pct_eval_set,
    round(100.0 * countIf(order_number is null) / nullif(count(),0), 2) as null_pct_order_number,
    round(100.0 * countIf(order_dow is null) / nullif(count(),0), 2) as null_pct_order_dow,
    round(100.0 * countIf(order_hour_of_day is null) / nullif(count(),0), 2) as null_pct_order_hour_of_day,
    round(100.0 * countIf(days_since_prior_order is null) / nullif(count(),0), 2) as null_pct_days_since_prior_order
  from cln
),

-- Duplicate Orders
dupes as (
  select
    countIf(cnt > 1) as duplicate_orders
  from (
    select order_id, count() as cnt
    from cln
    group by order_id
  )
),

-- Referential Integrity
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_id
  from `clean`.`g1_stg_insta_orders` o
),

-- Value Range Checks
value_ranges as (
  select
    countIf(order_number < 1) as invalid_order_number,
    countIf(order_hour_of_day < 0 or order_hour_of_day > 23) as invalid_order_hour,
    countIf(days_since_prior_order < 0 or days_since_prior_order > 30) as invalid_days_since_prior_order
  from cln
),

-- Join all metrics
joined as (
    select
        counts.row_count_raw,
        counts.row_count_clean,
        (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
        nulls.*,
        dupes.duplicate_orders,
        referential_integrity.invalid_user_id,
        value_ranges.invalid_order_number,
        value_ranges.invalid_order_hour,
        value_ranges.invalid_days_since_prior_order
    from counts
    cross join nulls
    cross join dupes
    cross join referential_integrity
    cross join value_ranges
)

select * from joined
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:38:13.152465 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */


  create view `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Orders
with cln as (
  -- Source cleaned orders data
  select * 
  from `clean`.`g1_stg_insta_orders`
),

users as (
  -- Reference users table for FK validation
  select user_id 
  from `clean`.`g1_stg_insta_users`
),

violations as (
  select
    order_id,
    user_id,
    eval_set,
    order_number,
    order_dow,
    order_hour_of_day,
    days_since_prior_order,

    -- Data Quality Issue Classification
    multiIf(
      order_id is null, 'null_order_id',
      user_id is null, 'null_user_id',
      user_id not in (select user_id from users), 'missing_user_ref',
      order_number < 1, 'invalid_order_number',
      order_dow not in (0,1,2,3,4,5,6), 'invalid_order_dow',
      order_hour_of_day < 0 or order_hour_of_day > 23, 'invalid_order_hour',
      days_since_prior_order < 0, 'negative_days_since_prior_order',
      'ok'
    ) as dq_issue

  from cln
)

-- Return only rows with detected anomalies
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:38:13.154434 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),

cln as (
    select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts_clean as (
    select count(*) as row_count_clean
    from cln
),

-- Null Percentage
nulls as (
  select
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
  from cln
),

-- Duplicate Users Check
dupes as (
  select
    countIf(cnt > 1) as duplicate_user_ids
  from (
    select user_id, count() as cnt
    from cln
    group by user_id
  )
),

-- Referential Integrity
invalid_user_in_orders as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),

user_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

-- Join all metrics
joined as (
  select
    counts.row_count_raw,
    counts.row_count_clean,
    (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
    nulls.null_pct_user_id,
    dupes.duplicate_user_ids,
    referential_integrity.invalid_user_in_orders,
    referential_integrity.user_without_orders
  from counts
  cross join nulls
  cross join dupes
  cross join referential_integrity
)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:38:13.542386 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.39 seconds
[0m18:38:13.544655 [debug] [Thread-2  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),

cln as (
    select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts_clean as (
    select count(*) as row_count_clean
    from cln
),

-- Null Percentage
nulls as (
  select
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
  from cln
),

-- Duplicate Users Check
dupes as (
  select
    countIf(cnt > 1) as duplicate_user_ids
  from (
    select user_id, count() as cnt
    from cln
    group by user_id
  )
),

-- Referential Integrity
invalid_user_in_orders as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),

user_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

-- Join all metrics
joined as (
  select
    counts.row_count_raw,
    counts.row_count_clean,
    (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
    nulls.null_pct_user_id,
    dupes.duplicate_user_ids,
    referential_integrity.invalid_user_in_orders,
    referential_integrity.user_without_orders
  from counts
  cross join nulls
  cross join dupes
  cross join referential_integrity
)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m18:38:13.557878 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.40 seconds
[0m18:38:13.565961 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m18:38:13.575104 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m18:38:13.584688 [debug] [Thread-2  ]: Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1314 ('joined') (line 61, col 1): joined as (
    select
      counts.row_count_raw,
      counts.row_count_clean,
      (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
      nulls.null_p. Expected one of: token, Comma, FROM, SELECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:38:13.585979 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11bc4c96-0bde-44d2-ad74-394c87a4f713', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7445752b3ca0>]}
[0m18:38:13.587604 [error] [Thread-2  ]: 19 of 19 ERROR creating sql view model `mart`.`g1_dq_insta_users_summary` ...... [[31mERROR[0m in 0.65s]
[0m18:38:13.590552 [debug] [Thread-2  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:38:13.612183 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.45 seconds
[0m18:38:13.621257 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m18:38:13.925676 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:38:13.934331 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m18:38:13.930849 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies` to `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m18:38:13.940307 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies` to `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m18:38:13.948241 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:38:13.957787 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary` to `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m18:38:14.243731 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:38:14.246832 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:38:14.254455 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:38:14.258480 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m18:38:14.269300 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m18:38:14.278467 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m18:38:14.544997 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.26 seconds
[0m18:38:14.548119 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m18:38:14.597558 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:38:14.599748 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:38:14.604104 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m18:38:14.608156 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary__dbt_tmp` to `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m18:38:14.839825 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:38:14.850464 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  ...
[0m18:38:14.892066 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:38:14.894227 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:38:14.903981 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  ...
[0m18:38:14.915356 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  ...
[0m18:38:15.125679 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:38:15.129572 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11bc4c96-0bde-44d2-ad74-394c87a4f713', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x744574791190>]}
[0m18:38:15.131289 [info ] [Thread-1  ]: 16 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_anomalies` ....... [[32mOK[0m in 2.21s]
[0m18:38:15.133433 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:38:15.202001 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:38:15.204293 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:38:15.210079 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11bc4c96-0bde-44d2-ad74-394c87a4f713', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7445748a8f10>]}
[0m18:38:15.214231 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11bc4c96-0bde-44d2-ad74-394c87a4f713', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7445747f7520>]}
[0m18:38:15.216942 [info ] [Thread-3  ]: 17 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_summary` ......... [[32mOK[0m in 2.28s]
[0m18:38:15.220245 [info ] [Thread-4  ]: 18 of 19 OK created sql view model `mart`.`g1_dq_insta_users_anomalies` ........ [[32mOK[0m in 2.28s]
[0m18:38:15.223058 [debug] [Thread-3  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:38:15.225717 [debug] [Thread-4  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:38:15.232241 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:38:15.233504 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m18:38:15.234650 [debug] [MainThread]: On list__mart: Close
[0m18:38:15.235644 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m18:38:15.236891 [debug] [MainThread]: On list__clean: Close
[0m18:38:15.237803 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_anomalies' was left open.
[0m18:38:15.239012 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: Close
[0m18:38:15.240006 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_summary' was left open.
[0m18:38:15.241125 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_summary: Close
[0m18:38:15.241999 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_anomalies' was left open.
[0m18:38:15.242875 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_anomalies: Close
[0m18:38:15.244193 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_summary' was left open.
[0m18:38:15.246293 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_summary: Close
[0m18:38:15.248772 [info ] [MainThread]: 
[0m18:38:15.250267 [info ] [MainThread]: Finished running 2 table models, 13 data tests, 4 view models in 0 hours 0 minutes and 23.59 seconds (23.59s).
[0m18:38:15.263794 [debug] [MainThread]: Command end result
[0m18:38:15.348952 [info ] [MainThread]: 
[0m18:38:15.350067 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m18:38:15.351255 [info ] [MainThread]: 
[0m18:38:15.352949 [error] [MainThread]:   Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1314 ('joined') (line 61, col 1): joined as (
    select
      counts.row_count_raw,
      counts.row_count_clean,
      (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
      nulls.null_p. Expected one of: token, Comma, FROM, SELECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:38:15.354199 [info ] [MainThread]: 
[0m18:38:15.355565 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m18:38:15.358588 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 26.23511, "process_in_blocks": "0", "process_kernel_time": 2.064904, "process_mem_max_rss": "119468", "process_out_blocks": "11304", "process_user_time": 9.797229}
[0m18:38:15.360008 [debug] [MainThread]: Command `dbt build` failed at 18:38:15.359582 after 26.24 seconds
[0m18:38:15.361676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74457ae95310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x744577bf35e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x744577236eb0>]}
[0m18:38:15.363526 [debug] [MainThread]: Flushing usage events
[0m18:42:40.824354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x700e62126310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x700e5ed7faf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x700e5ed7f9a0>]}


============================== 18:42:40.839503 | 664b8b41-1b74-41f1-ba62-5b8be5e19468 ==============================
[0m18:42:40.839503 [info ] [MainThread]: Running with dbt=1.8.9
[0m18:42:40.842291 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'version_check': 'True', 'log_cache_events': 'False', 'no_print': 'None', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'partial_parse': 'True', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'debug': 'False', 'warn_error': 'None', 'target_path': 'None', 'log_path': '/workdir/transforms/01_instacart/logs', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '.', 'printer_width': '80', 'use_colors': 'True', 'use_experimental_parser': 'False', 'write_json': 'True', 'quiet': 'False', 'empty': 'False', 'introspect': 'True', 'fail_fast': 'False', 'log_format': 'default'}
[0m18:42:41.211371 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '664b8b41-1b74-41f1-ba62-5b8be5e19468', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x700e616ca3a0>]}
[0m18:42:41.329854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '664b8b41-1b74-41f1-ba62-5b8be5e19468', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x700e600bdeb0>]}
[0m18:42:41.331690 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m18:42:41.530715 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m18:42:41.840791 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m18:42:41.842318 [debug] [MainThread]: Partial parsing: updated file: ex_01_instacart://models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:42:42.504480 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ex_01_mpg.clean
- models.ex_01_mpg.mart
[0m18:42:42.542887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '664b8b41-1b74-41f1-ba62-5b8be5e19468', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x700e5d065130>]}
[0m18:42:42.833303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '664b8b41-1b74-41f1-ba62-5b8be5e19468', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x700e5cfeba60>]}
[0m18:42:42.834574 [info ] [MainThread]: Found 6 models, 13 data tests, 1 source, 471 macros
[0m18:42:42.843822 [info ] [MainThread]: 
[0m18:42:42.846037 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:42:42.872437 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:42:42.876074 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:42:42.929584 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:42:42.931034 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:42:47.208996 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:42:47.251719 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:42:47.490888 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:42:47.526637 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:42:47.532623 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m18:42:47.535304 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m18:42:47.550495 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m18:42:47.556463 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m18:42:47.849855 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:42:47.855479 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:42:48.175729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '664b8b41-1b74-41f1-ba62-5b8be5e19468', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x700e61546970>]}
[0m18:42:48.177047 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m18:42:48.177891 [info ] [MainThread]: 
[0m18:42:48.200385 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:42:48.202194 [info ] [Thread-1  ]: 1 of 19 START sql table model `clean`.`g1_stg_insta_orders` .................... [RUN]
[0m18:42:48.206193 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_instacart.g1_stg_insta_orders'
[0m18:42:48.208064 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_orders
[0m18:42:48.233399 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:42:48.235819 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_orders
[0m18:42:48.367748 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m18:42:51.747639 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

            

    
        create table `clean`.`g1_stg_insta_orders__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (order_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
          )
        
        ...
[0m18:42:52.045987 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:42:52.064942 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    select name, type from system.columns where table = 'g1_stg_insta_orders__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:42:52.361976 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:42:52.370454 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:42:52.372172 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_orders__dbt_backup`
        ("order_id", "user_id", "eval_set", "order_number", "order_dow", "order_hour_of_day", "days_since_prior_order")

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
  ...
[0m18:42:54.841579 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 2.47 seconds
[0m18:42:54.853665 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_orders__dbt_backup` AND `clean`.`g1_stg_insta_orders` 
  
  ...
[0m18:42:55.195775 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m18:42:55.248010 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    drop table if exists `clean`.`g1_stg_insta_orders__dbt_backup` 
  ...
[0m18:42:55.549512 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:42:55.558097 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '664b8b41-1b74-41f1-ba62-5b8be5e19468', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x700e5e3fa400>]}
[0m18:42:55.559742 [info ] [Thread-1  ]: 1 of 19 OK created sql table model `clean`.`g1_stg_insta_orders` ............... [[32mOK[0m in 7.35s]
[0m18:42:55.561636 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:42:55.565106 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:42:55.566943 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:42:55.568658 [info ] [Thread-3  ]: 2 of 19 START test accepted_values_g1_stg_insta_orders_eval_set__prior__train__test  [RUN]
[0m18:42:55.573918 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:42:55.575904 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5'
[0m18:42:55.577522 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:42:55.571133 [info ] [Thread-4  ]: 3 of 19 START test accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [RUN]
[0m18:42:55.579450 [info ] [Thread-2  ]: 4 of 19 START test accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [RUN]
[0m18:42:55.581516 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:42:55.583142 [info ] [Thread-1  ]: 5 of 19 START test not_null_g1_stg_insta_orders_eval_set ....................... [RUN]
[0m18:42:55.585346 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145'
[0m18:42:55.587188 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1'
[0m18:42:55.604903 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_orders, now test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7)
[0m18:42:55.620995 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:42:55.629592 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:42:55.631360 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:42:55.633151 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:42:55.646356 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:42:55.657323 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:42:55.669946 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:42:55.685708 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:42:55.687678 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:42:55.695120 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:42:55.736943 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:42:55.734070 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:42:55.738947 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:42:55.748376 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:42:55.756680 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m18:42:55.755536 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:42:55.760282 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:42:55.762048 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m18:42:55.767496 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select eval_set
from `clean`.`g1_stg_insta_orders`
where eval_set is null



    ) dbt_internal_test...
[0m18:42:56.559964 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.79 seconds
[0m18:42:56.587198 [info ] [Thread-1  ]: 5 of 19 PASS not_null_g1_stg_insta_orders_eval_set ............................. [[32mPASS[0m in 0.98s]
[0m18:42:56.591596 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:42:56.594757 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:42:56.599043 [info ] [Thread-1  ]: 6 of 19 START test not_null_g1_stg_insta_orders_order_dow ...................... [RUN]
[0m18:42:56.610847 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240)
[0m18:42:56.613236 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:42:56.644774 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:42:56.648710 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:42:56.660574 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:42:56.664998 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_dow
from `clean`.`g1_stg_insta_orders`
where order_dow is null



    ) dbt_internal_test...
[0m18:42:57.018829 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:42:57.023536 [info ] [Thread-1  ]: 6 of 19 PASS not_null_g1_stg_insta_orders_order_dow ............................ [[32mPASS[0m in 0.41s]
[0m18:42:57.026104 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:42:57.027851 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:42:57.029228 [info ] [Thread-1  ]: 7 of 19 START test not_null_g1_stg_insta_orders_order_hour_of_day .............. [RUN]
[0m18:42:57.030748 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576)
[0m18:42:57.031809 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:42:57.041885 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:42:57.043596 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:42:57.051743 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:42:57.053480 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_hour_of_day
from `clean`.`g1_stg_insta_orders`
where order_hour_of_day is null



    ) dbt_internal_test...
[0m18:42:57.451940 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.40 seconds
[0m18:42:57.456784 [info ] [Thread-1  ]: 7 of 19 PASS not_null_g1_stg_insta_orders_order_hour_of_day .................... [[32mPASS[0m in 0.43s]
[0m18:42:57.459019 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:42:57.460576 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:42:57.462186 [info ] [Thread-1  ]: 8 of 19 START test not_null_g1_stg_insta_orders_order_id ....................... [RUN]
[0m18:42:57.464146 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600)
[0m18:42:57.465772 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:42:57.477314 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:42:57.479232 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:42:57.488400 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:42:57.491078 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from `clean`.`g1_stg_insta_orders`
where order_id is null



    ) dbt_internal_test...
[0m18:42:57.835495 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m18:42:57.840046 [info ] [Thread-1  ]: 8 of 19 PASS not_null_g1_stg_insta_orders_order_id ............................. [[32mPASS[0m in 0.38s]
[0m18:42:57.842567 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:42:57.844179 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:42:57.845645 [info ] [Thread-1  ]: 9 of 19 START test not_null_g1_stg_insta_orders_order_number ................... [RUN]
[0m18:42:57.847304 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619)
[0m18:42:57.848921 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:42:57.862234 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:42:57.864045 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:42:57.871600 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:42:57.873976 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_number
from `clean`.`g1_stg_insta_orders`
where order_number is null



    ) dbt_internal_test...
[0m18:42:58.226892 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:42:58.231048 [info ] [Thread-1  ]: 9 of 19 PASS not_null_g1_stg_insta_orders_order_number ......................... [[32mPASS[0m in 0.38s]
[0m18:42:58.233610 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:42:58.235209 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:42:58.236723 [info ] [Thread-1  ]: 10 of 19 START test not_null_g1_stg_insta_orders_user_id ....................... [RUN]
[0m18:42:58.237988 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619, now test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64)
[0m18:42:58.239158 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:42:58.251738 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:42:58.253386 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:42:58.260233 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:42:58.263929 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_orders`
where user_id is null



    ) dbt_internal_test...
[0m18:42:58.623105 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m18:42:58.627429 [info ] [Thread-1  ]: 10 of 19 PASS not_null_g1_stg_insta_orders_user_id ............................. [[32mPASS[0m in 0.39s]
[0m18:42:58.629570 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:42:58.631134 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:42:58.632444 [info ] [Thread-1  ]: 11 of 19 START test unique_g1_stg_insta_orders_order_id ........................ [RUN]
[0m18:42:58.633788 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64, now test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57)
[0m18:42:58.635156 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:42:58.651310 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:42:58.653267 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:42:58.659360 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:42:58.661513 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_orders`
where order_id is not null
group by order_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:42:59.376040 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.71 seconds
[0m18:42:59.383390 [info ] [Thread-1  ]: 11 of 19 PASS unique_g1_stg_insta_orders_order_id .............................. [[32mPASS[0m in 0.75s]
[0m18:42:59.386628 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:43:00.010072 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_dow as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_dow

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6'
)



    ) dbt_internal_test...
[0m18:43:00.099004 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        eval_set as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by eval_set

)

select *
from all_values
where value_field not in (
    'prior','train','test'
)



    ) dbt_internal_test...
[0m18:43:00.360431 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:43:00.364750 [info ] [Thread-4  ]: 3 of 19 PASS accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [[32mPASS[0m in 4.78s]
[0m18:43:00.366944 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:43:00.406072 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_hour_of_day as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_hour_of_day

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23'
)



    ) dbt_internal_test...
[0m18:43:00.501919 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.40 seconds
[0m18:43:00.506239 [info ] [Thread-3  ]: 2 of 19 PASS accepted_values_g1_stg_insta_orders_eval_set__prior__train__test .. [[32mPASS[0m in 4.93s]
[0m18:43:00.508329 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:43:00.773756 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.37 seconds
[0m18:43:00.778732 [info ] [Thread-2  ]: 4 of 19 PASS accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [[32mPASS[0m in 5.19s]
[0m18:43:00.780940 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:43:00.783824 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_users
[0m18:43:00.785932 [info ] [Thread-1  ]: 12 of 19 START sql table model `clean`.`g1_stg_insta_users` .................... [RUN]
[0m18:43:00.788228 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57, now model.ex_01_instacart.g1_stg_insta_users)
[0m18:43:00.790068 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_users
[0m18:43:00.799191 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:43:00.800990 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_users
[0m18:43:00.815204 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

            

    
        create table `clean`.`g1_stg_insta_users__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (user_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
          )
        
        ...
[0m18:43:01.161613 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m18:43:01.167982 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    select name, type from system.columns where table = 'g1_stg_insta_users__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:43:01.523578 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:43:01.527471 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:43:01.529335 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_users__dbt_backup`
        ("user_id")

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
  ...
[0m18:43:01.922018 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.39 seconds
[0m18:43:01.925387 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_users__dbt_backup` AND `clean`.`g1_stg_insta_users` 
  
  ...
[0m18:43:02.219491 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:43:02.229737 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    drop table if exists `clean`.`g1_stg_insta_users__dbt_backup` 
  ...
[0m18:43:02.507011 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:43:02.511394 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '664b8b41-1b74-41f1-ba62-5b8be5e19468', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x700e5ba92f70>]}
[0m18:43:02.513087 [info ] [Thread-1  ]: 12 of 19 OK created sql table model `clean`.`g1_stg_insta_users` ............... [[32mOK[0m in 1.72s]
[0m18:43:02.514817 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_users
[0m18:43:02.518040 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:43:02.519614 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:43:02.521249 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:43:02.523011 [info ] [Thread-3  ]: 13 of 19 START test not_null_g1_stg_insta_users_user_id ........................ [RUN]
[0m18:43:02.525669 [info ] [Thread-2  ]: 14 of 19 START test relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [RUN]
[0m18:43:02.527991 [info ] [Thread-4  ]: 15 of 19 START test unique_g1_stg_insta_users_user_id .......................... [RUN]
[0m18:43:02.529895 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5, now test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935)
[0m18:43:02.531902 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1, now test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726)
[0m18:43:02.534025 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145, now test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f)
[0m18:43:02.535864 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:43:02.537417 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:43:02.538859 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:43:02.551843 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:43:02.578911 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:43:02.588753 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:43:02.590930 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:43:02.593053 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:43:02.600915 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:43:02.602075 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:43:02.609031 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:43:02.619863 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:43:02.621576 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_users`
where user_id is null



    ) dbt_internal_test...
[0m18:43:02.624542 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select user_id as from_field
    from `clean`.`g1_stg_insta_orders`
    where user_id is not null
),

parent as (
    select user_id as to_field
    from `clean`.`g1_stg_insta_users`
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null
-- end_of_sql
settings join_use_nulls = 1



    ) dbt_internal_test...
[0m18:43:02.628143 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    user_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_users`
where user_id is not null
group by user_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:43:02.931325 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:43:02.935474 [info ] [Thread-3  ]: 13 of 19 PASS not_null_g1_stg_insta_users_user_id .............................. [[32mPASS[0m in 0.41s]
[0m18:43:02.937281 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:43:02.959537 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:43:02.963329 [info ] [Thread-4  ]: 15 of 19 PASS unique_g1_stg_insta_users_user_id ................................ [[32mPASS[0m in 0.43s]
[0m18:43:02.965929 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:43:03.219869 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.59 seconds
[0m18:43:03.223691 [info ] [Thread-2  ]: 14 of 19 PASS relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [[32mPASS[0m in 0.69s]
[0m18:43:03.225767 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:43:03.228950 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:43:03.230402 [debug] [Thread-3  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:43:03.233813 [debug] [Thread-4  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:43:03.232381 [info ] [Thread-1  ]: 16 of 19 START sql view model `mart`.`g1_dq_insta_orders_anomalies` ............ [RUN]
[0m18:43:03.236181 [debug] [Thread-2  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:43:03.238022 [info ] [Thread-3  ]: 17 of 19 START sql view model `mart`.`g1_dq_insta_orders_summary` .............. [RUN]
[0m18:43:03.240547 [info ] [Thread-4  ]: 18 of 19 START sql view model `mart`.`g1_dq_insta_users_anomalies` ............. [RUN]
[0m18:43:03.243096 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_users, now model.ex_01_instacart.g1_dq_insta_orders_anomalies)
[0m18:43:03.245373 [info ] [Thread-2  ]: 19 of 19 START sql view model `mart`.`g1_dq_insta_users_summary` ............... [RUN]
[0m18:43:03.247837 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935, now model.ex_01_instacart.g1_dq_insta_orders_summary)
[0m18:43:03.249935 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f, now model.ex_01_instacart.g1_dq_insta_users_anomalies)
[0m18:43:03.252227 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:43:03.254655 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726, now model.ex_01_instacart.g1_dq_insta_users_summary)
[0m18:43:03.256548 [debug] [Thread-3  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:43:03.258364 [debug] [Thread-4  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:43:03.268704 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:43:03.270946 [debug] [Thread-2  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:43:03.283199 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:43:03.292178 [debug] [Thread-4  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:43:03.303871 [debug] [Thread-2  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:43:03.306642 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:43:03.308354 [debug] [Thread-3  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:43:03.311030 [debug] [Thread-4  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:43:03.328986 [debug] [Thread-2  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:43:03.452440 [debug] [Thread-2  ]: Creating new relation g1_dq_insta_users_summary
[0m18:43:03.516019 [debug] [Thread-2  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:43:03.524290 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:43:03.526916 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:43:03.531342 [debug] [Thread-4  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:43:03.533594 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),

cln as (
    select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts_clean as (
    select count(*) as row_count_clean
    from cln
),

-- Null Percentage
nulls as (
  select
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
  from cln
),

-- Duplicate Users Check
dupes as (
  select
    countIf(cnt > 1) as duplicate_user_ids
  from (
    select user_id, count() as cnt
    from cln
    group by user_id
  )
),

-- Referential Integrity
invalid_user_in_orders as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),

user_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

-- Join all metrics
joined as (
  select
    rawDS.row_count_raw,
    counts.row_count_clean,
    (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
    nulls.null_pct_user_id,
    dupes.duplicate_user_ids,
    invalid_user_in_orders,
    user_without_orders
  from rawDS
  cross join counts
  cross join nulls
  cross join invalid_user_in_orders
  cross join user_without_orders

)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:43:03.537499 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */


  create view `mart`.`g1_dq_insta_orders_summary__dbt_tmp` 
  
    
    
  as (
    

-- Data Quality Summary for Orders
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  select * from `raw`.`raw___insta_orders`
),

cln as (
  select * from `clean`.`g1_stg_insta_orders`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage Check
nulls as (
  select
    round(100.0 * countIf(order_id is null) / nullif(count(),0), 2) as null_pct_order_id,
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id,
    round(100.0 * countIf(eval_set is null) / nullif(count(),0), 2) as null_pct_eval_set,
    round(100.0 * countIf(order_number is null) / nullif(count(),0), 2) as null_pct_order_number,
    round(100.0 * countIf(order_dow is null) / nullif(count(),0), 2) as null_pct_order_dow,
    round(100.0 * countIf(order_hour_of_day is null) / nullif(count(),0), 2) as null_pct_order_hour_of_day,
    round(100.0 * countIf(days_since_prior_order is null) / nullif(count(),0), 2) as null_pct_days_since_prior_order
  from cln
),

-- Duplicate Orders
dupes as (
  select
    countIf(cnt > 1) as duplicate_orders
  from (
    select order_id, count() as cnt
    from cln
    group by order_id
  )
),

-- Referential Integrity
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_id
  from `clean`.`g1_stg_insta_orders` o
),

-- Value Range Checks
value_ranges as (
  select
    countIf(order_number < 1) as invalid_order_number,
    countIf(order_hour_of_day < 0 or order_hour_of_day > 23) as invalid_order_hour,
    countIf(days_since_prior_order < 0 or days_since_prior_order > 30) as invalid_days_since_prior_order
  from cln
),

-- Join all metrics
joined as (
    select
        counts.row_count_raw,
        counts.row_count_clean,
        (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
        nulls.*,
        dupes.duplicate_orders,
        referential_integrity.invalid_user_id,
        value_ranges.invalid_order_number,
        value_ranges.invalid_order_hour,
        value_ranges.invalid_days_since_prior_order
    from counts
    cross join nulls
    cross join dupes
    cross join referential_integrity
    cross join value_ranges
)

select * from joined
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:43:03.540703 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */


  create view `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Orders
with cln as (
  -- Source cleaned orders data
  select * 
  from `clean`.`g1_stg_insta_orders`
),

users as (
  -- Reference users table for FK validation
  select user_id 
  from `clean`.`g1_stg_insta_users`
),

violations as (
  select
    order_id,
    user_id,
    eval_set,
    order_number,
    order_dow,
    order_hour_of_day,
    days_since_prior_order,

    -- Data Quality Issue Classification
    multiIf(
      order_id is null, 'null_order_id',
      user_id is null, 'null_user_id',
      user_id not in (select user_id from users), 'missing_user_ref',
      order_number < 1, 'invalid_order_number',
      order_dow not in (0,1,2,3,4,5,6), 'invalid_order_dow',
      order_hour_of_day < 0 or order_hour_of_day > 23, 'invalid_order_hour',
      days_since_prior_order < 0, 'negative_days_since_prior_order',
      'ok'
    ) as dq_issue

  from cln
)

-- Return only rows with detected anomalies
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:43:03.544063 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */


  create view `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Users

with cln as (
  select * from `clean`.`g1_stg_insta_users`
),
violations as (
  select
    user_id,

    multiIf(
      user_id is null, 'null_user_id',
      user_id <= 0, 'invalid_user_id',
      'ok'
    ) as dq_issue
  from cln
)
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:43:03.833735 [debug] [Thread-2  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),

cln as (
    select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts_clean as (
    select count(*) as row_count_clean
    from cln
),

-- Null Percentage
nulls as (
  select
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
  from cln
),

-- Duplicate Users Check
dupes as (
  select
    countIf(cnt > 1) as duplicate_user_ids
  from (
    select user_id, count() as cnt
    from cln
    group by user_id
  )
),

-- Referential Integrity
invalid_user_in_orders as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),

user_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

-- Join all metrics
joined as (
  select
    rawDS.row_count_raw,
    counts.row_count_clean,
    (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
    nulls.null_pct_user_id,
    dupes.duplicate_user_ids,
    invalid_user_in_orders,
    user_without_orders
  from rawDS
  cross join counts
  cross join nulls
  cross join invalid_user_in_orders
  cross join user_without_orders

)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m18:43:03.838598 [debug] [Thread-2  ]: Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1314 ('joined') (line 61, col 1): joined as (
    select
      rawDS.row_count_raw,
      counts.row_count_clean,
      (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
      nulls.null_pc. Expected one of: token, Comma, FROM, SELECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:43:03.839703 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '664b8b41-1b74-41f1-ba62-5b8be5e19468', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x700e5cc46f70>]}
[0m18:43:03.841150 [error] [Thread-2  ]: 19 of 19 ERROR creating sql view model `mart`.`g1_dq_insta_users_summary` ...... [[31mERROR[0m in 0.59s]
[0m18:43:03.842904 [debug] [Thread-2  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:43:03.851508 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:43:03.875682 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m18:43:03.893785 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:43:03.903203 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m18:43:03.905765 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m18:43:03.922225 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m18:43:04.163485 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:43:04.167620 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies` to `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m18:43:04.189108 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:43:04.192372 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies` to `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m18:43:04.200725 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:43:04.203539 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary` to `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m18:43:04.461727 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:43:04.470312 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m18:43:04.472326 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:43:04.482728 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m18:43:04.515277 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:43:04.524019 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m18:43:04.786949 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:43:04.790013 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:43:04.795175 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m18:43:04.800068 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m18:43:04.845389 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:43:04.848480 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary__dbt_tmp` to `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m18:43:05.155407 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:43:05.157716 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:43:05.159977 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m18:43:05.169809 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  ...
[0m18:43:05.179758 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  ...
[0m18:43:05.192601 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  ...
[0m18:43:05.484559 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:43:05.489098 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '664b8b41-1b74-41f1-ba62-5b8be5e19468', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x700e5bb56a60>]}
[0m18:43:05.491443 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:43:05.493351 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:43:05.495382 [info ] [Thread-1  ]: 16 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_anomalies` ....... [[32mOK[0m in 2.25s]
[0m18:43:05.499764 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '664b8b41-1b74-41f1-ba62-5b8be5e19468', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x700e5c8588e0>]}
[0m18:43:05.504081 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '664b8b41-1b74-41f1-ba62-5b8be5e19468', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x700e5c858370>]}
[0m18:43:05.506420 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:43:05.509214 [info ] [Thread-4  ]: 18 of 19 OK created sql view model `mart`.`g1_dq_insta_users_anomalies` ........ [[32mOK[0m in 2.25s]
[0m18:43:05.511614 [info ] [Thread-3  ]: 17 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_summary` ......... [[32mOK[0m in 2.26s]
[0m18:43:05.515315 [debug] [Thread-4  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:43:05.518650 [debug] [Thread-3  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:43:05.525311 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:43:05.526827 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m18:43:05.527664 [debug] [MainThread]: On list__clean: Close
[0m18:43:05.528367 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m18:43:05.529069 [debug] [MainThread]: On list__mart: Close
[0m18:43:05.529762 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_anomalies' was left open.
[0m18:43:05.530811 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: Close
[0m18:43:05.531668 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_summary' was left open.
[0m18:43:05.532522 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_summary: Close
[0m18:43:05.533357 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_anomalies' was left open.
[0m18:43:05.534005 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_anomalies: Close
[0m18:43:05.535029 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_summary' was left open.
[0m18:43:05.536097 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_summary: Close
[0m18:43:05.538408 [info ] [MainThread]: 
[0m18:43:05.540595 [info ] [MainThread]: Finished running 2 table models, 13 data tests, 4 view models in 0 hours 0 minutes and 22.69 seconds (22.69s).
[0m18:43:05.553980 [debug] [MainThread]: Command end result
[0m18:43:05.748311 [info ] [MainThread]: 
[0m18:43:05.749347 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m18:43:05.750362 [info ] [MainThread]: 
[0m18:43:05.752174 [error] [MainThread]:   Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1314 ('joined') (line 61, col 1): joined as (
    select
      rawDS.row_count_raw,
      counts.row_count_clean,
      (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
      nulls.null_pc. Expected one of: token, Comma, FROM, SELECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:43:05.753500 [info ] [MainThread]: 
[0m18:43:05.755462 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m18:43:05.758160 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 25.046976, "process_in_blocks": "0", "process_kernel_time": 1.859148, "process_mem_max_rss": "119720", "process_out_blocks": "11304", "process_user_time": 8.607616}
[0m18:43:05.759795 [debug] [MainThread]: Command `dbt build` failed at 18:43:05.759317 after 25.05 seconds
[0m18:43:05.761163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x700e62126310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x700e600bdeb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x700e616ca3a0>]}
[0m18:43:05.762269 [debug] [MainThread]: Flushing usage events
[0m18:45:23.971553 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703a70737310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703a6d378b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703a6d378a00>]}


============================== 18:45:23.986013 | 2caa1235-ea4d-4d36-bbfc-acceb62b5511 ==============================
[0m18:45:23.986013 [info ] [MainThread]: Running with dbt=1.8.9
[0m18:45:23.987422 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt build --profiles-dir . --target remote', 'debug': 'False', 'profiles_dir': '.', 'warn_error': 'None', 'introspect': 'True', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'printer_width': '80', 'empty': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'indirect_selection': 'eager', 'fail_fast': 'False', 'quiet': 'False', 'partial_parse': 'True', 'log_path': '/workdir/transforms/01_instacart/logs', 'log_cache_events': 'False', 'version_check': 'True', 'use_colors': 'True', 'log_format': 'default', 'use_experimental_parser': 'False', 'write_json': 'True'}
[0m18:45:24.331339 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2caa1235-ea4d-4d36-bbfc-acceb62b5511', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703a6fcc2ca0>]}
[0m18:45:24.450016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2caa1235-ea4d-4d36-bbfc-acceb62b5511', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703a6d3558b0>]}
[0m18:45:24.451870 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m18:45:24.646946 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m18:45:24.960949 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m18:45:24.962331 [debug] [MainThread]: Partial parsing: updated file: ex_01_instacart://models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:45:25.633960 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ex_01_mpg.mart
- models.ex_01_mpg.clean
[0m18:45:25.672734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2caa1235-ea4d-4d36-bbfc-acceb62b5511', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703a6b692eb0>]}
[0m18:45:25.969313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2caa1235-ea4d-4d36-bbfc-acceb62b5511', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703a6b5e0850>]}
[0m18:45:25.970466 [info ] [MainThread]: Found 6 models, 13 data tests, 1 source, 471 macros
[0m18:45:25.979139 [info ] [MainThread]: 
[0m18:45:25.981052 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:45:26.007105 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:45:26.009943 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:45:26.061867 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:45:26.063221 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:45:30.973222 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:45:31.107377 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:45:31.265857 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:45:31.458850 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:45:31.465200 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m18:45:31.467268 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m18:45:31.482065 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m18:45:31.489238 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m18:45:31.803374 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:45:31.814150 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:45:32.164806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2caa1235-ea4d-4d36-bbfc-acceb62b5511', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703a6b503eb0>]}
[0m18:45:32.167348 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m18:45:32.168879 [info ] [MainThread]: 
[0m18:45:32.195855 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:45:32.199152 [info ] [Thread-1  ]: 1 of 19 START sql table model `clean`.`g1_stg_insta_orders` .................... [RUN]
[0m18:45:32.202250 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_instacart.g1_stg_insta_orders'
[0m18:45:32.203711 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_orders
[0m18:45:32.230583 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:45:32.233208 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_orders
[0m18:45:32.391982 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m18:45:36.585270 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

            

    
        create table `clean`.`g1_stg_insta_orders__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (order_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
          )
        
        ...
[0m18:45:36.975492 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.39 seconds
[0m18:45:36.994543 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    select name, type from system.columns where table = 'g1_stg_insta_orders__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:45:37.329345 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:45:37.337501 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:45:37.339079 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_orders__dbt_backup`
        ("order_id", "user_id", "eval_set", "order_number", "order_dow", "order_hour_of_day", "days_since_prior_order")

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
  ...
[0m18:45:40.485219 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 3.14 seconds
[0m18:45:40.495954 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_orders__dbt_backup` AND `clean`.`g1_stg_insta_orders` 
  
  ...
[0m18:45:40.898081 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.40 seconds
[0m18:45:40.956176 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    drop table if exists `clean`.`g1_stg_insta_orders__dbt_backup` 
  ...
[0m18:45:41.332635 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m18:45:41.341135 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2caa1235-ea4d-4d36-bbfc-acceb62b5511', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703a6a974730>]}
[0m18:45:41.342852 [info ] [Thread-1  ]: 1 of 19 OK created sql table model `clean`.`g1_stg_insta_orders` ............... [[32mOK[0m in 9.14s]
[0m18:45:41.345567 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:45:41.350343 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:45:41.352746 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:45:41.354609 [info ] [Thread-3  ]: 2 of 19 START test accepted_values_g1_stg_insta_orders_eval_set__prior__train__test  [RUN]
[0m18:45:41.357370 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:45:41.359513 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:45:41.361508 [info ] [Thread-4  ]: 3 of 19 START test accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [RUN]
[0m18:45:41.364133 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5'
[0m18:45:41.366251 [info ] [Thread-2  ]: 4 of 19 START test accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [RUN]
[0m18:45:41.368387 [info ] [Thread-1  ]: 5 of 19 START test not_null_g1_stg_insta_orders_eval_set ....................... [RUN]
[0m18:45:41.371054 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145'
[0m18:45:41.373252 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:45:41.376750 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1'
[0m18:45:41.379268 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_orders, now test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7)
[0m18:45:41.381743 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:45:41.401629 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:45:41.417580 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:45:41.433901 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:45:41.453960 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:45:41.460626 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:45:41.483080 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:45:41.486226 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:45:41.488444 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:45:41.489916 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:45:41.491206 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:45:41.547496 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:45:41.575218 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:45:41.577935 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:45:41.586998 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:45:41.589923 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:45:41.592616 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m18:45:41.595021 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m18:45:41.598954 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select eval_set
from `clean`.`g1_stg_insta_orders`
where eval_set is null



    ) dbt_internal_test...
[0m18:45:42.288890 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.68 seconds
[0m18:45:42.307802 [info ] [Thread-1  ]: 5 of 19 PASS not_null_g1_stg_insta_orders_eval_set ............................. [[32mPASS[0m in 0.93s]
[0m18:45:42.310889 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:45:42.313360 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:45:42.315227 [info ] [Thread-1  ]: 6 of 19 START test not_null_g1_stg_insta_orders_order_dow ...................... [RUN]
[0m18:45:42.317397 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240)
[0m18:45:42.319357 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:45:42.336424 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:45:42.344414 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:45:42.354247 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:45:42.356993 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_dow
from `clean`.`g1_stg_insta_orders`
where order_dow is null



    ) dbt_internal_test...
[0m18:45:42.740061 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m18:45:42.745216 [info ] [Thread-1  ]: 6 of 19 PASS not_null_g1_stg_insta_orders_order_dow ............................ [[32mPASS[0m in 0.43s]
[0m18:45:42.747218 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:45:42.748889 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:45:42.750463 [info ] [Thread-1  ]: 7 of 19 START test not_null_g1_stg_insta_orders_order_hour_of_day .............. [RUN]
[0m18:45:42.751819 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576)
[0m18:45:42.753019 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:45:42.763899 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:45:42.765639 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:45:42.772477 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:45:42.775286 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_hour_of_day
from `clean`.`g1_stg_insta_orders`
where order_hour_of_day is null



    ) dbt_internal_test...
[0m18:45:43.184788 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.41 seconds
[0m18:45:43.189255 [info ] [Thread-1  ]: 7 of 19 PASS not_null_g1_stg_insta_orders_order_hour_of_day .................... [[32mPASS[0m in 0.44s]
[0m18:45:43.191140 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:45:43.192624 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:45:43.193864 [info ] [Thread-1  ]: 8 of 19 START test not_null_g1_stg_insta_orders_order_id ....................... [RUN]
[0m18:45:43.195146 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600)
[0m18:45:43.196517 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:45:43.210312 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:45:43.212016 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:45:43.219705 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:45:43.222446 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from `clean`.`g1_stg_insta_orders`
where order_id is null



    ) dbt_internal_test...
[0m18:45:43.530025 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:45:43.534525 [info ] [Thread-1  ]: 8 of 19 PASS not_null_g1_stg_insta_orders_order_id ............................. [[32mPASS[0m in 0.34s]
[0m18:45:43.536412 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:45:43.538010 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:45:43.539356 [info ] [Thread-1  ]: 9 of 19 START test not_null_g1_stg_insta_orders_order_number ................... [RUN]
[0m18:45:43.540696 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619)
[0m18:45:43.541792 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:45:43.552066 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:45:43.553902 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:45:43.560651 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:45:43.562689 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_number
from `clean`.`g1_stg_insta_orders`
where order_number is null



    ) dbt_internal_test...
[0m18:45:43.864237 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:45:43.870863 [info ] [Thread-1  ]: 9 of 19 PASS not_null_g1_stg_insta_orders_order_number ......................... [[32mPASS[0m in 0.33s]
[0m18:45:43.872794 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:45:43.874118 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:45:43.875415 [info ] [Thread-1  ]: 10 of 19 START test not_null_g1_stg_insta_orders_user_id ....................... [RUN]
[0m18:45:43.876744 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619, now test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64)
[0m18:45:43.877900 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:45:43.889940 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:45:43.891727 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:45:43.898391 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:45:43.900095 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_orders`
where user_id is null



    ) dbt_internal_test...
[0m18:45:44.198387 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:45:44.203271 [info ] [Thread-1  ]: 10 of 19 PASS not_null_g1_stg_insta_orders_user_id ............................. [[32mPASS[0m in 0.33s]
[0m18:45:44.205903 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:45:44.207232 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:45:44.208802 [info ] [Thread-1  ]: 11 of 19 START test unique_g1_stg_insta_orders_order_id ........................ [RUN]
[0m18:45:44.210249 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64, now test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57)
[0m18:45:44.211473 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:45:44.228893 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:45:44.230317 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:45:44.237905 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:45:44.239873 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_orders`
where order_id is not null
group by order_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:45:45.075371 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.83 seconds
[0m18:45:45.080127 [info ] [Thread-1  ]: 11 of 19 PASS unique_g1_stg_insta_orders_order_id .............................. [[32mPASS[0m in 0.87s]
[0m18:45:45.082028 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:45:45.503159 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        eval_set as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by eval_set

)

select *
from all_values
where value_field not in (
    'prior','train','test'
)



    ) dbt_internal_test...
[0m18:45:45.809772 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_hour_of_day as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_hour_of_day

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23'
)



    ) dbt_internal_test...
[0m18:45:45.858929 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:45:45.862996 [info ] [Thread-3  ]: 2 of 19 PASS accepted_values_g1_stg_insta_orders_eval_set__prior__train__test .. [[32mPASS[0m in 4.50s]
[0m18:45:45.865107 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:45:46.017997 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_dow as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_dow

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6'
)



    ) dbt_internal_test...
[0m18:45:46.169600 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m18:45:46.174057 [info ] [Thread-2  ]: 4 of 19 PASS accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [[32mPASS[0m in 4.80s]
[0m18:45:46.176011 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:45:46.423028 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.40 seconds
[0m18:45:46.428809 [info ] [Thread-4  ]: 3 of 19 PASS accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [[32mPASS[0m in 5.06s]
[0m18:45:46.432038 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:45:46.435094 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_users
[0m18:45:46.436951 [info ] [Thread-1  ]: 12 of 19 START sql table model `clean`.`g1_stg_insta_users` .................... [RUN]
[0m18:45:46.438812 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57, now model.ex_01_instacart.g1_stg_insta_users)
[0m18:45:46.440821 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_users
[0m18:45:46.452333 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:45:46.454116 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_users
[0m18:45:46.469168 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

            

    
        create table `clean`.`g1_stg_insta_users__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (user_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
          )
        
        ...
[0m18:45:46.758118 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:45:46.764881 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    select name, type from system.columns where table = 'g1_stg_insta_users__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:45:47.040719 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:45:47.045889 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:45:47.048963 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_users__dbt_backup`
        ("user_id")

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
  ...
[0m18:45:47.526069 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.47 seconds
[0m18:45:47.531059 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_users__dbt_backup` AND `clean`.`g1_stg_insta_users` 
  
  ...
[0m18:45:47.811129 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:45:47.820681 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    drop table if exists `clean`.`g1_stg_insta_users__dbt_backup` 
  ...
[0m18:45:48.141245 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:45:48.146988 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2caa1235-ea4d-4d36-bbfc-acceb62b5511', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703a6b1df850>]}
[0m18:45:48.149525 [info ] [Thread-1  ]: 12 of 19 OK created sql table model `clean`.`g1_stg_insta_users` ............... [[32mOK[0m in 1.71s]
[0m18:45:48.153450 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_users
[0m18:45:48.158631 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:45:48.161190 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:45:48.163965 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:45:48.166434 [info ] [Thread-2  ]: 13 of 19 START test not_null_g1_stg_insta_users_user_id ........................ [RUN]
[0m18:45:48.169142 [info ] [Thread-4  ]: 14 of 19 START test relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [RUN]
[0m18:45:48.171702 [info ] [Thread-3  ]: 15 of 19 START test unique_g1_stg_insta_users_user_id .......................... [RUN]
[0m18:45:48.174703 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1, now test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935)
[0m18:45:48.177344 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145, now test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726)
[0m18:45:48.179799 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5, now test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f)
[0m18:45:48.182183 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:45:48.186112 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:45:48.188802 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:45:48.230700 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:45:48.237964 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:45:48.254202 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:45:48.256226 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:45:48.264240 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:45:48.266204 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:45:48.272686 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:45:48.274218 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:45:48.282250 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:45:48.284093 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_users`
where user_id is null



    ) dbt_internal_test...
[0m18:45:48.285772 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    user_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_users`
where user_id is not null
group by user_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:45:48.289923 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select user_id as from_field
    from `clean`.`g1_stg_insta_orders`
    where user_id is not null
),

parent as (
    select user_id as to_field
    from `clean`.`g1_stg_insta_users`
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null
-- end_of_sql
settings join_use_nulls = 1



    ) dbt_internal_test...
[0m18:45:48.575207 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:45:48.580354 [info ] [Thread-2  ]: 13 of 19 PASS not_null_g1_stg_insta_users_user_id .............................. [[32mPASS[0m in 0.41s]
[0m18:45:48.583016 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:45:48.636924 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:45:48.640847 [info ] [Thread-3  ]: 15 of 19 PASS unique_g1_stg_insta_users_user_id ................................ [[32mPASS[0m in 0.46s]
[0m18:45:48.643176 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:45:48.890860 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.60 seconds
[0m18:45:48.896067 [info ] [Thread-4  ]: 14 of 19 PASS relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [[32mPASS[0m in 0.72s]
[0m18:45:48.898447 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:45:48.901433 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:45:48.902813 [debug] [Thread-2  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:45:48.904230 [info ] [Thread-1  ]: 16 of 19 START sql view model `mart`.`g1_dq_insta_orders_anomalies` ............ [RUN]
[0m18:45:48.906268 [debug] [Thread-3  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:45:48.908864 [info ] [Thread-2  ]: 17 of 19 START sql view model `mart`.`g1_dq_insta_orders_summary` .............. [RUN]
[0m18:45:48.911695 [debug] [Thread-4  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:45:48.913376 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_users, now model.ex_01_instacart.g1_dq_insta_orders_anomalies)
[0m18:45:48.915636 [info ] [Thread-3  ]: 18 of 19 START sql view model `mart`.`g1_dq_insta_users_anomalies` ............. [RUN]
[0m18:45:48.918187 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935, now model.ex_01_instacart.g1_dq_insta_orders_summary)
[0m18:45:48.920701 [info ] [Thread-4  ]: 19 of 19 START sql view model `mart`.`g1_dq_insta_users_summary` ............... [RUN]
[0m18:45:48.922859 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:45:48.926083 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f, now model.ex_01_instacart.g1_dq_insta_users_anomalies)
[0m18:45:48.928430 [debug] [Thread-2  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:45:48.930947 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726, now model.ex_01_instacart.g1_dq_insta_users_summary)
[0m18:45:48.945107 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:45:48.946410 [debug] [Thread-3  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:45:48.957796 [debug] [Thread-2  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:45:48.959751 [debug] [Thread-4  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:45:48.967301 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:45:48.971212 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:45:48.982218 [debug] [Thread-4  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:45:48.984308 [debug] [Thread-2  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:45:49.025902 [debug] [Thread-3  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:45:49.100784 [debug] [Thread-4  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:45:49.169344 [debug] [Thread-4  ]: Creating new relation g1_dq_insta_users_summary
[0m18:45:49.337392 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:45:49.341361 [debug] [Thread-4  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:45:49.346775 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),

cln as (
    select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts_clean as (
    select count(*) as row_count_clean
    from cln
),

-- Null Percentage
nulls as (
  select
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
  from cln
),

-- Duplicate Users Check
dupes as (
  select
    countIf(cnt > 1) as duplicate_user_ids
  from (
    select user_id, count() as cnt
    from cln
    group by user_id
  )
),

-- Referential Integrity
invalid_user_in_orders as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),

user_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

-- Join all metrics
joined as (
  select
    rawDS.row_count_raw,
    counts_clean.row_count_clean,
    (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
    nulls.null_pct_user_id,
    dupes.duplicate_user_ids,
    invalid_user_in_orders,
    user_without_orders
  from rawDS
  cross join counts_clean
  cross join nulls
  cross join invalid_user_in_orders
  cross join user_without_orders

)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:45:49.368197 [debug] [Thread-2  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:45:49.372018 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */


  create view `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Users

with cln as (
  select * from `clean`.`g1_stg_insta_users`
),
violations as (
  select
    user_id,

    multiIf(
      user_id is null, 'null_user_id',
      user_id <= 0, 'invalid_user_id',
      'ok'
    ) as dq_issue
  from cln
)
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:45:49.395041 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */


  create view `mart`.`g1_dq_insta_orders_summary__dbt_tmp` 
  
    
    
  as (
    

-- Data Quality Summary for Orders
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  select * from `raw`.`raw___insta_orders`
),

cln as (
  select * from `clean`.`g1_stg_insta_orders`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage Check
nulls as (
  select
    round(100.0 * countIf(order_id is null) / nullif(count(),0), 2) as null_pct_order_id,
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id,
    round(100.0 * countIf(eval_set is null) / nullif(count(),0), 2) as null_pct_eval_set,
    round(100.0 * countIf(order_number is null) / nullif(count(),0), 2) as null_pct_order_number,
    round(100.0 * countIf(order_dow is null) / nullif(count(),0), 2) as null_pct_order_dow,
    round(100.0 * countIf(order_hour_of_day is null) / nullif(count(),0), 2) as null_pct_order_hour_of_day,
    round(100.0 * countIf(days_since_prior_order is null) / nullif(count(),0), 2) as null_pct_days_since_prior_order
  from cln
),

-- Duplicate Orders
dupes as (
  select
    countIf(cnt > 1) as duplicate_orders
  from (
    select order_id, count() as cnt
    from cln
    group by order_id
  )
),

-- Referential Integrity
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_id
  from `clean`.`g1_stg_insta_orders` o
),

-- Value Range Checks
value_ranges as (
  select
    countIf(order_number < 1) as invalid_order_number,
    countIf(order_hour_of_day < 0 or order_hour_of_day > 23) as invalid_order_hour,
    countIf(days_since_prior_order < 0 or days_since_prior_order > 30) as invalid_days_since_prior_order
  from cln
),

-- Join all metrics
joined as (
    select
        counts.row_count_raw,
        counts.row_count_clean,
        (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
        nulls.*,
        dupes.duplicate_orders,
        referential_integrity.invalid_user_id,
        value_ranges.invalid_order_number,
        value_ranges.invalid_order_hour,
        value_ranges.invalid_days_since_prior_order
    from counts
    cross join nulls
    cross join dupes
    cross join referential_integrity
    cross join value_ranges
)

select * from joined
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:45:49.405697 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:45:49.409597 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */


  create view `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Orders
with cln as (
  -- Source cleaned orders data
  select * 
  from `clean`.`g1_stg_insta_orders`
),

users as (
  -- Reference users table for FK validation
  select user_id 
  from `clean`.`g1_stg_insta_users`
),

violations as (
  select
    order_id,
    user_id,
    eval_set,
    order_number,
    order_dow,
    order_hour_of_day,
    days_since_prior_order,

    -- Data Quality Issue Classification
    multiIf(
      order_id is null, 'null_order_id',
      user_id is null, 'null_user_id',
      user_id not in (select user_id from users), 'missing_user_ref',
      order_number < 1, 'invalid_order_number',
      order_dow not in (0,1,2,3,4,5,6), 'invalid_order_dow',
      order_hour_of_day < 0 or order_hour_of_day > 23, 'invalid_order_hour',
      days_since_prior_order < 0, 'negative_days_since_prior_order',
      'ok'
    ) as dq_issue

  from cln
)

-- Return only rows with detected anomalies
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:45:49.667902 [debug] [Thread-4  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),

cln as (
    select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts_clean as (
    select count(*) as row_count_clean
    from cln
),

-- Null Percentage
nulls as (
  select
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
  from cln
),

-- Duplicate Users Check
dupes as (
  select
    countIf(cnt > 1) as duplicate_user_ids
  from (
    select user_id, count() as cnt
    from cln
    group by user_id
  )
),

-- Referential Integrity
invalid_user_in_orders as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),

user_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

-- Join all metrics
joined as (
  select
    rawDS.row_count_raw,
    counts_clean.row_count_clean,
    (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
    nulls.null_pct_user_id,
    dupes.duplicate_user_ids,
    invalid_user_in_orders,
    user_without_orders
  from rawDS
  cross join counts_clean
  cross join nulls
  cross join invalid_user_in_orders
  cross join user_without_orders

)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m18:45:49.676133 [debug] [Thread-4  ]: Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1314 ('joined') (line 61, col 1): joined as (
    select
      rawDS.row_count_raw,
      counts_clean.row_count_clean,
      (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
      nulls.n. Expected one of: token, Comma, FROM, SELECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:45:49.677781 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2caa1235-ea4d-4d36-bbfc-acceb62b5511', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703a6a072280>]}
[0m18:45:49.681267 [error] [Thread-4  ]: 19 of 19 ERROR creating sql view model `mart`.`g1_dq_insta_users_summary` ...... [[31mERROR[0m in 0.75s]
[0m18:45:49.687521 [debug] [Thread-4  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:45:49.709367 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:45:49.742125 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:45:49.748306 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m18:45:49.752419 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:45:49.774241 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m18:45:49.787423 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m18:45:50.063371 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:45:50.066240 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:45:50.070829 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies` to `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m18:45:50.075347 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies` to `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m18:45:50.078226 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:45:50.088727 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary` to `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m18:45:50.368103 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:45:50.370625 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:45:50.372688 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:45:50.382633 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m18:45:50.392490 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m18:45:50.400554 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m18:45:50.685746 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:45:50.689459 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:45:50.692215 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:45:50.698167 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary__dbt_tmp` to `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m18:45:50.703152 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m18:45:50.708161 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m18:45:50.978208 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:45:50.980253 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:45:50.990207 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  ...
[0m18:45:51.004737 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:45:51.006338 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  ...
[0m18:45:51.024133 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  ...
[0m18:45:51.324790 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:45:51.327781 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:45:51.332001 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2caa1235-ea4d-4d36-bbfc-acceb62b5511', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703a6a15aee0>]}
[0m18:45:51.336185 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2caa1235-ea4d-4d36-bbfc-acceb62b5511', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703a6a15dee0>]}
[0m18:45:51.338064 [info ] [Thread-3  ]: 18 of 19 OK created sql view model `mart`.`g1_dq_insta_users_anomalies` ........ [[32mOK[0m in 2.41s]
[0m18:45:51.340449 [info ] [Thread-2  ]: 17 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_summary` ......... [[32mOK[0m in 2.42s]
[0m18:45:51.343859 [debug] [Thread-3  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:45:51.346018 [debug] [Thread-2  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:45:51.376998 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:45:51.380860 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2caa1235-ea4d-4d36-bbfc-acceb62b5511', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703a6a08a5b0>]}
[0m18:45:51.382395 [info ] [Thread-1  ]: 16 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_anomalies` ....... [[32mOK[0m in 2.47s]
[0m18:45:51.384556 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:45:51.389039 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:45:51.390068 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m18:45:51.390907 [debug] [MainThread]: On list__clean: Close
[0m18:45:51.391724 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m18:45:51.392818 [debug] [MainThread]: On list__mart: Close
[0m18:45:51.394008 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_anomalies' was left open.
[0m18:45:51.395098 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: Close
[0m18:45:51.396266 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_anomalies' was left open.
[0m18:45:51.397372 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_anomalies: Close
[0m18:45:51.398300 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_summary' was left open.
[0m18:45:51.399014 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_summary: Close
[0m18:45:51.400021 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_summary' was left open.
[0m18:45:51.401069 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_summary: Close
[0m18:45:51.403428 [info ] [MainThread]: 
[0m18:45:51.405266 [info ] [MainThread]: Finished running 2 table models, 13 data tests, 4 view models in 0 hours 0 minutes and 25.42 seconds (25.42s).
[0m18:45:51.418703 [debug] [MainThread]: Command end result
[0m18:45:51.507182 [info ] [MainThread]: 
[0m18:45:51.509144 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m18:45:51.511105 [info ] [MainThread]: 
[0m18:45:51.513383 [error] [MainThread]:   Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1314 ('joined') (line 61, col 1): joined as (
    select
      rawDS.row_count_raw,
      counts_clean.row_count_clean,
      (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
      nulls.n. Expected one of: token, Comma, FROM, SELECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:45:51.514830 [info ] [MainThread]: 
[0m18:45:51.517244 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m18:45:51.520700 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 27.684044, "process_in_blocks": "0", "process_kernel_time": 2.160599, "process_mem_max_rss": "119272", "process_out_blocks": "11312", "process_user_time": 9.404251}
[0m18:45:51.522445 [debug] [MainThread]: Command `dbt build` failed at 18:45:51.521766 after 27.69 seconds
[0m18:45:51.523842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703a70737310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703a6ca98a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703a6b5667c0>]}
[0m18:45:51.525159 [debug] [MainThread]: Flushing usage events
[0m18:46:57.198676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791a464be310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791a4311ba90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791a4311b940>]}


============================== 18:46:57.215718 | f053e21e-c510-4f82-bf9b-595ad5e68df5 ==============================
[0m18:46:57.215718 [info ] [MainThread]: Running with dbt=1.8.9
[0m18:46:57.217536 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'debug': 'False', 'use_experimental_parser': 'False', 'use_colors': 'True', 'version_check': 'True', 'target_path': 'None', 'introspect': 'True', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'empty': 'False', 'static_parser': 'True', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_path': '/workdir/transforms/01_instacart/logs', 'write_json': 'True', 'log_format': 'default', 'profiles_dir': '.', 'printer_width': '80', 'cache_selected_only': 'False', 'no_print': 'None', 'log_cache_events': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'quiet': 'False'}
[0m18:46:57.580192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f053e21e-c510-4f82-bf9b-595ad5e68df5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791a430faa60>]}
[0m18:46:57.705899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f053e21e-c510-4f82-bf9b-595ad5e68df5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791a4321bb20>]}
[0m18:46:57.708000 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m18:46:57.912826 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m18:46:58.222072 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m18:46:58.223539 [debug] [MainThread]: Partial parsing: updated file: ex_01_instacart://models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:46:58.932124 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ex_01_mpg.mart
- models.ex_01_mpg.clean
[0m18:46:58.973980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f053e21e-c510-4f82-bf9b-595ad5e68df5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791a413ec130>]}
[0m18:46:59.282982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f053e21e-c510-4f82-bf9b-595ad5e68df5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791a42878520>]}
[0m18:46:59.284837 [info ] [MainThread]: Found 6 models, 13 data tests, 1 source, 471 macros
[0m18:46:59.292891 [info ] [MainThread]: 
[0m18:46:59.294958 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:46:59.316317 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:46:59.323954 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:46:59.368759 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:46:59.372759 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:47:03.567150 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:47:03.858969 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:47:03.933183 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:47:04.206511 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:47:04.213399 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m18:47:04.215880 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m18:47:04.231781 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m18:47:04.239036 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m18:47:04.591152 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:47:04.623808 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m18:47:04.956459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f053e21e-c510-4f82-bf9b-595ad5e68df5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791a412f4fd0>]}
[0m18:47:04.958042 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m18:47:04.959185 [info ] [MainThread]: 
[0m18:47:04.986060 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:47:04.988393 [info ] [Thread-1  ]: 1 of 19 START sql table model `clean`.`g1_stg_insta_orders` .................... [RUN]
[0m18:47:04.991272 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_instacart.g1_stg_insta_orders'
[0m18:47:04.994212 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_orders
[0m18:47:05.040476 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:47:05.043500 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_orders
[0m18:47:05.187329 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m18:47:09.239720 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

            

    
        create table `clean`.`g1_stg_insta_orders__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (order_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
          )
        
        ...
[0m18:47:09.542112 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:47:09.561146 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    select name, type from system.columns where table = 'g1_stg_insta_orders__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:47:09.845325 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:47:09.854082 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:47:09.856339 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_orders__dbt_backup`
        ("order_id", "user_id", "eval_set", "order_number", "order_dow", "order_hour_of_day", "days_since_prior_order")

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
  ...
[0m18:47:12.525732 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 2.67 seconds
[0m18:47:12.536931 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_orders__dbt_backup` AND `clean`.`g1_stg_insta_orders` 
  
  ...
[0m18:47:12.823845 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:47:12.891454 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    drop table if exists `clean`.`g1_stg_insta_orders__dbt_backup` 
  ...
[0m18:47:13.188230 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:47:13.197660 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f053e21e-c510-4f82-bf9b-595ad5e68df5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791a40758880>]}
[0m18:47:13.200268 [info ] [Thread-1  ]: 1 of 19 OK created sql table model `clean`.`g1_stg_insta_orders` ............... [[32mOK[0m in 8.21s]
[0m18:47:13.202258 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:47:13.205403 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:47:13.207302 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:47:13.211765 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:47:13.209295 [info ] [Thread-3  ]: 2 of 19 START test accepted_values_g1_stg_insta_orders_eval_set__prior__train__test  [RUN]
[0m18:47:13.215265 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:47:13.217181 [info ] [Thread-4  ]: 3 of 19 START test accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [RUN]
[0m18:47:13.219782 [info ] [Thread-2  ]: 4 of 19 START test accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [RUN]
[0m18:47:13.222770 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5'
[0m18:47:13.224654 [info ] [Thread-1  ]: 5 of 19 START test not_null_g1_stg_insta_orders_eval_set ....................... [RUN]
[0m18:47:13.227422 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145'
[0m18:47:13.231017 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1'
[0m18:47:13.233282 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:47:13.235710 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_orders, now test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7)
[0m18:47:13.237720 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:47:13.239344 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:47:13.262761 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:47:13.287096 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:47:13.301403 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:47:13.314797 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:47:13.333590 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:47:13.337739 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:47:13.340415 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:47:13.342546 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:47:13.355675 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:47:13.391401 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:47:13.411285 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:47:13.427394 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:47:13.435085 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:47:13.438594 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:47:13.440901 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m18:47:13.443471 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m18:47:13.445096 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select eval_set
from `clean`.`g1_stg_insta_orders`
where eval_set is null



    ) dbt_internal_test...
[0m18:47:14.089737 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.64 seconds
[0m18:47:14.098867 [info ] [Thread-1  ]: 5 of 19 PASS not_null_g1_stg_insta_orders_eval_set ............................. [[32mPASS[0m in 0.86s]
[0m18:47:14.101331 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:47:14.102852 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:47:14.104204 [info ] [Thread-1  ]: 6 of 19 START test not_null_g1_stg_insta_orders_order_dow ...................... [RUN]
[0m18:47:14.105445 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240)
[0m18:47:14.106954 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:47:14.122976 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:47:14.124510 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:47:14.132711 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:47:14.134860 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_dow
from `clean`.`g1_stg_insta_orders`
where order_dow is null



    ) dbt_internal_test...
[0m18:47:14.425276 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:47:14.443309 [info ] [Thread-1  ]: 6 of 19 PASS not_null_g1_stg_insta_orders_order_dow ............................ [[32mPASS[0m in 0.34s]
[0m18:47:14.448082 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:47:14.451621 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:47:14.457040 [info ] [Thread-1  ]: 7 of 19 START test not_null_g1_stg_insta_orders_order_hour_of_day .............. [RUN]
[0m18:47:14.461884 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576)
[0m18:47:14.463971 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:47:14.498813 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:47:14.502691 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:47:14.535664 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:47:14.539443 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_hour_of_day
from `clean`.`g1_stg_insta_orders`
where order_hour_of_day is null



    ) dbt_internal_test...
[0m18:47:14.848100 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:47:14.853701 [info ] [Thread-1  ]: 7 of 19 PASS not_null_g1_stg_insta_orders_order_hour_of_day .................... [[32mPASS[0m in 0.39s]
[0m18:47:14.857034 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:47:14.859134 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:47:14.862978 [info ] [Thread-1  ]: 8 of 19 START test not_null_g1_stg_insta_orders_order_id ....................... [RUN]
[0m18:47:14.866844 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600)
[0m18:47:14.869106 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:47:14.887847 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:47:14.890706 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:47:14.900045 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:47:14.902397 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from `clean`.`g1_stg_insta_orders`
where order_id is null



    ) dbt_internal_test...
[0m18:47:15.187838 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:47:15.195173 [info ] [Thread-1  ]: 8 of 19 PASS not_null_g1_stg_insta_orders_order_id ............................. [[32mPASS[0m in 0.33s]
[0m18:47:15.199021 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:47:15.202224 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:47:15.205898 [info ] [Thread-1  ]: 9 of 19 START test not_null_g1_stg_insta_orders_order_number ................... [RUN]
[0m18:47:15.208957 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619)
[0m18:47:15.211047 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:47:15.237507 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:47:15.241295 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:47:15.251576 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:47:15.254740 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_number
from `clean`.`g1_stg_insta_orders`
where order_number is null



    ) dbt_internal_test...
[0m18:47:15.594847 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:47:15.601443 [info ] [Thread-1  ]: 9 of 19 PASS not_null_g1_stg_insta_orders_order_number ......................... [[32mPASS[0m in 0.39s]
[0m18:47:15.604915 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:47:15.607143 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:47:15.608747 [info ] [Thread-1  ]: 10 of 19 START test not_null_g1_stg_insta_orders_user_id ....................... [RUN]
[0m18:47:15.611535 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619, now test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64)
[0m18:47:15.614088 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:47:15.639133 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:47:15.645088 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:47:15.659694 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:47:15.662699 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_orders`
where user_id is null



    ) dbt_internal_test...
[0m18:47:15.956379 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:47:15.962774 [info ] [Thread-1  ]: 10 of 19 PASS not_null_g1_stg_insta_orders_user_id ............................. [[32mPASS[0m in 0.35s]
[0m18:47:15.965649 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:47:15.967754 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:47:15.969787 [info ] [Thread-1  ]: 11 of 19 START test unique_g1_stg_insta_orders_order_id ........................ [RUN]
[0m18:47:15.973159 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64, now test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57)
[0m18:47:15.974814 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:47:16.008748 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:47:16.013001 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:47:16.022256 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:47:16.025909 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_orders`
where order_id is not null
group by order_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:47:17.039326 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 1.01 seconds
[0m18:47:17.042632 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        eval_set as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by eval_set

)

select *
from all_values
where value_field not in (
    'prior','train','test'
)



    ) dbt_internal_test...
[0m18:47:17.051202 [info ] [Thread-1  ]: 11 of 19 PASS unique_g1_stg_insta_orders_order_id .............................. [[32mPASS[0m in 1.08s]
[0m18:47:17.059542 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:47:17.095403 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_hour_of_day as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_hour_of_day

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23'
)



    ) dbt_internal_test...
[0m18:47:17.327942 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_dow as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_dow

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6'
)



    ) dbt_internal_test...
[0m18:47:17.386994 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:47:17.390958 [info ] [Thread-3  ]: 2 of 19 PASS accepted_values_g1_stg_insta_orders_eval_set__prior__train__test .. [[32mPASS[0m in 4.17s]
[0m18:47:17.393298 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:47:17.406441 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:47:17.412327 [info ] [Thread-2  ]: 4 of 19 PASS accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [[32mPASS[0m in 4.18s]
[0m18:47:17.415684 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:47:17.647861 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:47:17.652371 [info ] [Thread-4  ]: 3 of 19 PASS accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [[32mPASS[0m in 4.43s]
[0m18:47:17.654513 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:47:17.657902 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_users
[0m18:47:17.659659 [info ] [Thread-1  ]: 12 of 19 START sql table model `clean`.`g1_stg_insta_users` .................... [RUN]
[0m18:47:17.661137 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57, now model.ex_01_instacart.g1_stg_insta_users)
[0m18:47:17.662410 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_users
[0m18:47:17.672006 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:47:17.673523 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_users
[0m18:47:17.686664 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

            

    
        create table `clean`.`g1_stg_insta_users__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (user_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
          )
        
        ...
[0m18:47:17.988331 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:47:17.995312 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    select name, type from system.columns where table = 'g1_stg_insta_users__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:47:18.271657 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:47:18.276599 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:47:18.278821 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_users__dbt_backup`
        ("user_id")

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
  ...
[0m18:47:18.790070 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.51 seconds
[0m18:47:18.795269 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_users__dbt_backup` AND `clean`.`g1_stg_insta_users` 
  
  ...
[0m18:47:19.079850 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:47:19.108925 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    drop table if exists `clean`.`g1_stg_insta_users__dbt_backup` 
  ...
[0m18:47:19.395659 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:47:19.400173 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f053e21e-c510-4f82-bf9b-595ad5e68df5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791a3ff5f3a0>]}
[0m18:47:19.402529 [info ] [Thread-1  ]: 12 of 19 OK created sql table model `clean`.`g1_stg_insta_users` ............... [[32mOK[0m in 1.74s]
[0m18:47:19.405225 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_users
[0m18:47:19.408869 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:47:19.411008 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:47:19.415820 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:47:19.413308 [info ] [Thread-2  ]: 13 of 19 START test not_null_g1_stg_insta_users_user_id ........................ [RUN]
[0m18:47:19.419379 [info ] [Thread-4  ]: 14 of 19 START test relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [RUN]
[0m18:47:19.422255 [info ] [Thread-3  ]: 15 of 19 START test unique_g1_stg_insta_users_user_id .......................... [RUN]
[0m18:47:19.425459 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1, now test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935)
[0m18:47:19.427702 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145, now test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726)
[0m18:47:19.429540 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5, now test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f)
[0m18:47:19.431584 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:47:19.433866 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:47:19.435993 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:47:19.450538 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:47:19.493496 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:47:19.497400 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:47:19.501408 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:47:19.504835 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:47:19.512534 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:47:19.515990 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:47:19.525242 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:47:19.537509 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:47:19.541590 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_users`
where user_id is null



    ) dbt_internal_test...
[0m18:47:19.544302 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    user_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_users`
where user_id is not null
group by user_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:47:19.549398 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select user_id as from_field
    from `clean`.`g1_stg_insta_orders`
    where user_id is not null
),

parent as (
    select user_id as to_field
    from `clean`.`g1_stg_insta_users`
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null
-- end_of_sql
settings join_use_nulls = 1



    ) dbt_internal_test...
[0m18:47:19.819402 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:47:19.823949 [info ] [Thread-2  ]: 13 of 19 PASS not_null_g1_stg_insta_users_user_id .............................. [[32mPASS[0m in 0.40s]
[0m18:47:19.826125 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:47:19.883251 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:47:19.888156 [info ] [Thread-3  ]: 15 of 19 PASS unique_g1_stg_insta_users_user_id ................................ [[32mPASS[0m in 0.46s]
[0m18:47:19.890053 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:47:20.132805 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.58 seconds
[0m18:47:20.137397 [info ] [Thread-4  ]: 14 of 19 PASS relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [[32mPASS[0m in 0.71s]
[0m18:47:20.139932 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:47:20.142981 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:47:20.144647 [debug] [Thread-2  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:47:20.146981 [debug] [Thread-3  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:47:20.149024 [info ] [Thread-1  ]: 16 of 19 START sql view model `mart`.`g1_dq_insta_orders_anomalies` ............ [RUN]
[0m18:47:20.151544 [debug] [Thread-4  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:47:20.153551 [info ] [Thread-2  ]: 17 of 19 START sql view model `mart`.`g1_dq_insta_orders_summary` .............. [RUN]
[0m18:47:20.156272 [info ] [Thread-3  ]: 18 of 19 START sql view model `mart`.`g1_dq_insta_users_anomalies` ............. [RUN]
[0m18:47:20.158801 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_users, now model.ex_01_instacart.g1_dq_insta_orders_anomalies)
[0m18:47:20.161184 [info ] [Thread-4  ]: 19 of 19 START sql view model `mart`.`g1_dq_insta_users_summary` ............... [RUN]
[0m18:47:20.163412 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935, now model.ex_01_instacart.g1_dq_insta_orders_summary)
[0m18:47:20.166229 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f, now model.ex_01_instacart.g1_dq_insta_users_anomalies)
[0m18:47:20.169105 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:47:20.171138 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726, now model.ex_01_instacart.g1_dq_insta_users_summary)
[0m18:47:20.172590 [debug] [Thread-2  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:47:20.174209 [debug] [Thread-3  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:47:20.186640 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:47:20.187937 [debug] [Thread-4  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:47:20.199216 [debug] [Thread-2  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:47:20.210222 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:47:20.223683 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:47:20.225258 [debug] [Thread-4  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:47:20.239244 [debug] [Thread-3  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:47:20.252921 [debug] [Thread-2  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:47:20.323442 [debug] [Thread-4  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:47:20.418997 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:47:20.422332 [debug] [Thread-4  ]: Creating new relation g1_dq_insta_users_summary
[0m18:47:20.429045 [debug] [Thread-2  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:47:20.443458 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:47:20.448434 [debug] [Thread-4  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:47:20.454658 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */


  create view `mart`.`g1_dq_insta_orders_summary__dbt_tmp` 
  
    
    
  as (
    

-- Data Quality Summary for Orders
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  select * from `raw`.`raw___insta_orders`
),

cln as (
  select * from `clean`.`g1_stg_insta_orders`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage Check
nulls as (
  select
    round(100.0 * countIf(order_id is null) / nullif(count(),0), 2) as null_pct_order_id,
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id,
    round(100.0 * countIf(eval_set is null) / nullif(count(),0), 2) as null_pct_eval_set,
    round(100.0 * countIf(order_number is null) / nullif(count(),0), 2) as null_pct_order_number,
    round(100.0 * countIf(order_dow is null) / nullif(count(),0), 2) as null_pct_order_dow,
    round(100.0 * countIf(order_hour_of_day is null) / nullif(count(),0), 2) as null_pct_order_hour_of_day,
    round(100.0 * countIf(days_since_prior_order is null) / nullif(count(),0), 2) as null_pct_days_since_prior_order
  from cln
),

-- Duplicate Orders
dupes as (
  select
    countIf(cnt > 1) as duplicate_orders
  from (
    select order_id, count() as cnt
    from cln
    group by order_id
  )
),

-- Referential Integrity
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_id
  from `clean`.`g1_stg_insta_orders` o
),

-- Value Range Checks
value_ranges as (
  select
    countIf(order_number < 1) as invalid_order_number,
    countIf(order_hour_of_day < 0 or order_hour_of_day > 23) as invalid_order_hour,
    countIf(days_since_prior_order < 0 or days_since_prior_order > 30) as invalid_days_since_prior_order
  from cln
),

-- Join all metrics
joined as (
    select
        counts.row_count_raw,
        counts.row_count_clean,
        (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
        nulls.*,
        dupes.duplicate_orders,
        referential_integrity.invalid_user_id,
        value_ranges.invalid_order_number,
        value_ranges.invalid_order_hour,
        value_ranges.invalid_days_since_prior_order
    from counts
    cross join nulls
    cross join dupes
    cross join referential_integrity
    cross join value_ranges
)

select * from joined
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:47:20.458124 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */


  create view `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Orders
with cln as (
  -- Source cleaned orders data
  select * 
  from `clean`.`g1_stg_insta_orders`
),

users as (
  -- Reference users table for FK validation
  select user_id 
  from `clean`.`g1_stg_insta_users`
),

violations as (
  select
    order_id,
    user_id,
    eval_set,
    order_number,
    order_dow,
    order_hour_of_day,
    days_since_prior_order,

    -- Data Quality Issue Classification
    multiIf(
      order_id is null, 'null_order_id',
      user_id is null, 'null_user_id',
      user_id not in (select user_id from users), 'missing_user_ref',
      order_number < 1, 'invalid_order_number',
      order_dow not in (0,1,2,3,4,5,6), 'invalid_order_dow',
      order_hour_of_day < 0 or order_hour_of_day > 23, 'invalid_order_hour',
      days_since_prior_order < 0, 'negative_days_since_prior_order',
      'ok'
    ) as dq_issue

  from cln
)

-- Return only rows with detected anomalies
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:47:20.465075 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),

cln as (
    select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts_clean as (
    select count(*) as row_count_clean
    from cln
),

-- Null Percentage
nulls as (
  select
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
  from cln
),

-- Duplicate Users Check
dupes as (
  select
    countIf(cnt > 1) as duplicate_user_ids
  from (
    select user_id, count() as cnt
    from cln
    group by user_id
  )
),

-- Referential Integrity
invalid_user_in_orders as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),

user_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

-- Join all metrics
joined as (
  select
    rawDS.row_count_raw,
    counts_clean.row_count_clean,
    (rawDS.row_count_raw - counts_clean.row_count_clean) as dropped_rows,
    nulls.null_pct_user_id,
    dupes.duplicate_user_ids,
    invalid_user_in_orders,
    user_without_orders
  from rawDS
  cross join counts_clean
  cross join nulls
  cross join invalid_user_in_orders
  cross join user_without_orders

)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:47:20.469868 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */


  create view `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Users

with cln as (
  select * from `clean`.`g1_stg_insta_users`
),
violations as (
  select
    user_id,

    multiIf(
      user_id is null, 'null_user_id',
      user_id <= 0, 'invalid_user_id',
      'ok'
    ) as dq_issue
  from cln
)
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:47:20.779851 [debug] [Thread-4  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),

cln as (
    select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts_clean as (
    select count(*) as row_count_clean
    from cln
),

-- Null Percentage
nulls as (
  select
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
  from cln
),

-- Duplicate Users Check
dupes as (
  select
    countIf(cnt > 1) as duplicate_user_ids
  from (
    select user_id, count() as cnt
    from cln
    group by user_id
  )
),

-- Referential Integrity
invalid_user_in_orders as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),

user_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

-- Join all metrics
joined as (
  select
    rawDS.row_count_raw,
    counts_clean.row_count_clean,
    (rawDS.row_count_raw - counts_clean.row_count_clean) as dropped_rows,
    nulls.null_pct_user_id,
    dupes.duplicate_user_ids,
    invalid_user_in_orders,
    user_without_orders
  from rawDS
  cross join counts_clean
  cross join nulls
  cross join invalid_user_in_orders
  cross join user_without_orders

)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m18:47:20.792902 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:47:20.796864 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:47:20.836918 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m18:47:20.894022 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m18:47:20.919632 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m18:47:20.886083 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m18:47:20.930587 [debug] [Thread-4  ]: Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1314 ('joined') (line 61, col 1): joined as (
    select
      rawDS.row_count_raw,
      counts_clean.row_count_clean,
      (rawDS.row_count_raw - counts_clean.row_count_clean) as dropped_rows,
      nu. Expected one of: token, Comma, FROM, SELECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:47:20.955807 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f053e21e-c510-4f82-bf9b-595ad5e68df5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791a3fe01ca0>]}
[0m18:47:20.959699 [error] [Thread-4  ]: 19 of 19 ERROR creating sql view model `mart`.`g1_dq_insta_users_summary` ...... [[31mERROR[0m in 0.78s]
[0m18:47:20.974792 [debug] [Thread-4  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:47:21.230896 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:47:21.234290 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:47:21.240149 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies` to `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m18:47:21.244117 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:47:21.250333 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies` to `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m18:47:21.259431 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary` to `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m18:47:21.547225 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:47:21.560938 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m18:47:21.574502 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:47:21.577219 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:47:21.599029 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m18:47:21.607307 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m18:47:21.853551 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:47:21.859448 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m18:47:21.902957 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:47:21.906944 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:47:21.912609 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m18:47:21.923174 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary__dbt_tmp` to `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m18:47:22.166190 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:47:22.206744 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  ...
[0m18:47:22.244658 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:47:22.262476 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m18:47:22.339500 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  ...
[0m18:47:22.357727 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  ...
[0m18:47:22.539482 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:47:22.558020 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f053e21e-c510-4f82-bf9b-595ad5e68df5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791a3feea580>]}
[0m18:47:22.562710 [info ] [Thread-3  ]: 18 of 19 OK created sql view model `mart`.`g1_dq_insta_users_anomalies` ........ [[32mOK[0m in 2.39s]
[0m18:47:22.576437 [debug] [Thread-3  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:47:22.657611 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:47:22.660724 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:47:22.666371 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f053e21e-c510-4f82-bf9b-595ad5e68df5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791a3ff81f70>]}
[0m18:47:22.673522 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f053e21e-c510-4f82-bf9b-595ad5e68df5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791a3ff5eac0>]}
[0m18:47:22.676482 [info ] [Thread-1  ]: 16 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_anomalies` ....... [[32mOK[0m in 2.51s]
[0m18:47:22.679862 [info ] [Thread-2  ]: 17 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_summary` ......... [[32mOK[0m in 2.51s]
[0m18:47:22.683112 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:47:22.687106 [debug] [Thread-2  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:47:22.695858 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:47:22.697349 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m18:47:22.698970 [debug] [MainThread]: On list__mart: Close
[0m18:47:22.700721 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m18:47:22.703583 [debug] [MainThread]: On list__clean: Close
[0m18:47:22.705526 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_anomalies' was left open.
[0m18:47:22.707338 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: Close
[0m18:47:22.709322 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_anomalies' was left open.
[0m18:47:22.712462 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_anomalies: Close
[0m18:47:22.714429 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_summary' was left open.
[0m18:47:22.716330 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_summary: Close
[0m18:47:22.718320 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_summary' was left open.
[0m18:47:22.720041 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_summary: Close
[0m18:47:22.722731 [info ] [MainThread]: 
[0m18:47:22.725782 [info ] [MainThread]: Finished running 2 table models, 13 data tests, 4 view models in 0 hours 0 minutes and 23.43 seconds (23.43s).
[0m18:47:22.748146 [debug] [MainThread]: Command end result
[0m18:47:23.072236 [info ] [MainThread]: 
[0m18:47:23.074382 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m18:47:23.075926 [info ] [MainThread]: 
[0m18:47:23.081524 [error] [MainThread]:   Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1314 ('joined') (line 61, col 1): joined as (
    select
      rawDS.row_count_raw,
      counts_clean.row_count_clean,
      (rawDS.row_count_raw - counts_clean.row_count_clean) as dropped_rows,
      nu. Expected one of: token, Comma, FROM, SELECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:47:23.086336 [info ] [MainThread]: 
[0m18:47:23.088342 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m18:47:23.092284 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 26.036736, "process_in_blocks": "0", "process_kernel_time": 2.369513, "process_mem_max_rss": "119976", "process_out_blocks": "11304", "process_user_time": 10.236944}
[0m18:47:23.094690 [debug] [MainThread]: Command `dbt build` failed at 18:47:23.094095 after 26.04 seconds
[0m18:47:23.096613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791a464be310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791a4321bb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x791a443e8280>]}
[0m18:47:23.098670 [debug] [MainThread]: Flushing usage events
[0m18:49:14.978207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74493bc87310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7449388e1d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7449388e1be0>]}


============================== 18:49:14.993043 | d3a2c175-0b9d-4961-bb82-51271a5c4412 ==============================
[0m18:49:14.993043 [info ] [MainThread]: Running with dbt=1.8.9
[0m18:49:14.994690 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'use_colors': 'True', 'log_format': 'default', 'no_print': 'None', 'target_path': 'None', 'warn_error': 'None', 'use_experimental_parser': 'False', 'empty': 'False', 'debug': 'False', 'indirect_selection': 'eager', 'introspect': 'True', 'version_check': 'True', 'log_path': '/workdir/transforms/01_instacart/logs', 'fail_fast': 'False', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'static_parser': 'True', 'write_json': 'True', 'quiet': 'False', 'profiles_dir': '.', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m18:49:15.341590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd3a2c175-0b9d-4961-bb82-51271a5c4412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7449389efd30>]}
[0m18:49:15.451676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd3a2c175-0b9d-4961-bb82-51271a5c4412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74493897bb50>]}
[0m18:49:15.453299 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m18:49:15.663457 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m18:49:15.979424 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m18:49:15.980960 [debug] [MainThread]: Partial parsing: updated file: ex_01_instacart://models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:49:16.638365 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ex_01_mpg.mart
- models.ex_01_mpg.clean
[0m18:49:16.670506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd3a2c175-0b9d-4961-bb82-51271a5c4412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x744936bf7eb0>]}
[0m18:49:16.968754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd3a2c175-0b9d-4961-bb82-51271a5c4412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x744936b48cd0>]}
[0m18:49:16.969885 [info ] [MainThread]: Found 6 models, 13 data tests, 1 source, 471 macros
[0m18:49:16.976449 [info ] [MainThread]: 
[0m18:49:16.978111 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:49:16.998307 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:49:17.001620 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:49:17.046027 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:49:17.051954 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:49:21.418843 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:49:21.437237 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:49:21.709857 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:49:21.737678 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:49:21.751210 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m18:49:21.753174 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m18:49:21.769709 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m18:49:21.774957 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m18:49:22.074691 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:49:22.079660 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:49:22.425057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd3a2c175-0b9d-4961-bb82-51271a5c4412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x744938899be0>]}
[0m18:49:22.426620 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m18:49:22.427715 [info ] [MainThread]: 
[0m18:49:22.457113 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:49:22.459643 [info ] [Thread-1  ]: 1 of 19 START sql table model `clean`.`g1_stg_insta_orders` .................... [RUN]
[0m18:49:22.463108 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_instacart.g1_stg_insta_orders'
[0m18:49:22.465690 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_orders
[0m18:49:22.494501 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:49:22.496377 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_orders
[0m18:49:22.623133 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m18:49:26.087826 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

            

    
        create table `clean`.`g1_stg_insta_orders__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (order_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
          )
        
        ...
[0m18:49:26.375763 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:49:26.398518 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    select name, type from system.columns where table = 'g1_stg_insta_orders__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:49:26.674036 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:49:26.682803 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:49:26.684486 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_orders__dbt_backup`
        ("order_id", "user_id", "eval_set", "order_number", "order_dow", "order_hour_of_day", "days_since_prior_order")

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
  ...
[0m18:49:29.869748 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 3.18 seconds
[0m18:49:29.879428 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_orders__dbt_backup` AND `clean`.`g1_stg_insta_orders` 
  
  ...
[0m18:49:30.162648 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:49:30.215419 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    drop table if exists `clean`.`g1_stg_insta_orders__dbt_backup` 
  ...
[0m18:49:30.573024 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m18:49:30.597429 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3a2c175-0b9d-4961-bb82-51271a5c4412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x744936abc0a0>]}
[0m18:49:30.600605 [info ] [Thread-1  ]: 1 of 19 OK created sql table model `clean`.`g1_stg_insta_orders` ............... [[32mOK[0m in 8.13s]
[0m18:49:30.612478 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:49:30.618289 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:49:30.621001 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:49:30.626110 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:49:30.623483 [info ] [Thread-3  ]: 2 of 19 START test accepted_values_g1_stg_insta_orders_eval_set__prior__train__test  [RUN]
[0m18:49:30.632731 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:49:30.635498 [info ] [Thread-4  ]: 3 of 19 START test accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [RUN]
[0m18:49:30.638807 [info ] [Thread-2  ]: 4 of 19 START test accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [RUN]
[0m18:49:30.642827 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5'
[0m18:49:30.648581 [info ] [Thread-1  ]: 5 of 19 START test not_null_g1_stg_insta_orders_eval_set ....................... [RUN]
[0m18:49:30.652158 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145'
[0m18:49:30.656130 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1'
[0m18:49:30.659125 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:49:30.665268 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_orders, now test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7)
[0m18:49:30.668157 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:49:30.671262 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:49:30.688277 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:49:30.879575 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:49:30.897143 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:49:30.913052 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:49:30.929684 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:49:30.959005 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:49:30.961157 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:49:31.073577 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:49:31.126821 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:49:31.338736 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:49:31.335155 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:49:31.347395 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:49:31.351626 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:49:31.355837 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:49:31.358409 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m18:49:31.361360 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m18:49:31.369683 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select eval_set
from `clean`.`g1_stg_insta_orders`
where eval_set is null



    ) dbt_internal_test...
[0m18:49:32.129068 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.75 seconds
[0m18:49:32.145681 [info ] [Thread-1  ]: 5 of 19 PASS not_null_g1_stg_insta_orders_eval_set ............................. [[32mPASS[0m in 1.48s]
[0m18:49:32.148639 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:49:32.150430 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:49:32.152487 [info ] [Thread-1  ]: 6 of 19 START test not_null_g1_stg_insta_orders_order_dow ...................... [RUN]
[0m18:49:32.154556 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240)
[0m18:49:32.156150 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:49:32.174334 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:49:32.176913 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:49:32.186085 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:49:32.188042 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_dow
from `clean`.`g1_stg_insta_orders`
where order_dow is null



    ) dbt_internal_test...
[0m18:49:32.577773 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.39 seconds
[0m18:49:32.582422 [info ] [Thread-1  ]: 6 of 19 PASS not_null_g1_stg_insta_orders_order_dow ............................ [[32mPASS[0m in 0.43s]
[0m18:49:32.584576 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:49:32.586252 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:49:32.587554 [info ] [Thread-1  ]: 7 of 19 START test not_null_g1_stg_insta_orders_order_hour_of_day .............. [RUN]
[0m18:49:32.588947 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576)
[0m18:49:32.590984 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:49:32.603444 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:49:32.605178 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:49:32.612554 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:49:32.615774 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_hour_of_day
from `clean`.`g1_stg_insta_orders`
where order_hour_of_day is null



    ) dbt_internal_test...
[0m18:49:32.977827 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m18:49:32.982307 [info ] [Thread-1  ]: 7 of 19 PASS not_null_g1_stg_insta_orders_order_hour_of_day .................... [[32mPASS[0m in 0.39s]
[0m18:49:32.984418 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:49:32.986025 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:49:32.987424 [info ] [Thread-1  ]: 8 of 19 START test not_null_g1_stg_insta_orders_order_id ....................... [RUN]
[0m18:49:32.988910 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600)
[0m18:49:32.990022 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:49:33.000846 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:49:33.002713 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:49:33.009695 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:49:33.011586 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from `clean`.`g1_stg_insta_orders`
where order_id is null



    ) dbt_internal_test...
[0m18:49:33.389071 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m18:49:33.394217 [info ] [Thread-1  ]: 8 of 19 PASS not_null_g1_stg_insta_orders_order_id ............................. [[32mPASS[0m in 0.41s]
[0m18:49:33.397149 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:49:33.399576 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:49:33.401356 [info ] [Thread-1  ]: 9 of 19 START test not_null_g1_stg_insta_orders_order_number ................... [RUN]
[0m18:49:33.403300 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619)
[0m18:49:33.405212 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:49:33.417774 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:49:33.419602 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:49:33.431538 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:49:33.435085 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_number
from `clean`.`g1_stg_insta_orders`
where order_number is null



    ) dbt_internal_test...
[0m18:49:33.799428 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m18:49:33.804029 [info ] [Thread-1  ]: 9 of 19 PASS not_null_g1_stg_insta_orders_order_number ......................... [[32mPASS[0m in 0.40s]
[0m18:49:33.806405 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:49:33.808433 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:49:33.811049 [info ] [Thread-1  ]: 10 of 19 START test not_null_g1_stg_insta_orders_user_id ....................... [RUN]
[0m18:49:33.813968 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619, now test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64)
[0m18:49:33.817463 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:49:33.832065 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:49:33.834486 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:49:33.843275 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:49:33.849257 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_orders`
where user_id is null



    ) dbt_internal_test...
[0m18:49:34.237335 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.39 seconds
[0m18:49:34.245857 [info ] [Thread-1  ]: 10 of 19 PASS not_null_g1_stg_insta_orders_user_id ............................. [[32mPASS[0m in 0.43s]
[0m18:49:34.252154 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:49:34.254579 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:49:34.256716 [info ] [Thread-1  ]: 11 of 19 START test unique_g1_stg_insta_orders_order_id ........................ [RUN]
[0m18:49:34.258719 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64, now test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57)
[0m18:49:34.260455 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:49:34.280061 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:49:34.281693 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:49:34.288463 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:49:34.290281 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_orders`
where order_id is not null
group by order_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:49:35.305764 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 1.01 seconds
[0m18:49:35.311145 [info ] [Thread-1  ]: 11 of 19 PASS unique_g1_stg_insta_orders_order_id .............................. [[32mPASS[0m in 1.05s]
[0m18:49:35.314796 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:49:35.624644 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        eval_set as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by eval_set

)

select *
from all_values
where value_field not in (
    'prior','train','test'
)



    ) dbt_internal_test...
[0m18:49:35.675190 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_dow as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_dow

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6'
)



    ) dbt_internal_test...
[0m18:49:36.077309 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_hour_of_day as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_hour_of_day

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23'
)



    ) dbt_internal_test...
[0m18:49:36.087129 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.46 seconds
[0m18:49:36.091379 [info ] [Thread-3  ]: 2 of 19 PASS accepted_values_g1_stg_insta_orders_eval_set__prior__train__test .. [[32mPASS[0m in 5.45s]
[0m18:49:36.094589 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:49:36.118689 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.44 seconds
[0m18:49:36.127452 [info ] [Thread-4  ]: 3 of 19 PASS accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [[32mPASS[0m in 5.48s]
[0m18:49:36.133005 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:49:36.478306 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.40 seconds
[0m18:49:36.482291 [info ] [Thread-2  ]: 4 of 19 PASS accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [[32mPASS[0m in 5.83s]
[0m18:49:36.484751 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:49:36.488749 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_users
[0m18:49:36.491435 [info ] [Thread-1  ]: 12 of 19 START sql table model `clean`.`g1_stg_insta_users` .................... [RUN]
[0m18:49:36.494791 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57, now model.ex_01_instacart.g1_stg_insta_users)
[0m18:49:36.496434 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_users
[0m18:49:36.507366 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:49:36.509188 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_users
[0m18:49:36.527565 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

            

    
        create table `clean`.`g1_stg_insta_users__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (user_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
          )
        
        ...
[0m18:49:36.883943 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:49:36.893036 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    select name, type from system.columns where table = 'g1_stg_insta_users__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:49:37.237321 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m18:49:37.243059 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:49:37.245705 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_users__dbt_backup`
        ("user_id")

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
  ...
[0m18:49:37.740711 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.49 seconds
[0m18:49:37.744053 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_users__dbt_backup` AND `clean`.`g1_stg_insta_users` 
  
  ...
[0m18:49:38.079050 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:49:38.092116 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    drop table if exists `clean`.`g1_stg_insta_users__dbt_backup` 
  ...
[0m18:49:38.399340 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:49:38.403223 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3a2c175-0b9d-4961-bb82-51271a5c4412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7449356cc430>]}
[0m18:49:38.405617 [info ] [Thread-1  ]: 12 of 19 OK created sql table model `clean`.`g1_stg_insta_users` ............... [[32mOK[0m in 1.91s]
[0m18:49:38.407756 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_users
[0m18:49:38.410432 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:49:38.414428 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:49:38.412920 [info ] [Thread-4  ]: 13 of 19 START test not_null_g1_stg_insta_users_user_id ........................ [RUN]
[0m18:49:38.417438 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:49:38.419038 [info ] [Thread-2  ]: 14 of 19 START test relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [RUN]
[0m18:49:38.421870 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145, now test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935)
[0m18:49:38.424098 [info ] [Thread-3  ]: 15 of 19 START test unique_g1_stg_insta_users_user_id .......................... [RUN]
[0m18:49:38.426217 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1, now test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726)
[0m18:49:38.427945 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:49:38.430208 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5, now test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f)
[0m18:49:38.431722 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:49:38.444658 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:49:38.448192 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:49:38.484727 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:49:38.481279 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:49:38.488523 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:49:38.495729 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:49:38.497176 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:49:38.505319 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:49:38.506837 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:49:38.508639 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_users`
where user_id is null



    ) dbt_internal_test...
[0m18:49:38.517462 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select user_id as from_field
    from `clean`.`g1_stg_insta_orders`
    where user_id is not null
),

parent as (
    select user_id as to_field
    from `clean`.`g1_stg_insta_users`
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null
-- end_of_sql
settings join_use_nulls = 1



    ) dbt_internal_test...
[0m18:49:38.522799 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:49:38.498102 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    user_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_users`
where user_id is not null
group by user_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:49:38.826387 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:49:38.830776 [info ] [Thread-4  ]: 13 of 19 PASS not_null_g1_stg_insta_users_user_id .............................. [[32mPASS[0m in 0.41s]
[0m18:49:38.832495 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:49:38.836843 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m18:49:38.840933 [info ] [Thread-3  ]: 15 of 19 PASS unique_g1_stg_insta_users_user_id ................................ [[32mPASS[0m in 0.41s]
[0m18:49:38.843676 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:49:39.093392 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.60 seconds
[0m18:49:39.097793 [info ] [Thread-2  ]: 14 of 19 PASS relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [[32mPASS[0m in 0.67s]
[0m18:49:39.099967 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:49:39.104877 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:49:39.106252 [debug] [Thread-4  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:49:39.108115 [debug] [Thread-3  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:49:39.111734 [debug] [Thread-2  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:49:39.110049 [info ] [Thread-1  ]: 16 of 19 START sql view model `mart`.`g1_dq_insta_orders_anomalies` ............ [RUN]
[0m18:49:39.114417 [info ] [Thread-4  ]: 17 of 19 START sql view model `mart`.`g1_dq_insta_orders_summary` .............. [RUN]
[0m18:49:39.116689 [info ] [Thread-3  ]: 18 of 19 START sql view model `mart`.`g1_dq_insta_users_anomalies` ............. [RUN]
[0m18:49:39.119945 [info ] [Thread-2  ]: 19 of 19 START sql view model `mart`.`g1_dq_insta_users_summary` ............... [RUN]
[0m18:49:39.122283 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_users, now model.ex_01_instacart.g1_dq_insta_orders_anomalies)
[0m18:49:39.123974 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935, now model.ex_01_instacart.g1_dq_insta_orders_summary)
[0m18:49:39.126328 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f, now model.ex_01_instacart.g1_dq_insta_users_anomalies)
[0m18:49:39.128345 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726, now model.ex_01_instacart.g1_dq_insta_users_summary)
[0m18:49:39.130166 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:49:39.131797 [debug] [Thread-4  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:49:39.133749 [debug] [Thread-3  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:49:39.135276 [debug] [Thread-2  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:49:39.146085 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:49:39.157194 [debug] [Thread-4  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:49:39.166726 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:49:39.178783 [debug] [Thread-2  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:49:39.181441 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:49:39.182731 [debug] [Thread-4  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:49:39.184932 [debug] [Thread-3  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:49:39.192094 [debug] [Thread-2  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:49:39.299272 [debug] [Thread-2  ]: Creating new relation g1_dq_insta_users_summary
[0m18:49:39.370286 [debug] [Thread-4  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:49:39.374517 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:49:39.379777 [debug] [Thread-2  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:49:39.381024 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:49:39.385211 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */


  create view `mart`.`g1_dq_insta_orders_summary__dbt_tmp` 
  
    
    
  as (
    

-- Data Quality Summary for Orders
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  select * from `raw`.`raw___insta_orders`
),

cln as (
  select * from `clean`.`g1_stg_insta_orders`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage Check
nulls as (
  select
    round(100.0 * countIf(order_id is null) / nullif(count(),0), 2) as null_pct_order_id,
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id,
    round(100.0 * countIf(eval_set is null) / nullif(count(),0), 2) as null_pct_eval_set,
    round(100.0 * countIf(order_number is null) / nullif(count(),0), 2) as null_pct_order_number,
    round(100.0 * countIf(order_dow is null) / nullif(count(),0), 2) as null_pct_order_dow,
    round(100.0 * countIf(order_hour_of_day is null) / nullif(count(),0), 2) as null_pct_order_hour_of_day,
    round(100.0 * countIf(days_since_prior_order is null) / nullif(count(),0), 2) as null_pct_days_since_prior_order
  from cln
),

-- Duplicate Orders
dupes as (
  select
    countIf(cnt > 1) as duplicate_orders
  from (
    select order_id, count() as cnt
    from cln
    group by order_id
  )
),

-- Referential Integrity
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_id
  from `clean`.`g1_stg_insta_orders` o
),

-- Value Range Checks
value_ranges as (
  select
    countIf(order_number < 1) as invalid_order_number,
    countIf(order_hour_of_day < 0 or order_hour_of_day > 23) as invalid_order_hour,
    countIf(days_since_prior_order < 0 or days_since_prior_order > 30) as invalid_days_since_prior_order
  from cln
),

-- Join all metrics
joined as (
    select
        counts.row_count_raw,
        counts.row_count_clean,
        (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
        nulls.*,
        dupes.duplicate_orders,
        referential_integrity.invalid_user_id,
        value_ranges.invalid_order_number,
        value_ranges.invalid_order_hour,
        value_ranges.invalid_days_since_prior_order
    from counts
    cross join nulls
    cross join dupes
    cross join referential_integrity
    cross join value_ranges
)

select * from joined
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:49:39.388164 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */


  create view `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Users

with cln as (
  select * from `clean`.`g1_stg_insta_users`
),
violations as (
  select
    user_id,

    multiIf(
      user_id is null, 'null_user_id',
      user_id <= 0, 'invalid_user_id',
      'ok'
    ) as dq_issue
  from cln
)
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:49:39.390370 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),

cln as (
    select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts_clean as (
    select count(*) as row_count_clean
    from cln
),

-- Null Percentage
nulls as (
  select
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
  from cln
),

-- Duplicate Users Check
dupes as (
  select
    countIf(cnt > 1) as duplicate_user_ids
  from (
    select user_id, count() as cnt
    from cln
    group by user_id
  )
),

-- Referential Integrity
invalid_user_in_orders as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),

user_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

-- Join all metrics
joined as (
  select
    rawDS.row_count_raw,
    counts_clean.row_count_clean,
    (rawDS.row_count_raw - counts_clean.row_count_clean) as dropped_rows,
    nulls.null_pct_user_id,
    dupes.duplicate_user_ids,
    iu.invalid_user_in_orders,
    uwo.user_without_orders
  from rawDS
  cross join counts_clean
  cross join nulls
  cross join invalid_user_in_orders iu
  cross join user_without_orders uwo

)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:49:39.393900 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */


  create view `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Orders
with cln as (
  -- Source cleaned orders data
  select * 
  from `clean`.`g1_stg_insta_orders`
),

users as (
  -- Reference users table for FK validation
  select user_id 
  from `clean`.`g1_stg_insta_users`
),

violations as (
  select
    order_id,
    user_id,
    eval_set,
    order_number,
    order_dow,
    order_hour_of_day,
    days_since_prior_order,

    -- Data Quality Issue Classification
    multiIf(
      order_id is null, 'null_order_id',
      user_id is null, 'null_user_id',
      user_id not in (select user_id from users), 'missing_user_ref',
      order_number < 1, 'invalid_order_number',
      order_dow not in (0,1,2,3,4,5,6), 'invalid_order_dow',
      order_hour_of_day < 0 or order_hour_of_day > 23, 'invalid_order_hour',
      days_since_prior_order < 0, 'negative_days_since_prior_order',
      'ok'
    ) as dq_issue

  from cln
)

-- Return only rows with detected anomalies
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:49:39.704347 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:49:39.707215 [debug] [Thread-2  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),

cln as (
    select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts_clean as (
    select count(*) as row_count_clean
    from cln
),

-- Null Percentage
nulls as (
  select
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
  from cln
),

-- Duplicate Users Check
dupes as (
  select
    countIf(cnt > 1) as duplicate_user_ids
  from (
    select user_id, count() as cnt
    from cln
    group by user_id
  )
),

-- Referential Integrity
invalid_user_in_orders as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),

user_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

-- Join all metrics
joined as (
  select
    rawDS.row_count_raw,
    counts_clean.row_count_clean,
    (rawDS.row_count_raw - counts_clean.row_count_clean) as dropped_rows,
    nulls.null_pct_user_id,
    dupes.duplicate_user_ids,
    iu.invalid_user_in_orders,
    uwo.user_without_orders
  from rawDS
  cross join counts_clean
  cross join nulls
  cross join invalid_user_in_orders iu
  cross join user_without_orders uwo

)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m18:49:39.735424 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m18:49:39.743995 [debug] [Thread-2  ]: Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1314 ('joined') (line 61, col 1): joined as (
    select
      rawDS.row_count_raw,
      counts_clean.row_count_clean,
      (rawDS.row_count_raw - counts_clean.row_count_clean) as dropped_rows,
      nu. Expected one of: token, Comma, FROM, SELECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:49:39.745947 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3a2c175-0b9d-4961-bb82-51271a5c4412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x744935793d00>]}
[0m18:49:39.748126 [error] [Thread-2  ]: 19 of 19 ERROR creating sql view model `mart`.`g1_dq_insta_users_summary` ...... [[31mERROR[0m in 0.62s]
[0m18:49:39.751955 [debug] [Thread-2  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:49:39.755680 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m18:49:39.767961 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m18:49:39.796841 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.40 seconds
[0m18:49:39.806080 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m18:49:40.010681 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:49:40.014381 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies` to `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m18:49:40.054489 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:49:40.059273 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies` to `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m18:49:40.104332 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:49:40.107519 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary` to `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m18:49:40.307046 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:49:40.315408 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m18:49:40.358775 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:49:40.367922 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m18:49:40.403700 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:49:40.412208 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m18:49:40.595425 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:49:40.603061 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m18:49:40.654446 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:49:40.660305 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m18:49:40.686530 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:49:40.691286 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary__dbt_tmp` to `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m18:49:40.898501 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:49:40.925326 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  ...
[0m18:49:40.977411 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:49:40.979599 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:49:40.992586 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  ...
[0m18:49:41.003320 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  ...
[0m18:49:41.200769 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:49:41.205094 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3a2c175-0b9d-4961-bb82-51271a5c4412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7449356c8f70>]}
[0m18:49:41.206773 [info ] [Thread-3  ]: 18 of 19 OK created sql view model `mart`.`g1_dq_insta_users_anomalies` ........ [[32mOK[0m in 2.08s]
[0m18:49:41.208732 [debug] [Thread-3  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:49:41.277766 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:49:41.283244 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3a2c175-0b9d-4961-bb82-51271a5c4412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x744935626c10>]}
[0m18:49:41.285038 [info ] [Thread-1  ]: 16 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_anomalies` ....... [[32mOK[0m in 2.16s]
[0m18:49:41.287241 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:49:41.291374 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:49:41.295735 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3a2c175-0b9d-4961-bb82-51271a5c4412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7449356c83d0>]}
[0m18:49:41.298678 [info ] [Thread-4  ]: 17 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_summary` ......... [[32mOK[0m in 2.17s]
[0m18:49:41.300931 [debug] [Thread-4  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:49:41.305855 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:49:41.306917 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m18:49:41.308142 [debug] [MainThread]: On list__mart: Close
[0m18:49:41.309223 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m18:49:41.310477 [debug] [MainThread]: On list__clean: Close
[0m18:49:41.311447 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_anomalies' was left open.
[0m18:49:41.312740 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: Close
[0m18:49:41.314655 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_anomalies' was left open.
[0m18:49:41.315641 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_anomalies: Close
[0m18:49:41.316701 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_summary' was left open.
[0m18:49:41.318025 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_summary: Close
[0m18:49:41.319195 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_summary' was left open.
[0m18:49:41.320028 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_summary: Close
[0m18:49:41.322522 [info ] [MainThread]: 
[0m18:49:41.323831 [info ] [MainThread]: Finished running 2 table models, 13 data tests, 4 view models in 0 hours 0 minutes and 24.34 seconds (24.34s).
[0m18:49:41.341979 [debug] [MainThread]: Command end result
[0m18:49:41.595160 [info ] [MainThread]: 
[0m18:49:41.596577 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m18:49:41.597776 [info ] [MainThread]: 
[0m18:49:41.599613 [error] [MainThread]:   Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1314 ('joined') (line 61, col 1): joined as (
    select
      rawDS.row_count_raw,
      counts_clean.row_count_clean,
      (rawDS.row_count_raw - counts_clean.row_count_clean) as dropped_rows,
      nu. Expected one of: token, Comma, FROM, SELECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:49:41.600919 [info ] [MainThread]: 
[0m18:49:41.602379 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m18:49:41.605414 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 26.777792, "process_in_blocks": "0", "process_kernel_time": 2.285419, "process_mem_max_rss": "120040", "process_out_blocks": "11312", "process_user_time": 9.60199}
[0m18:49:41.607011 [debug] [MainThread]: Command `dbt build` failed at 18:49:41.606625 after 26.78 seconds
[0m18:49:41.608209 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74493bc87310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7449389efd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x744935eef1c0>]}
[0m18:49:41.609364 [debug] [MainThread]: Flushing usage events
[0m18:52:44.524199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73c640ea6310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73c63db04b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73c63db04a00>]}


============================== 18:52:44.540296 | 748bee95-4999-4786-a87a-ae466f63582d ==============================
[0m18:52:44.540296 [info ] [MainThread]: Running with dbt=1.8.9
[0m18:52:44.542565 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'log_format': 'default', 'log_cache_events': 'False', 'debug': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'quiet': 'False', 'profiles_dir': '.', 'target_path': 'None', 'log_path': '/workdir/transforms/01_instacart/logs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False', 'introspect': 'True', 'version_check': 'True', 'warn_error': 'None', 'no_print': 'None', 'fail_fast': 'False', 'write_json': 'True', 'printer_width': '80', 'use_experimental_parser': 'False', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'empty': 'False', 'partial_parse': 'True'}
[0m18:52:44.935288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '748bee95-4999-4786-a87a-ae466f63582d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73c640447ca0>]}
[0m18:52:45.049191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '748bee95-4999-4786-a87a-ae466f63582d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73c63e6359a0>]}
[0m18:52:45.051461 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m18:52:45.291120 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m18:52:45.625808 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m18:52:45.627190 [debug] [MainThread]: Partial parsing: updated file: ex_01_instacart://models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:52:46.348704 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ex_01_mpg.mart
- models.ex_01_mpg.clean
[0m18:52:46.395311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '748bee95-4999-4786-a87a-ae466f63582d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73c63be24eb0>]}
[0m18:52:46.747219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '748bee95-4999-4786-a87a-ae466f63582d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73c63be0a850>]}
[0m18:52:46.748681 [info ] [MainThread]: Found 6 models, 13 data tests, 1 source, 471 macros
[0m18:52:46.757745 [info ] [MainThread]: 
[0m18:52:46.761645 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:52:46.793147 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:52:46.796841 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:52:46.858979 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:52:46.863900 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:52:52.006270 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:52:52.008640 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:52:52.356187 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:52:52.391938 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m18:52:52.398168 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m18:52:52.400308 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m18:52:52.415240 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m18:52:52.420906 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m18:52:52.815298 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.39 seconds
[0m18:52:52.827315 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.40 seconds
[0m18:52:53.208170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '748bee95-4999-4786-a87a-ae466f63582d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73c640dfe7c0>]}
[0m18:52:53.209748 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m18:52:53.210801 [info ] [MainThread]: 
[0m18:52:53.239227 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:52:53.241724 [info ] [Thread-1  ]: 1 of 19 START sql table model `clean`.`g1_stg_insta_orders` .................... [RUN]
[0m18:52:53.244307 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_instacart.g1_stg_insta_orders'
[0m18:52:53.246196 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_orders
[0m18:52:53.275045 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:52:53.276957 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_orders
[0m18:52:53.411463 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m18:52:56.897047 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

            

    
        create table `clean`.`g1_stg_insta_orders__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (order_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
          )
        
        ...
[0m18:52:57.199298 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:52:57.220623 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    select name, type from system.columns where table = 'g1_stg_insta_orders__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:52:57.503033 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:52:57.511925 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:52:57.513872 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_orders__dbt_backup`
        ("order_id", "user_id", "eval_set", "order_number", "order_dow", "order_hour_of_day", "days_since_prior_order")

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
  ...
[0m18:53:00.069341 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 2.55 seconds
[0m18:53:00.081973 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_orders__dbt_backup` AND `clean`.`g1_stg_insta_orders` 
  
  ...
[0m18:53:00.365362 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:53:00.430845 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    drop table if exists `clean`.`g1_stg_insta_orders__dbt_backup` 
  ...
[0m18:53:00.730545 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:53:00.738478 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '748bee95-4999-4786-a87a-ae466f63582d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73c63ba05af0>]}
[0m18:53:00.740288 [info ] [Thread-1  ]: 1 of 19 OK created sql table model `clean`.`g1_stg_insta_orders` ............... [[32mOK[0m in 7.49s]
[0m18:53:00.742699 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:53:00.746698 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:53:00.748018 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:53:00.749976 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:53:00.751995 [info ] [Thread-3  ]: 2 of 19 START test accepted_values_g1_stg_insta_orders_eval_set__prior__train__test  [RUN]
[0m18:53:00.754554 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:53:00.756159 [info ] [Thread-4  ]: 3 of 19 START test accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [RUN]
[0m18:53:00.757875 [info ] [Thread-2  ]: 4 of 19 START test accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [RUN]
[0m18:53:00.760501 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5'
[0m18:53:00.762279 [info ] [Thread-1  ]: 5 of 19 START test not_null_g1_stg_insta_orders_eval_set ....................... [RUN]
[0m18:53:00.764912 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145'
[0m18:53:00.767132 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1'
[0m18:53:00.769986 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:53:00.772054 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_orders, now test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7)
[0m18:53:00.773852 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:53:00.775878 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:53:00.789222 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:53:00.836655 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:53:00.843150 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:53:00.856746 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:53:00.876171 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:53:00.880515 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:53:00.899564 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:53:00.900953 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:53:00.924001 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:53:00.931471 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:53:00.938495 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:53:00.941184 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:53:00.944000 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m18:53:00.945276 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m18:53:00.954426 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:53:00.959794 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:53:00.964599 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select eval_set
from `clean`.`g1_stg_insta_orders`
where eval_set is null



    ) dbt_internal_test...
[0m18:53:01.601724 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.63 seconds
[0m18:53:01.617161 [info ] [Thread-1  ]: 5 of 19 PASS not_null_g1_stg_insta_orders_eval_set ............................. [[32mPASS[0m in 0.84s]
[0m18:53:01.619979 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:53:01.621977 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:53:01.623596 [info ] [Thread-1  ]: 6 of 19 START test not_null_g1_stg_insta_orders_order_dow ...................... [RUN]
[0m18:53:01.625985 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240)
[0m18:53:01.628154 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:53:01.644221 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:53:01.647090 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:53:01.656731 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:53:01.659057 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_dow
from `clean`.`g1_stg_insta_orders`
where order_dow is null



    ) dbt_internal_test...
[0m18:53:02.014292 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:53:02.019823 [info ] [Thread-1  ]: 6 of 19 PASS not_null_g1_stg_insta_orders_order_dow ............................ [[32mPASS[0m in 0.39s]
[0m18:53:02.022369 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:53:02.023995 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:53:02.025667 [info ] [Thread-1  ]: 7 of 19 START test not_null_g1_stg_insta_orders_order_hour_of_day .............. [RUN]
[0m18:53:02.027636 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576)
[0m18:53:02.029370 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:53:02.045503 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:53:02.047881 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:53:02.057842 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:53:02.062535 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_hour_of_day
from `clean`.`g1_stg_insta_orders`
where order_hour_of_day is null



    ) dbt_internal_test...
[0m18:53:02.383760 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:53:02.388927 [info ] [Thread-1  ]: 7 of 19 PASS not_null_g1_stg_insta_orders_order_hour_of_day .................... [[32mPASS[0m in 0.36s]
[0m18:53:02.391764 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:53:02.393278 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:53:02.395147 [info ] [Thread-1  ]: 8 of 19 START test not_null_g1_stg_insta_orders_order_id ....................... [RUN]
[0m18:53:02.397111 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600)
[0m18:53:02.398830 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:53:02.411545 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:53:02.413802 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:53:02.421823 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:53:02.424034 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from `clean`.`g1_stg_insta_orders`
where order_id is null



    ) dbt_internal_test...
[0m18:53:02.741063 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:53:02.746694 [info ] [Thread-1  ]: 8 of 19 PASS not_null_g1_stg_insta_orders_order_id ............................. [[32mPASS[0m in 0.35s]
[0m18:53:02.749884 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:53:02.751842 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:53:02.754319 [info ] [Thread-1  ]: 9 of 19 START test not_null_g1_stg_insta_orders_order_number ................... [RUN]
[0m18:53:02.757372 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619)
[0m18:53:02.760193 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:53:02.781295 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:53:02.784405 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:53:02.793641 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:53:02.798585 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_number
from `clean`.`g1_stg_insta_orders`
where order_number is null



    ) dbt_internal_test...
[0m18:53:03.129077 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:53:03.133651 [info ] [Thread-1  ]: 9 of 19 PASS not_null_g1_stg_insta_orders_order_number ......................... [[32mPASS[0m in 0.38s]
[0m18:53:03.135608 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:53:03.137238 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:53:03.138861 [info ] [Thread-1  ]: 10 of 19 START test not_null_g1_stg_insta_orders_user_id ....................... [RUN]
[0m18:53:03.140359 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619, now test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64)
[0m18:53:03.141900 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:53:03.153840 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:53:03.155742 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:53:03.167567 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:53:03.170509 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_orders`
where user_id is null



    ) dbt_internal_test...
[0m18:53:03.444188 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:53:03.448775 [info ] [Thread-1  ]: 10 of 19 PASS not_null_g1_stg_insta_orders_user_id ............................. [[32mPASS[0m in 0.31s]
[0m18:53:03.450763 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:53:03.452289 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:53:03.453856 [info ] [Thread-1  ]: 11 of 19 START test unique_g1_stg_insta_orders_order_id ........................ [RUN]
[0m18:53:03.455499 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64, now test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57)
[0m18:53:03.456611 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:53:03.477846 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:53:03.480418 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:53:03.487892 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:53:03.489894 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_orders`
where order_id is not null
group by order_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:53:04.182104 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.69 seconds
[0m18:53:04.186943 [info ] [Thread-1  ]: 11 of 19 PASS unique_g1_stg_insta_orders_order_id .............................. [[32mPASS[0m in 0.73s]
[0m18:53:04.188946 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:53:04.819833 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_dow as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_dow

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6'
)



    ) dbt_internal_test...
[0m18:53:04.822235 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_hour_of_day as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_hour_of_day

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23'
)



    ) dbt_internal_test...
[0m18:53:05.119035 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        eval_set as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by eval_set

)

select *
from all_values
where value_field not in (
    'prior','train','test'
)



    ) dbt_internal_test...
[0m18:53:05.211925 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m18:53:05.216155 [info ] [Thread-2  ]: 4 of 19 PASS accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [[32mPASS[0m in 4.45s]
[0m18:53:05.219066 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.39 seconds
[0m18:53:05.220970 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:53:05.225574 [info ] [Thread-4  ]: 3 of 19 PASS accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [[32mPASS[0m in 4.46s]
[0m18:53:05.229230 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:53:05.491530 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.37 seconds
[0m18:53:05.497634 [info ] [Thread-3  ]: 2 of 19 PASS accepted_values_g1_stg_insta_orders_eval_set__prior__train__test .. [[32mPASS[0m in 4.74s]
[0m18:53:05.501041 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:53:05.504708 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_users
[0m18:53:05.507482 [info ] [Thread-1  ]: 12 of 19 START sql table model `clean`.`g1_stg_insta_users` .................... [RUN]
[0m18:53:05.509930 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57, now model.ex_01_instacart.g1_stg_insta_users)
[0m18:53:05.511676 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_users
[0m18:53:05.522723 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:53:05.526074 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_users
[0m18:53:05.545052 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

            

    
        create table `clean`.`g1_stg_insta_users__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (user_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
          )
        
        ...
[0m18:53:05.857971 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:53:05.864650 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    select name, type from system.columns where table = 'g1_stg_insta_users__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:53:06.137638 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:53:06.141343 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:53:06.143163 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_users__dbt_backup`
        ("user_id")

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
  ...
[0m18:53:06.535388 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.39 seconds
[0m18:53:06.539020 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_users__dbt_backup` AND `clean`.`g1_stg_insta_users` 
  
  ...
[0m18:53:06.881314 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m18:53:06.890254 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    drop table if exists `clean`.`g1_stg_insta_users__dbt_backup` 
  ...
[0m18:53:07.174242 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:53:07.179291 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '748bee95-4999-4786-a87a-ae466f63582d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73c63dc1bd90>]}
[0m18:53:07.181079 [info ] [Thread-1  ]: 12 of 19 OK created sql table model `clean`.`g1_stg_insta_users` ............... [[32mOK[0m in 1.67s]
[0m18:53:07.184125 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_users
[0m18:53:07.187434 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:53:07.189242 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:53:07.190933 [info ] [Thread-4  ]: 13 of 19 START test not_null_g1_stg_insta_users_user_id ........................ [RUN]
[0m18:53:07.193778 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:53:07.195746 [info ] [Thread-3  ]: 14 of 19 START test relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [RUN]
[0m18:53:07.198113 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145, now test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935)
[0m18:53:07.200379 [info ] [Thread-2  ]: 15 of 19 START test unique_g1_stg_insta_users_user_id .......................... [RUN]
[0m18:53:07.203611 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5, now test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726)
[0m18:53:07.205770 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:53:07.207803 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1, now test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f)
[0m18:53:07.210045 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:53:07.232071 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:53:07.235417 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:53:07.275989 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:53:07.279908 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:53:07.282026 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:53:07.293005 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:53:07.294796 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:53:07.296773 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:53:07.305115 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:53:07.307312 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_users`
where user_id is null



    ) dbt_internal_test...
[0m18:53:07.315517 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:53:07.320867 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    user_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_users`
where user_id is not null
group by user_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:53:07.326810 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select user_id as from_field
    from `clean`.`g1_stg_insta_orders`
    where user_id is not null
),

parent as (
    select user_id as to_field
    from `clean`.`g1_stg_insta_users`
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null
-- end_of_sql
settings join_use_nulls = 1



    ) dbt_internal_test...
[0m18:53:07.623334 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:53:07.627664 [info ] [Thread-4  ]: 13 of 19 PASS not_null_g1_stg_insta_users_user_id .............................. [[32mPASS[0m in 0.43s]
[0m18:53:07.629402 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:53:07.644871 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:53:07.649073 [info ] [Thread-2  ]: 15 of 19 PASS unique_g1_stg_insta_users_user_id ................................ [[32mPASS[0m in 0.44s]
[0m18:53:07.652434 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:53:07.954692 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.63 seconds
[0m18:53:07.958827 [info ] [Thread-3  ]: 14 of 19 PASS relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [[32mPASS[0m in 0.76s]
[0m18:53:07.960768 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:53:07.964253 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:53:07.966019 [debug] [Thread-4  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:53:07.967671 [info ] [Thread-1  ]: 16 of 19 START sql view model `mart`.`g1_dq_insta_orders_anomalies` ............ [RUN]
[0m18:53:07.969781 [debug] [Thread-2  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:53:07.971683 [debug] [Thread-3  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:53:07.973357 [info ] [Thread-4  ]: 17 of 19 START sql view model `mart`.`g1_dq_insta_orders_summary` .............. [RUN]
[0m18:53:07.975795 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_users, now model.ex_01_instacart.g1_dq_insta_orders_anomalies)
[0m18:53:07.978469 [info ] [Thread-2  ]: 18 of 19 START sql view model `mart`.`g1_dq_insta_users_anomalies` ............. [RUN]
[0m18:53:07.980853 [info ] [Thread-3  ]: 19 of 19 START sql view model `mart`.`g1_dq_insta_users_summary` ............... [RUN]
[0m18:53:07.983238 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935, now model.ex_01_instacart.g1_dq_insta_orders_summary)
[0m18:53:07.985806 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:53:07.988297 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f, now model.ex_01_instacart.g1_dq_insta_users_anomalies)
[0m18:53:07.990711 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726, now model.ex_01_instacart.g1_dq_insta_users_summary)
[0m18:53:07.992676 [debug] [Thread-4  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:53:08.007015 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:53:08.009010 [debug] [Thread-2  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:53:08.010946 [debug] [Thread-3  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:53:08.024964 [debug] [Thread-4  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:53:08.034884 [debug] [Thread-2  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:53:08.042446 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:53:08.052838 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:53:08.061895 [debug] [Thread-4  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:53:08.063378 [debug] [Thread-2  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:53:08.125789 [debug] [Thread-3  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:53:08.280706 [debug] [Thread-3  ]: Creating new relation g1_dq_insta_users_summary
[0m18:53:08.316063 [debug] [Thread-4  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:53:08.323324 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:53:08.325271 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:53:08.326450 [debug] [Thread-2  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:53:08.329965 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */


  create view `mart`.`g1_dq_insta_orders_summary__dbt_tmp` 
  
    
    
  as (
    

-- Data Quality Summary for Orders
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  select * from `raw`.`raw___insta_orders`
),

cln as (
  select * from `clean`.`g1_stg_insta_orders`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage Check
nulls as (
  select
    round(100.0 * countIf(order_id is null) / nullif(count(),0), 2) as null_pct_order_id,
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id,
    round(100.0 * countIf(eval_set is null) / nullif(count(),0), 2) as null_pct_eval_set,
    round(100.0 * countIf(order_number is null) / nullif(count(),0), 2) as null_pct_order_number,
    round(100.0 * countIf(order_dow is null) / nullif(count(),0), 2) as null_pct_order_dow,
    round(100.0 * countIf(order_hour_of_day is null) / nullif(count(),0), 2) as null_pct_order_hour_of_day,
    round(100.0 * countIf(days_since_prior_order is null) / nullif(count(),0), 2) as null_pct_days_since_prior_order
  from cln
),

-- Duplicate Orders
dupes as (
  select
    countIf(cnt > 1) as duplicate_orders
  from (
    select order_id, count() as cnt
    from cln
    group by order_id
  )
),

-- Referential Integrity
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_id
  from `clean`.`g1_stg_insta_orders` o
),

-- Value Range Checks
value_ranges as (
  select
    countIf(order_number < 1) as invalid_order_number,
    countIf(order_hour_of_day < 0 or order_hour_of_day > 23) as invalid_order_hour,
    countIf(days_since_prior_order < 0 or days_since_prior_order > 30) as invalid_days_since_prior_order
  from cln
),

-- Join all metrics
joined as (
    select
        counts.row_count_raw,
        counts.row_count_clean,
        (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
        nulls.*,
        dupes.duplicate_orders,
        referential_integrity.invalid_user_id,
        value_ranges.invalid_order_number,
        value_ranges.invalid_order_hour,
        value_ranges.invalid_days_since_prior_order
    from counts
    cross join nulls
    cross join dupes
    cross join referential_integrity
    cross join value_ranges
)

select * from joined
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:53:08.332062 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */


  create view `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Orders
with cln as (
  -- Source cleaned orders data
  select * 
  from `clean`.`g1_stg_insta_orders`
),

users as (
  -- Reference users table for FK validation
  select user_id 
  from `clean`.`g1_stg_insta_users`
),

violations as (
  select
    order_id,
    user_id,
    eval_set,
    order_number,
    order_dow,
    order_hour_of_day,
    days_since_prior_order,

    -- Data Quality Issue Classification
    multiIf(
      order_id is null, 'null_order_id',
      user_id is null, 'null_user_id',
      user_id not in (select user_id from users), 'missing_user_ref',
      order_number < 1, 'invalid_order_number',
      order_dow not in (0,1,2,3,4,5,6), 'invalid_order_dow',
      order_hour_of_day < 0 or order_hour_of_day > 23, 'invalid_order_hour',
      days_since_prior_order < 0, 'negative_days_since_prior_order',
      'ok'
    ) as dq_issue

  from cln
)

-- Return only rows with detected anomalies
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:53:08.337880 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),

cln as (
    select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts_clean as (
    select count(*) as row_count_clean
    from cln
),

-- Null Percentage
nulls as (
  select
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
  from cln
),

-- Duplicate Users Check
dupes as (
  select
    countIf(cnt > 1) as duplicate_user_ids
  from (
    select user_id, count() as cnt
    from cln
    group by user_id
  )
),

-- Referential Integrity
invalid_user_in_orders as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),

user_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

-- Join all metrics
joined as (
  select
    rawDs.row_count_raw,
    counts_clean.row_count_clean,
    (rawDs.row_count_raw - counts_clean.row_count_clean) as dropped_rows,
    nulls.null_pct_user_id,
    dupes.duplicate_user_ids,
    iu.invalid_user_in_orders,
    uwo.user_without_orders
  from rawDs
  cross join counts_clean
  cross join nulls
  cross join invalid_user_in_orders iu
  cross join user_without_orders uwo

)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:53:08.340872 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */


  create view `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Users

with cln as (
  select * from `clean`.`g1_stg_insta_users`
),
violations as (
  select
    user_id,

    multiIf(
      user_id is null, 'null_user_id',
      user_id <= 0, 'invalid_user_id',
      'ok'
    ) as dq_issue
  from cln
)
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:53:08.598646 [debug] [Thread-3  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),

cln as (
    select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts_clean as (
    select count(*) as row_count_clean
    from cln
),

-- Null Percentage
nulls as (
  select
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
  from cln
),

-- Duplicate Users Check
dupes as (
  select
    countIf(cnt > 1) as duplicate_user_ids
  from (
    select user_id, count() as cnt
    from cln
    group by user_id
  )
),

-- Referential Integrity
invalid_user_in_orders as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),

user_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

-- Join all metrics
joined as (
  select
    rawDs.row_count_raw,
    counts_clean.row_count_clean,
    (rawDs.row_count_raw - counts_clean.row_count_clean) as dropped_rows,
    nulls.null_pct_user_id,
    dupes.duplicate_user_ids,
    iu.invalid_user_in_orders,
    uwo.user_without_orders
  from rawDs
  cross join counts_clean
  cross join nulls
  cross join invalid_user_in_orders iu
  cross join user_without_orders uwo

)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m18:53:08.603913 [debug] [Thread-3  ]: Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1314 ('joined') (line 61, col 1): joined as (
    select
      rawDs.row_count_raw,
      counts_clean.row_count_clean,
      (rawDs.row_count_raw - counts_clean.row_count_clean) as dropped_rows,
      nu. Expected one of: token, Comma, FROM, SELECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:53:08.605054 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '748bee95-4999-4786-a87a-ae466f63582d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73c63b9bea60>]}
[0m18:53:08.606813 [error] [Thread-3  ]: 19 of 19 ERROR creating sql view model `mart`.`g1_dq_insta_users_summary` ...... [[31mERROR[0m in 0.61s]
[0m18:53:08.609287 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.26 seconds
[0m18:53:08.611426 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:53:08.613669 [debug] [Thread-3  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:53:08.640197 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m18:53:08.645978 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m18:53:08.658401 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:53:08.666799 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m18:53:08.923511 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:53:08.927100 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies` to `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m18:53:08.931854 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:53:08.934954 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies` to `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m18:53:08.951764 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:53:08.954729 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary` to `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m18:53:09.268703 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:53:09.270852 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:53:09.279751 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:53:09.284885 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m18:53:09.293853 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m18:53:09.303250 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m18:53:09.624611 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:53:09.628541 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:53:09.634630 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m18:53:09.637454 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:53:09.642291 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m18:53:09.652105 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary__dbt_tmp` to `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m18:53:09.934805 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:53:09.946596 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  ...
[0m18:53:09.957764 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:53:09.969413 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  ...
[0m18:53:09.984224 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:53:09.994429 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  ...
[0m18:53:10.229232 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:53:10.234073 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '748bee95-4999-4786-a87a-ae466f63582d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73c63b92fd30>]}
[0m18:53:10.235913 [info ] [Thread-1  ]: 16 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_anomalies` ....... [[32mOK[0m in 2.26s]
[0m18:53:10.239682 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:53:10.267654 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:53:10.275039 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '748bee95-4999-4786-a87a-ae466f63582d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73c63a77ec70>]}
[0m18:53:10.277003 [info ] [Thread-2  ]: 18 of 19 OK created sql view model `mart`.`g1_dq_insta_users_anomalies` ........ [[32mOK[0m in 2.29s]
[0m18:53:10.280359 [debug] [Thread-2  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:53:10.292131 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:53:10.298523 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '748bee95-4999-4786-a87a-ae466f63582d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73c63a7d58b0>]}
[0m18:53:10.300478 [info ] [Thread-4  ]: 17 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_summary` ......... [[32mOK[0m in 2.32s]
[0m18:53:10.304134 [debug] [Thread-4  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:53:10.311040 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:53:10.312876 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m18:53:10.314794 [debug] [MainThread]: On list__mart: Close
[0m18:53:10.316155 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m18:53:10.317704 [debug] [MainThread]: On list__clean: Close
[0m18:53:10.318958 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_anomalies' was left open.
[0m18:53:10.320607 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: Close
[0m18:53:10.322479 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_summary' was left open.
[0m18:53:10.324077 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_summary: Close
[0m18:53:10.325430 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_summary' was left open.
[0m18:53:10.326960 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_summary: Close
[0m18:53:10.328409 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_anomalies' was left open.
[0m18:53:10.330704 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_anomalies: Close
[0m18:53:10.333514 [info ] [MainThread]: 
[0m18:53:10.335821 [info ] [MainThread]: Finished running 2 table models, 13 data tests, 4 view models in 0 hours 0 minutes and 23.57 seconds (23.57s).
[0m18:53:10.354683 [debug] [MainThread]: Command end result
[0m18:53:10.555429 [info ] [MainThread]: 
[0m18:53:10.556484 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m18:53:10.557578 [info ] [MainThread]: 
[0m18:53:10.559754 [error] [MainThread]:   Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1314 ('joined') (line 61, col 1): joined as (
    select
      rawDs.row_count_raw,
      counts_clean.row_count_clean,
      (rawDs.row_count_raw - counts_clean.row_count_clean) as dropped_rows,
      nu. Expected one of: token, Comma, FROM, SELECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:53:10.561347 [info ] [MainThread]: 
[0m18:53:10.563008 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m18:53:10.567019 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 26.17992, "process_in_blocks": "0", "process_kernel_time": 2.002389, "process_mem_max_rss": "119504", "process_out_blocks": "11320", "process_user_time": 9.414459}
[0m18:53:10.569504 [debug] [MainThread]: Command `dbt build` failed at 18:53:10.568853 after 26.18 seconds
[0m18:53:10.571721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73c640ea6310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73c63e6359a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x73c63bdc6940>]}
[0m18:53:10.573260 [debug] [MainThread]: Flushing usage events
[0m18:56:29.236775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7547a8d5be20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7547a59c2b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7547a59c2a30>]}


============================== 18:56:29.251452 | 46d6db25-bedb-4ceb-96aa-335d8646c8af ==============================
[0m18:56:29.251452 [info ] [MainThread]: Running with dbt=1.8.9
[0m18:56:29.253900 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'quiet': 'False', 'debug': 'False', 'profiles_dir': '.', 'version_check': 'True', 'log_format': 'default', 'warn_error': 'None', 'target_path': 'None', 'cache_selected_only': 'False', 'log_path': '/workdir/transforms/01_instacart/logs', 'empty': 'False', 'introspect': 'True', 'static_parser': 'True', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'use_colors': 'True', 'fail_fast': 'False', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'no_print': 'None', 'printer_width': '80'}
[0m18:56:29.605586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '46d6db25-bedb-4ceb-96aa-335d8646c8af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7547a59271f0>]}
[0m18:56:29.716734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '46d6db25-bedb-4ceb-96aa-335d8646c8af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7547a59fc910>]}
[0m18:56:29.718542 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m18:56:29.955685 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m18:56:30.279454 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m18:56:30.281110 [debug] [MainThread]: Partial parsing: updated file: ex_01_instacart://models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:56:30.995967 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ex_01_mpg.clean
- models.ex_01_mpg.mart
[0m18:56:31.041053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '46d6db25-bedb-4ceb-96aa-335d8646c8af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7547a3cd4eb0>]}
[0m18:56:31.363911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '46d6db25-bedb-4ceb-96aa-335d8646c8af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7547a3c24cd0>]}
[0m18:56:31.365592 [info ] [MainThread]: Found 6 models, 13 data tests, 1 source, 471 macros
[0m18:56:31.372150 [info ] [MainThread]: 
[0m18:56:31.373849 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:56:31.394889 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:56:31.397164 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:56:31.444629 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:56:31.448906 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:56:35.583064 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:56:35.620226 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:56:35.878598 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:56:35.937157 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:56:35.945360 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m18:56:35.958826 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m18:56:35.980137 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m18:56:35.994263 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m18:56:36.301797 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:56:36.296901 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:56:36.614160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '46d6db25-bedb-4ceb-96aa-335d8646c8af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7547a3791850>]}
[0m18:56:36.617461 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m18:56:36.619427 [info ] [MainThread]: 
[0m18:56:36.652118 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:56:36.654753 [info ] [Thread-1  ]: 1 of 19 START sql table model `clean`.`g1_stg_insta_orders` .................... [RUN]
[0m18:56:36.658825 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_instacart.g1_stg_insta_orders'
[0m18:56:36.660455 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_orders
[0m18:56:36.693571 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:56:36.696127 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_orders
[0m18:56:36.822329 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m18:56:40.292208 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

            

    
        create table `clean`.`g1_stg_insta_orders__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (order_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
          )
        
        ...
[0m18:56:40.584285 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:56:40.608463 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    select name, type from system.columns where table = 'g1_stg_insta_orders__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:56:40.927580 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:56:40.936302 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m18:56:40.938343 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_orders__dbt_backup`
        ("order_id", "user_id", "eval_set", "order_number", "order_dow", "order_hour_of_day", "days_since_prior_order")

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
  ...
[0m18:56:43.571092 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 2.63 seconds
[0m18:56:43.586008 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_orders__dbt_backup` AND `clean`.`g1_stg_insta_orders` 
  
  ...
[0m18:56:43.868614 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:56:43.933823 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    drop table if exists `clean`.`g1_stg_insta_orders__dbt_backup` 
  ...
[0m18:56:44.251550 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:56:44.262829 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d6db25-bedb-4ceb-96aa-335d8646c8af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7547a38e4700>]}
[0m18:56:44.266007 [info ] [Thread-1  ]: 1 of 19 OK created sql table model `clean`.`g1_stg_insta_orders` ............... [[32mOK[0m in 7.60s]
[0m18:56:44.269228 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_orders
[0m18:56:44.274778 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:56:44.276954 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:56:44.279077 [info ] [Thread-3  ]: 2 of 19 START test accepted_values_g1_stg_insta_orders_eval_set__prior__train__test  [RUN]
[0m18:56:44.281755 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:56:44.286010 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:56:44.283804 [info ] [Thread-4  ]: 3 of 19 START test accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [RUN]
[0m18:56:44.290107 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5'
[0m18:56:44.291784 [info ] [Thread-2  ]: 4 of 19 START test accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [RUN]
[0m18:56:44.295064 [info ] [Thread-1  ]: 5 of 19 START test not_null_g1_stg_insta_orders_eval_set ....................... [RUN]
[0m18:56:44.298140 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145'
[0m18:56:44.299808 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:56:44.303509 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1'
[0m18:56:44.305952 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_orders, now test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7)
[0m18:56:44.307757 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:56:44.322269 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:56:44.342166 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:56:44.354359 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:56:44.368207 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:56:44.387261 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:56:44.402442 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:56:44.409418 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:56:44.412036 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:56:44.424435 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:56:44.460383 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:56:44.482407 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m18:56:44.485243 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m18:56:44.493890 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m18:56:44.501554 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m18:56:44.505247 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m18:56:44.506723 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:56:44.509903 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select eval_set
from `clean`.`g1_stg_insta_orders`
where eval_set is null



    ) dbt_internal_test...
[0m18:56:44.515325 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m18:56:45.076815 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.56 seconds
[0m18:56:45.132262 [info ] [Thread-1  ]: 5 of 19 PASS not_null_g1_stg_insta_orders_eval_set ............................. [[32mPASS[0m in 0.83s]
[0m18:56:45.146350 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m18:56:45.154391 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:56:45.158072 [info ] [Thread-1  ]: 6 of 19 START test not_null_g1_stg_insta_orders_order_dow ...................... [RUN]
[0m18:56:45.161148 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240)
[0m18:56:45.168724 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:56:45.187448 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:56:45.189904 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:56:45.199553 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m18:56:45.204020 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_dow
from `clean`.`g1_stg_insta_orders`
where order_dow is null



    ) dbt_internal_test...
[0m18:56:45.530541 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:56:45.534928 [info ] [Thread-1  ]: 6 of 19 PASS not_null_g1_stg_insta_orders_order_dow ............................ [[32mPASS[0m in 0.37s]
[0m18:56:45.537064 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m18:56:45.538527 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:56:45.540029 [info ] [Thread-1  ]: 7 of 19 START test not_null_g1_stg_insta_orders_order_hour_of_day .............. [RUN]
[0m18:56:45.542046 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576)
[0m18:56:45.543350 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:56:45.556335 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:56:45.558674 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:56:45.566839 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m18:56:45.568740 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_hour_of_day
from `clean`.`g1_stg_insta_orders`
where order_hour_of_day is null



    ) dbt_internal_test...
[0m18:56:45.894259 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:56:45.899091 [info ] [Thread-1  ]: 7 of 19 PASS not_null_g1_stg_insta_orders_order_hour_of_day .................... [[32mPASS[0m in 0.36s]
[0m18:56:45.901680 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m18:56:45.903539 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:56:45.905283 [info ] [Thread-1  ]: 8 of 19 START test not_null_g1_stg_insta_orders_order_id ....................... [RUN]
[0m18:56:45.907003 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600)
[0m18:56:45.908381 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:56:45.919888 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:56:45.921613 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:56:45.928620 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m18:56:45.930599 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from `clean`.`g1_stg_insta_orders`
where order_id is null



    ) dbt_internal_test...
[0m18:56:46.250121 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:56:46.257443 [info ] [Thread-1  ]: 8 of 19 PASS not_null_g1_stg_insta_orders_order_id ............................. [[32mPASS[0m in 0.35s]
[0m18:56:46.260176 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m18:56:46.262025 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:56:46.263859 [info ] [Thread-1  ]: 9 of 19 START test not_null_g1_stg_insta_orders_order_number ................... [RUN]
[0m18:56:46.265939 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619)
[0m18:56:46.267373 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:56:46.279786 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:56:46.282575 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:56:46.290635 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m18:56:46.293733 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_number
from `clean`.`g1_stg_insta_orders`
where order_number is null



    ) dbt_internal_test...
[0m18:56:46.617453 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:56:46.622317 [info ] [Thread-1  ]: 9 of 19 PASS not_null_g1_stg_insta_orders_order_number ......................... [[32mPASS[0m in 0.36s]
[0m18:56:46.624495 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m18:56:46.626011 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:56:46.627825 [info ] [Thread-1  ]: 10 of 19 START test not_null_g1_stg_insta_orders_user_id ....................... [RUN]
[0m18:56:46.629778 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619, now test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64)
[0m18:56:46.632100 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:56:46.644409 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:56:46.648554 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:56:46.657575 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m18:56:46.660048 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_orders`
where user_id is null



    ) dbt_internal_test...
[0m18:56:46.983626 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:56:46.990915 [info ] [Thread-1  ]: 10 of 19 PASS not_null_g1_stg_insta_orders_user_id ............................. [[32mPASS[0m in 0.36s]
[0m18:56:46.995185 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m18:56:46.996769 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:56:46.998619 [info ] [Thread-1  ]: 11 of 19 START test unique_g1_stg_insta_orders_order_id ........................ [RUN]
[0m18:56:47.000661 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64, now test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57)
[0m18:56:47.002544 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:56:47.023814 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:56:47.025699 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:56:47.032967 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m18:56:47.035721 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_orders`
where order_id is not null
group by order_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:56:47.725065 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.69 seconds
[0m18:56:47.733102 [info ] [Thread-1  ]: 11 of 19 PASS unique_g1_stg_insta_orders_order_id .............................. [[32mPASS[0m in 0.73s]
[0m18:56:47.739365 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m18:56:48.063725 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_dow as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_dow

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6'
)



    ) dbt_internal_test...
[0m18:56:48.067484 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        eval_set as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by eval_set

)

select *
from all_values
where value_field not in (
    'prior','train','test'
)



    ) dbt_internal_test...
[0m18:56:48.420878 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m18:56:48.424923 [info ] [Thread-4  ]: 3 of 19 PASS accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [[32mPASS[0m in 4.13s]
[0m18:56:48.427009 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m18:56:48.448681 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m18:56:48.453401 [info ] [Thread-3  ]: 2 of 19 PASS accepted_values_g1_stg_insta_orders_eval_set__prior__train__test .. [[32mPASS[0m in 4.16s]
[0m18:56:48.456675 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m18:56:48.522716 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_hour_of_day as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_hour_of_day

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23'
)



    ) dbt_internal_test...
[0m18:56:48.852349 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:56:48.858051 [info ] [Thread-2  ]: 4 of 19 PASS accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [[32mPASS[0m in 4.56s]
[0m18:56:48.860877 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m18:56:48.865409 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_users
[0m18:56:48.868101 [info ] [Thread-1  ]: 12 of 19 START sql table model `clean`.`g1_stg_insta_users` .................... [RUN]
[0m18:56:48.870912 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57, now model.ex_01_instacart.g1_stg_insta_users)
[0m18:56:48.872812 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_users
[0m18:56:48.888938 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:56:48.890820 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_users
[0m18:56:48.905173 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

            

    
        create table `clean`.`g1_stg_insta_users__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (user_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
          )
        
        ...
[0m18:56:49.343076 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.44 seconds
[0m18:56:49.354579 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    select name, type from system.columns where table = 'g1_stg_insta_users__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m18:56:49.650235 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:56:49.653835 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_users"
[0m18:56:49.655394 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_users__dbt_backup`
        ("user_id")

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
  ...
[0m18:56:50.058106 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.40 seconds
[0m18:56:50.063339 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_users__dbt_backup` AND `clean`.`g1_stg_insta_users` 
  
  ...
[0m18:56:50.363464 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:56:50.384197 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    drop table if exists `clean`.`g1_stg_insta_users__dbt_backup` 
  ...
[0m18:56:50.668533 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:56:50.674783 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d6db25-bedb-4ceb-96aa-335d8646c8af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7547a3efe1f0>]}
[0m18:56:50.677624 [info ] [Thread-1  ]: 12 of 19 OK created sql table model `clean`.`g1_stg_insta_users` ............... [[32mOK[0m in 1.80s]
[0m18:56:50.680336 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_users
[0m18:56:50.682821 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:56:50.684220 [info ] [Thread-3  ]: 13 of 19 START test not_null_g1_stg_insta_users_user_id ........................ [RUN]
[0m18:56:50.686350 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:56:50.688114 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5, now test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935)
[0m18:56:50.689869 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:56:50.691661 [info ] [Thread-2  ]: 14 of 19 START test relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [RUN]
[0m18:56:50.694099 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:56:50.695953 [info ] [Thread-4  ]: 15 of 19 START test unique_g1_stg_insta_users_user_id .......................... [RUN]
[0m18:56:50.698148 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1, now test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726)
[0m18:56:50.714882 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:56:50.716616 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145, now test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f)
[0m18:56:50.718562 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:56:50.720920 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:56:50.722682 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:56:50.768324 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:56:50.775644 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:56:50.773764 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m18:56:50.779253 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:56:50.782395 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:56:50.795774 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m18:56:50.803738 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_users`
where user_id is null



    ) dbt_internal_test...
[0m18:56:50.811439 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m18:56:50.818395 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    user_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_users`
where user_id is not null
group by user_id
having count(*) > 1



    ) dbt_internal_test...
[0m18:56:50.829572 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select user_id as from_field
    from `clean`.`g1_stg_insta_orders`
    where user_id is not null
),

parent as (
    select user_id as to_field
    from `clean`.`g1_stg_insta_users`
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null
-- end_of_sql
settings join_use_nulls = 1



    ) dbt_internal_test...
[0m18:56:51.108356 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:56:51.112660 [info ] [Thread-3  ]: 13 of 19 PASS not_null_g1_stg_insta_users_user_id .............................. [[32mPASS[0m in 0.42s]
[0m18:56:51.114653 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m18:56:51.147866 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:56:51.152254 [info ] [Thread-4  ]: 15 of 19 PASS unique_g1_stg_insta_users_user_id ................................ [[32mPASS[0m in 0.44s]
[0m18:56:51.154444 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m18:56:51.434900 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.60 seconds
[0m18:56:51.439720 [info ] [Thread-2  ]: 14 of 19 PASS relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [[32mPASS[0m in 0.74s]
[0m18:56:51.442168 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m18:56:51.445271 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:56:51.447230 [debug] [Thread-3  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:56:51.451128 [debug] [Thread-4  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:56:51.453510 [debug] [Thread-2  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:56:51.449118 [info ] [Thread-1  ]: 16 of 19 START sql view model `mart`.`g1_dq_insta_orders_anomalies` ............ [RUN]
[0m18:56:51.455761 [info ] [Thread-3  ]: 17 of 19 START sql view model `mart`.`g1_dq_insta_orders_summary` .............. [RUN]
[0m18:56:51.458538 [info ] [Thread-4  ]: 18 of 19 START sql view model `mart`.`g1_dq_insta_users_anomalies` ............. [RUN]
[0m18:56:51.461465 [info ] [Thread-2  ]: 19 of 19 START sql view model `mart`.`g1_dq_insta_users_summary` ............... [RUN]
[0m18:56:51.464765 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_users, now model.ex_01_instacart.g1_dq_insta_orders_anomalies)
[0m18:56:51.466870 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935, now model.ex_01_instacart.g1_dq_insta_orders_summary)
[0m18:56:51.468530 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f, now model.ex_01_instacart.g1_dq_insta_users_anomalies)
[0m18:56:51.470294 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726, now model.ex_01_instacart.g1_dq_insta_users_summary)
[0m18:56:51.472300 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:56:51.474708 [debug] [Thread-3  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:56:51.476661 [debug] [Thread-4  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:56:51.479240 [debug] [Thread-2  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:56:51.492738 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:56:51.511816 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:56:51.516185 [debug] [Thread-4  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:56:51.527213 [debug] [Thread-2  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:56:51.530076 [debug] [Thread-3  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:56:51.532657 [debug] [Thread-4  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:56:51.534122 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:56:51.547666 [debug] [Thread-2  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:56:51.681247 [debug] [Thread-2  ]: Creating new relation g1_dq_insta_users_summary
[0m18:56:51.740321 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m18:56:51.748762 [debug] [Thread-2  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m18:56:51.750841 [debug] [Thread-4  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m18:56:51.755586 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m18:56:51.758770 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */


  create view `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Orders
with cln as (
  -- Source cleaned orders data
  select * 
  from `clean`.`g1_stg_insta_orders`
),

users as (
  -- Reference users table for FK validation
  select user_id 
  from `clean`.`g1_stg_insta_users`
),

violations as (
  select
    order_id,
    user_id,
    eval_set,
    order_number,
    order_dow,
    order_hour_of_day,
    days_since_prior_order,

    -- Data Quality Issue Classification
    multiIf(
      order_id is null, 'null_order_id',
      user_id is null, 'null_user_id',
      user_id not in (select user_id from users), 'missing_user_ref',
      order_number < 1, 'invalid_order_number',
      order_dow not in (0,1,2,3,4,5,6), 'invalid_order_dow',
      order_hour_of_day < 0 or order_hour_of_day > 23, 'invalid_order_hour',
      days_since_prior_order < 0, 'negative_days_since_prior_order',
      'ok'
    ) as dq_issue

  from cln
)

-- Return only rows with detected anomalies
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:56:51.761070 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),

cln as (
    select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts_clean as (
    select count(*) as row_count_clean
    from cln
),

-- Null Percentage
nulls as (
    select round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
    from cln
),

-- Duplicate Users Check
dupes as (
    select countIf(cnt > 1) as duplicate_user_ids
    from (
        select user_id, count() as cnt
        from cln
        group by user_id
    )
),

-- Referential Integrity
invalid_users as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),

users_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
),

-- Join all metrics
joined as (
    select
        r.row_count_raw,
        c.row_count_clean,
        (r.row_count_raw - c.row_count_clean) as dropped_rows,
        n.null_pct_user_id,
        d.duplicate_user_ids,
        iu.invalid_user_in_orders,
        uwo.user_without_orders
    from rawDs r
    cross join counts_clean c
    cross join nulls n
    cross join dupes d
    cross join invalid_users iu
    cross join users_without_orders uwo
)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:56:51.766652 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */


  create view `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Users

with cln as (
  select * from `clean`.`g1_stg_insta_users`
),
violations as (
  select
    user_id,

    multiIf(
      user_id is null, 'null_user_id',
      user_id <= 0, 'invalid_user_id',
      'ok'
    ) as dq_issue
  from cln
)
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:56:51.768541 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */


  create view `mart`.`g1_dq_insta_orders_summary__dbt_tmp` 
  
    
    
  as (
    

-- Data Quality Summary for Orders
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  select * from `raw`.`raw___insta_orders`
),

cln as (
  select * from `clean`.`g1_stg_insta_orders`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage Check
nulls as (
  select
    round(100.0 * countIf(order_id is null) / nullif(count(),0), 2) as null_pct_order_id,
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id,
    round(100.0 * countIf(eval_set is null) / nullif(count(),0), 2) as null_pct_eval_set,
    round(100.0 * countIf(order_number is null) / nullif(count(),0), 2) as null_pct_order_number,
    round(100.0 * countIf(order_dow is null) / nullif(count(),0), 2) as null_pct_order_dow,
    round(100.0 * countIf(order_hour_of_day is null) / nullif(count(),0), 2) as null_pct_order_hour_of_day,
    round(100.0 * countIf(days_since_prior_order is null) / nullif(count(),0), 2) as null_pct_days_since_prior_order
  from cln
),

-- Duplicate Orders
dupes as (
  select
    countIf(cnt > 1) as duplicate_orders
  from (
    select order_id, count() as cnt
    from cln
    group by order_id
  )
),

-- Referential Integrity
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_id
  from `clean`.`g1_stg_insta_orders` o
),

-- Value Range Checks
value_ranges as (
  select
    countIf(order_number < 1) as invalid_order_number,
    countIf(order_hour_of_day < 0 or order_hour_of_day > 23) as invalid_order_hour,
    countIf(days_since_prior_order < 0 or days_since_prior_order > 30) as invalid_days_since_prior_order
  from cln
),

-- Join all metrics
joined as (
    select
        counts.row_count_raw,
        counts.row_count_clean,
        (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
        nulls.*,
        dupes.duplicate_orders,
        referential_integrity.invalid_user_id,
        value_ranges.invalid_order_number,
        value_ranges.invalid_order_hour,
        value_ranges.invalid_days_since_prior_order
    from counts
    cross join nulls
    cross join dupes
    cross join referential_integrity
    cross join value_ranges
)

select * from joined
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m18:56:52.079479 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m18:56:52.082790 [debug] [Thread-2  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),

cln as (
    select * from `clean`.`g1_stg_insta_users`
),

-- Row Count Comparison
counts_clean as (
    select count(*) as row_count_clean
    from cln
),

-- Null Percentage
nulls as (
    select round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
    from cln
),

-- Duplicate Users Check
dupes as (
    select countIf(cnt > 1) as duplicate_user_ids
    from (
        select user_id, count() as cnt
        from cln
        group by user_id
    )
),

-- Referential Integrity
invalid_users as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),

users_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
),

-- Join all metrics
joined as (
    select
        r.row_count_raw,
        c.row_count_clean,
        (r.row_count_raw - c.row_count_clean) as dropped_rows,
        n.null_pct_user_id,
        d.duplicate_user_ids,
        iu.invalid_user_in_orders,
        uwo.user_without_orders
    from rawDs r
    cross join counts_clean c
    cross join nulls n
    cross join dupes d
    cross join invalid_users iu
    cross join users_without_orders uwo
)

select * from joined;
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m18:56:52.085184 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m18:56:52.105807 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m18:56:52.107888 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m18:56:52.118336 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m18:56:52.130701 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m18:56:52.141668 [debug] [Thread-2  ]: Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1772 (end of query) (line 76, col 21): ;
      
    )
        
        
                      -- end_of_sql
                      
                      . Expected one of: token, Dot, OpeningRoundBracket, UUID, alias, AS, identifier, FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:56:52.142946 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d6db25-bedb-4ceb-96aa-335d8646c8af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7547a3b9aaf0>]}
[0m18:56:52.144584 [error] [Thread-2  ]: 19 of 19 ERROR creating sql view model `mart`.`g1_dq_insta_users_summary` ...... [[31mERROR[0m in 0.67s]
[0m18:56:52.146811 [debug] [Thread-2  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m18:56:52.398721 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:56:52.401611 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies` to `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m18:56:52.407294 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:56:52.409606 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:56:52.412892 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies` to `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m18:56:52.416483 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary` to `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m18:56:52.684710 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:56:52.696844 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m18:56:52.699920 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:56:52.704088 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:56:52.714966 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m18:56:52.725659 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m18:56:52.983586 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:56:52.987350 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m18:56:53.021001 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:56:53.023279 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m18:56:53.026707 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m18:56:53.030199 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary__dbt_tmp` to `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m18:56:53.280381 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:56:53.300550 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  ...
[0m18:56:53.308030 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m18:56:53.311043 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:56:53.335619 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  ...
[0m18:56:53.353915 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  ...
[0m18:56:53.586866 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:56:53.591064 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d6db25-bedb-4ceb-96aa-335d8646c8af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7547a2787c70>]}
[0m18:56:53.592653 [info ] [Thread-1  ]: 16 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_anomalies` ....... [[32mOK[0m in 2.13s]
[0m18:56:53.594402 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m18:56:53.629693 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m18:56:53.634675 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d6db25-bedb-4ceb-96aa-335d8646c8af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7547a27b74c0>]}
[0m18:56:53.637195 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m18:56:53.639788 [info ] [Thread-3  ]: 17 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_summary` ......... [[32mOK[0m in 2.17s]
[0m18:56:53.644333 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d6db25-bedb-4ceb-96aa-335d8646c8af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7547a27a2cd0>]}
[0m18:56:53.646656 [debug] [Thread-3  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m18:56:53.648944 [info ] [Thread-4  ]: 18 of 19 OK created sql view model `mart`.`g1_dq_insta_users_anomalies` ........ [[32mOK[0m in 2.18s]
[0m18:56:53.653550 [debug] [Thread-4  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m18:56:53.658038 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:56:53.659222 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m18:56:53.660577 [debug] [MainThread]: On list__mart: Close
[0m18:56:53.661984 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m18:56:53.663027 [debug] [MainThread]: On list__clean: Close
[0m18:56:53.663944 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_anomalies' was left open.
[0m18:56:53.664852 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: Close
[0m18:56:53.665689 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_summary' was left open.
[0m18:56:53.666899 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_summary: Close
[0m18:56:53.667956 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_anomalies' was left open.
[0m18:56:53.668757 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_anomalies: Close
[0m18:56:53.669610 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_summary' was left open.
[0m18:56:53.670825 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_summary: Close
[0m18:56:53.674049 [info ] [MainThread]: 
[0m18:56:53.676271 [info ] [MainThread]: Finished running 2 table models, 13 data tests, 4 view models in 0 hours 0 minutes and 22.30 seconds (22.30s).
[0m18:56:53.689689 [debug] [MainThread]: Command end result
[0m18:56:53.780821 [info ] [MainThread]: 
[0m18:56:53.782445 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m18:56:53.784234 [info ] [MainThread]: 
[0m18:56:53.786753 [error] [MainThread]:   Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1772 (end of query) (line 76, col 21): ;
      
    )
        
        
                      -- end_of_sql
                      
                      . Expected one of: token, Dot, OpeningRoundBracket, UUID, alias, AS, identifier, FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m18:56:53.788345 [info ] [MainThread]: 
[0m18:56:53.790066 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m18:56:53.794155 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 24.728643, "process_in_blocks": "0", "process_kernel_time": 1.932997, "process_mem_max_rss": "119660", "process_out_blocks": "11320", "process_user_time": 8.750624}
[0m18:56:53.796328 [debug] [MainThread]: Command `dbt build` failed at 18:56:53.795725 after 24.73 seconds
[0m18:56:53.797966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7547a8d5be20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7547a59271f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7547a389f2b0>]}
[0m18:56:53.799050 [debug] [MainThread]: Flushing usage events
[0m19:00:17.037563 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x786c6926fe20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x786c65eccb80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x786c65ecca30>]}


============================== 19:00:17.053996 | d3acd220-b385-490c-87b0-6b7ec26b0dd5 ==============================
[0m19:00:17.053996 [info ] [MainThread]: Running with dbt=1.8.9
[0m19:00:17.056090 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'indirect_selection': 'eager', 'profiles_dir': '.', 'log_cache_events': 'False', 'log_path': '/workdir/transforms/01_instacart/logs', 'target_path': 'None', 'no_print': 'None', 'static_parser': 'True', 'empty': 'False', 'debug': 'False', 'printer_width': '80', 'version_check': 'True', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'use_experimental_parser': 'False', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'log_format': 'default', 'fail_fast': 'False', 'use_colors': 'True', 'cache_selected_only': 'False', 'invocation_command': 'dbt build --profiles-dir . --target remote'}
[0m19:00:17.447789 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd3acd220-b385-490c-87b0-6b7ec26b0dd5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x786c68704910>]}
[0m19:00:17.554216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd3acd220-b385-490c-87b0-6b7ec26b0dd5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x786c65e97d60>]}
[0m19:00:17.555799 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m19:00:17.797726 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m19:00:18.132248 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:00:18.134077 [debug] [MainThread]: Partial parsing: updated file: ex_01_instacart://models/mart/dq/g1_dq_insta_users_summary.sql
[0m19:00:18.876178 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ex_01_mpg.clean
- models.ex_01_mpg.mart
[0m19:00:18.927630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd3acd220-b385-490c-87b0-6b7ec26b0dd5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x786c641fdeb0>]}
[0m19:00:19.317176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd3acd220-b385-490c-87b0-6b7ec26b0dd5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x786c640dad30>]}
[0m19:00:19.319215 [info ] [MainThread]: Found 6 models, 13 data tests, 1 source, 471 macros
[0m19:00:19.334432 [info ] [MainThread]: 
[0m19:00:19.338043 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m19:00:19.384011 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m19:00:19.387885 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m19:00:19.443410 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:00:19.451010 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:00:23.858614 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m19:00:23.884877 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m19:00:24.134165 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m19:00:24.177472 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m19:00:24.183395 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m19:00:24.185581 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m19:00:24.200604 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m19:00:24.206764 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m19:00:24.504949 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:00:24.526401 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m19:00:24.818080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd3acd220-b385-490c-87b0-6b7ec26b0dd5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x786c691c2430>]}
[0m19:00:24.820047 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m19:00:24.821299 [info ] [MainThread]: 
[0m19:00:24.845173 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_orders
[0m19:00:24.847035 [info ] [Thread-1  ]: 1 of 19 START sql table model `clean`.`g1_stg_insta_orders` .................... [RUN]
[0m19:00:24.849439 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_instacart.g1_stg_insta_orders'
[0m19:00:24.851043 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_orders
[0m19:00:24.877400 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m19:00:24.879080 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_orders
[0m19:00:24.995368 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m19:00:28.527862 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

            

    
        create table `clean`.`g1_stg_insta_orders__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (order_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
          )
        
        ...
[0m19:00:28.815014 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m19:00:28.836490 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    select name, type from system.columns where table = 'g1_stg_insta_orders__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m19:00:29.132118 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m19:00:29.146511 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m19:00:29.150405 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_orders__dbt_backup`
        ("order_id", "user_id", "eval_set", "order_number", "order_dow", "order_hour_of_day", "days_since_prior_order")

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
  ...
[0m19:00:31.881272 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 2.73 seconds
[0m19:00:31.896435 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_orders__dbt_backup` AND `clean`.`g1_stg_insta_orders` 
  
  ...
[0m19:00:32.173102 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m19:00:32.250812 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    drop table if exists `clean`.`g1_stg_insta_orders__dbt_backup` 
  ...
[0m19:00:32.547594 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:00:32.564959 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3acd220-b385-490c-87b0-6b7ec26b0dd5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x786c63db5b20>]}
[0m19:00:32.569338 [info ] [Thread-1  ]: 1 of 19 OK created sql table model `clean`.`g1_stg_insta_orders` ............... [[32mOK[0m in 7.71s]
[0m19:00:32.573624 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_orders
[0m19:00:32.580814 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m19:00:32.584072 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m19:00:32.586816 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m19:00:32.589756 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m19:00:32.592841 [info ] [Thread-3  ]: 2 of 19 START test accepted_values_g1_stg_insta_orders_eval_set__prior__train__test  [RUN]
[0m19:00:32.596214 [info ] [Thread-4  ]: 3 of 19 START test accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [RUN]
[0m19:00:32.599326 [info ] [Thread-2  ]: 4 of 19 START test accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [RUN]
[0m19:00:32.609827 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5'
[0m19:00:32.614678 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145'
[0m19:00:32.602665 [info ] [Thread-1  ]: 5 of 19 START test not_null_g1_stg_insta_orders_eval_set ....................... [RUN]
[0m19:00:32.619014 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1'
[0m19:00:32.622275 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m19:00:32.625211 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m19:00:32.627985 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_orders, now test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7)
[0m19:00:32.630959 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m19:00:32.673897 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m19:00:32.749693 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m19:00:32.755087 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m19:00:32.783914 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m19:00:32.788785 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m19:00:32.792333 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m19:00:32.794575 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m19:00:32.795852 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m19:00:32.808608 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m19:00:32.901887 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m19:00:32.910065 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m19:00:32.911589 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m19:00:32.926917 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m19:00:32.930298 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m19:00:32.932007 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select eval_set
from `clean`.`g1_stg_insta_orders`
where eval_set is null



    ) dbt_internal_test...
[0m19:00:32.935354 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m19:00:32.941754 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m19:00:33.261945 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m19:00:33.277604 [info ] [Thread-1  ]: 5 of 19 PASS not_null_g1_stg_insta_orders_eval_set ............................. [[32mPASS[0m in 0.65s]
[0m19:00:33.282336 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m19:00:33.284532 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m19:00:33.287144 [info ] [Thread-1  ]: 6 of 19 START test not_null_g1_stg_insta_orders_order_dow ...................... [RUN]
[0m19:00:33.289802 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240)
[0m19:00:33.292203 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m19:00:33.308284 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m19:00:33.310784 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m19:00:33.318686 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m19:00:33.321890 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_dow
from `clean`.`g1_stg_insta_orders`
where order_dow is null



    ) dbt_internal_test...
[0m19:00:34.067649 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.74 seconds
[0m19:00:34.076558 [info ] [Thread-1  ]: 6 of 19 PASS not_null_g1_stg_insta_orders_order_dow ............................ [[32mPASS[0m in 0.79s]
[0m19:00:34.081991 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m19:00:34.084471 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m19:00:34.088000 [info ] [Thread-1  ]: 7 of 19 START test not_null_g1_stg_insta_orders_order_hour_of_day .............. [RUN]
[0m19:00:34.091504 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576)
[0m19:00:34.094216 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m19:00:34.157391 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m19:00:34.188289 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m19:00:34.209733 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m19:00:34.213252 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_hour_of_day
from `clean`.`g1_stg_insta_orders`
where order_hour_of_day is null



    ) dbt_internal_test...
[0m19:00:34.500432 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m19:00:34.507123 [info ] [Thread-1  ]: 7 of 19 PASS not_null_g1_stg_insta_orders_order_hour_of_day .................... [[32mPASS[0m in 0.42s]
[0m19:00:34.509560 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m19:00:34.511214 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m19:00:34.514446 [info ] [Thread-1  ]: 8 of 19 START test not_null_g1_stg_insta_orders_order_id ....................... [RUN]
[0m19:00:34.517161 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600)
[0m19:00:34.519161 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m19:00:34.535210 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m19:00:34.537088 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m19:00:34.543789 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m19:00:34.546168 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from `clean`.`g1_stg_insta_orders`
where order_id is null



    ) dbt_internal_test...
[0m19:00:34.824346 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m19:00:34.829340 [info ] [Thread-1  ]: 8 of 19 PASS not_null_g1_stg_insta_orders_order_id ............................. [[32mPASS[0m in 0.31s]
[0m19:00:34.831338 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m19:00:34.832908 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m19:00:34.834324 [info ] [Thread-1  ]: 9 of 19 START test not_null_g1_stg_insta_orders_order_number ................... [RUN]
[0m19:00:34.835549 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619)
[0m19:00:34.836839 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m19:00:34.848264 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m19:00:34.850154 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m19:00:34.858820 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m19:00:34.860927 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_number
from `clean`.`g1_stg_insta_orders`
where order_number is null



    ) dbt_internal_test...
[0m19:00:35.171653 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m19:00:35.176088 [info ] [Thread-1  ]: 9 of 19 PASS not_null_g1_stg_insta_orders_order_number ......................... [[32mPASS[0m in 0.34s]
[0m19:00:35.178269 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m19:00:35.179961 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m19:00:35.181238 [info ] [Thread-1  ]: 10 of 19 START test not_null_g1_stg_insta_orders_user_id ....................... [RUN]
[0m19:00:35.182627 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619, now test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64)
[0m19:00:35.184067 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m19:00:35.195921 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m19:00:35.198689 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m19:00:35.210261 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m19:00:35.212750 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_orders`
where user_id is null



    ) dbt_internal_test...
[0m19:00:35.522394 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m19:00:35.527093 [info ] [Thread-1  ]: 10 of 19 PASS not_null_g1_stg_insta_orders_user_id ............................. [[32mPASS[0m in 0.34s]
[0m19:00:35.529576 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m19:00:35.531209 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m19:00:35.532745 [info ] [Thread-1  ]: 11 of 19 START test unique_g1_stg_insta_orders_order_id ........................ [RUN]
[0m19:00:35.535908 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64, now test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57)
[0m19:00:35.537377 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m19:00:35.558306 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m19:00:35.560482 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m19:00:35.570518 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m19:00:35.573859 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_orders`
where order_id is not null
group by order_id
having count(*) > 1



    ) dbt_internal_test...
[0m19:00:36.255790 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.68 seconds
[0m19:00:36.262895 [info ] [Thread-1  ]: 11 of 19 PASS unique_g1_stg_insta_orders_order_id .............................. [[32mPASS[0m in 0.73s]
[0m19:00:36.266634 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m19:00:36.609606 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_hour_of_day as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_hour_of_day

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23'
)



    ) dbt_internal_test...
[0m19:00:36.920629 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        eval_set as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by eval_set

)

select *
from all_values
where value_field not in (
    'prior','train','test'
)



    ) dbt_internal_test...
[0m19:00:36.922834 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_dow as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_dow

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6'
)



    ) dbt_internal_test...
[0m19:00:36.949357 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m19:00:36.953327 [info ] [Thread-2  ]: 4 of 19 PASS accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [[32mPASS[0m in 4.33s]
[0m19:00:36.955423 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m19:00:37.317803 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.39 seconds
[0m19:00:37.322192 [info ] [Thread-4  ]: 3 of 19 PASS accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [[32mPASS[0m in 4.71s]
[0m19:00:37.324065 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m19:00:37.332337 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.41 seconds
[0m19:00:37.337589 [info ] [Thread-3  ]: 2 of 19 PASS accepted_values_g1_stg_insta_orders_eval_set__prior__train__test .. [[32mPASS[0m in 4.73s]
[0m19:00:37.340291 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m19:00:37.344662 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_users
[0m19:00:37.347394 [info ] [Thread-1  ]: 12 of 19 START sql table model `clean`.`g1_stg_insta_users` .................... [RUN]
[0m19:00:37.350554 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57, now model.ex_01_instacart.g1_stg_insta_users)
[0m19:00:37.352378 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_users
[0m19:00:37.365685 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_users"
[0m19:00:37.367403 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_users
[0m19:00:37.386015 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

            

    
        create table `clean`.`g1_stg_insta_users__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (user_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
          )
        
        ...
[0m19:00:37.723863 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m19:00:37.734649 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    select name, type from system.columns where table = 'g1_stg_insta_users__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m19:00:38.022180 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m19:00:38.027634 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_users"
[0m19:00:38.029777 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_users__dbt_backup`
        ("user_id")

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
  ...
[0m19:00:38.466465 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.44 seconds
[0m19:00:38.469866 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_users__dbt_backup` AND `clean`.`g1_stg_insta_users` 
  
  ...
[0m19:00:38.767936 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:00:38.778340 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    drop table if exists `clean`.`g1_stg_insta_users__dbt_backup` 
  ...
[0m19:00:39.069496 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m19:00:39.073652 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3acd220-b385-490c-87b0-6b7ec26b0dd5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x786c63cf11c0>]}
[0m19:00:39.075391 [info ] [Thread-1  ]: 12 of 19 OK created sql table model `clean`.`g1_stg_insta_users` ............... [[32mOK[0m in 1.72s]
[0m19:00:39.077277 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_users
[0m19:00:39.080387 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m19:00:39.081835 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m19:00:39.083583 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m19:00:39.085316 [info ] [Thread-4  ]: 13 of 19 START test not_null_g1_stg_insta_users_user_id ........................ [RUN]
[0m19:00:39.087752 [info ] [Thread-3  ]: 14 of 19 START test relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [RUN]
[0m19:00:39.090018 [info ] [Thread-2  ]: 15 of 19 START test unique_g1_stg_insta_users_user_id .......................... [RUN]
[0m19:00:39.092168 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145, now test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935)
[0m19:00:39.094035 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5, now test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726)
[0m19:00:39.095820 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1, now test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f)
[0m19:00:39.097479 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m19:00:39.098899 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m19:00:39.100909 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m19:00:39.123016 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m19:00:39.145835 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m19:00:39.154918 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m19:00:39.158998 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m19:00:39.161851 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m19:00:39.170442 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m19:00:39.177879 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m19:00:39.181672 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m19:00:39.189191 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m19:00:39.191290 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_users`
where user_id is null



    ) dbt_internal_test...
[0m19:00:39.197719 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    user_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_users`
where user_id is not null
group by user_id
having count(*) > 1



    ) dbt_internal_test...
[0m19:00:39.199820 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select user_id as from_field
    from `clean`.`g1_stg_insta_orders`
    where user_id is not null
),

parent as (
    select user_id as to_field
    from `clean`.`g1_stg_insta_users`
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null
-- end_of_sql
settings join_use_nulls = 1



    ) dbt_internal_test...
[0m19:00:39.525213 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m19:00:39.529381 [info ] [Thread-4  ]: 13 of 19 PASS not_null_g1_stg_insta_users_user_id .............................. [[32mPASS[0m in 0.44s]
[0m19:00:39.531246 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m19:00:39.562758 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m19:00:39.567045 [info ] [Thread-2  ]: 15 of 19 PASS unique_g1_stg_insta_users_user_id ................................ [[32mPASS[0m in 0.47s]
[0m19:00:39.569126 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m19:00:39.904511 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.70 seconds
[0m19:00:39.912376 [info ] [Thread-3  ]: 14 of 19 PASS relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [[32mPASS[0m in 0.82s]
[0m19:00:39.916471 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m19:00:39.921228 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m19:00:39.924417 [debug] [Thread-4  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m19:00:39.926498 [debug] [Thread-2  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m19:00:39.941366 [info ] [Thread-2  ]: 18 of 19 START sql view model `mart`.`g1_dq_insta_users_anomalies` ............. [RUN]
[0m19:00:39.929437 [info ] [Thread-1  ]: 16 of 19 START sql view model `mart`.`g1_dq_insta_orders_anomalies` ............ [RUN]
[0m19:00:39.931493 [debug] [Thread-3  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m19:00:39.936250 [info ] [Thread-4  ]: 17 of 19 START sql view model `mart`.`g1_dq_insta_orders_summary` .............. [RUN]
[0m19:00:39.945341 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f, now model.ex_01_instacart.g1_dq_insta_users_anomalies)
[0m19:00:39.958500 [debug] [Thread-2  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m19:00:39.947563 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_users, now model.ex_01_instacart.g1_dq_insta_orders_anomalies)
[0m19:00:39.953803 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935, now model.ex_01_instacart.g1_dq_insta_orders_summary)
[0m19:00:39.950467 [info ] [Thread-3  ]: 19 of 19 START sql view model `mart`.`g1_dq_insta_users_summary` ............... [RUN]
[0m19:00:39.974652 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m19:00:39.995359 [debug] [Thread-4  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m19:00:40.005766 [debug] [Thread-2  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m19:00:40.017812 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726, now model.ex_01_instacart.g1_dq_insta_users_summary)
[0m19:00:40.059855 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m19:00:40.061303 [debug] [Thread-4  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m19:00:40.062994 [debug] [Thread-3  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_summary
[0m19:00:40.064861 [debug] [Thread-2  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m19:00:40.067917 [debug] [Thread-4  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m19:00:40.074892 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m19:00:40.082203 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m19:00:40.249556 [debug] [Thread-3  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_summary
[0m19:00:40.291193 [debug] [Thread-3  ]: Creating new relation g1_dq_insta_users_summary
[0m19:00:40.299272 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m19:00:40.282512 [debug] [Thread-2  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m19:00:40.305712 [debug] [Thread-4  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m19:00:40.311080 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m19:00:40.313888 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with 
rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),

cln as (
    select * from `clean`.`g1_stg_insta_users`
),

counts_clean as (
    select count(*) as row_count_clean
    from cln
),

nulls as (
    select round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
    from cln
),

dupes as (
    select countIf(cnt > 1) as duplicate_user_ids
    from (
        select user_id, count() as cnt
        from cln
        group by user_id
    )
),

invalid_users as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),

users_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

-- Join all metrics
select
    r.row_count_raw,
    c.row_count_clean,
    (r.row_count_raw - c.row_count_clean) as dropped_rows,
    n.null_pct_user_id,
    d.duplicate_user_ids,
    iu.invalid_user_in_orders,
    uwo.user_without_orders
from rawDs r
cross join counts_clean c
cross join nulls n
cross join dupes d
cross join invalid_users iu
cross join users_without_orders uwo;
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m19:00:40.316849 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */


  create view `mart`.`g1_dq_insta_orders_summary__dbt_tmp` 
  
    
    
  as (
    

-- Data Quality Summary for Orders
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  select * from `raw`.`raw___insta_orders`
),

cln as (
  select * from `clean`.`g1_stg_insta_orders`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage Check
nulls as (
  select
    round(100.0 * countIf(order_id is null) / nullif(count(),0), 2) as null_pct_order_id,
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id,
    round(100.0 * countIf(eval_set is null) / nullif(count(),0), 2) as null_pct_eval_set,
    round(100.0 * countIf(order_number is null) / nullif(count(),0), 2) as null_pct_order_number,
    round(100.0 * countIf(order_dow is null) / nullif(count(),0), 2) as null_pct_order_dow,
    round(100.0 * countIf(order_hour_of_day is null) / nullif(count(),0), 2) as null_pct_order_hour_of_day,
    round(100.0 * countIf(days_since_prior_order is null) / nullif(count(),0), 2) as null_pct_days_since_prior_order
  from cln
),

-- Duplicate Orders
dupes as (
  select
    countIf(cnt > 1) as duplicate_orders
  from (
    select order_id, count() as cnt
    from cln
    group by order_id
  )
),

-- Referential Integrity
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_id
  from `clean`.`g1_stg_insta_orders` o
),

-- Value Range Checks
value_ranges as (
  select
    countIf(order_number < 1) as invalid_order_number,
    countIf(order_hour_of_day < 0 or order_hour_of_day > 23) as invalid_order_hour,
    countIf(days_since_prior_order < 0 or days_since_prior_order > 30) as invalid_days_since_prior_order
  from cln
),

-- Join all metrics
joined as (
    select
        counts.row_count_raw,
        counts.row_count_clean,
        (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
        nulls.*,
        dupes.duplicate_orders,
        referential_integrity.invalid_user_id,
        value_ranges.invalid_order_number,
        value_ranges.invalid_order_hour,
        value_ranges.invalid_days_since_prior_order
    from counts
    cross join nulls
    cross join dupes
    cross join referential_integrity
    cross join value_ranges
)

select * from joined
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m19:00:40.319491 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */


  create view `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Orders
with cln as (
  -- Source cleaned orders data
  select * 
  from `clean`.`g1_stg_insta_orders`
),

users as (
  -- Reference users table for FK validation
  select user_id 
  from `clean`.`g1_stg_insta_users`
),

violations as (
  select
    order_id,
    user_id,
    eval_set,
    order_number,
    order_dow,
    order_hour_of_day,
    days_since_prior_order,

    -- Data Quality Issue Classification
    multiIf(
      order_id is null, 'null_order_id',
      user_id is null, 'null_user_id',
      user_id not in (select user_id from users), 'missing_user_ref',
      order_number < 1, 'invalid_order_number',
      order_dow not in (0,1,2,3,4,5,6), 'invalid_order_dow',
      order_hour_of_day < 0 or order_hour_of_day > 23, 'invalid_order_hour',
      days_since_prior_order < 0, 'negative_days_since_prior_order',
      'ok'
    ) as dq_issue

  from cln
)

-- Return only rows with detected anomalies
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m19:00:40.321742 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */


  create view `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Users

with cln as (
  select * from `clean`.`g1_stg_insta_users`
),
violations as (
  select
    user_id,

    multiIf(
      user_id is null, 'null_user_id',
      user_id <= 0, 'invalid_user_id',
      'ok'
    ) as dq_issue
  from cln
)
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m19:00:40.693343 [debug] [Thread-3  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with 
rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),

cln as (
    select * from `clean`.`g1_stg_insta_users`
),

counts_clean as (
    select count(*) as row_count_clean
    from cln
),

nulls as (
    select round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
    from cln
),

dupes as (
    select countIf(cnt > 1) as duplicate_user_ids
    from (
        select user_id, count() as cnt
        from cln
        group by user_id
    )
),

invalid_users as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),

users_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

-- Join all metrics
select
    r.row_count_raw,
    c.row_count_clean,
    (r.row_count_raw - c.row_count_clean) as dropped_rows,
    n.null_pct_user_id,
    d.duplicate_user_ids,
    iu.invalid_user_in_orders,
    uwo.user_without_orders
from rawDs r
cross join counts_clean c
cross join nulls n
cross join dupes d
cross join invalid_users iu
cross join users_without_orders uwo;
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m19:00:40.699702 [debug] [Thread-3  ]: Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1587 (end of query) (line 69, col 36): ;
      
    )
        
        
                      -- end_of_sql
                      
                      . Expected one of: FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m19:00:40.701691 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3acd220-b385-490c-87b0-6b7ec26b0dd5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x786c62d96520>]}
[0m19:00:40.703713 [error] [Thread-3  ]: 19 of 19 ERROR creating sql view model `mart`.`g1_dq_insta_users_summary` ...... [[31mERROR[0m in 0.68s]
[0m19:00:40.706176 [debug] [Thread-3  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m19:00:40.718634 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.39 seconds
[0m19:00:40.721501 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.39 seconds
[0m19:00:40.760498 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m19:00:40.761835 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m19:00:40.768844 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.44 seconds
[0m19:00:40.777953 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m19:00:41.105239 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m19:00:41.109166 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies` to `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m19:00:41.111534 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m19:00:41.118081 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies` to `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m19:00:41.148994 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.37 seconds
[0m19:00:41.151593 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary` to `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m19:00:41.457123 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m19:00:41.465242 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m19:00:41.474412 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m19:00:41.488907 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m19:00:41.511590 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m19:00:41.528174 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m19:00:41.855740 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.37 seconds
[0m19:00:41.858253 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.37 seconds
[0m19:00:41.861989 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m19:00:41.866386 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m19:00:41.902066 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.37 seconds
[0m19:00:41.905491 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary__dbt_tmp` to `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m19:00:42.195963 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m19:00:42.198605 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m19:00:42.209432 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  ...
[0m19:00:42.219387 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  ...
[0m19:00:42.257030 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m19:00:42.268399 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  ...
[0m19:00:42.597479 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m19:00:42.606479 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m19:00:42.608405 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3acd220-b385-490c-87b0-6b7ec26b0dd5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x786c62a268b0>]}
[0m19:00:42.613118 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3acd220-b385-490c-87b0-6b7ec26b0dd5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x786c62c8c580>]}
[0m19:00:42.615763 [info ] [Thread-1  ]: 16 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_anomalies` ....... [[32mOK[0m in 2.66s]
[0m19:00:42.618936 [info ] [Thread-2  ]: 18 of 19 OK created sql view model `mart`.`g1_dq_insta_users_anomalies` ........ [[32mOK[0m in 2.67s]
[0m19:00:42.622712 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m19:00:42.625114 [debug] [Thread-2  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m19:00:42.650151 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m19:00:42.654621 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3acd220-b385-490c-87b0-6b7ec26b0dd5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x786c62b88af0>]}
[0m19:00:42.656434 [info ] [Thread-4  ]: 17 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_summary` ......... [[32mOK[0m in 2.70s]
[0m19:00:42.658970 [debug] [Thread-4  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m19:00:42.666058 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:00:42.667181 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m19:00:42.668350 [debug] [MainThread]: On list__mart: Close
[0m19:00:42.669670 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m19:00:42.670972 [debug] [MainThread]: On list__clean: Close
[0m19:00:42.672330 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_anomalies' was left open.
[0m19:00:42.673454 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: Close
[0m19:00:42.674260 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_summary' was left open.
[0m19:00:42.675437 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_summary: Close
[0m19:00:42.676325 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_summary' was left open.
[0m19:00:42.677541 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_summary: Close
[0m19:00:42.678284 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_anomalies' was left open.
[0m19:00:42.679205 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_anomalies: Close
[0m19:00:42.682450 [info ] [MainThread]: 
[0m19:00:42.684005 [info ] [MainThread]: Finished running 2 table models, 13 data tests, 4 view models in 0 hours 0 minutes and 23.34 seconds (23.34s).
[0m19:00:42.700552 [debug] [MainThread]: Command end result
[0m19:00:42.796831 [info ] [MainThread]: 
[0m19:00:42.798079 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:00:42.799242 [info ] [MainThread]: 
[0m19:00:42.801502 [error] [MainThread]:   Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1587 (end of query) (line 69, col 36): ;
      
    )
        
        
                      -- end_of_sql
                      
                      . Expected one of: FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m19:00:42.802727 [info ] [MainThread]: 
[0m19:00:42.804246 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m19:00:42.808805 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 25.946365, "process_in_blocks": "0", "process_kernel_time": 2.660068, "process_mem_max_rss": "119728", "process_out_blocks": "11312", "process_user_time": 11.547209}
[0m19:00:42.810872 [debug] [MainThread]: Command `dbt build` failed at 19:00:42.810396 after 25.95 seconds
[0m19:00:42.812785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x786c6926fe20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x786c684991f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x786c640da7f0>]}
[0m19:00:42.814245 [debug] [MainThread]: Flushing usage events
[0m19:04:19.188164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e5ccfdde310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e5ccca35af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e5ccca359a0>]}


============================== 19:04:19.205890 | 4adc2af6-7bae-4c93-be96-34f1fd5d6fb4 ==============================
[0m19:04:19.205890 [info ] [MainThread]: Running with dbt=1.8.9
[0m19:04:19.208962 [debug] [MainThread]: running dbt with arguments {'empty': 'False', 'target_path': 'None', 'debug': 'False', 'cache_selected_only': 'False', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'static_parser': 'True', 'use_colors': 'True', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '.', 'warn_error': 'None', 'introspect': 'True', 'log_cache_events': 'False', 'no_print': 'None', 'fail_fast': 'False', 'write_json': 'True', 'indirect_selection': 'eager', 'quiet': 'False', 'partial_parse': 'True', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_format': 'default', 'use_experimental_parser': 'False', 'log_path': '/workdir/transforms/01_instacart/logs', 'version_check': 'True'}
[0m19:04:19.675662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4adc2af6-7bae-4c93-be96-34f1fd5d6fb4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e5cd25a3880>]}
[0m19:04:19.783827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4adc2af6-7bae-4c93-be96-34f1fd5d6fb4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e5ccc8a4af0>]}
[0m19:04:19.785581 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m19:04:19.994598 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m19:04:20.299544 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:04:20.300901 [debug] [MainThread]: Partial parsing: updated file: ex_01_instacart://models/mart/dq/g1_dq_insta_users_summary.sql
[0m19:04:20.962269 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ex_01_mpg.mart
- models.ex_01_mpg.clean
[0m19:04:20.997981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4adc2af6-7bae-4c93-be96-34f1fd5d6fb4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e5ccad1f130>]}
[0m19:04:21.290124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4adc2af6-7bae-4c93-be96-34f1fd5d6fb4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e5ccac38220>]}
[0m19:04:21.291275 [info ] [MainThread]: Found 6 models, 13 data tests, 1 source, 471 macros
[0m19:04:21.297390 [info ] [MainThread]: 
[0m19:04:21.300102 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m19:04:21.323032 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m19:04:21.325347 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m19:04:21.376964 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:04:21.378262 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:04:25.647865 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m19:04:25.658548 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m19:04:25.936588 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m19:04:25.938646 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m19:04:25.976647 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m19:04:25.979118 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m19:04:26.008031 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m19:04:26.009659 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m19:04:26.294043 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m19:04:26.313054 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:04:26.611222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4adc2af6-7bae-4c93-be96-34f1fd5d6fb4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e5ccf1f6970>]}
[0m19:04:26.613264 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m19:04:26.614626 [info ] [MainThread]: 
[0m19:04:26.641460 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_orders
[0m19:04:26.643305 [info ] [Thread-1  ]: 1 of 19 START sql table model `clean`.`g1_stg_insta_orders` .................... [RUN]
[0m19:04:26.645180 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_instacart.g1_stg_insta_orders'
[0m19:04:26.646711 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_orders
[0m19:04:26.670025 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m19:04:26.671657 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_orders
[0m19:04:26.795625 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m19:04:30.221643 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

            

    
        create table `clean`.`g1_stg_insta_orders__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (order_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
          )
        
        ...
[0m19:04:30.526455 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:04:30.547720 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    select name, type from system.columns where table = 'g1_stg_insta_orders__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m19:04:30.825376 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m19:04:30.835369 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m19:04:30.837509 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_orders__dbt_backup`
        ("order_id", "user_id", "eval_set", "order_number", "order_dow", "order_hour_of_day", "days_since_prior_order")

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
  ...
[0m19:04:33.627712 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 2.79 seconds
[0m19:04:33.638097 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_orders__dbt_backup` AND `clean`.`g1_stg_insta_orders` 
  
  ...
[0m19:04:33.939941 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:04:33.996469 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    drop table if exists `clean`.`g1_stg_insta_orders__dbt_backup` 
  ...
[0m19:04:34.272241 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m19:04:34.281191 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4adc2af6-7bae-4c93-be96-34f1fd5d6fb4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e5cca96c8b0>]}
[0m19:04:34.282812 [info ] [Thread-1  ]: 1 of 19 OK created sql table model `clean`.`g1_stg_insta_orders` ............... [[32mOK[0m in 7.63s]
[0m19:04:34.284629 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_orders
[0m19:04:34.287892 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m19:04:34.289329 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m19:04:34.291954 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m19:04:34.294143 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m19:04:34.290568 [info ] [Thread-3  ]: 2 of 19 START test accepted_values_g1_stg_insta_orders_eval_set__prior__train__test  [RUN]
[0m19:04:34.296526 [info ] [Thread-4  ]: 3 of 19 START test accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [RUN]
[0m19:04:34.299316 [info ] [Thread-2  ]: 4 of 19 START test accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [RUN]
[0m19:04:34.301778 [info ] [Thread-1  ]: 5 of 19 START test not_null_g1_stg_insta_orders_eval_set ....................... [RUN]
[0m19:04:34.304366 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5'
[0m19:04:34.306649 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145'
[0m19:04:34.309316 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1'
[0m19:04:34.312023 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_orders, now test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7)
[0m19:04:34.314217 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m19:04:34.316894 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m19:04:34.318882 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m19:04:34.320333 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m19:04:34.374346 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m19:04:34.377488 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m19:04:34.399956 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m19:04:34.412812 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m19:04:34.415769 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m19:04:34.417760 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m19:04:34.431011 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m19:04:34.432420 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m19:04:34.476864 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m19:04:34.487903 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m19:04:34.505795 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m19:04:34.507561 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m19:04:34.510470 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m19:04:34.512692 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select eval_set
from `clean`.`g1_stg_insta_orders`
where eval_set is null



    ) dbt_internal_test...
[0m19:04:34.515462 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m19:04:34.520078 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m19:04:34.814479 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:04:34.823157 [info ] [Thread-1  ]: 5 of 19 PASS not_null_g1_stg_insta_orders_eval_set ............................. [[32mPASS[0m in 0.51s]
[0m19:04:34.825533 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m19:04:34.827147 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m19:04:34.828610 [info ] [Thread-1  ]: 6 of 19 START test not_null_g1_stg_insta_orders_order_dow ...................... [RUN]
[0m19:04:34.829800 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240)
[0m19:04:34.831054 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m19:04:34.844926 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m19:04:34.847037 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m19:04:34.854832 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m19:04:34.856756 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_dow
from `clean`.`g1_stg_insta_orders`
where order_dow is null



    ) dbt_internal_test...
[0m19:04:35.153393 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:04:35.160669 [info ] [Thread-1  ]: 6 of 19 PASS not_null_g1_stg_insta_orders_order_dow ............................ [[32mPASS[0m in 0.33s]
[0m19:04:35.164492 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m19:04:35.169061 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m19:04:35.172326 [info ] [Thread-1  ]: 7 of 19 START test not_null_g1_stg_insta_orders_order_hour_of_day .............. [RUN]
[0m19:04:35.175103 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576)
[0m19:04:35.179199 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m19:04:35.207562 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m19:04:35.211400 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m19:04:35.223605 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m19:04:35.226949 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_hour_of_day
from `clean`.`g1_stg_insta_orders`
where order_hour_of_day is null



    ) dbt_internal_test...
[0m19:04:35.522623 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m19:04:35.529192 [info ] [Thread-1  ]: 7 of 19 PASS not_null_g1_stg_insta_orders_order_hour_of_day .................... [[32mPASS[0m in 0.35s]
[0m19:04:35.539578 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m19:04:35.542586 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m19:04:35.545652 [info ] [Thread-1  ]: 8 of 19 START test not_null_g1_stg_insta_orders_order_id ....................... [RUN]
[0m19:04:35.548322 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600)
[0m19:04:35.550516 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m19:04:35.570378 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m19:04:35.572700 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m19:04:35.579934 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m19:04:35.582051 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from `clean`.`g1_stg_insta_orders`
where order_id is null



    ) dbt_internal_test...
[0m19:04:35.880297 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:04:35.884966 [info ] [Thread-1  ]: 8 of 19 PASS not_null_g1_stg_insta_orders_order_id ............................. [[32mPASS[0m in 0.34s]
[0m19:04:35.887811 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m19:04:35.889447 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m19:04:35.891392 [info ] [Thread-1  ]: 9 of 19 START test not_null_g1_stg_insta_orders_order_number ................... [RUN]
[0m19:04:35.893045 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619)
[0m19:04:35.894244 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m19:04:35.905480 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m19:04:35.907114 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m19:04:35.914953 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m19:04:35.917379 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_number
from `clean`.`g1_stg_insta_orders`
where order_number is null



    ) dbt_internal_test...
[0m19:04:36.216022 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:04:36.220267 [info ] [Thread-1  ]: 9 of 19 PASS not_null_g1_stg_insta_orders_order_number ......................... [[32mPASS[0m in 0.33s]
[0m19:04:36.222164 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m19:04:36.223570 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m19:04:36.224846 [info ] [Thread-1  ]: 10 of 19 START test not_null_g1_stg_insta_orders_user_id ....................... [RUN]
[0m19:04:36.226189 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619, now test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64)
[0m19:04:36.227355 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m19:04:36.240755 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m19:04:36.243164 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m19:04:36.255661 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m19:04:36.267070 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_orders`
where user_id is null



    ) dbt_internal_test...
[0m19:04:36.590233 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m19:04:36.594563 [info ] [Thread-1  ]: 10 of 19 PASS not_null_g1_stg_insta_orders_user_id ............................. [[32mPASS[0m in 0.37s]
[0m19:04:36.600963 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m19:04:36.602863 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m19:04:36.604285 [info ] [Thread-1  ]: 11 of 19 START test unique_g1_stg_insta_orders_order_id ........................ [RUN]
[0m19:04:36.606374 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64, now test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57)
[0m19:04:36.608592 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m19:04:36.628791 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m19:04:36.630481 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m19:04:36.636846 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m19:04:36.639270 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_orders`
where order_id is not null
group by order_id
having count(*) > 1



    ) dbt_internal_test...
[0m19:04:37.312563 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.67 seconds
[0m19:04:37.316696 [info ] [Thread-1  ]: 11 of 19 PASS unique_g1_stg_insta_orders_order_id .............................. [[32mPASS[0m in 0.71s]
[0m19:04:37.319271 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m19:04:38.056212 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_dow as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_dow

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6'
)



    ) dbt_internal_test...
[0m19:04:38.422424 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        eval_set as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by eval_set

)

select *
from all_values
where value_field not in (
    'prior','train','test'
)



    ) dbt_internal_test...
[0m19:04:38.511038 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.45 seconds
[0m19:04:38.516539 [info ] [Thread-4  ]: 3 of 19 PASS accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [[32mPASS[0m in 4.21s]
[0m19:04:38.519276 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m19:04:38.768011 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_hour_of_day as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_hour_of_day

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23'
)



    ) dbt_internal_test...
[0m19:04:38.805102 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m19:04:38.809758 [info ] [Thread-3  ]: 2 of 19 PASS accepted_values_g1_stg_insta_orders_eval_set__prior__train__test .. [[32mPASS[0m in 4.51s]
[0m19:04:38.811973 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m19:04:39.095601 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m19:04:39.099977 [info ] [Thread-2  ]: 4 of 19 PASS accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [[32mPASS[0m in 4.79s]
[0m19:04:39.102048 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m19:04:39.104756 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_users
[0m19:04:39.107122 [info ] [Thread-1  ]: 12 of 19 START sql table model `clean`.`g1_stg_insta_users` .................... [RUN]
[0m19:04:39.108755 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57, now model.ex_01_instacart.g1_stg_insta_users)
[0m19:04:39.110227 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_users
[0m19:04:39.122212 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_users"
[0m19:04:39.124126 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_users
[0m19:04:39.138256 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

            

    
        create table `clean`.`g1_stg_insta_users__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (user_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
          )
        
        ...
[0m19:04:39.456421 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m19:04:39.463927 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    select name, type from system.columns where table = 'g1_stg_insta_users__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m19:04:39.812374 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m19:04:39.816502 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_users"
[0m19:04:39.818410 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_users__dbt_backup`
        ("user_id")

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
  ...
[0m19:04:40.257138 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.44 seconds
[0m19:04:40.263577 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_users__dbt_backup` AND `clean`.`g1_stg_insta_users` 
  
  ...
[0m19:04:40.618406 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m19:04:40.628958 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    drop table if exists `clean`.`g1_stg_insta_users__dbt_backup` 
  ...
[0m19:04:40.971401 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m19:04:40.975307 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4adc2af6-7bae-4c93-be96-34f1fd5d6fb4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e5cc9785310>]}
[0m19:04:40.977020 [info ] [Thread-1  ]: 12 of 19 OK created sql table model `clean`.`g1_stg_insta_users` ............... [[32mOK[0m in 1.87s]
[0m19:04:40.979120 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_users
[0m19:04:40.982425 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m19:04:40.983881 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m19:04:40.985846 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m19:04:40.987545 [info ] [Thread-3  ]: 13 of 19 START test not_null_g1_stg_insta_users_user_id ........................ [RUN]
[0m19:04:40.990172 [info ] [Thread-2  ]: 14 of 19 START test relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [RUN]
[0m19:04:40.992778 [info ] [Thread-4  ]: 15 of 19 START test unique_g1_stg_insta_users_user_id .......................... [RUN]
[0m19:04:40.994817 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5, now test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935)
[0m19:04:40.996602 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1, now test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726)
[0m19:04:40.998815 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145, now test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f)
[0m19:04:41.000630 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m19:04:41.002822 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m19:04:41.004925 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m19:04:41.018161 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m19:04:41.047188 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m19:04:41.053355 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m19:04:41.056203 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m19:04:41.057445 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m19:04:41.058683 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m19:04:41.065712 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m19:04:41.073092 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m19:04:41.080069 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m19:04:41.083386 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select user_id as from_field
    from `clean`.`g1_stg_insta_orders`
    where user_id is not null
),

parent as (
    select user_id as to_field
    from `clean`.`g1_stg_insta_users`
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null
-- end_of_sql
settings join_use_nulls = 1



    ) dbt_internal_test...
[0m19:04:41.085343 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    user_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_users`
where user_id is not null
group by user_id
having count(*) > 1



    ) dbt_internal_test...
[0m19:04:41.088464 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_users`
where user_id is null



    ) dbt_internal_test...
[0m19:04:41.464032 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.37 seconds
[0m19:04:41.468567 [info ] [Thread-3  ]: 13 of 19 PASS not_null_g1_stg_insta_users_user_id .............................. [[32mPASS[0m in 0.47s]
[0m19:04:41.470342 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m19:04:41.518613 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.43 seconds
[0m19:04:41.522722 [info ] [Thread-4  ]: 15 of 19 PASS unique_g1_stg_insta_users_user_id ................................ [[32mPASS[0m in 0.52s]
[0m19:04:41.524744 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m19:04:41.959950 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.87 seconds
[0m19:04:41.964092 [info ] [Thread-2  ]: 14 of 19 PASS relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [[32mPASS[0m in 0.97s]
[0m19:04:41.966289 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m19:04:41.969155 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m19:04:41.971613 [info ] [Thread-1  ]: 16 of 19 START sql view model `mart`.`g1_dq_insta_orders_anomalies` ............ [RUN]
[0m19:04:41.973609 [debug] [Thread-3  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m19:04:41.976230 [debug] [Thread-4  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m19:04:41.977993 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_users, now model.ex_01_instacart.g1_dq_insta_orders_anomalies)
[0m19:04:41.979451 [debug] [Thread-2  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m19:04:41.981776 [info ] [Thread-3  ]: 17 of 19 START sql view model `mart`.`g1_dq_insta_orders_summary` .............. [RUN]
[0m19:04:41.985361 [info ] [Thread-4  ]: 18 of 19 START sql view model `mart`.`g1_dq_insta_users_anomalies` ............. [RUN]
[0m19:04:41.988468 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m19:04:41.990989 [info ] [Thread-2  ]: 19 of 19 START sql view model `mart`.`g1_dq_insta_users_summary` ............... [RUN]
[0m19:04:41.993680 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935, now model.ex_01_instacart.g1_dq_insta_orders_summary)
[0m19:04:41.995845 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f, now model.ex_01_instacart.g1_dq_insta_users_anomalies)
[0m19:04:42.003440 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726, now model.ex_01_instacart.g1_dq_insta_users_summary)
[0m19:04:42.012165 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m19:04:42.013623 [debug] [Thread-3  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m19:04:42.015206 [debug] [Thread-4  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m19:04:42.017156 [debug] [Thread-2  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_summary
[0m19:04:42.030905 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m19:04:42.032269 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m19:04:42.041573 [debug] [Thread-4  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m19:04:42.053518 [debug] [Thread-2  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m19:04:42.104607 [debug] [Thread-3  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m19:04:42.112444 [debug] [Thread-4  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m19:04:42.147562 [debug] [Thread-2  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_summary
[0m19:04:42.156758 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m19:04:42.162835 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m19:04:42.176323 [debug] [Thread-4  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m19:04:42.184591 [debug] [Thread-2  ]: Creating new relation g1_dq_insta_users_summary
[0m19:04:42.187463 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */


  create view `mart`.`g1_dq_insta_orders_summary__dbt_tmp` 
  
    
    
  as (
    

-- Data Quality Summary for Orders
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  select * from `raw`.`raw___insta_orders`
),

cln as (
  select * from `clean`.`g1_stg_insta_orders`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage Check
nulls as (
  select
    round(100.0 * countIf(order_id is null) / nullif(count(),0), 2) as null_pct_order_id,
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id,
    round(100.0 * countIf(eval_set is null) / nullif(count(),0), 2) as null_pct_eval_set,
    round(100.0 * countIf(order_number is null) / nullif(count(),0), 2) as null_pct_order_number,
    round(100.0 * countIf(order_dow is null) / nullif(count(),0), 2) as null_pct_order_dow,
    round(100.0 * countIf(order_hour_of_day is null) / nullif(count(),0), 2) as null_pct_order_hour_of_day,
    round(100.0 * countIf(days_since_prior_order is null) / nullif(count(),0), 2) as null_pct_days_since_prior_order
  from cln
),

-- Duplicate Orders
dupes as (
  select
    countIf(cnt > 1) as duplicate_orders
  from (
    select order_id, count() as cnt
    from cln
    group by order_id
  )
),

-- Referential Integrity
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_id
  from `clean`.`g1_stg_insta_orders` o
),

-- Value Range Checks
value_ranges as (
  select
    countIf(order_number < 1) as invalid_order_number,
    countIf(order_hour_of_day < 0 or order_hour_of_day > 23) as invalid_order_hour,
    countIf(days_since_prior_order < 0 or days_since_prior_order > 30) as invalid_days_since_prior_order
  from cln
),

-- Join all metrics
joined as (
    select
        counts.row_count_raw,
        counts.row_count_clean,
        (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
        nulls.*,
        dupes.duplicate_orders,
        referential_integrity.invalid_user_id,
        value_ranges.invalid_order_number,
        value_ranges.invalid_order_hour,
        value_ranges.invalid_days_since_prior_order
    from counts
    cross join nulls
    cross join dupes
    cross join referential_integrity
    cross join value_ranges
)

select * from joined
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m19:04:42.189654 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */


  create view `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Orders
with cln as (
  -- Source cleaned orders data
  select * 
  from `clean`.`g1_stg_insta_orders`
),

users as (
  -- Reference users table for FK validation
  select user_id 
  from `clean`.`g1_stg_insta_users`
),

violations as (
  select
    order_id,
    user_id,
    eval_set,
    order_number,
    order_dow,
    order_hour_of_day,
    days_since_prior_order,

    -- Data Quality Issue Classification
    multiIf(
      order_id is null, 'null_order_id',
      user_id is null, 'null_user_id',
      user_id not in (select user_id from users), 'missing_user_ref',
      order_number < 1, 'invalid_order_number',
      order_dow not in (0,1,2,3,4,5,6), 'invalid_order_dow',
      order_hour_of_day < 0 or order_hour_of_day > 23, 'invalid_order_hour',
      days_since_prior_order < 0, 'negative_days_since_prior_order',
      'ok'
    ) as dq_issue

  from cln
)

-- Return only rows with detected anomalies
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m19:04:42.193175 [debug] [Thread-2  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m19:04:42.194623 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */


  create view `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Users

with cln as (
  select * from `clean`.`g1_stg_insta_users`
),
violations as (
  select
    user_id,

    multiIf(
      user_id is null, 'null_user_id',
      user_id <= 0, 'invalid_user_id',
      'ok'
    ) as dq_issue
  from cln
)
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m19:04:42.203456 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users

with 
rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),
cln as (
    select * from `clean`.`g1_stg_insta_users`
),
counts_clean as (
    select count(*) as row_count_clean from cln
),
nulls as (
    select round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
    from cln
),
dupes as (
    select countIf(cnt > 1) as duplicate_user_ids
    from (
        select user_id, count() as cnt
        from cln
        group by user_id
    )
),
invalid_users as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),
users_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

select 
    r.row_count_raw,
    c.row_count_clean,
    (r.row_count_raw - c.row_count_clean) as dropped_rows,
    n.null_pct_user_id,
    d.duplicate_user_ids,
    iu.invalid_user_in_orders,
    uwo.user_without_orders
from (select * from rawDs) r
cross join (select * from counts_clean) c
cross join (select * from nulls) n
cross join (select * from dupes) d
cross join (select * from invalid_users) iu
cross join (select * from users_without_orders) uwo
;
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m19:04:42.527274 [debug] [Thread-2  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users

with 
rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),
cln as (
    select * from `clean`.`g1_stg_insta_users`
),
counts_clean as (
    select count(*) as row_count_clean from cln
),
nulls as (
    select round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
    from cln
),
dupes as (
    select countIf(cnt > 1) as duplicate_user_ids
    from (
        select user_id, count() as cnt
        from cln
        group by user_id
    )
),
invalid_users as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),
users_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

select 
    r.row_count_raw,
    c.row_count_clean,
    (r.row_count_raw - c.row_count_clean) as dropped_rows,
    n.null_pct_user_id,
    d.duplicate_user_ids,
    iu.invalid_user_in_orders,
    uwo.user_without_orders
from (select * from rawDs) r
cross join (select * from counts_clean) c
cross join (select * from nulls) n
cross join (select * from dupes) d
cross join (select * from invalid_users) iu
cross join (select * from users_without_orders) uwo
;
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m19:04:42.532482 [debug] [Thread-2  ]: Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1576 (end of query) (line 61, col 1): ;
      
    )
        
        
                      -- end_of_sql
                      
                      . Expected one of: FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m19:04:42.533597 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4adc2af6-7bae-4c93-be96-34f1fd5d6fb4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e5cca9dfa00>]}
[0m19:04:42.535070 [error] [Thread-2  ]: 19 of 19 ERROR creating sql view model `mart`.`g1_dq_insta_users_summary` ...... [[31mERROR[0m in 0.53s]
[0m19:04:42.536883 [debug] [Thread-2  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m19:04:42.562177 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m19:04:42.564151 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.37 seconds
[0m19:04:42.582922 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m19:04:42.591557 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m19:04:42.610372 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.41 seconds
[0m19:04:42.618514 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m19:04:42.970090 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m19:04:42.972683 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m19:04:42.976348 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies` to `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m19:04:42.978622 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m19:04:42.981761 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary` to `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m19:04:42.987463 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies` to `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m19:04:43.362760 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m19:04:43.365715 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m19:04:43.367993 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m19:04:43.379354 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m19:04:43.388017 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m19:04:43.396435 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m19:04:43.772784 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.37 seconds
[0m19:04:43.775321 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m19:04:43.777512 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m19:04:43.780962 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m19:04:43.784779 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary__dbt_tmp` to `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m19:04:43.788064 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m19:04:44.163517 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.37 seconds
[0m19:04:44.166006 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.37 seconds
[0m19:04:44.173977 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m19:04:44.179651 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  ...
[0m19:04:44.190633 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  ...
[0m19:04:44.207182 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  ...
[0m19:04:44.523947 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m19:04:44.526260 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m19:04:44.530281 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4adc2af6-7bae-4c93-be96-34f1fd5d6fb4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e5cc9798cd0>]}
[0m19:04:44.534951 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4adc2af6-7bae-4c93-be96-34f1fd5d6fb4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e5cc97f92e0>]}
[0m19:04:44.537261 [info ] [Thread-1  ]: 16 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_anomalies` ....... [[32mOK[0m in 2.55s]
[0m19:04:44.540311 [info ] [Thread-3  ]: 17 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_summary` ......... [[32mOK[0m in 2.54s]
[0m19:04:44.542774 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m19:04:44.545005 [debug] [Thread-3  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m19:04:44.577311 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.37 seconds
[0m19:04:44.580651 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4adc2af6-7bae-4c93-be96-34f1fd5d6fb4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e5cc970f430>]}
[0m19:04:44.582665 [info ] [Thread-4  ]: 18 of 19 OK created sql view model `mart`.`g1_dq_insta_users_anomalies` ........ [[32mOK[0m in 2.59s]
[0m19:04:44.585289 [debug] [Thread-4  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m19:04:44.590130 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:04:44.591109 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m19:04:44.592012 [debug] [MainThread]: On list__clean: Close
[0m19:04:44.593197 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m19:04:44.594583 [debug] [MainThread]: On list__mart: Close
[0m19:04:44.595549 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_anomalies' was left open.
[0m19:04:44.596458 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: Close
[0m19:04:44.597191 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_summary' was left open.
[0m19:04:44.598379 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_summary: Close
[0m19:04:44.599550 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_anomalies' was left open.
[0m19:04:44.600883 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_anomalies: Close
[0m19:04:44.601797 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_summary' was left open.
[0m19:04:44.603447 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_summary: Close
[0m19:04:44.606095 [info ] [MainThread]: 
[0m19:04:44.607201 [info ] [MainThread]: Finished running 2 table models, 13 data tests, 4 view models in 0 hours 0 minutes and 23.31 seconds (23.31s).
[0m19:04:44.619775 [debug] [MainThread]: Command end result
[0m19:04:44.706832 [info ] [MainThread]: 
[0m19:04:44.707939 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:04:44.708997 [info ] [MainThread]: 
[0m19:04:44.710951 [error] [MainThread]:   Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1576 (end of query) (line 61, col 1): ;
      
    )
        
        
                      -- end_of_sql
                      
                      . Expected one of: FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m19:04:44.712262 [info ] [MainThread]: 
[0m19:04:44.713623 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m19:04:44.716453 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 25.679773, "process_in_blocks": "0", "process_kernel_time": 1.789367, "process_mem_max_rss": "119584", "process_out_blocks": "11320", "process_user_time": 8.184552}
[0m19:04:44.718520 [debug] [MainThread]: Command `dbt build` failed at 19:04:44.717592 after 25.68 seconds
[0m19:04:44.720386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e5ccfdde310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e5ccdc71640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e5ccc27c220>]}
[0m19:04:44.722949 [debug] [MainThread]: Flushing usage events
[0m19:07:57.532546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71dd84484310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71dd810dea90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71dd810de940>]}


============================== 19:07:57.544867 | ff584c21-1173-40d7-9573-cab18537d50a ==============================
[0m19:07:57.544867 [info ] [MainThread]: Running with dbt=1.8.9
[0m19:07:57.546977 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'target_path': 'None', 'log_path': '/workdir/transforms/01_instacart/logs', 'send_anonymous_usage_stats': 'True', 'empty': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'write_json': 'True', 'no_print': 'None', 'debug': 'False', 'log_format': 'default', 'cache_selected_only': 'False', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'use_colors': 'True', 'profiles_dir': '.', 'introspect': 'True', 'use_experimental_parser': 'False', 'static_parser': 'True', 'warn_error': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True'}
[0m19:07:57.902953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ff584c21-1173-40d7-9573-cab18537d50a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71dd83a1efd0>]}
[0m19:07:58.008407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ff584c21-1173-40d7-9573-cab18537d50a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71dd81bbc430>]}
[0m19:07:58.010063 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m19:07:58.311754 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m19:07:58.668583 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:07:58.669638 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:07:58.690341 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ex_01_mpg.mart
- models.ex_01_mpg.clean
[0m19:07:58.826776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ff584c21-1173-40d7-9573-cab18537d50a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71dd807f5dc0>]}
[0m19:07:59.142205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ff584c21-1173-40d7-9573-cab18537d50a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71dd806f7fa0>]}
[0m19:07:59.143392 [info ] [MainThread]: Found 6 models, 13 data tests, 1 source, 471 macros
[0m19:07:59.150418 [info ] [MainThread]: 
[0m19:07:59.152246 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m19:07:59.173166 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m19:07:59.175468 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m19:07:59.223275 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:07:59.231971 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:08:03.253190 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m19:08:03.287655 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m19:08:03.527332 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m19:08:03.577953 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m19:08:03.584332 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m19:08:03.596908 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m19:08:03.602638 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m19:08:03.608117 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m19:08:03.924520 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m19:08:03.952121 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m19:08:04.366804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ff584c21-1173-40d7-9573-cab18537d50a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71dd8080db20>]}
[0m19:08:04.368079 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m19:08:04.368908 [info ] [MainThread]: 
[0m19:08:04.393503 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_orders
[0m19:08:04.395434 [info ] [Thread-1  ]: 1 of 19 START sql table model `clean`.`g1_stg_insta_orders` .................... [RUN]
[0m19:08:04.397491 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list__mart, now model.ex_01_instacart.g1_stg_insta_orders)
[0m19:08:04.399104 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_orders
[0m19:08:04.423925 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m19:08:04.426224 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_orders
[0m19:08:04.574140 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

            

    
        create table `clean`.`g1_stg_insta_orders__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (order_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
          )
        
        ...
[0m19:08:04.897477 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m19:08:04.916811 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    select name, type from system.columns where table = 'g1_stg_insta_orders__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m19:08:05.251602 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m19:08:05.266275 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m19:08:05.271472 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_orders__dbt_backup`
        ("order_id", "user_id", "eval_set", "order_number", "order_dow", "order_hour_of_day", "days_since_prior_order")

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
  ...
[0m19:08:08.362289 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 3.09 seconds
[0m19:08:08.372320 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_orders__dbt_backup` AND `clean`.`g1_stg_insta_orders` 
  
  ...
[0m19:08:08.717257 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m19:08:08.773444 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    drop table if exists `clean`.`g1_stg_insta_orders__dbt_backup` 
  ...
[0m19:08:09.115170 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m19:08:09.124491 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff584c21-1173-40d7-9573-cab18537d50a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71dd80f2f130>]}
[0m19:08:09.126518 [info ] [Thread-1  ]: 1 of 19 OK created sql table model `clean`.`g1_stg_insta_orders` ............... [[32mOK[0m in 4.73s]
[0m19:08:09.128763 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_orders
[0m19:08:09.132454 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m19:08:09.133926 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m19:08:09.135730 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m19:08:09.137281 [info ] [Thread-3  ]: 2 of 19 START test accepted_values_g1_stg_insta_orders_eval_set__prior__train__test  [RUN]
[0m19:08:09.140419 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m19:08:09.141867 [info ] [Thread-4  ]: 3 of 19 START test accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [RUN]
[0m19:08:09.146545 [info ] [Thread-2  ]: 4 of 19 START test accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [RUN]
[0m19:08:09.149297 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5'
[0m19:08:09.151043 [info ] [Thread-1  ]: 5 of 19 START test not_null_g1_stg_insta_orders_eval_set ....................... [RUN]
[0m19:08:09.153748 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145'
[0m19:08:09.156432 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1'
[0m19:08:09.158715 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m19:08:09.161735 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_orders, now test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7)
[0m19:08:09.164124 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m19:08:09.166658 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m19:08:09.185089 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m19:08:09.210121 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m19:08:09.218398 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m19:08:09.236553 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m19:08:09.254330 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m19:08:09.256964 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m19:08:09.259552 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m19:08:09.272764 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m19:08:09.284821 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m19:08:09.314262 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m19:08:09.327351 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m19:08:09.346559 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m19:08:09.348541 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m19:08:09.351741 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m19:08:09.353300 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m19:08:09.356875 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select eval_set
from `clean`.`g1_stg_insta_orders`
where eval_set is null



    ) dbt_internal_test...
[0m19:08:09.359362 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m19:08:10.174531 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.81 seconds
[0m19:08:10.182698 [info ] [Thread-1  ]: 5 of 19 PASS not_null_g1_stg_insta_orders_eval_set ............................. [[32mPASS[0m in 1.02s]
[0m19:08:10.185366 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m19:08:10.187481 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m19:08:10.188962 [info ] [Thread-1  ]: 6 of 19 START test not_null_g1_stg_insta_orders_order_dow ...................... [RUN]
[0m19:08:10.190673 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240)
[0m19:08:10.193216 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m19:08:10.203406 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m19:08:10.205063 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m19:08:10.211703 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m19:08:10.214190 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_dow
from `clean`.`g1_stg_insta_orders`
where order_dow is null



    ) dbt_internal_test...
[0m19:08:10.648691 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.43 seconds
[0m19:08:10.654130 [info ] [Thread-1  ]: 6 of 19 PASS not_null_g1_stg_insta_orders_order_dow ............................ [[32mPASS[0m in 0.46s]
[0m19:08:10.656622 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m19:08:10.658467 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m19:08:10.659908 [info ] [Thread-1  ]: 7 of 19 START test not_null_g1_stg_insta_orders_order_hour_of_day .............. [RUN]
[0m19:08:10.661305 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576)
[0m19:08:10.662583 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m19:08:10.672490 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m19:08:10.674194 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m19:08:10.683030 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m19:08:10.685062 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_hour_of_day
from `clean`.`g1_stg_insta_orders`
where order_hour_of_day is null



    ) dbt_internal_test...
[0m19:08:11.353341 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.67 seconds
[0m19:08:11.358457 [info ] [Thread-1  ]: 7 of 19 PASS not_null_g1_stg_insta_orders_order_hour_of_day .................... [[32mPASS[0m in 0.70s]
[0m19:08:11.361110 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m19:08:11.362819 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m19:08:11.364118 [info ] [Thread-1  ]: 8 of 19 START test not_null_g1_stg_insta_orders_order_id ....................... [RUN]
[0m19:08:11.365395 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600)
[0m19:08:11.366797 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m19:08:11.379593 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m19:08:11.381296 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m19:08:11.389730 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m19:08:11.392541 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from `clean`.`g1_stg_insta_orders`
where order_id is null



    ) dbt_internal_test...
[0m19:08:11.819263 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.42 seconds
[0m19:08:11.824795 [info ] [Thread-1  ]: 8 of 19 PASS not_null_g1_stg_insta_orders_order_id ............................. [[32mPASS[0m in 0.46s]
[0m19:08:11.827166 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m19:08:11.828897 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m19:08:11.831617 [info ] [Thread-1  ]: 9 of 19 START test not_null_g1_stg_insta_orders_order_number ................... [RUN]
[0m19:08:11.833638 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619)
[0m19:08:11.835537 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m19:08:11.849039 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m19:08:11.850635 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m19:08:11.859809 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m19:08:11.862654 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_number
from `clean`.`g1_stg_insta_orders`
where order_number is null



    ) dbt_internal_test...
[0m19:08:12.246986 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.38 seconds
[0m19:08:12.256274 [info ] [Thread-1  ]: 9 of 19 PASS not_null_g1_stg_insta_orders_order_number ......................... [[32mPASS[0m in 0.42s]
[0m19:08:12.267667 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m19:08:12.270891 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m19:08:12.274069 [info ] [Thread-1  ]: 10 of 19 START test not_null_g1_stg_insta_orders_user_id ....................... [RUN]
[0m19:08:12.276963 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619, now test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64)
[0m19:08:12.279411 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m19:08:12.313352 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m19:08:12.317693 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m19:08:12.345846 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m19:08:12.351117 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_orders`
where user_id is null



    ) dbt_internal_test...
[0m19:08:12.779423 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.42 seconds
[0m19:08:12.789022 [info ] [Thread-1  ]: 10 of 19 PASS not_null_g1_stg_insta_orders_user_id ............................. [[32mPASS[0m in 0.51s]
[0m19:08:12.792510 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m19:08:12.794483 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m19:08:12.796653 [info ] [Thread-1  ]: 11 of 19 START test unique_g1_stg_insta_orders_order_id ........................ [RUN]
[0m19:08:12.799634 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64, now test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57)
[0m19:08:12.801647 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m19:08:12.824619 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m19:08:12.836324 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m19:08:12.845022 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m19:08:12.848354 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_orders`
where order_id is not null
group by order_id
having count(*) > 1



    ) dbt_internal_test...
[0m19:08:13.745275 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.89 seconds
[0m19:08:13.749982 [info ] [Thread-1  ]: 11 of 19 PASS unique_g1_stg_insta_orders_order_id .............................. [[32mPASS[0m in 0.95s]
[0m19:08:13.753019 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m19:08:14.378043 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        eval_set as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by eval_set

)

select *
from all_values
where value_field not in (
    'prior','train','test'
)



    ) dbt_internal_test...
[0m19:08:14.836663 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_hour_of_day as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_hour_of_day

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23'
)



    ) dbt_internal_test...
[0m19:08:14.929036 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.55 seconds
[0m19:08:14.935088 [info ] [Thread-3  ]: 2 of 19 PASS accepted_values_g1_stg_insta_orders_eval_set__prior__train__test .. [[32mPASS[0m in 5.79s]
[0m19:08:14.938820 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m19:08:15.142269 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_dow as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_dow

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6'
)



    ) dbt_internal_test...
[0m19:08:15.194647 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m19:08:15.199021 [info ] [Thread-2  ]: 4 of 19 PASS accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [[32mPASS[0m in 6.04s]
[0m19:08:15.201841 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m19:08:15.486636 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m19:08:15.493363 [info ] [Thread-4  ]: 3 of 19 PASS accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [[32mPASS[0m in 6.34s]
[0m19:08:15.506985 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m19:08:15.511489 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_users
[0m19:08:15.515014 [info ] [Thread-1  ]: 12 of 19 START sql table model `clean`.`g1_stg_insta_users` .................... [RUN]
[0m19:08:15.517949 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57, now model.ex_01_instacart.g1_stg_insta_users)
[0m19:08:15.520196 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_users
[0m19:08:15.543184 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_users"
[0m19:08:15.545345 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_users
[0m19:08:15.562890 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

            

    
        create table `clean`.`g1_stg_insta_users__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (user_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
          )
        
        ...
[0m19:08:15.960603 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.40 seconds
[0m19:08:15.966667 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    select name, type from system.columns where table = 'g1_stg_insta_users__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m19:08:16.292744 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m19:08:16.297084 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_users"
[0m19:08:16.299203 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_users__dbt_backup`
        ("user_id")

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
  ...
[0m19:08:16.800511 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.50 seconds
[0m19:08:16.803807 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_users__dbt_backup` AND `clean`.`g1_stg_insta_users` 
  
  ...
[0m19:08:17.151460 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m19:08:17.160483 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    drop table if exists `clean`.`g1_stg_insta_users__dbt_backup` 
  ...
[0m19:08:17.460826 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:08:17.464605 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff584c21-1173-40d7-9573-cab18537d50a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71dd7f28a1c0>]}
[0m19:08:17.466309 [info ] [Thread-1  ]: 12 of 19 OK created sql table model `clean`.`g1_stg_insta_users` ............... [[32mOK[0m in 1.95s]
[0m19:08:17.468740 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_users
[0m19:08:17.471935 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m19:08:17.473898 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m19:08:17.476064 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m19:08:17.477979 [info ] [Thread-2  ]: 13 of 19 START test not_null_g1_stg_insta_users_user_id ........................ [RUN]
[0m19:08:17.480039 [info ] [Thread-4  ]: 14 of 19 START test relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [RUN]
[0m19:08:17.482659 [info ] [Thread-3  ]: 15 of 19 START test unique_g1_stg_insta_users_user_id .......................... [RUN]
[0m19:08:17.485176 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1, now test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935)
[0m19:08:17.487674 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145, now test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726)
[0m19:08:17.489891 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5, now test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f)
[0m19:08:17.491385 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m19:08:17.494034 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m19:08:17.496055 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m19:08:17.519984 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m19:08:17.543754 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m19:08:17.544910 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m19:08:17.547068 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m19:08:17.554783 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m19:08:17.567387 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m19:08:17.568783 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m19:08:17.560908 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m19:08:17.575657 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m19:08:17.578411 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select user_id as from_field
    from `clean`.`g1_stg_insta_orders`
    where user_id is not null
),

parent as (
    select user_id as to_field
    from `clean`.`g1_stg_insta_users`
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null
-- end_of_sql
settings join_use_nulls = 1



    ) dbt_internal_test...
[0m19:08:17.583360 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_users`
where user_id is null



    ) dbt_internal_test...
[0m19:08:17.587502 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    user_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_users`
where user_id is not null
group by user_id
having count(*) > 1



    ) dbt_internal_test...
[0m19:08:17.891529 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m19:08:17.895768 [info ] [Thread-2  ]: 13 of 19 PASS not_null_g1_stg_insta_users_user_id .............................. [[32mPASS[0m in 0.41s]
[0m19:08:17.897896 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m19:08:17.934799 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.35 seconds
[0m19:08:17.939473 [info ] [Thread-3  ]: 15 of 19 PASS unique_g1_stg_insta_users_user_id ................................ [[32mPASS[0m in 0.45s]
[0m19:08:17.941295 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m19:08:18.235088 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.65 seconds
[0m19:08:18.239777 [info ] [Thread-4  ]: 14 of 19 PASS relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [[32mPASS[0m in 0.75s]
[0m19:08:18.241914 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m19:08:18.244588 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m19:08:18.246018 [debug] [Thread-2  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m19:08:18.248809 [debug] [Thread-3  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m19:08:18.250895 [debug] [Thread-4  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m19:08:18.247393 [info ] [Thread-1  ]: 16 of 19 START sql view model `mart`.`g1_dq_insta_orders_anomalies` ............ [RUN]
[0m19:08:18.253755 [info ] [Thread-2  ]: 17 of 19 START sql view model `mart`.`g1_dq_insta_orders_summary` .............. [RUN]
[0m19:08:18.256241 [info ] [Thread-3  ]: 18 of 19 START sql view model `mart`.`g1_dq_insta_users_anomalies` ............. [RUN]
[0m19:08:18.259701 [info ] [Thread-4  ]: 19 of 19 START sql view model `mart`.`g1_dq_insta_users_summary` ............... [RUN]
[0m19:08:18.261712 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_users, now model.ex_01_instacart.g1_dq_insta_orders_anomalies)
[0m19:08:18.263342 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935, now model.ex_01_instacart.g1_dq_insta_orders_summary)
[0m19:08:18.265330 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f, now model.ex_01_instacart.g1_dq_insta_users_anomalies)
[0m19:08:18.267332 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726, now model.ex_01_instacart.g1_dq_insta_users_summary)
[0m19:08:18.268860 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m19:08:18.270652 [debug] [Thread-2  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m19:08:18.273181 [debug] [Thread-3  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m19:08:18.275271 [debug] [Thread-4  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_summary
[0m19:08:18.285928 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m19:08:18.296769 [debug] [Thread-2  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m19:08:18.306106 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m19:08:18.316872 [debug] [Thread-4  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m19:08:18.321082 [debug] [Thread-2  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m19:08:18.323119 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m19:08:18.325356 [debug] [Thread-3  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m19:08:18.339115 [debug] [Thread-4  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_summary
[0m19:08:18.466114 [debug] [Thread-4  ]: Creating new relation g1_dq_insta_users_summary
[0m19:08:18.521202 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m19:08:18.524127 [debug] [Thread-4  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m19:08:18.535038 [debug] [Thread-2  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m19:08:18.537069 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m19:08:18.540018 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */


  create view `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Orders
with cln as (
  -- Source cleaned orders data
  select * 
  from `clean`.`g1_stg_insta_orders`
),

users as (
  -- Reference users table for FK validation
  select user_id 
  from `clean`.`g1_stg_insta_users`
),

violations as (
  select
    order_id,
    user_id,
    eval_set,
    order_number,
    order_dow,
    order_hour_of_day,
    days_since_prior_order,

    -- Data Quality Issue Classification
    multiIf(
      order_id is null, 'null_order_id',
      user_id is null, 'null_user_id',
      user_id not in (select user_id from users), 'missing_user_ref',
      order_number < 1, 'invalid_order_number',
      order_dow not in (0,1,2,3,4,5,6), 'invalid_order_dow',
      order_hour_of_day < 0 or order_hour_of_day > 23, 'invalid_order_hour',
      days_since_prior_order < 0, 'negative_days_since_prior_order',
      'ok'
    ) as dq_issue

  from cln
)

-- Return only rows with detected anomalies
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m19:08:18.542388 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */


  create view `mart`.`g1_dq_insta_orders_summary__dbt_tmp` 
  
    
    
  as (
    

-- Data Quality Summary for Orders
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  select * from `raw`.`raw___insta_orders`
),

cln as (
  select * from `clean`.`g1_stg_insta_orders`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage Check
nulls as (
  select
    round(100.0 * countIf(order_id is null) / nullif(count(),0), 2) as null_pct_order_id,
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id,
    round(100.0 * countIf(eval_set is null) / nullif(count(),0), 2) as null_pct_eval_set,
    round(100.0 * countIf(order_number is null) / nullif(count(),0), 2) as null_pct_order_number,
    round(100.0 * countIf(order_dow is null) / nullif(count(),0), 2) as null_pct_order_dow,
    round(100.0 * countIf(order_hour_of_day is null) / nullif(count(),0), 2) as null_pct_order_hour_of_day,
    round(100.0 * countIf(days_since_prior_order is null) / nullif(count(),0), 2) as null_pct_days_since_prior_order
  from cln
),

-- Duplicate Orders
dupes as (
  select
    countIf(cnt > 1) as duplicate_orders
  from (
    select order_id, count() as cnt
    from cln
    group by order_id
  )
),

-- Referential Integrity
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_id
  from `clean`.`g1_stg_insta_orders` o
),

-- Value Range Checks
value_ranges as (
  select
    countIf(order_number < 1) as invalid_order_number,
    countIf(order_hour_of_day < 0 or order_hour_of_day > 23) as invalid_order_hour,
    countIf(days_since_prior_order < 0 or days_since_prior_order > 30) as invalid_days_since_prior_order
  from cln
),

-- Join all metrics
joined as (
    select
        counts.row_count_raw,
        counts.row_count_clean,
        (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
        nulls.*,
        dupes.duplicate_orders,
        referential_integrity.invalid_user_id,
        value_ranges.invalid_order_number,
        value_ranges.invalid_order_hour,
        value_ranges.invalid_days_since_prior_order
    from counts
    cross join nulls
    cross join dupes
    cross join referential_integrity
    cross join value_ranges
)

select * from joined
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m19:08:18.544079 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users

with 
rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),
cln as (
    select * from `clean`.`g1_stg_insta_users`
),
counts_clean as (
    select count(*) as row_count_clean from cln
),
nulls as (
    select round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
    from cln
),
dupes as (
    select countIf(cnt > 1) as duplicate_user_ids
    from (
        select user_id, count() as cnt
        from cln
        group by user_id
    )
),
invalid_users as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),
users_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

select 
    r.row_count_raw,
    c.row_count_clean,
    (r.row_count_raw - c.row_count_clean) as dropped_rows,
    n.null_pct_user_id,
    d.duplicate_user_ids,
    iu.invalid_user_in_orders,
    uwo.user_without_orders
from (select * from rawDs) r
cross join (select * from counts_clean) c
cross join (select * from nulls) n
cross join (select * from dupes) d
cross join (select * from invalid_users) iu
cross join (select * from users_without_orders) uwo
;
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m19:08:18.550798 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */


  create view `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Users

with cln as (
  select * from `clean`.`g1_stg_insta_users`
),
violations as (
  select
    user_id,

    multiIf(
      user_id is null, 'null_user_id',
      user_id <= 0, 'invalid_user_id',
      'ok'
    ) as dq_issue
  from cln
)
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m19:08:18.834649 [debug] [Thread-4  ]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users

with 
rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),
cln as (
    select * from `clean`.`g1_stg_insta_users`
),
counts_clean as (
    select count(*) as row_count_clean from cln
),
nulls as (
    select round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
    from cln
),
dupes as (
    select countIf(cnt > 1) as duplicate_user_ids
    from (
        select user_id, count() as cnt
        from cln
        group by user_id
    )
),
invalid_users as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),
users_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

select 
    r.row_count_raw,
    c.row_count_clean,
    (r.row_count_raw - c.row_count_clean) as dropped_rows,
    n.null_pct_user_id,
    d.duplicate_user_ids,
    iu.invalid_user_in_orders,
    uwo.user_without_orders
from (select * from rawDs) r
cross join (select * from counts_clean) c
cross join (select * from nulls) n
cross join (select * from dupes) d
cross join (select * from invalid_users) iu
cross join (select * from users_without_orders) uwo
;
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m19:08:18.842089 [debug] [Thread-4  ]: Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1576 (end of query) (line 61, col 1): ;
      
    )
        
        
                      -- end_of_sql
                      
                      . Expected one of: FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m19:08:18.844773 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:08:18.846035 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff584c21-1173-40d7-9573-cab18537d50a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71dd80433f10>]}
[0m19:08:18.854126 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:08:18.870506 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m19:08:18.872787 [error] [Thread-4  ]: 19 of 19 ERROR creating sql view model `mart`.`g1_dq_insta_users_summary` ...... [[31mERROR[0m in 0.58s]
[0m19:08:18.883048 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m19:08:18.889072 [debug] [Thread-4  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m19:08:18.891454 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m19:08:18.906220 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m19:08:19.164630 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m19:08:19.168277 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies` to `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m19:08:19.176082 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m19:08:19.179328 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies` to `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m19:08:19.212719 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:08:19.217996 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary` to `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m19:08:19.451856 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m19:08:19.454230 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m19:08:19.463284 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m19:08:19.472632 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m19:08:19.562120 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m19:08:19.571056 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m19:08:19.756893 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m19:08:19.760770 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m19:08:19.763301 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m19:08:19.769405 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m19:08:19.857862 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m19:08:19.861033 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary__dbt_tmp` to `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m19:08:20.042641 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m19:08:20.057004 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  ...
[0m19:08:20.064675 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m19:08:20.074761 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  ...
[0m19:08:20.157361 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:08:20.167019 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  ...
[0m19:08:20.369689 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m19:08:20.371653 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:08:20.375739 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff584c21-1173-40d7-9573-cab18537d50a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71dd80437610>]}
[0m19:08:20.380697 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff584c21-1173-40d7-9573-cab18537d50a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71dd7f28da00>]}
[0m19:08:20.383111 [info ] [Thread-1  ]: 16 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_anomalies` ....... [[32mOK[0m in 2.11s]
[0m19:08:20.385709 [info ] [Thread-3  ]: 18 of 19 OK created sql view model `mart`.`g1_dq_insta_users_anomalies` ........ [[32mOK[0m in 2.12s]
[0m19:08:20.388596 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m19:08:20.390874 [debug] [Thread-3  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m19:08:20.481471 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m19:08:20.486392 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff584c21-1173-40d7-9573-cab18537d50a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71dd7f244fa0>]}
[0m19:08:20.488236 [info ] [Thread-2  ]: 17 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_summary` ......... [[32mOK[0m in 2.22s]
[0m19:08:20.490202 [debug] [Thread-2  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m19:08:20.494536 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:08:20.495833 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_anomalies' was left open.
[0m19:08:20.496677 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: Close
[0m19:08:20.497391 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m19:08:20.498405 [debug] [MainThread]: On list__clean: Close
[0m19:08:20.499330 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_anomalies' was left open.
[0m19:08:20.500268 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_anomalies: Close
[0m19:08:20.501289 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_summary' was left open.
[0m19:08:20.502288 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_summary: Close
[0m19:08:20.502939 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_summary' was left open.
[0m19:08:20.503548 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_summary: Close
[0m19:08:20.504906 [info ] [MainThread]: 
[0m19:08:20.506442 [info ] [MainThread]: Finished running 2 table models, 13 data tests, 4 view models in 0 hours 0 minutes and 21.35 seconds (21.35s).
[0m19:08:20.521396 [debug] [MainThread]: Command end result
[0m19:08:20.608629 [info ] [MainThread]: 
[0m19:08:20.609664 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:08:20.610665 [info ] [MainThread]: 
[0m19:08:20.612785 [error] [MainThread]:   Database Error in model g1_dq_insta_users_summary (models/mart/dq/g1_dq_insta_users_summary.sql)
  HTTPDriver for http://54.87.106.52:8123 received ClickHouse error code 62
   Code: 62. DB::Exception: Syntax error: failed at position 1576 (end of query) (line 61, col 1): ;
      
    )
        
        
                      -- end_of_sql
                      
                      . Expected one of: FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 23.12.6.19 (official build))
  compiled code at target/run/ex_01_instacart/models/mart/dq/g1_dq_insta_users_summary.sql
[0m19:08:20.614528 [info ] [MainThread]: 
[0m19:08:20.616089 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m19:08:20.619319 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 23.239336, "process_in_blocks": "0", "process_kernel_time": 1.880296, "process_mem_max_rss": "115668", "process_out_blocks": "10248", "process_user_time": 8.756008}
[0m19:08:20.620855 [debug] [MainThread]: Command `dbt build` failed at 19:08:20.620447 after 23.24 seconds
[0m19:08:20.622362 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71dd84484310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71dd806dfc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x71dd806dfc40>]}
[0m19:08:20.623578 [debug] [MainThread]: Flushing usage events
[0m19:09:35.847417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70ad143c6310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70ad11044430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70ad11044580>]}


============================== 19:09:35.863859 | 7a880e1b-d428-4c33-a852-078dd34c0b94 ==============================
[0m19:09:35.863859 [info ] [MainThread]: Running with dbt=1.8.9
[0m19:09:35.865617 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'invocation_command': 'dbt build --profiles-dir . --target remote', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'partial_parse': 'True', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'log_path': '/workdir/transforms/01_instacart/logs', 'static_parser': 'True', 'warn_error': 'None', 'profiles_dir': '.', 'version_check': 'True', 'empty': 'False', 'debug': 'False', 'write_json': 'True', 'fail_fast': 'False', 'no_print': 'None', 'printer_width': '80', 'log_cache_events': 'False', 'log_format': 'default'}
[0m19:09:36.235672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7a880e1b-d428-4c33-a852-078dd34c0b94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70ad13957b80>]}
[0m19:09:36.359085 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7a880e1b-d428-4c33-a852-078dd34c0b94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70ad122d7250>]}
[0m19:09:36.360951 [info ] [MainThread]: Registered adapter: clickhouse=1.8.6
[0m19:09:36.565264 [debug] [MainThread]: checksum: 265ce5244aff672775eaff93c261d21692ed3f5650f4d9e918c76acdb0e9479a, vars: {}, profile: , target: remote, version: 1.8.9
[0m19:09:36.868834 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:09:36.870178 [debug] [MainThread]: Partial parsing: updated file: ex_01_instacart://models/mart/dq/g1_dq_insta_users_summary.sql
[0m19:09:37.496199 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ex_01_mpg.clean
- models.ex_01_mpg.mart
[0m19:09:37.490741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7a880e1b-d428-4c33-a852-078dd34c0b94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70ad0f334eb0>]}
[0m19:09:37.770553 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7a880e1b-d428-4c33-a852-078dd34c0b94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70ad0f284df0>]}
[0m19:09:37.771639 [info ] [MainThread]: Found 6 models, 13 data tests, 1 source, 471 macros
[0m19:09:37.777720 [info ] [MainThread]: 
[0m19:09:37.779396 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m19:09:37.800114 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m19:09:37.812853 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m19:09:37.842020 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:09:37.855253 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:09:42.262609 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m19:09:42.542626 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m19:09:43.030640 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m19:09:43.298858 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.27 seconds
[0m19:09:43.306478 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__mart)
[0m19:09:43.314208 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__clean)
[0m19:09:43.327116 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__mart: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__mart"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'mart'
      

  ...
[0m19:09:43.332891 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__clean: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "connection_name": "list__clean"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'clean'
      

  ...
[0m19:09:43.621662 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m19:09:43.889761 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.55 seconds
[0m19:09:44.080622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7a880e1b-d428-4c33-a852-078dd34c0b94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70ad14325790>]}
[0m19:09:44.083845 [info ] [MainThread]: Concurrency: 4 threads (target='remote')
[0m19:09:44.085467 [info ] [MainThread]: 
[0m19:09:44.109494 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_orders
[0m19:09:44.111914 [info ] [Thread-1  ]: 1 of 19 START sql table model `clean`.`g1_stg_insta_orders` .................... [RUN]
[0m19:09:44.114304 [debug] [Thread-1  ]: Acquiring new clickhouse connection 'model.ex_01_instacart.g1_stg_insta_orders'
[0m19:09:44.115719 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_orders
[0m19:09:44.139940 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m19:09:44.141557 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_orders
[0m19:09:44.256198 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m19:09:47.698925 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

            

    
        create table `clean`.`g1_stg_insta_orders__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (order_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
          )
        
        ...
[0m19:09:48.000183 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:09:48.022805 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    select name, type from system.columns where table = 'g1_stg_insta_orders__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m19:09:48.319722 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:09:48.328509 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_orders"
[0m19:09:48.330172 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_orders__dbt_backup`
        ("order_id", "user_id", "eval_set", "order_number", "order_dow", "order_hour_of_day", "days_since_prior_order")

-- Clean layer: Orders table
-- Purpose: Standardize data types and preserve NaN values for numeric continuity.
-- Primary Key: order_id
-- Foreign Key: user_id → g1_stg_insta_users.user_id

select
  cast(order_id as Int64)               as order_id,
  cast(user_id as Int64)                as user_id,
  cast(eval_set as String)              as eval_set,
  cast(order_number as Int64)           as order_number,
  cast(order_dow as Int64)              as order_dow,
  cast(order_hour_of_day as Int64)      as order_hour_of_day,
  cast(days_since_prior_order as Float64) as days_since_prior_order
from `raw`.`raw___insta_orders`
  ...
[0m19:09:51.154599 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 2.82 seconds
[0m19:09:51.166948 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_orders__dbt_backup` AND `clean`.`g1_stg_insta_orders` 
  
  ...
[0m19:09:51.471650 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:09:51.526067 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_orders: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_orders"} */

    drop table if exists `clean`.`g1_stg_insta_orders__dbt_backup` 
  ...
[0m19:09:51.850405 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m19:09:51.866608 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a880e1b-d428-4c33-a852-078dd34c0b94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70ad0e63ba00>]}
[0m19:09:51.869129 [info ] [Thread-1  ]: 1 of 19 OK created sql table model `clean`.`g1_stg_insta_orders` ............... [[32mOK[0m in 7.75s]
[0m19:09:51.872561 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_orders
[0m19:09:51.877279 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m19:09:51.879870 [info ] [Thread-3  ]: 2 of 19 START test accepted_values_g1_stg_insta_orders_eval_set__prior__train__test  [RUN]
[0m19:09:51.883530 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m19:09:51.886339 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m19:09:51.889208 [debug] [Thread-3  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5'
[0m19:09:51.893233 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m19:09:51.896359 [info ] [Thread-4  ]: 3 of 19 START test accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [RUN]
[0m19:09:51.899633 [info ] [Thread-2  ]: 4 of 19 START test accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [RUN]
[0m19:09:51.902797 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m19:09:51.906591 [info ] [Thread-1  ]: 5 of 19 START test not_null_g1_stg_insta_orders_eval_set ....................... [RUN]
[0m19:09:51.910249 [debug] [Thread-4  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145'
[0m19:09:51.920841 [debug] [Thread-2  ]: Acquiring new clickhouse connection 'test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1'
[0m19:09:51.935151 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_orders, now test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7)
[0m19:09:51.947418 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m19:09:51.950213 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m19:09:51.952953 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m19:09:52.081043 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m19:09:52.084414 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m19:09:52.085613 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m19:09:52.103797 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m19:09:52.107022 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m19:09:52.108999 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m19:09:52.110422 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m19:09:52.117468 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m19:09:52.161351 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"
[0m19:09:52.180257 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"
[0m19:09:52.196440 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"
[0m19:09:52.197327 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"
[0m19:09:52.200137 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m19:09:52.203357 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m19:09:52.206378 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m19:09:52.208897 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select eval_set
from `clean`.`g1_stg_insta_orders`
where eval_set is null



    ) dbt_internal_test...
[0m19:09:52.861868 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.65 seconds
[0m19:09:52.870446 [info ] [Thread-1  ]: 5 of 19 PASS not_null_g1_stg_insta_orders_eval_set ............................. [[32mPASS[0m in 0.94s]
[0m19:09:52.872630 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7
[0m19:09:52.874106 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m19:09:52.875566 [info ] [Thread-1  ]: 6 of 19 START test not_null_g1_stg_insta_orders_order_dow ...................... [RUN]
[0m19:09:52.876850 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_eval_set.5b1e98eee7, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240)
[0m19:09:52.877984 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m19:09:52.890952 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m19:09:52.893511 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m19:09:52.901266 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"
[0m19:09:52.903385 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_dow
from `clean`.`g1_stg_insta_orders`
where order_dow is null



    ) dbt_internal_test...
[0m19:09:53.232969 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m19:09:53.237667 [info ] [Thread-1  ]: 6 of 19 PASS not_null_g1_stg_insta_orders_order_dow ............................ [[32mPASS[0m in 0.36s]
[0m19:09:53.239805 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240
[0m19:09:53.241375 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m19:09:53.242770 [info ] [Thread-1  ]: 7 of 19 START test not_null_g1_stg_insta_orders_order_hour_of_day .............. [RUN]
[0m19:09:53.244015 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_dow.9c58aec240, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576)
[0m19:09:53.245322 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m19:09:53.257345 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m19:09:53.259079 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m19:09:53.269038 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"
[0m19:09:53.271310 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_hour_of_day
from `clean`.`g1_stg_insta_orders`
where order_hour_of_day is null



    ) dbt_internal_test...
[0m19:09:53.567409 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m19:09:53.571614 [info ] [Thread-1  ]: 7 of 19 PASS not_null_g1_stg_insta_orders_order_hour_of_day .................... [[32mPASS[0m in 0.33s]
[0m19:09:53.573522 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576
[0m19:09:53.575230 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m19:09:53.576979 [info ] [Thread-1  ]: 8 of 19 START test not_null_g1_stg_insta_orders_order_id ....................... [RUN]
[0m19:09:53.579234 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_hour_of_day.a24ef46576, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600)
[0m19:09:53.580748 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m19:09:53.591559 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m19:09:53.593108 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m19:09:53.598978 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"
[0m19:09:53.600728 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from `clean`.`g1_stg_insta_orders`
where order_id is null



    ) dbt_internal_test...
[0m19:09:53.888622 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m19:09:53.895495 [info ] [Thread-1  ]: 8 of 19 PASS not_null_g1_stg_insta_orders_order_id ............................. [[32mPASS[0m in 0.32s]
[0m19:09:53.898110 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600
[0m19:09:53.899563 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m19:09:53.900990 [info ] [Thread-1  ]: 9 of 19 START test not_null_g1_stg_insta_orders_order_number ................... [RUN]
[0m19:09:53.902390 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_id.db2c429600, now test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619)
[0m19:09:53.903684 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m19:09:53.914561 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m19:09:53.916286 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m19:09:53.923903 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"
[0m19:09:53.925989 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_number
from `clean`.`g1_stg_insta_orders`
where order_number is null



    ) dbt_internal_test...
[0m19:09:54.242782 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m19:09:54.247690 [info ] [Thread-1  ]: 9 of 19 PASS not_null_g1_stg_insta_orders_order_number ......................... [[32mPASS[0m in 0.35s]
[0m19:09:54.250134 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619
[0m19:09:54.251825 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m19:09:54.253797 [info ] [Thread-1  ]: 10 of 19 START test not_null_g1_stg_insta_orders_user_id ....................... [RUN]
[0m19:09:54.255792 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_order_number.f87f132619, now test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64)
[0m19:09:54.257213 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m19:09:54.269136 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m19:09:54.272004 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m19:09:54.282021 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"
[0m19:09:54.284373 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_orders`
where user_id is null



    ) dbt_internal_test...
[0m19:09:54.602703 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m19:09:54.609360 [info ] [Thread-1  ]: 10 of 19 PASS not_null_g1_stg_insta_orders_user_id ............................. [[32mPASS[0m in 0.35s]
[0m19:09:54.613253 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64
[0m19:09:54.615397 [debug] [Thread-1  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m19:09:54.617514 [info ] [Thread-1  ]: 11 of 19 START test unique_g1_stg_insta_orders_order_id ........................ [RUN]
[0m19:09:54.619834 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_orders_user_id.ce8c0e7d64, now test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57)
[0m19:09:54.622117 [debug] [Thread-1  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m19:09:54.643675 [debug] [Thread-1  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m19:09:54.654279 [debug] [Thread-1  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m19:09:54.662552 [debug] [Thread-1  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"
[0m19:09:54.665267 [debug] [Thread-1  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_orders`
where order_id is not null
group by order_id
having count(*) > 1



    ) dbt_internal_test...
[0m19:09:55.226531 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.56 seconds
[0m19:09:55.230805 [info ] [Thread-1  ]: 11 of 19 PASS unique_g1_stg_insta_orders_order_id .............................. [[32mPASS[0m in 0.61s]
[0m19:09:55.232654 [debug] [Thread-1  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57
[0m19:09:55.898369 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_hour_of_day as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_hour_of_day

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23'
)



    ) dbt_internal_test...
[0m19:09:55.900686 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        order_dow as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by order_dow

)

select *
from all_values
where value_field not in (
    '0','1','2','3','4','5','6'
)



    ) dbt_internal_test...
[0m19:09:56.234872 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        eval_set as value_field,
        count(*) as n_records

    from `clean`.`g1_stg_insta_orders`
    group by eval_set

)

select *
from all_values
where value_field not in (
    'prior','train','test'
)



    ) dbt_internal_test...
[0m19:09:56.300231 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.40 seconds
[0m19:09:56.302604 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.40 seconds
[0m19:09:56.307996 [info ] [Thread-4  ]: 3 of 19 PASS accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6  [[32mPASS[0m in 4.40s]
[0m19:09:56.312866 [info ] [Thread-2  ]: 4 of 19 PASS accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23  [[32mPASS[0m in 4.39s]
[0m19:09:56.315566 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145
[0m19:09:56.317954 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1
[0m19:09:56.575166 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m19:09:56.579457 [info ] [Thread-3  ]: 2 of 19 PASS accepted_values_g1_stg_insta_orders_eval_set__prior__train__test .. [[32mPASS[0m in 4.69s]
[0m19:09:56.581387 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5
[0m19:09:56.583545 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_stg_insta_users
[0m19:09:56.586381 [info ] [Thread-1  ]: 12 of 19 START sql table model `clean`.`g1_stg_insta_users` .................... [RUN]
[0m19:09:56.588077 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_orders_order_id.fad103cb57, now model.ex_01_instacart.g1_stg_insta_users)
[0m19:09:56.589488 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_stg_insta_users
[0m19:09:56.598617 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_stg_insta_users"
[0m19:09:56.600462 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_stg_insta_users
[0m19:09:56.611868 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

            

    
        create table `clean`.`g1_stg_insta_users__dbt_backup`
        
  
        
  engine = MergeTree()
        order by (user_id)
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
          )
        
        ...
[0m19:09:56.921368 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m19:09:56.928099 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    select name, type from system.columns where table = 'g1_stg_insta_users__dbt_backup'
    
      and database = 'clean'
    
    order by position
  ...
[0m19:09:57.215635 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m19:09:57.219429 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_stg_insta_users"
[0m19:09:57.221240 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

  
    
    
    
        
         


        insert into `clean`.`g1_stg_insta_users__dbt_backup`
        ("user_id")

-- Clean layer: Users table  
-- Purpose: Normalize and standardize distinct users extracted from orders.  
-- Primary Key: user_id  
-- Foreign Key: None (referenced by orders.user_id)

select distinct
  cast(user_id as Int64) as user_id
from `clean`.`g1_stg_insta_orders`
  ...
[0m19:09:57.631870 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.41 seconds
[0m19:09:57.635059 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */
EXCHANGE TABLES `clean`.`g1_stg_insta_users__dbt_backup` AND `clean`.`g1_stg_insta_users` 
  
  ...
[0m19:09:57.920434 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m19:09:57.935211 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_stg_insta_users: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_stg_insta_users"} */

    drop table if exists `clean`.`g1_stg_insta_users__dbt_backup` 
  ...
[0m19:09:58.244500 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m19:09:58.248372 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a880e1b-d428-4c33-a852-078dd34c0b94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70ad0dce1be0>]}
[0m19:09:58.250116 [info ] [Thread-1  ]: 12 of 19 OK created sql table model `clean`.`g1_stg_insta_users` ............... [[32mOK[0m in 1.66s]
[0m19:09:58.252110 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_stg_insta_users
[0m19:09:58.254998 [debug] [Thread-2  ]: Began running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m19:09:58.256538 [debug] [Thread-3  ]: Began running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m19:09:58.258049 [debug] [Thread-4  ]: Began running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m19:09:58.259760 [info ] [Thread-2  ]: 13 of 19 START test not_null_g1_stg_insta_users_user_id ........................ [RUN]
[0m19:09:58.262317 [info ] [Thread-3  ]: 14 of 19 START test relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [RUN]
[0m19:09:58.264638 [info ] [Thread-4  ]: 15 of 19 START test unique_g1_stg_insta_users_user_id .......................... [RUN]
[0m19:09:58.267006 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_hour_of_day__0__1__2__3__4__5__6__7__8__9__10__11__12__13__14__15__16__17__18__19__20__21__22__23.b52ff00dc1, now test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935)
[0m19:09:58.268923 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_eval_set__prior__train__test.ace370e4f5, now test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726)
[0m19:09:58.270914 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.accepted_values_g1_stg_insta_orders_order_dow__0__1__2__3__4__5__6.ec9bf99145, now test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f)
[0m19:09:58.272491 [debug] [Thread-2  ]: Began compiling node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m19:09:58.274114 [debug] [Thread-3  ]: Began compiling node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m19:09:58.275551 [debug] [Thread-4  ]: Began compiling node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m19:09:58.294975 [debug] [Thread-2  ]: Writing injected SQL for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m19:09:58.317488 [debug] [Thread-3  ]: Writing injected SQL for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m19:09:58.322609 [debug] [Thread-4  ]: Writing injected SQL for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m19:09:58.326082 [debug] [Thread-2  ]: Began executing node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m19:09:58.328648 [debug] [Thread-3  ]: Began executing node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m19:09:58.335846 [debug] [Thread-4  ]: Began executing node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m19:09:58.337522 [debug] [Thread-2  ]: Writing runtime sql for node "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"
[0m19:09:58.345960 [debug] [Thread-3  ]: Writing runtime sql for node "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"
[0m19:09:58.353044 [debug] [Thread-4  ]: Writing runtime sql for node "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"
[0m19:09:58.356648 [debug] [Thread-2  ]: dbt_clickhouse adapter: On test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select user_id
from `clean`.`g1_stg_insta_users`
where user_id is null



    ) dbt_internal_test...
[0m19:09:58.358444 [debug] [Thread-3  ]: dbt_clickhouse adapter: On test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select user_id as from_field
    from `clean`.`g1_stg_insta_orders`
    where user_id is not null
),

parent as (
    select user_id as to_field
    from `clean`.`g1_stg_insta_users`
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null
-- end_of_sql
settings join_use_nulls = 1



    ) dbt_internal_test...
[0m19:09:58.362336 [debug] [Thread-4  ]: dbt_clickhouse adapter: On test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    user_id as unique_field,
    count(*) as n_records

from `clean`.`g1_stg_insta_users`
where user_id is not null
group by user_id
having count(*) > 1



    ) dbt_internal_test...
[0m19:09:58.663777 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:09:58.668412 [info ] [Thread-2  ]: 13 of 19 PASS not_null_g1_stg_insta_users_user_id .............................. [[32mPASS[0m in 0.40s]
[0m19:09:58.670395 [debug] [Thread-2  ]: Finished running node test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935
[0m19:09:58.724346 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.36 seconds
[0m19:09:58.728588 [info ] [Thread-4  ]: 15 of 19 PASS unique_g1_stg_insta_users_user_id ................................ [[32mPASS[0m in 0.46s]
[0m19:09:58.730683 [debug] [Thread-4  ]: Finished running node test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f
[0m19:09:59.135903 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.77 seconds
[0m19:09:59.140485 [info ] [Thread-3  ]: 14 of 19 PASS relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_  [[32mPASS[0m in 0.87s]
[0m19:09:59.143521 [debug] [Thread-3  ]: Finished running node test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726
[0m19:09:59.146814 [debug] [Thread-1  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m19:09:59.148149 [debug] [Thread-2  ]: Began running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m19:09:59.151446 [debug] [Thread-4  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m19:09:59.153768 [debug] [Thread-3  ]: Began running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m19:09:59.149715 [info ] [Thread-1  ]: 16 of 19 START sql view model `mart`.`g1_dq_insta_orders_anomalies` ............ [RUN]
[0m19:09:59.155869 [info ] [Thread-2  ]: 17 of 19 START sql view model `mart`.`g1_dq_insta_orders_summary` .............. [RUN]
[0m19:09:59.158507 [info ] [Thread-4  ]: 18 of 19 START sql view model `mart`.`g1_dq_insta_users_anomalies` ............. [RUN]
[0m19:09:59.161803 [info ] [Thread-3  ]: 19 of 19 START sql view model `mart`.`g1_dq_insta_users_summary` ............... [RUN]
[0m19:09:59.164650 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.ex_01_instacart.g1_stg_insta_users, now model.ex_01_instacart.g1_dq_insta_orders_anomalies)
[0m19:09:59.166770 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.not_null_g1_stg_insta_users_user_id.34caa3f935, now model.ex_01_instacart.g1_dq_insta_orders_summary)
[0m19:09:59.168744 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.unique_g1_stg_insta_users_user_id.2fd469966f, now model.ex_01_instacart.g1_dq_insta_users_anomalies)
[0m19:09:59.170686 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly test.ex_01_instacart.relationships_g1_stg_insta_orders_user_id__user_id__ref_g1_stg_insta_users_.e8cd2e2726, now model.ex_01_instacart.g1_dq_insta_users_summary)
[0m19:09:59.172852 [debug] [Thread-1  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m19:09:59.175011 [debug] [Thread-2  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m19:09:59.177675 [debug] [Thread-4  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m19:09:59.179753 [debug] [Thread-3  ]: Began compiling node model.ex_01_instacart.g1_dq_insta_users_summary
[0m19:09:59.192353 [debug] [Thread-1  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m19:09:59.204823 [debug] [Thread-2  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m19:09:59.212959 [debug] [Thread-4  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m19:09:59.224406 [debug] [Thread-3  ]: Writing injected SQL for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m19:09:59.227632 [debug] [Thread-1  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m19:09:59.230034 [debug] [Thread-4  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m19:09:59.236914 [debug] [Thread-2  ]: Began executing node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m19:09:59.244476 [debug] [Thread-3  ]: Began executing node model.ex_01_instacart.g1_dq_insta_users_summary
[0m19:09:59.384876 [debug] [Thread-3  ]: Creating new relation g1_dq_insta_users_summary
[0m19:09:59.387600 [debug] [Thread-1  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_anomalies"
[0m19:09:59.398521 [debug] [Thread-3  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_summary"
[0m19:09:59.408077 [debug] [Thread-4  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_users_anomalies"
[0m19:09:59.409229 [debug] [Thread-2  ]: Writing runtime sql for node "model.ex_01_instacart.g1_dq_insta_orders_summary"
[0m19:09:59.413227 [debug] [Thread-3  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_summary"} */


  create view `mart`.`g1_dq_insta_users_summary` 
  
    
    
  as (
    

-- Data Quality Summary for Users

with 
rawDs as (
    select count(distinct user_id) as row_count_raw
    from `raw`.`raw___insta_orders`
),
cln as (
    select * from `clean`.`g1_stg_insta_users`
),
counts_clean as (
    select count(*) as row_count_clean from cln
),
nulls as (
    select round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id
    from cln
),
dupes as (
    select countIf(cnt > 1) as duplicate_user_ids
    from (
        select user_id, count() as cnt
        from cln
        group by user_id
    )
),
invalid_users as (
    select count(*) as invalid_user_in_orders
    from `clean`.`g1_stg_insta_orders`
    where user_id not in (select user_id from cln)
),
users_without_orders as (
    select count(*) as user_without_orders
    from cln
    where user_id not in (select user_id from `clean`.`g1_stg_insta_orders`)
)

select 
    r.row_count_raw,
    c.row_count_clean,
    (r.row_count_raw - c.row_count_clean) as dropped_rows,
    n.null_pct_user_id,
    d.duplicate_user_ids,
    iu.invalid_user_in_orders,
    uwo.user_without_orders
from (select * from rawDs) r
cross join (select * from counts_clean) c
cross join (select * from nulls) n
cross join (select * from dupes) d
cross join (select * from invalid_users) iu
cross join (select * from users_without_orders) uwo
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m19:09:59.416138 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */


  create view `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Users

with cln as (
  select * from `clean`.`g1_stg_insta_users`
),
violations as (
  select
    user_id,

    multiIf(
      user_id is null, 'null_user_id',
      user_id <= 0, 'invalid_user_id',
      'ok'
    ) as dq_issue
  from cln
)
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m19:09:59.419672 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */


  create view `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` 
  
    
    
  as (
    

-- Row-level Data Quality Violations for Orders
with cln as (
  -- Source cleaned orders data
  select * 
  from `clean`.`g1_stg_insta_orders`
),

users as (
  -- Reference users table for FK validation
  select user_id 
  from `clean`.`g1_stg_insta_users`
),

violations as (
  select
    order_id,
    user_id,
    eval_set,
    order_number,
    order_dow,
    order_hour_of_day,
    days_since_prior_order,

    -- Data Quality Issue Classification
    multiIf(
      order_id is null, 'null_order_id',
      user_id is null, 'null_user_id',
      user_id not in (select user_id from users), 'missing_user_ref',
      order_number < 1, 'invalid_order_number',
      order_dow not in (0,1,2,3,4,5,6), 'invalid_order_dow',
      order_hour_of_day < 0 or order_hour_of_day > 23, 'invalid_order_hour',
      days_since_prior_order < 0, 'negative_days_since_prior_order',
      'ok'
    ) as dq_issue

  from cln
)

-- Return only rows with detected anomalies
select *
from violations
where dq_issue != 'ok'
limit 100
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m19:09:59.422120 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */


  create view `mart`.`g1_dq_insta_orders_summary__dbt_tmp` 
  
    
    
  as (
    

-- Data Quality Summary for Orders
-- Tracks: row counts, null %, duplicates, referential integrity, value ranges

with rawDs as (
  select * from `raw`.`raw___insta_orders`
),

cln as (
  select * from `clean`.`g1_stg_insta_orders`
),

-- Row Count Comparison
counts as (
  select
    (select count() from rawDs)  as row_count_raw,
    (select count() from cln)    as row_count_clean
),

-- Null Percentage Check
nulls as (
  select
    round(100.0 * countIf(order_id is null) / nullif(count(),0), 2) as null_pct_order_id,
    round(100.0 * countIf(user_id is null) / nullif(count(),0), 2) as null_pct_user_id,
    round(100.0 * countIf(eval_set is null) / nullif(count(),0), 2) as null_pct_eval_set,
    round(100.0 * countIf(order_number is null) / nullif(count(),0), 2) as null_pct_order_number,
    round(100.0 * countIf(order_dow is null) / nullif(count(),0), 2) as null_pct_order_dow,
    round(100.0 * countIf(order_hour_of_day is null) / nullif(count(),0), 2) as null_pct_order_hour_of_day,
    round(100.0 * countIf(days_since_prior_order is null) / nullif(count(),0), 2) as null_pct_days_since_prior_order
  from cln
),

-- Duplicate Orders
dupes as (
  select
    countIf(cnt > 1) as duplicate_orders
  from (
    select order_id, count() as cnt
    from cln
    group by order_id
  )
),

-- Referential Integrity
referential_integrity as (
  select
    countIf(o.user_id not in (select distinct user_id from `clean`.`g1_stg_insta_users`)) as invalid_user_id
  from `clean`.`g1_stg_insta_orders` o
),

-- Value Range Checks
value_ranges as (
  select
    countIf(order_number < 1) as invalid_order_number,
    countIf(order_hour_of_day < 0 or order_hour_of_day > 23) as invalid_order_hour,
    countIf(days_since_prior_order < 0 or days_since_prior_order > 30) as invalid_days_since_prior_order
  from cln
),

-- Join all metrics
joined as (
    select
        counts.row_count_raw,
        counts.row_count_clean,
        (counts.row_count_raw - counts.row_count_clean) as dropped_rows,
        nulls.*,
        dupes.duplicate_orders,
        referential_integrity.invalid_user_id,
        value_ranges.invalid_order_number,
        value_ranges.invalid_order_hour,
        value_ranges.invalid_days_since_prior_order
    from counts
    cross join nulls
    cross join dupes
    cross join referential_integrity
    cross join value_ranges
)

select * from joined
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m19:09:59.746885 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m19:09:59.749270 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.32 seconds
[0m19:09:59.762592 [debug] [Thread-3  ]: dbt_clickhouse adapter: SQL status: OK in 0.34 seconds
[0m19:09:59.776058 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m19:09:59.779785 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m19:09:59.785629 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a880e1b-d428-4c33-a852-078dd34c0b94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70ad0dd7a370>]}
[0m19:09:59.791925 [info ] [Thread-3  ]: 19 of 19 OK created sql view model `mart`.`g1_dq_insta_users_summary` .......... [[32mOK[0m in 0.62s]
[0m19:09:59.793856 [debug] [Thread-3  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_summary
[0m19:09:59.801276 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.37 seconds
[0m19:09:59.810785 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m19:10:00.097097 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m19:10:00.100050 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m19:10:00.102784 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m19:10:00.106574 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies` to `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  
  ...
[0m19:10:00.109961 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies` to `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  
  ...
[0m19:10:00.114093 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary` to `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  
  ...
[0m19:10:00.400594 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m19:10:00.402929 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m19:10:00.414235 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m19:10:00.424528 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m19:10:00.451496 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.33 seconds
[0m19:10:00.460947 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m19:10:00.711262 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m19:10:00.714267 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    rename table `mart`.`g1_dq_insta_orders_summary__dbt_tmp` to `mart`.`g1_dq_insta_orders_summary` 
  
  ...
[0m19:10:00.716334 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.29 seconds
[0m19:10:00.721666 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    rename table `mart`.`g1_dq_insta_orders_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_orders_anomalies` 
  
  ...
[0m19:10:00.758073 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:10:00.761258 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    rename table `mart`.`g1_dq_insta_users_anomalies__dbt_tmp` to `mart`.`g1_dq_insta_users_anomalies` 
  
  ...
[0m19:10:01.027762 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m19:10:01.030344 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m19:10:01.043383 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.28 seconds
[0m19:10:01.046800 [debug] [Thread-2  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_summary: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_summary"} */

    drop table if exists `mart`.`g1_dq_insta_orders_summary__dbt_backup` 
  ...
[0m19:10:01.057898 [debug] [Thread-1  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_orders_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_orders_anomalies__dbt_backup` 
  ...
[0m19:10:01.068083 [debug] [Thread-4  ]: dbt_clickhouse adapter: On model.ex_01_instacart.g1_dq_insta_users_anomalies: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "clickhouse_ftw", "target_name": "remote", "node_id": "model.ex_01_instacart.g1_dq_insta_users_anomalies"} */

    drop table if exists `mart`.`g1_dq_insta_users_anomalies__dbt_backup` 
  ...
[0m19:10:01.374205 [debug] [Thread-2  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:10:01.376938 [debug] [Thread-1  ]: dbt_clickhouse adapter: SQL status: OK in 0.31 seconds
[0m19:10:01.379396 [debug] [Thread-4  ]: dbt_clickhouse adapter: SQL status: OK in 0.30 seconds
[0m19:10:01.384276 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a880e1b-d428-4c33-a852-078dd34c0b94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70ad0eed4220>]}
[0m19:10:01.389533 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a880e1b-d428-4c33-a852-078dd34c0b94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70ad0dd000d0>]}
[0m19:10:01.394508 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a880e1b-d428-4c33-a852-078dd34c0b94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70ad0dd73b20>]}
[0m19:10:01.396692 [info ] [Thread-2  ]: 17 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_summary` ......... [[32mOK[0m in 2.22s]
[0m19:10:01.405232 [debug] [Thread-2  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_summary
[0m19:10:01.398939 [info ] [Thread-1  ]: 16 of 19 OK created sql view model `mart`.`g1_dq_insta_orders_anomalies` ....... [[32mOK[0m in 2.23s]
[0m19:10:01.402238 [info ] [Thread-4  ]: 18 of 19 OK created sql view model `mart`.`g1_dq_insta_users_anomalies` ........ [[32mOK[0m in 2.23s]
[0m19:10:01.410492 [debug] [Thread-1  ]: Finished running node model.ex_01_instacart.g1_dq_insta_orders_anomalies
[0m19:10:01.414696 [debug] [Thread-4  ]: Finished running node model.ex_01_instacart.g1_dq_insta_users_anomalies
[0m19:10:01.421313 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:10:01.422628 [debug] [MainThread]: Connection 'list__mart' was left open.
[0m19:10:01.423662 [debug] [MainThread]: On list__mart: Close
[0m19:10:01.424590 [debug] [MainThread]: Connection 'list__clean' was left open.
[0m19:10:01.425525 [debug] [MainThread]: On list__clean: Close
[0m19:10:01.426584 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_anomalies' was left open.
[0m19:10:01.427426 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_anomalies: Close
[0m19:10:01.428257 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_summary' was left open.
[0m19:10:01.429085 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_summary: Close
[0m19:10:01.430050 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_users_anomalies' was left open.
[0m19:10:01.431021 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_users_anomalies: Close
[0m19:10:01.431945 [debug] [MainThread]: Connection 'model.ex_01_instacart.g1_dq_insta_orders_summary' was left open.
[0m19:10:01.433315 [debug] [MainThread]: On model.ex_01_instacart.g1_dq_insta_orders_summary: Close
[0m19:10:01.435838 [info ] [MainThread]: 
[0m19:10:01.437667 [info ] [MainThread]: Finished running 2 table models, 13 data tests, 4 view models in 0 hours 0 minutes and 23.66 seconds (23.66s).
[0m19:10:01.453066 [debug] [MainThread]: Command end result
[0m19:10:01.542135 [info ] [MainThread]: 
[0m19:10:01.543336 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:10:01.544581 [info ] [MainThread]: 
[0m19:10:01.546010 [info ] [MainThread]: Done. PASS=19 WARN=0 ERROR=0 SKIP=0 TOTAL=19
[0m19:10:01.548724 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 25.867111, "process_in_blocks": "0", "process_kernel_time": 1.682793, "process_mem_max_rss": "119388", "process_out_blocks": "11304", "process_user_time": 8.24127}
[0m19:10:01.550032 [debug] [MainThread]: Command `dbt build` succeeded at 19:10:01.549591 after 25.87 seconds
[0m19:10:01.551026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70ad143c6310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70ad122e32e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x70ad122d7250>]}
[0m19:10:01.551962 [debug] [MainThread]: Flushing usage events
